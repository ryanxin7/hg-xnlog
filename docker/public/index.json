[{"categories":["Github"],"content":"ä½¿ç”¨ GitHub Actions æ¥è‡ªåŠ¨æ„å»º Docker é•œåƒå¹¶å°†å…¶ä¸Šä¼ åˆ° Docker Registry æ—¶ï¼Œéœ€è¦ä»¥ä¸‹æ­¥éª¤è¿›è¡Œè®¾ç½®ï¼š å·¥ä½œæµä¼šåœ¨æ¯æ¬¡å°†ä»£ç æ¨é€åˆ° main åˆ†æ”¯æ—¶æ‰§è¡Œã€‚å®ƒé¦–å…ˆæ£€å‡ºä»£ç ï¼Œç„¶åè®¾ç½® Docker Buildx ç¯å¢ƒï¼Œæ¥ç€ç™»å½•åˆ°æŒ‡å®šçš„ Docker Registryï¼Œæœ€åæ„å»ºå¹¶æ¨é€ Docker é•œåƒã€‚ åˆ›å»º Dockerfileï¼šåœ¨ä½ çš„ GitHub ä»“åº“ä¸­åˆ›å»ºä¸€ä¸ªåä¸º Dockerfile çš„æ–‡ä»¶ï¼Œç”¨äºå®šä¹‰é•œåƒçš„æ„å»ºè¿‡ç¨‹å’Œå†…å®¹ã€‚ è®¾ç½® Secretsï¼šåœ¨ä»“åº“çš„è®¾ç½®ä¸­ï¼Œæ·»åŠ ä¸‰ä¸ª Secretsï¼Œåˆ†åˆ«æ˜¯ä½ çš„ Docker Registry ç”¨æˆ·åã€å¯†ç æˆ–è®¿é—®ä»¤ç‰Œï¼Œä»¥åŠ Docker Registry çš„åœ°å€ã€‚ åˆ›å»º Workflow æ–‡ä»¶ï¼šåœ¨ .github/workflows/ ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª .yml æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼šdocker-build.ymlï¼‰ï¼Œåœ¨è¿™ä¸ªæ–‡ä»¶ä¸­å®šä¹‰å·¥ä½œæµç¨‹çš„æ­¥éª¤ã€‚ Workflow é…ç½®ï¼šåœ¨ Workflow æ–‡ä»¶ä¸­ï¼Œé…ç½®å·¥ä½œæµç¨‹çš„è§¦å‘æ¡ä»¶ï¼Œæ¯”å¦‚å½“ä»£ç è¢«æ¨é€åˆ°ç‰¹å®šåˆ†æ”¯æ—¶è§¦å‘ã€‚ç„¶åï¼Œå®šä¹‰æ„å»ºæ­¥éª¤ï¼ŒåŒ…æ‹¬ï¼š æ£€å‡ºä»£ç  è®¾ç½® Docker Buildx ç¯å¢ƒï¼ˆç”¨äºæ„å»ºå¤šå¹³å°é•œåƒï¼‰ ç™»å½•åˆ° Docker Registryï¼Œä½¿ç”¨ä¹‹å‰è®¾ç½®çš„ Secrets ä½¿ç”¨ Docker æ„å»ºå’Œæ¨é€é•œåƒåˆ° Registryï¼Œå¯ä»¥æŒ‡å®šæ ‡ç­¾ç­‰ä¿¡æ¯ã€‚ ","date":"2023-08-25","objectID":"/posts/blog/push-docker-images-github-registry/:0:0","tags":["Docker","Hugo"],"title":"ä½¿ç”¨Github Action æ„å»ºDockeré•œåƒå¹¶ä¸Šä¼ Registry","uri":"/posts/blog/push-docker-images-github-registry/"},{"categories":["Github"],"content":"åˆ›å»ºæ‹¥æœ‰ä¸Šä¼ æƒé™çš„token ","date":"2023-08-25","objectID":"/posts/blog/push-docker-images-github-registry/:1:0","tags":["Docker","Hugo"],"title":"ä½¿ç”¨Github Action æ„å»ºDockeré•œåƒå¹¶ä¸Šä¼ Registry","uri":"/posts/blog/push-docker-images-github-registry/"},{"categories":["Github"],"content":"æµ‹è¯•ç™»å½•Registry æµ‹è¯•ç™»å½• root@harbor01[14:16:02]~ #:docker login --username ryanxin7 --password ghp_xxxxxxxx ghcr.io WARNING! Using --password via the CLI is insecure. Use --password-stdin. WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded","date":"2023-08-25","objectID":"/posts/blog/push-docker-images-github-registry/:2:0","tags":["Docker","Hugo"],"title":"ä½¿ç”¨Github Action æ„å»ºDockeré•œåƒå¹¶ä¸Šä¼ Registry","uri":"/posts/blog/push-docker-images-github-registry/"},{"categories":["Github"],"content":"æ„å»ºé•œåƒæµ‹è¯•ä¸Šä¼ åˆ°Regisry root@harbor01[14:22:43]/dockerfile/xn-blog #:docker image build -t ghcr.io/xnlog:latest ./ DEPRECATED: The legacy builder is deprecated and will be removed in a future release. Install the buildx component to build images with BuildKit: https://docs.docker.com/go/buildx/ Sending build context to Docker daemon 19.04MB Step 1/4 : FROM nginx:latest ---\u003e 89da1fb6dcb9 Step 2/4 : COPY public/ /usr/share/nginx/html ---\u003e Using cache ---\u003e 342e46da94ee Step 3/4 : COPY default.conf /etc/nginx/conf.d/default.conf ---\u003e Using cache ---\u003e 56c7d4347a26 Step 4/4 : EXPOSE 8848 ---\u003e Using cache ---\u003e 35e2e284b708 Successfully built 35e2e284b708 Successfully tagged ghcr.io/xnlog:latest root@racknerd-20e7f5:~# docker pull ghcr.io/ryanxin7/xnlog:latest latest: Pulling from ryanxin7/xnlog 52d2b7f179e3: Pull complete fd9f026c6310: Pull complete 055fa98b4363: Pull complete 96576293dd29: Pull complete a7c4092be904: Pull complete e3b6889c8954: Pull complete da761d9a302b: Pull complete e8c074410147: Pull complete 4d2b965ac974: Pull complete Digest: sha256:3bcffe2f09e7584d9b05da90af16c43b195c377ce645dbc013f8b9ba70ce83de Status: Downloaded newer image for ghcr.io/ryanxin7/xnlog:latest ghcr.io/ryanxin7/xnlog:latest","date":"2023-08-25","objectID":"/posts/blog/push-docker-images-github-registry/:3:0","tags":["Docker","Hugo"],"title":"ä½¿ç”¨Github Action æ„å»ºDockeré•œåƒå¹¶ä¸Šä¼ Registry","uri":"/posts/blog/push-docker-images-github-registry/"},{"categories":["Github"],"content":"åœ¨packagesä¸­æŸ¥çœ‹é•œåƒ ","date":"2023-08-25","objectID":"/posts/blog/push-docker-images-github-registry/:4:0","tags":["Docker","Hugo"],"title":"ä½¿ç”¨Github Action æ„å»ºDockeré•œåƒå¹¶ä¸Šä¼ Registry","uri":"/posts/blog/push-docker-images-github-registry/"},{"categories":["Github"],"content":"é…ç½®action secret ","date":"2023-08-25","objectID":"/posts/blog/push-docker-images-github-registry/:5:0","tags":["Docker","Hugo"],"title":"ä½¿ç”¨Github Action æ„å»ºDockeré•œåƒå¹¶ä¸Šä¼ Registry","uri":"/posts/blog/push-docker-images-github-registry/"},{"categories":["Github"],"content":"åˆ›å»ºworkflowæ–‡ä»¶ mkdir workflow name: Docker Image CI for GHCR on: push jobs: build_and_publish: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Build and push the image run: | docker login --username ryanxin7 --password ${{ secrets.DOCKERPACKAING }} ghcr.io docker build docker/. --tag ghcr.io/ryanxin7/xnlog:latest docker push ghcr.io/ryanxin7/xnlog:latest ","date":"2023-08-25","objectID":"/posts/blog/push-docker-images-github-registry/:6:0","tags":["Docker","Hugo"],"title":"ä½¿ç”¨Github Action æ„å»ºDockeré•œåƒå¹¶ä¸Šä¼ Registry","uri":"/posts/blog/push-docker-images-github-registry/"},{"categories":["Github"],"content":"æµ‹è¯•æäº¤ä»£ç  xx9z@xin MINGW64 /c/xnblog/xnlog (main) $ git add . xx9z@xin MINGW64 /c/xnblog/xnlog (main) $ git commit -m \"blog update\" [main a5724b1] blog update 5 files changed, 477 insertions(+) create mode 100644 content/posts/Blog/push-docker-images-github-registry.md rename \"content/posts/\\344\\275\\277\\347\\224\\250Algolia\\345\\256\\236\\347\\216\\260Hugo\\346\\234\\254\\345\\234\\260\\346\\231\\272\\350\\203\\275\\346\\220\\234\\347\\264\\242.md\" =\u003e \"content/posts/Blog/\\344\\275\\277\\347\\224\\250Algolia\\345\\256\\236\\347\\216\\260Hugo\\346\\234\\254\\345\\234\\260\\346\\231\\272\\350\\203\\275\\346\\220\\234\\347\\264\\242.md\" (100%) create mode 100644 content/posts/kubernetes/k8s-replace-NFS-storage.md create mode 100644 \"content/posts/kubernetes/k8s\\345\\274\\272\\345\\210\\266\\345\\210\\240\\351\\231\\244pod\u0026pv\u0026pvc\\345\\222\\214ns\u0026namespace\\346\\226\\271\\346\\263\\225.md\" create mode 100644 content/posts/kubernetes/redis-on-k8scluster.md xx9z@xin MINGW64 /c/xnblog/xnlog (main) $ git push origin main Enumerating objects: 14, done. Counting objects: 100% (14/14), done. Delta compression using up to 16 threads Compressing objects: 100% (9/9), done. Writing objects: 100% (10/10), 5.57 KiB | 2.78 MiB/s, done. Total 10 (delta 2), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (2/2), completed with 2 local objects. To github.com:ryanxin7/hg-xnlog.git 12d766d..a5724b1 main -\u003e main ","date":"2023-08-25","objectID":"/posts/blog/push-docker-images-github-registry/:7:0","tags":["Docker","Hugo"],"title":"ä½¿ç”¨Github Action æ„å»ºDockeré•œåƒå¹¶ä¸Šä¼ Registry","uri":"/posts/blog/push-docker-images-github-registry/"},{"categories":["Hugo"],"content":"1.ç®€ä»‹ Algoliaæ˜¯ä¸€å®¶æä¾›æœç´¢å³æœåŠ¡çš„æŠ€æœ¯å…¬å¸ï¼Œå¸®åŠ©å¼€å‘è€…ä¸ºä»–ä»¬çš„åº”ç”¨ç¨‹åºæˆ–ç½‘ç«™æ„å»ºé«˜é€Ÿã€ç²¾å‡†çš„æœç´¢åŠŸèƒ½ã€‚ å…è´¹çš„è®¡åˆ’æ¯ä¸ªæœˆå¯ä»¥æŸ¥è¯¢10000æ¬¡ï¼Œå¯¹äºä¸ªäººç«™ç‚¹ä¹Ÿæ˜¯å¤Ÿç”¨äº†ã€‚ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:1:0","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"2. é…ç½®Algolia Algoliaçš„é…ç½®æ­¥éª¤é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ–¹é¢ï¼šåˆ›å»ºè´¦æˆ·ã€å¯¼å…¥æ•°æ®ã€è®¾ç½®ç´¢å¼•ã€é›†æˆåˆ°åº”ç”¨ç¨‹åºä¸­ä»¥åŠè°ƒæ•´æœç´¢ä½“éªŒã€‚ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:2:0","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"2.1 åˆ›å»ºè´¦å· è®¿é—®Algoliaçš„å®˜æ–¹ç½‘ç«™ï¼ˆhttps://www.algolia.com/ï¼‰ï¼Œæ³¨å†Œä¸€ä¸ªè´¦æˆ·å¹¶ç™»å½•ã€‚Googleå’ŒGithubè´¦å·å¯ä»¥ç›´æ¥ç™»å½•ã€‚ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:2:1","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"2.2 åˆ›å»ºåº”ç”¨ç¨‹åº é€‰æ‹©å…è´¹å¥—é¤ é€‰æ‹©ä½ç½® ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:2:2","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"2.3 åˆ›å»ºç´¢å¼• åœ¨Algoliaæ§åˆ¶å°ä¸­ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ç´¢å¼•ã€‚ç´¢å¼•æ˜¯å­˜å‚¨æ•°æ®çš„å®¹å™¨ï¼Œç”¨äºæ‰§è¡Œæœç´¢æ“ä½œã€‚ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:2:3","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"2.4 å¯¼å…¥æ•°æ® æ‚¨å¯ä»¥ä½¿ç”¨Algoliaçš„APIã€SDKæˆ–å·¥å…·æ¥å¯¼å…¥æ•°æ®ï¼Œç¡®ä¿æ•°æ®å­—æ®µä¸æœç´¢éœ€æ±‚åŒ¹é…ã€‚ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:2:4","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"2.5 é…ç½®æœç´¢å±æ€§ å®šä¹‰ç´¢å¼•å­—æ®µï¼Œä¸ºæ¯ä¸ªç´¢å¼•å®šä¹‰éœ€è¦æœç´¢å’Œæ˜¾ç¤ºçš„å­—æ®µã€‚ä¹Ÿå¯ä»¥è®¾ç½®å­—æ®µçš„æœç´¢æƒé‡å’Œè¿‡æ»¤æ¡ä»¶ã€‚ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:2:5","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"2.6 é…ç½®æ’åè§„åˆ™ è°ƒæ•´æœç´¢ç»“æœçš„æ’åè§„åˆ™ï¼Œä»¥ç¡®ä¿æœ€ç›¸å…³çš„ç»“æœæ˜¾ç¤ºåœ¨é¡¶éƒ¨ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:2:6","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"2.6 æµ‹è¯•æœç´¢ é€šè¿‡Algolia UIç•Œé¢ï¼Œæµ‹è¯•æœç´¢æ•ˆæœã€‚ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:2:7","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"3.é…ç½®hugoä¸»é¢˜ä½¿ç”¨Algoliaæœç´¢ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:3:0","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"3.1 è·å–Algolia Key ç‚¹å‡»å³ä¸Šè§’å¤´åƒâ€”\u003esettingâ€”\u003e API Keys ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:3:1","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"3.2 é…ç½®ä¸»é¢˜ç›¸å…³å‚æ•° ä¸ºäº†ç”Ÿæˆæœç´¢åŠŸèƒ½æ‰€éœ€è¦çš„ index.json, è¯·åœ¨ä½ çš„ ç½‘ç«™é…ç½® ä¸­æ·»åŠ  JSON è¾“å‡ºæ–‡ä»¶ç±»å‹åˆ° outputs éƒ¨åˆ†çš„ home å­—æ®µä¸­ã€‚ åœ¨ Hugo ä¸­ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ç½‘ç«™é…ç½®æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ config.tomlã€config.yaml æˆ– config.jsonï¼‰æ¥æŒ‡å®šä¸åŒéƒ¨åˆ†çš„è¾“å‡ºæ ¼å¼ã€‚è¿™æ ·ï¼Œå¯ä»¥åœ¨ç”Ÿæˆç½‘ç«™é¡µé¢æ—¶ï¼Œä¸ºä¸åŒçš„é¡µé¢éƒ¨åˆ†é€‰æ‹©ä¸åŒçš„è¾“å‡ºæ ¼å¼ï¼ŒåŒ…æ‹¬ JSONã€‚ æ‰“å¼€ç½‘ç«™é…ç½®æ–‡ä»¶ã€‚ å¯»æ‰¾åä¸º outputs çš„éƒ¨åˆ†ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºå®ƒã€‚ åœ¨ outputs éƒ¨åˆ†ä¸­ï¼Œå¯ä»¥ä¸ºä¸åŒçš„é¡µé¢éƒ¨åˆ†æŒ‡å®šè¾“å‡ºæ ¼å¼ã€‚ # Options to make hugo output files home = [\"HTML\", \"RSS\", \"JSON\", \"BaiduUrls\"] page = [\"HTML\", \"MarkDown\"] section = [\"HTML\", \"RSS\"] taxonomy = [\"HTML\", \"RSS\"] taxonomyTerm = [\"HTML\"]ä¿å­˜ç½‘ç«™é…ç½®æ–‡ä»¶ åœ¨è¿è¡Œ Hugo æ„å»ºå‘½ä»¤ï¼ˆä¾‹å¦‚ hugo æˆ– hugo buildï¼‰ä»¥ç”Ÿæˆç½‘ç«™æ—¶ï¼ŒHugo å°†ç”Ÿæˆ index.json æ–‡ä»¶ä½œä¸ºä¸Šè¿°éƒ¨åˆ†çš„è¾“å‡ºã€‚ outputFormats åœ¨ Algolia ä¸­ï¼ŒoutputFormats æ˜¯ç”¨äºæ§åˆ¶è¿”å›æœç´¢ç»“æœçš„æ ¼å¼çš„è®¾ç½®é€‰é¡¹ä¹‹ä¸€ã€‚ é€šè¿‡è°ƒæ•´ outputFormatsï¼Œå¯ä»¥å†³å®šæœç´¢ç»“æœä»¥ä½•ç§æ ¼å¼è¿”å›åº”ç”¨ç¨‹åºã€‚ [MarkDown] mediaType = \"text/markdown\" isPlainText = true isHTML = false # Options to make output baidu_urls.txt file [BaiduUrls] baseName = \"baidu_urls\" mediaType = \"text/plain\" isPlainText = true isHTML = falseè¿™æ®µä»£ç çš„ä½œç”¨æ˜¯ä¸º Hugo ç½‘ç«™ç”Ÿæˆ Algolia æœç´¢æ‰€éœ€çš„ JSON ç´¢å¼•æ–‡ä»¶ï¼Œä»¥ä¾¿åœ¨æœç´¢æ—¶å¿«é€Ÿæ£€ç´¢å’Œå±•ç¤ºå†…å®¹ã€‚ {{- if .Site.Params.search -}} {{- $index := slice -}} {{- $pages := where .Site.RegularPages \"Params.password\" \"eq\" nil -}} {{- if .Site.Params.page.hiddenFromSearch -}} {{- $pages = where $pages \"Params.hiddenfromsearch\" false -}} {{- else -}} {{- $pages = where $pages \"Params.hiddenfromsearch\" \"!=\" true -}} {{- end -}} {{- range $pages -}} {{- $uri := .RelPermalink -}} {{- if $.Site.Params.search.absoluteURL -}} {{- $uri = .Permalink -}} {{- end -}} {{- $meta := dict \"uri\" $uri \"title\" .Title \"tags\" .Params.tags \"categories\" .Params.categories -}} {{- $meta = $.Site.Params.dateFormat | default \"2006-01-02\" | .PublishDate.Format | dict \"date\" | merge $meta -}} {{- with .Description -}} {{- $index = $index | append (dict \"content\" . \"objectID\" $uri | merge $meta) -}} {{- end -}} {{- $params := .Params | merge $.Site.Params.page -}} {{/* Extended Markdown syntax */}} {{- $content := dict \"Content\" .Content \"Ruby\" $params.ruby \"Fraction\" $params.fraction \"Fontawesome\" $params.fontawesome | partial \"function/content.html\" -}} {{/* Remove line number for code */}} {{- $content = $content | replaceRE `\u003cspan class=\"lnt?\"\u003e *\\d*\\n?\u003c/span\u003e` \"\" -}} {{- range $i, $contenti := split $content \"\u003ch2 id=\" -}} {{- if gt $i 0 -}} {{- $contenti = printf \"\u003ch2 id=%v\" $contenti -}} {{- end -}} {{- range $j, $contentj := split $contenti \"\u003ch3 id=\" -}} {{- if gt $j 0 -}} {{- $contentj = printf \"\u003ch3 id=%v\" $contentj -}} {{- end -}} {{/* Plainify, unescape and remove (\\n, \\t) */}} {{- $contentj = $contentj | plainify | htmlUnescape | replaceRE `[\\n\\t ]+` \" \" -}} {{- if gt $.Site.Params.search.contentLength 0 -}} {{- $contentj = substr $contentj 0 $.Site.Params.search.contentLength -}} {{- end -}} {{- if $contentj | and (ne $contentj \" \") -}} {{- $one := printf \"%v:%v:%v\" $uri $i $j | dict \"content\" $contentj \"objectID\" | merge $meta -}} {{- $index = $index | append $one -}} {{- end -}} {{- end -}} {{- end -}} {{- end -}} {{- $index | jsonify | safeJS -}} {{- end -}}","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:3:2","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"3.3 é…ç½®hugoä¸»é¢˜åº”ç”¨Algolia # æœç´¢é…ç½® [params.search] enable = true # æœç´¢å¼•æ“çš„ç±»å‹ [\"lunr\", \"algolia\", \"fuse\"] type = \"algolia\" # æ–‡ç« å†…å®¹æœ€é•¿ç´¢å¼•é•¿åº¦ contentLength = 4000 # æœç´¢æ¡†çš„å ä½æç¤ºè¯­ placeholder = \"\" # æœ€å¤§ç»“æœæ•°ç›® maxResultLength = 10 # ç»“æœå†…å®¹ç‰‡æ®µé•¿åº¦ snippetLength = 50 # æœç´¢ç»“æœä¸­é«˜äº®éƒ¨åˆ†çš„ HTML æ ‡ç­¾ highlightTag = \"em\" # æ˜¯å¦åœ¨æœç´¢ç´¢å¼•ä¸­ä½¿ç”¨åŸºäº baseURL çš„ç»å¯¹è·¯å¾„ absoluteURL = false [params.search.algolia] index = \"xx-log\" appID = \"SFSFN4DBN1\" searchKey = \"bd48328538sdb2f38b20753c17c60ba92f\"","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:3:3","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Hugo"],"content":"4.æµ‹è¯•æ•ˆæœ ","date":"2023-08-15","objectID":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/:4:0","tags":["ä¸ªäººç½‘ç«™","Hugo"],"title":"ä½¿ç”¨Algoliaå®ç°Hugoæœ¬åœ°æ™ºèƒ½æœç´¢","uri":"/posts/blog/%E4%BD%BF%E7%94%A8algolia%E5%AE%9E%E7%8E%B0hugo%E6%9C%AC%E5%9C%B0%E6%99%BA%E8%83%BD%E6%90%9C%E7%B4%A2/"},{"categories":["Kubernetes"],"content":"k8så¼ºåˆ¶åˆ é™¤pod\u0026pv\u0026pvcå’Œns\u0026namespaceæ–¹æ³• æ³¨æ„ï¼šä»¥ä¸‹æ“ä½œæ–¹æ³•ååˆ†å±é™©ï¼Œä¸‰æ€è€Œè¡Œï¼ï¼ï¼ å¦‚æœåç§°ç©ºé—´ã€podã€pvã€pvcå…¨éƒ¨å¤„äºâ€œTerminatingâ€çŠ¶æ€æ—¶ï¼Œæ­¤æ—¶çš„è¯¥åç§°ç©ºé—´ä¸‹çš„æ‰€æœ‰æ§åˆ¶å™¨éƒ½å·²ç»è¢«åˆ é™¤äº†ï¼Œä¹‹æ‰€ä»¥å‡ºç°podã€pvcã€pvã€nsæ— æ³•åˆ é™¤ï¼Œé‚£æ˜¯å› ä¸ºkubelet é˜»å¡ï¼Œæœ‰å…¶ä»–çš„èµ„æºåœ¨ä½¿ç”¨è¯¥namespaceï¼Œæ¯”å¦‚CRDç­‰ï¼Œå°è¯•é‡å¯kubeletï¼Œå†åˆ é™¤è¯¥namespace ä¹Ÿä¸å¥½ä½¿ã€‚ æ­£ç¡®çš„åˆ é™¤æ–¹æ³•ï¼šåˆ é™¤podâ€“\u003e åˆ é™¤pvc â€”\u003e åˆ é™¤pv â€“\u003e åˆ é™¤åç§°ç©ºé—´ ","date":"2023-08-14","objectID":"/posts/kubernetes/advanced/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/:0:0","tags":["Kubernetes"],"title":"k8så¼ºåˆ¶åˆ é™¤pod\u0026pv\u0026pvcå’Œns\u0026namespaceæ–¹æ³•","uri":"/posts/kubernetes/advanced/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/"},{"categories":["Kubernetes"],"content":"ä¸€ã€å¼ºåˆ¶åˆ é™¤pod $ kubectl delete pod \u003cyour-pod-name\u003e -n \u003cname-space\u003e --force --grace-period=0è§£å†³æ–¹æ³•ï¼šåŠ å‚æ•° --force --grace-period=0ï¼Œgrace-periodè¡¨ç¤ºè¿‡æ¸¡å­˜æ´»æœŸï¼Œé»˜è®¤30sï¼Œåœ¨åˆ é™¤PODä¹‹å‰å…è®¸PODæ…¢æ…¢ç»ˆæ­¢å…¶ä¸Šçš„å®¹å™¨è¿›ç¨‹ï¼Œä»è€Œä¼˜é›…é€€å‡ºï¼Œ0è¡¨ç¤ºç«‹å³ç»ˆæ­¢POD ","date":"2023-08-14","objectID":"/posts/kubernetes/advanced/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/:1:0","tags":["Kubernetes"],"title":"k8så¼ºåˆ¶åˆ é™¤pod\u0026pv\u0026pvcå’Œns\u0026namespaceæ–¹æ³•","uri":"/posts/kubernetes/advanced/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/"},{"categories":["Kubernetes"],"content":"äºŒã€å¼ºåˆ¶åˆ é™¤pvã€pvc ç›´æ¥åˆ é™¤k8s etcdæ•°æ®åº“ä¸­çš„è®°å½• $ kubectl patch pv xxx -p '{\"metadata\":{\"finalizers\":null}}' $ kubectl patch pvc xxx -p '{\"metadata\":{\"finalizers\":null}}'","date":"2023-08-14","objectID":"/posts/kubernetes/advanced/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/:2:0","tags":["Kubernetes"],"title":"k8så¼ºåˆ¶åˆ é™¤pod\u0026pv\u0026pvcå’Œns\u0026namespaceæ–¹æ³•","uri":"/posts/kubernetes/advanced/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/"},{"categories":["Kubernetes"],"content":"ä¸‰ã€å¼ºåˆ¶åˆ é™¤ns åœ¨å°è¯•ä»¥ä¸‹å‘½ä»¤å¼ºåˆ¶åˆ é™¤ä¹Ÿä¸å¥½ä½¿ï¼š $ kubectl delete ns \u003cterminating-namespace\u003e --force --grace-period=0è§£å†³æ–¹æ³•ï¼š 1ï¼‰è¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥æŸ¥çœ‹å¤„äºâ€œTerminatingâ€çŠ¶æ€çš„namespaceï¼š $ kubectl get namespaces2ï¼‰é€‰æ‹©ä¸€ä¸ªTerminating namespaceï¼Œå¹¶æŸ¥çœ‹namespace ä¸­çš„finalizerã€‚è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š $ kubectl get namespace \u003cterminating-namespace\u003e -o yamlè¾“å‡ºä¿¡æ¯å¦‚ä¸‹ï¼š apiVersion: v1 kind: Namespace metadata: creationTimestamp: \"2019-11-20T15:18:06Z\" deletionTimestamp: \"2020-01-16T02:50:02Z\" name: \u003cterminating-namespace\u003e resourceVersion: \"3249493\" selfLink: /api/v1/namespaces/knative-eventing uid: f300ea38-c8c2-4653-b432-b66103e412db spec: finalizers: - kubernetes status:3ï¼‰å¯¼å‡ºjsonæ ¼å¼åˆ°æ–‡ä»¶ $ kubectl get namespace \u003cterminating-namespace\u003e -o json \u003etmp.json4ï¼‰ç¼–è¾‘tmp.josnï¼Œåˆ é™¤finalizers å­—æ®µçš„å€¼ { \"apiVersion\": \"v1\", \"kind\": \"Namespace\", \"metadata\": { \"creationTimestamp\": \"2019-11-20T15:18:06Z\", \"deletionTimestamp\": \"2020-01-16T02:50:02Z\", \"name\": \"\u003cterminating-namespace\u003e\", \"resourceVersion\": \"3249493\", \"selfLink\": \"/api/v1/namespaces/knative-eventing\", \"uid\": \"f300ea38-c8c2-4653-b432-b66103e412db\" }, \"spec\": { #ä»æ­¤è¡Œå¼€å§‹åˆ é™¤ \"finalizers\": [] }, # åˆ åˆ°æ­¤è¡Œ \"status\": { \"phase\": \"Terminating\" } }5ï¼‰å¼€å¯proxy $ kubectl proxyæ‰§è¡Œè¯¥å‘½ä»¤åï¼Œå½“å‰ç»ˆç«¯ä¼šè¢«å¡ä½ 6ï¼‰æ‰“å¼€æ–°çš„ä¸€ä¸ªçª—å£ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ $ curl -k -H \"Content-Type: application/json\" -X PUT --data-binary @tmp.json http://127.0.0.1:8001/api/v1/namespaces/\u003cterminating-namespace\u003e/finalizeè¾“å‡ºä¿¡æ¯å¦‚ä¸‹ï¼š { \"kind\": \"Namespace\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"istio-system\", \"selfLink\": \"/api/v1/namespaces/istio-system/finalize\", \"uid\": \"2e274537-727f-4a8f-ae8c-397473ed619a\", \"resourceVersion\": \"3249492\", \"creationTimestamp\": \"2019-11-20T15:18:06Z\", \"deletionTimestamp\": \"2020-01-16T02:50:02Z\" }, \"spec\": { }, \"status\": { \"phase\": \"Terminating\" } }7ï¼‰ç¡®è®¤å¤„äºTerminating çŠ¶æ€çš„namespaceå·²ç»è¢«åˆ é™¤ $ kubectl get namespaceså¦‚æœè¿˜æœ‰å¤„äºTerminating çŠ¶æ€çš„namespaceï¼Œé‡å¤ä»¥ä¸Šæ“ä½œï¼Œåˆ é™¤å³å¯ï¼ ","date":"2023-08-14","objectID":"/posts/kubernetes/advanced/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/:3:0","tags":["Kubernetes"],"title":"k8så¼ºåˆ¶åˆ é™¤pod\u0026pv\u0026pvcå’Œns\u0026namespaceæ–¹æ³•","uri":"/posts/kubernetes/advanced/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/"},{"categories":["Kubernetes"],"content":"k8sä¸­éƒ¨ç½²å•èŠ‚ç‚¹redis https://gitee.com/zdevops/k8s-yaml/blob/main/redis/single/ ","date":"2023-08-14","objectID":"/posts/kubernetes/advanced/redis-on-k8scluster/:0:0","tags":["Kubernetes"],"title":"k8sä¸­éƒ¨ç½²å•èŠ‚ç‚¹redis","uri":"/posts/kubernetes/advanced/redis-on-k8scluster/"},{"categories":["Kubernetes"],"content":"redis-cm.yaml --- apiVersion: v1 kind: ConfigMap metadata: name: redis-config namespace: zdevops data: redis-config: | appendonly yes protected-mode no dir /data port 6379 requirepass redis@abc.com ","date":"2023-08-14","objectID":"/posts/kubernetes/advanced/redis-on-k8scluster/:1:0","tags":["Kubernetes"],"title":"k8sä¸­éƒ¨ç½²å•èŠ‚ç‚¹redis","uri":"/posts/kubernetes/advanced/redis-on-k8scluster/"},{"categories":["Kubernetes"],"content":"redis-sts.yaml --- apiVersion: apps/v1 kind: StatefulSet metadata: name: redis namespace: zdevops labels: app: redis spec: serviceName: redis-headless replicas: 1 selector: matchLabels: app: redis template: metadata: labels: app: redis spec: containers: - name: redis image: 'registry.zdevops.com.cn/library/redis:6.2.7' command: - \"redis-server\" args: - \"/etc/redis/redis.conf\" ports: - name: redis-6379 containerPort: 6379 protocol: TCP volumeMounts: - name: config mountPath: /etc/redis - name: data mountPath: /data resources: limits: cpu: '2' memory: 4000Mi requests: cpu: 100m memory: 500Mi volumes: - name: config configMap: name: redis-config items: - key: redis-config path: redis.conf volumeClaimTemplates: - metadata: name: data namespace: zdevops spec: accessModes: [ \"ReadWriteOnce\" ] storageClassName: \"glusterfs\" resources: requests: storage: 5Gi --- apiVersion: v1 kind: Service metadata: name: redis-headless namespace: zdevops labels: app: redis spec: ports: - name: redis-6379 protocol: TCP port: 6379 targetPort: 6379 selector: app: redis clusterIP: None type: ClusterIP","date":"2023-08-14","objectID":"/posts/kubernetes/advanced/redis-on-k8scluster/:2:0","tags":["Kubernetes"],"title":"k8sä¸­éƒ¨ç½²å•èŠ‚ç‚¹redis","uri":"/posts/kubernetes/advanced/redis-on-k8scluster/"},{"categories":["Kubernetes"],"content":"# /etc/rsyncd: configuration file for rsync daemon mode # See rsyncd.conf man page for more options. # configuration example: uid = root gid = root use chroot = no max connections = 200 timeout = 6000 ignore errors read only = false list = false auth users = rsync_backup secrets file = /etc/rsync.passwd log file = /var/log/rsyncd.log # pid file = /var/run/rsyncd.pid # exclude = lost+found/ # transfer logging = yes # timeout = 900 # ignore nonreadable = yes # dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2 [nfs-backup] comment = welcome to backup! path = /nfs-server [mysql-data-backup] comment = welcome to backup! path = /nfs-server2/tj-prod-mysql57-data-pvc-d4968732-0cf1-4395-9854-fd4581d2906d [mysql-log-backup] comment = welcome to backup! path = /nfs-server2/tj-prod-mysql57-log-pvc-7f831088-8828-4ab5-8e20-03ab5b048cdd [tree-file-backup] comment = welcome to backup! path = /nfs-server2/tj-prod-app-data-pvc-0770e2e6-70c4-4426-9a43-75e2cab94291 # [ftp] # path = /home/ftp # comment = ftp export areanohup rsync -avzrogpP --append-verify rsync_backup@127.0.0.1::tree-file-backup /nfs-server2/tj-prod-app-data-pvc-51174db7-fd78-4448-b9fb-21b6f8577e58 \u003e /var/log/rsync-log-treefile.log 2\u003e\u00261 \u0026 tail -f /var/log/rsync-log-treefile.log tree-file-server-for-pt/storage/high/2022/02/14/86b7f9c882e744a5b51be2c551f24a4b.jpg 32,827 100% 244.71kB/s 0:00:00 (xfr#138425, ir-chk=149321/287796) tree-file-server-for-pt/storage/high/2022/02/14/86b834f605614e07bccc92feaa9ab687.jpg 35,251 100% 256.90kB/s 0:00:00 (xfr#138426, ir-chk=149320/287796) tree-file-server-for-pt/storage/high/2022/02/14/86b8ac41b8394c529c00994427078f0f.png 1,345 100% 9.80kB/s 0:00:00 (xfr#138427, ir-chk=149319/287796) tree-file-server-for-pt/storage/high/2022/02/14/86b8b2ed44dc45c3ae182eccff7b4499.png 1,722 100% 12.55kB/s 0:00:00 (xfr#138428, ir-chk=149318/287796) tree-file-server-for-pt/storage/high/2022/02/14/86b932ab32e4472b8bb582c160885877.jpg 34,690 100% 250.94kB/s 0:00:00 (xfr#138429, ir-chk=149317/287796) tree-file-server-for-pt/storage/high/2022/02/14/86b9ad6ecdec45c9846aee66df52769f.png 1,978 100% 14.31kB/s 0:00:00 (xfr#138430, ir-chk=149316/287796) tree-file-server-for-pt/storage/high/2022/02/14/86ba0c2fd3a7462597c2c1e688a081d9.jpg 37,435 100% 270.80kB/s 0:00:00 (xfr#138431, ir-chk=149315/287796) tree-file-server-for-pt/storage/high/2022/02/14/86ba59e758674905ba39073f647db788.png 1,184 100% 8.50kB/s 0:00:00 (xfr#138432, ir-chk=149314/287796) tree-file-server-for-pt/storage/high/2022/02/14/86ba8bf9b31e464fa53b5cef03b29d52.jpg 31,866 100% 227.15kB/s 0:00:00 (xfr#138433, ir-chk=149313/287796) tree-file-server-for-pt/storage/high/2022/02/14/86bb4df3f5e8490f8f1eb421706828aa.jpg 33,953 100% 240.27kB/s 0:00:00 (xfr#138434, ir-chk=149312/287796) tree-file-server-for-pt/storage/high/2022/02/14/86bbc7d02a5f4076a6a2545f6cfc729d.jpg 30,784 100% 216.28kB/s 0:00:00 (xfr#138435, ir-chk=149311/287796) tree-file-server-for-pt/storage/high/2022/02/14/86bc058ff7e847dd9c6b6c7a69d551a8.jpg","date":"2023-08-14","objectID":"/posts/kubernetes/advanced/k8s-replace-nfs-storage/:0:0","tags":["Kubernetes","NFS"],"title":"ç”Ÿäº§æ¡ˆä¾‹-Kubernetes æ›¿æ¢åç«¯å­˜å‚¨","uri":"/posts/kubernetes/advanced/k8s-replace-nfs-storage/"},{"categories":null,"content":"Ryan's friends","date":"2023-07-26","objectID":"/friends/","tags":null,"title":"å‹æƒ…é“¾æ¥","uri":"/friends/"},{"categories":null,"content":"äº¤æ¢åç‰‡ - nickname: Ryan's NoteBooks avatar: http://cdn1.ryanxin.live/ryan-ai11.png url: http://xinn.cc description: è®°å½•æ–‡å­—ï¼Œé‡è§å…±é¸£","date":"2023-07-26","objectID":"/friends/:1:0","tags":null,"title":"å‹æƒ…é“¾æ¥","uri":"/friends/"},{"categories":["Hugo"],"content":"è¯­æ³• admonition shortcode æ”¯æŒ 12 ç§ å¸®åŠ©ä½ åœ¨é¡µé¢ä¸­æ’å…¥æç¤ºçš„æ¨ªå¹…ã€‚ æ”¯æŒ Markdown æˆ–è€… HTML æ ¼å¼ã€‚ æ³¨æ„\rä¸€ä¸ª æ³¨æ„ æ¨ªå¹…\ræ‘˜è¦\rä¸€ä¸ª æ‘˜è¦ æ¨ªå¹…\rä¿¡æ¯\rä¸€ä¸ª ä¿¡æ¯ æ¨ªå¹…\ræŠ€å·§\rä¸€ä¸ª æŠ€å·§ æ¨ªå¹…\ræˆåŠŸ\rä¸€ä¸ª æˆåŠŸ æ¨ªå¹…\ré—®é¢˜\rä¸€ä¸ª é—®é¢˜ æ¨ªå¹…\rè­¦å‘Š\rä¸€ä¸ª è­¦å‘Š æ¨ªå¹…\rå¤±è´¥\rä¸€ä¸ª å¤±è´¥ æ¨ªå¹…\rå±é™©\rä¸€ä¸ª å±é™© æ¨ªå¹…\rBug\rä¸€ä¸ª Bug æ¨ªå¹…\rç¤ºä¾‹\rä¸€ä¸ª ç¤ºä¾‹ æ¨ªå¹…\rå¼•ç”¨\rä¸€ä¸ª å¼•ç”¨ æ¨ªå¹…\radmonition shortcode æœ‰ä»¥ä¸‹å‘½åå‚æ•°ï¼š type [å¿…éœ€]ï¼ˆç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ï¼‰ admonition æ¨ªå¹…çš„ç±»å‹ï¼Œé»˜è®¤å€¼æ˜¯ noteã€‚ title [å¯é€‰]ï¼ˆç¬¬äºŒä¸ªä½ç½®å‚æ•°ï¼‰ admonition æ¨ªå¹…çš„æ ‡é¢˜ï¼Œé»˜è®¤å€¼æ˜¯ type å‚æ•°çš„å€¼ã€‚ï¼ˆæ”¯æŒ markdownï¼‰ open [å¯é€‰]ï¼ˆç¬¬ä¸‰ä¸ªä½ç½®å‚æ•°ï¼‰ æ¨ªå¹…å†…å®¹æ˜¯å¦é»˜è®¤å±•å¼€ï¼Œé»˜è®¤å€¼æ˜¯ trueã€‚ ä¸€ä¸ª admonition ç¤ºä¾‹ï¼š {{\u003c admonition type=tip title=\"This is a tip\" open=false \u003e}}\rä¸€ä¸ª **æŠ€å·§** æ¨ªå¹…\r{{\u003c /admonition \u003e}}\ræˆ–è€…\r{{\u003c admonition tip \"This is a tip\" false \u003e}}\rä¸€ä¸ª **æŠ€å·§** æ¨ªå¹…\r{{\u003c /admonition \u003e}}å‘ˆç°çš„è¾“å‡ºæ•ˆæœå¦‚ä¸‹ï¼š This is a tip\rä¸€ä¸ª æŠ€å·§ æ¨ªå¹…\r","date":"2023-07-24","objectID":"/posts/blog/%E4%BA%94%E8%8A%B1%E5%85%AB%E9%97%A8%E7%9A%84-markdown-admonitions/:1:0","tags":["ä¸ªäººç½‘ç«™"],"title":"äº”èŠ±å…«é—¨çš„ Markdown Admonition","uri":"/posts/blog/%E4%BA%94%E8%8A%B1%E5%85%AB%E9%97%A8%E7%9A%84-markdown-admonitions/"},{"categories":null,"content":"1. å¼€é€š Github Aciton ä¸Šä¼ ä»£ç ä¸€èˆ¬å·²Githubä»“åº“ä¸ºä¸»ï¼Œä½†Jenkinsç”±äºç½‘ç»œåŸå› ç»å¸¸æ— æ³•æ‹‰å–Githubä¸Šçš„ä»£ç ï¼Œäºæ˜¯è€ƒè™‘å°†Githubä»“åº“è‡ªåŠ¨åŒæ­¥åˆ°Giteeä¸Šï¼Œæ‹‰å–å›½å†…ä»“åº“ä»£ç è¿›è¡Œè‡ªåŠ¨éƒ¨ç½²ã€‚ ","date":"2023-06-12","objectID":"/posts/cicd/github-synctogitee/:1:0","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Github Actions è‡ªåŠ¨åŒæ­¥åˆ° Gitee","uri":"/posts/cicd/github-synctogitee/"},{"categories":null,"content":"1.1 åœ¨Githubä»“åº“ä¸‹å¼€é€šActionsçš„åŠŸèƒ½ ç‚¹å‡»Actionsé€‰é¡¹å¡â†’ ç‚¹å‡»å³ä¸‹è§’Create a new workflowï¼Œå‘½åä¸ºSyncToGitee.ymlå³å¯ ","date":"2023-06-12","objectID":"/posts/cicd/github-synctogitee/:1:1","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Github Actions è‡ªåŠ¨åŒæ­¥åˆ° Gitee","uri":"/posts/cicd/github-synctogitee/"},{"categories":null,"content":"1.2 ç¼–å†™workflowçš„ymlä»£ç  å¯ä»¥å¤åˆ¶å¦‚ä¸‹ä»£ç åˆ°è‡ªå·±ymlä¸­ï¼Œéœ€è¦æ›´æ”¹çš„åœ°æ–¹ï¼Œåœ¨ä»£ç ä¸­å·²ç»æ ‡å‡ºã€‚ name: SyncToGitee on: push: branches: - main jobs: repo-sync: runs-on: ubuntu-latest steps: - name: Checkout source codes uses: actions/checkout@v3 - name: Mirror the Github organization repos to Gitee. uses: Yikun/hub-mirror-action@master with: src: 'github/ryanxin7' # è¿™é‡Œæ”¹ä¸ºè‡ªå·±githubè´¦å·åç§°ï¼Œå¦‚github/ryanxin7 dst: 'gitee/ryanxin' # è¿™é‡Œæ”¹ä¸ºgiteeä¸Šè´¦å·åç§°ï¼Œå¦‚gitee/ryanxin dst_key: ${{ secrets.GITEE_PRIVATE_KEY }} # è¿™æ˜¯æœ¬åœ°ç”Ÿæˆçš„ç§é’¥ï¼ŒGithubæ‹¿ç€ç§é’¥è°ƒç”¨Giteeå…¬é’¥ dst_token: ${{ secrets.GITEE_TOKEN }} # è¿™æ˜¯giteeä¸Šç”Ÿæˆçš„tokenï¼Œä¸‹é¢ä¼šè®² force_update: true static_list: \"xxlog\" # åŒæ­¥çš„ä»“åº“åç§°ï¼Œè¿™é‡Œä¸ºxxlogï¼Œæ„æ€æ˜¯ä¼šè‡ªåŠ¨åŒæ­¥è¯¥ä»“åº“åˆ°giteeä¸‹åŒåä»“åº“ debug: true","date":"2023-06-12","objectID":"/posts/cicd/github-synctogitee/:1:2","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Github Actions è‡ªåŠ¨åŒæ­¥åˆ° Gitee","uri":"/posts/cicd/github-synctogitee/"},{"categories":null,"content":"2.é…ç½®å…¬é’¥ç§é’¥å’ŒGitee Token ","date":"2023-06-12","objectID":"/posts/cicd/github-synctogitee/:2:0","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Github Actions è‡ªåŠ¨åŒæ­¥åˆ° Gitee","uri":"/posts/cicd/github-synctogitee/"},{"categories":null,"content":"2.1 é…ç½®Giteeç§é’¥ é…ç½®å…¬é’¥å’Œç§é’¥ï¼šå…¬é’¥æ˜¯Giteeè¿™é‡Œæ‹¿ç€ï¼Œç§é’¥æ˜¯Githubæ‹¿ç€ã€‚å› ä¸ºæ˜¯Githubè¿™é‡Œè¦åŒæ­¥åˆ°Gitee. ç”Ÿæˆç§é’¥å’Œå…¬é’¥ï¼šssh-kengen -t ed25529 -C xxxx@xxx.com ï¼Œå…·ä½“å¯å‚è§ï¼šç”Ÿæˆ/æ·»åŠ SSHå…¬é’¥ ç”Ÿæˆå®Œä¹‹åï¼Œä¼šåœ¨æŒ‡å®šç›®å½•ä¸‹æœ‰ä¸¤ä¸ªæ–‡ä»¶ï¼šid_ed25519å’Œid_ed25519.publicï¼Œå‰è€…æ˜¯ç§é’¥ï¼Œåè€…æ˜¯å…¬é’¥ å°†id_ed25519ç”¨è®°äº‹æœ¬æ‰“å¼€ï¼Œå¤åˆ¶é‡Œé¢å†…å®¹ï¼Œç²˜è´´åˆ°Githubä¸ªäººä»“åº“ä¸‹çš„secretä¸­ã€‚ æ­¥éª¤ï¼šç‚¹å‡»ä»“åº“é¦–é¡µé€‰é¡¹å¡settingï¼Œä¼šçœ‹åˆ°å¦‚ä¸‹å›¾ï¼Œç‚¹å‡»æ–°å»ºNew repository secretï¼š è¾“å…¥Nameä¸ºGITEE_PRIVATE_KEY, Valueä¸ºå¤åˆ¶id_ed25519çš„ç§é’¥å†…å®¹ ","date":"2023-06-12","objectID":"/posts/cicd/github-synctogitee/:2:1","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Github Actions è‡ªåŠ¨åŒæ­¥åˆ° Gitee","uri":"/posts/cicd/github-synctogitee/"},{"categories":null,"content":"2.2 é…ç½®Gitee å…¬é’¥ è¾“å…¥æ ‡é¢˜ä¸ºGITEE_PUB_KEY, Valueä¸ºå¤åˆ¶id_ed25519.pubçš„ç§é’¥å†…å®¹ ","date":"2023-06-12","objectID":"/posts/cicd/github-synctogitee/:2:2","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Github Actions è‡ªåŠ¨åŒæ­¥åˆ° Gitee","uri":"/posts/cicd/github-synctogitee/"},{"categories":null,"content":"2.3 é…ç½®ç§äººä»¤ç‰Œ æ‰“å¼€Giteeä¸ªäººè´¦å·çš„è®¾ç½®é¡µé¢ â†’ ç‚¹å‡»å®‰å…¨è®¾ç½®ä¸‹çš„ç§äººä»¤ç‰Œ â†’ å³ä¸Šè§’ç”Ÿæˆæ–°ä»¤ç‰Œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š éœ€è¦æ·»åŠ ä»¥ä¸‹æƒé™ï¼š ç‚¹å‡»æäº¤ä¹‹åï¼Œä¼šå¾—åˆ°ç±»ä¼¼ä¸‹å›¾æ‰€ç¤ºçš„ç§äººä»¤ç‰Œï¼Œå°†å…¶å¤åˆ¶ï¼Œå¹¶é…ç½®åˆ°Githubçš„secretç•Œé¢ï¼Œç±»ä¼¼ä¸Šä¸€æ­¥çš„ç§é’¥é‚£æ ·ã€‚ é…ç½®åˆ°Githubçš„secretç•Œé¢ æœ€ç»ˆGithubè¿™é‡Œé…ç½®çš„Actions secretså¦‚ä¸‹ï¼š ","date":"2023-06-12","objectID":"/posts/cicd/github-synctogitee/:2:3","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Github Actions è‡ªåŠ¨åŒæ­¥åˆ° Gitee","uri":"/posts/cicd/github-synctogitee/"},{"categories":null,"content":"3.æŸ¥çœ‹åŒæ­¥çŠ¶æ€ æˆåŠŸåŒæ­¥ ","date":"2023-06-12","objectID":"/posts/cicd/github-synctogitee/:2:4","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Github Actions è‡ªåŠ¨åŒæ­¥åˆ° Gitee","uri":"/posts/cicd/github-synctogitee/"},{"categories":null,"content":"Jenkins å®‰è£…ä¸åŸºç¡€é…ç½® ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-install/:1:0","tags":["CI/CD"],"title":"Jenkins å®‰è£…ä¸åŸºç¡€é…ç½®","uri":"/posts/cicd/jenkins-install/"},{"categories":null,"content":"é…ç½®javaç¯å¢ƒ Jdkä¸‹è½½ï¼šhttps://www.oracle.com/java/technologies/downloads/ ç‰ˆæœ¬jdkè¦æ±‚: tar -xf #åˆ›å»ºè½¯è¿æ¥ root@etcd02[11:05:51]/apps/Jenkins #:ln -sv /apps/jdk1.8.0_371/ /usr/local/jdk '/usr/local/jdk' -\u003e '/apps/Jenkins/jdk1.8.0_371/' root@etcd02[11:07:53]/apps/Jenkins #:ln -sv /apps/jdk1.8.0_371/bin/java /usr/bin/java '/usr/bin/java' -\u003e '/apps/Jenkins/jdk1.8.0_371/bin/java'root@server:/apps# ln -sv /apps/jdk-17.0.6/ /usr/local/jdk '/usr/local/jdk' -\u003e '/apps/jdk-17.0.6/' root@server:/apps# ln -sv /apps/jdk-17.0.6/bin/java /usr/bin/java '/usr/bin/java' -\u003e '/apps/jdk-17.0.6/bin/java' apt-get install fontconfig","date":"2023-06-12","objectID":"/posts/cicd/jenkins-install/:1:1","tags":["CI/CD"],"title":"Jenkins å®‰è£…ä¸åŸºç¡€é…ç½®","uri":"/posts/cicd/jenkins-install/"},{"categories":null,"content":"é…ç½®ç¯å¢ƒå˜é‡ vim /etc/profile.d/jdk-bin-path.sh export JAVA_HOME=/usr/local/jdk export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar source /etc/profile.d/jdk-bin-path.shroot@etcd02[13:55:57]/etc/profile.d #:java -version java version \"1.8.0_371\" Java(TM) SE Runtime Environment (build 1.8.0_371-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.371-b11, mixed mode)","date":"2023-06-12","objectID":"/posts/cicd/jenkins-install/:1:2","tags":["CI/CD"],"title":"Jenkins å®‰è£…ä¸åŸºç¡€é…ç½®","uri":"/posts/cicd/jenkins-install/"},{"categories":null,"content":"å®‰è£…Jenkins Ubuntu å®‰è£…åŒ…ä¸‹è½½ï¼š https://mirrors.tuna.tsinghua.edu.cn/jenkins/debian-stable/ å®‰è£…å®‰è£…ä¾èµ– apt install net-tools dpkg -i jenkins_2.361.4_all.deb è·å–å¯†ç  è®¾ç½®æ¸…åæº è¯¥urlæ˜¯å›½å†…çš„æ¸…åå¤§å­¦çš„é•œåƒåœ°å€ï¼ˆå»ºè®®ä½¿ç”¨æ¸…åå¤§å­¦çš„é•œåƒæœåŠ¡å™¨ï¼Œä¿®æ”¹ååˆ·æ–°é¡µé¢å³å¯. https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json find / -name *.UpdateCenter.xml /var/lib/jenkins/hudson.model.UpdateCenter.xml vim /var/lib/jenkins/hudson.model.UpdateCenter.xml \u003c?xml version='1.1' encoding='UTF-8'?\u003e \u003csites\u003e \u003csite\u003e \u003cid\u003edefault\u003c/id\u003e \u003curl\u003ehttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json\u003c/url\u003e \u003c/site\u003e \u003c/sites\u003eä¸‹è½½æ’ä»¶ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-install/:1:3","tags":["CI/CD"],"title":"Jenkins å®‰è£…ä¸åŸºç¡€é…ç½®","uri":"/posts/cicd/jenkins-install/"},{"categories":null,"content":"1.å®‰è£…æ’ä»¶ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:1:0","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"1.1 å®‰è£…NodeJSæ’ä»¶ ç‚¹å‡»ç³»ç»Ÿç®¡ç†,ç„¶åç‚¹å‡»æ’ä»¶ç®¡ç†,åœ¨å¯é€‰æ’ä»¶é‡Œé¢æœç´¢NodeJSæ’ä»¶,ç„¶åå®‰è£… ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:1:1","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"1.2 å®‰è£…è¿æ¥SSHçš„æ’ä»¶ Publish Over SSHç”¨äºè¿æ¥è¿œç¨‹æœåŠ¡å™¨ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:1:2","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"1.3 å®‰è£…æŠŠåº”ç”¨å‘å¸ƒåˆ°è¿œç¨‹æœåŠ¡å™¨çš„æ’ä»¶ **Deploy to container **æ’ä»¶ç”¨äºæŠŠæ‰“åŒ…çš„åº”ç”¨å‘å¸ƒåˆ°è¿œç¨‹æœåŠ¡ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:1:3","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"2. é…ç½®gitå’ŒNodeJSç¯å¢ƒ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:2:0","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"2.1 å®‰è£…é…ç½®git #å®‰è£…git root@server:~# apt install git root@server:~# whereis git #æŸ¥çœ‹gitçš„æ‰§è¡Œæ–‡ä»¶ä½ç½®, é»˜è®¤æ˜¯åœ¨ /usr/bin/git whereis git git: /usr/bin/git /usr/share/man/man1/git.1.gz ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:2:1","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"2.2 å®‰è£…é…ç½®NodeJS NodeJs ä¸‹è½½åœ°å€ï¼šhttps://nodejs.org/dist/ cd /apps tar -zxvf node-v16.18.1-linux-x64.tar.gz #åˆ›å»ºè½¯è¿æ¥ ln -sv node-v16.18.1-linux-x64/ /usr/local/nodeå¡«å†™æœ¬åœ°nodeè·¯å¾„ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:2:2","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"3. æ–°å»ºé¡¹ç›®éƒ¨ç½²ä¿¡æ¯ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:3:0","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"3.1 æºç ç®¡ç† å¡«å†™é¡¹ç›®ä»“åº“åœ°å€ é…ç½®å…å¯†å…¬é’¥è®¤è¯ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:3:1","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"3.2 æ„å»ºè§¦å‘å™¨ å®šæ—¶æ¯äº”åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ä»£ç ä»“åº“æœ‰æ²¡æœ‰æ–°çš„æäº¤ï¼Œå¦‚æœæœ‰æ–°çš„æäº¤å°±è‡ªåŠ¨æ„å»ºé¡¹ç›®å¹¶å‘å¸ƒåˆ°ç›®æ ‡å‰ç«¯æœåŠ¡å™¨ã€‚ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:3:2","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"3.3 æ„å»ºç¯å¢ƒ 3.4 æ‰§è¡ŒShellå‘½ä»¤ npm config get registry npm install --legacy-peer-deps npm run docs:build cd src/.vuepress/dist export DIST_NAME=\"dist-v\"$(date +\"%Y%m%d%H%M%S\")\"\" tar -zcf $WORKSPACE/deployment/$DIST_NAME.tar.gz ./* \\cp $WORKSPACE/deployment/$DIST_NAME.tar.gz $WORKSPACE/deployment/dist-latest.tar.gz rm -rf $WORKSPACE/src/.vuepress/dist","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:3:3","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"3.5 æ„å»ºåæ“ä½œ ç”¨åˆ°SSH Publishers æ’ä»¶ï¼Œå°†é¡¹ç›®ä»£ç æ–‡ä»¶æ¨é€åˆ°ç›®æ ‡ä¸»æœºã€‚ SSH Publishers é…ç½® ç³»ç»Ÿç®¡ç†â€”\u003e ç³»ç»Ÿé…ç½® â€”\u003e Publish over SSH Passphrase: å…¬é’¥å¯†ç  Name:ç›®æ ‡æœåŠ¡å™¨åç§° Hostnameï¼šç›®æ ‡æœåŠ¡å™¨IPåœ°å€ Username: ç›®æ ‡ä¸»æœºç”¨æˆ·å Remote Directoryï¼šç›®æ ‡ä¸»æœºå­˜æ”¾ç›®å½• ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:3:4","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"4.æµ‹è¯•é¡¹ç›®è‡ªåŠ¨å‘å¸ƒ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:4:0","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"4.1 æµ‹è¯•æ‰‹åŠ¨æ„å»ºå‘å¸ƒ ç«‹å³æ„å»º æ§åˆ¶å°è¾“å‡ºæŸ¥çœ‹ä»»åŠ¡è¿›åº¦ æ„å»ºæˆåŠŸ å‰ç«¯æœåŠ¡å™¨ç›®å½•ä¸‹éªŒè¯ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:4:1","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":null,"content":"4.2 æµ‹è¯•è‡ªåŠ¨æ„å»ºå‘å¸ƒ ä»£ç æ›´æ–°åè‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒ ","date":"2023-06-12","objectID":"/posts/cicd/jenkins-autodeploy/:4:2","tags":["CI/CD","æŒç»­é›†æˆ"],"title":"Jenkinså®è·µ-è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒå‰ç«¯é¡¹ç›®","uri":"/posts/cicd/jenkins-autodeploy/"},{"categories":["å°è®°"],"content":"å‰æƒ…å›é¡¾ï¼š å¼€å‘åœ¨Jenkinså‘ç‰ˆå‡ºç°é—®é¢˜ ç„¶åæ›´æ–°äº†ä¸€ä¸‹è¯ä¹¦æ—¶é—´ Jenkins è¿˜æ˜¯æ— æ³•æ›´æ–°ï¼Œè¿™æ¬¡æ˜¯timeout äºæ˜¯æŸ¥çœ‹helm æ‰§è¡Œå†å²ï¼Œè¿˜æ˜¯timed out ","date":"2023-05-16","objectID":"/posts/notes/k8s-certificate-missery/:1:0","tags":["Kubernetes"],"title":"K8Sé›†ç¾¤è¯ä¹¦åˆ°æœŸé—®é¢˜","uri":"/posts/notes/k8s-certificate-missery/"},{"categories":["å°è®°"],"content":"æ€è·¯ä¸€ é‡æ–°åˆ›å»ºä¸€ä¸ªsa è´¦å· apiVersion: v1\rkind: ServiceAccount\rmetadata:\rname: rmxc-jenkinss\rnamespace: rmxc-prod\r# æˆæƒnamespace rmxc-devç»™rmxc-jenkins\r---\rapiVersion: rbac.authorization.k8s.io/v1\rkind: RoleBinding\rmetadata:\rname: rmxc-jenkins-rolebinding\rnamespace: rmxc-dev\rroleRef:\rapiGroup: rbac.authorization.k8s.io\rkind: ClusterRole\rname: edit\rsubjects:\r- kind: ServiceAccount\rname: rmxc-jenkins\rnamespace: rmxc-prodè·å–token å¡«å†™åˆ° contextä¸­ ServiceAccount çš„Secrets æ˜¯ç©ºçš„ ğŸ¤® 1.20ï¼ˆå«1.20ï¼‰ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œåœ¨åˆ›å»ºsaæ—¶ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªsecretï¼Œç„¶åè¿™ä¸ªä¼šæŠŠè¿™ä¸ªsecreté€šè¿‡æŠ•å°„å·æŒ‚è½½åˆ°podé‡Œã€‚ 1.21~1.23è¿™å‡ ä¸ªç‰ˆæœ¬ï¼Œåœ¨åˆ›å»ºsaæ—¶ä¹Ÿä¼šè‡ªåŠ¨åˆ›å»ºsecretï¼Œä½†æ˜¯åœ¨podé‡Œå¹¶ä¸ä¼šä½¿ç”¨secreté‡Œçš„tokenï¼Œè€Œæ˜¯ç”±kubeletåˆ°token Request apiå»ç”³è¯·ä¸€ä¸ªtokenã€‚ 1.24ç‰ˆæœ¬ï¼Œåœ¨åˆ›å»ºsaæ—¶ä¸å†è‡ªåŠ¨åˆ›å»ºsecretäº†ï¼Œæ˜¯ç”±kubelet åˆ° tokenRequest apiå»ç”³è¯·tokenã€‚ åœ¨1.21åˆ°1.23çš„ç‰ˆæœ¬é‡Œï¼Œå½“æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªservice accountä¹‹åï¼Œç³»ç»Ÿä¹Ÿä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªsecretã€‚ è¿™ä¸ªsecreté‡Œä¼šæœ‰ä¸€ä¸ªæ°¸ä¸è¿‡æœŸçš„tokenã€‚ä½†æ˜¯åœ¨podé‡Œå¹¶ä¸ä¼šä½¿ç”¨secretçš„è¿™ä¸ªtokenã€‚ å¯æ˜¯å½“å‰é›†ç¾¤ç¯å¢ƒæ˜¯ v1.21.1 åº”è¯¥è‡ªåŠ¨åˆ›å»ºæ‰å¯¹,ç„¶è€Œå¹¶æ²¡æœ‰è‡ªåŠ¨åˆ›å»ºğŸ¤® [root@master-01 kubernetes]# realkubeadm version\rkubeadm version: \u0026version.Info{Major:\"1\", Minor:\"21\", GitVersion:\"v1.21.1\", GitCommit:\"5e58841cce77d4bc13713ad2b91fa0d961e69192\", GitTreeState:\"clean\", BuildDate:\"2021-05-12T14:17:27Z\", GoVersion:\"go1.16.4\", Compiler:\"gc\", Platform:\"linux/amd64\"} 1.24.x æ‰‹åŠ¨åˆ›å»ºsecretæ–¹æ³•ï¼š è®©k8så¸®æˆ‘ä»¬å¡«å¥½æ°¸ä¸è¿‡æœŸtoken apiVersion: v1 kind: Secret metadata: name: secret-sa-sample annotations: kubernetes.io/service-account.name: \"sa-name\" type: kubernetes.io/service-account-token","date":"2023-05-16","objectID":"/posts/notes/k8s-certificate-missery/:2:0","tags":["Kubernetes"],"title":"K8Sé›†ç¾¤è¯ä¹¦åˆ°æœŸé—®é¢˜","uri":"/posts/notes/k8s-certificate-missery/"},{"categories":["å°è®°"],"content":"æ€è·¯äºŒ æ­¤æ—¶å·²ç»æ„Ÿè§‰K8Sé›†ç¾¤æœ‰ç‚¹ä¸å¯¹åŠ²ï¼Œè·Ÿè¢«ä»€ä¹ˆä¸œè¥¿å¡ä½äº†ä¸€æ ·ğŸ™ƒ,å¼€å§‹æ’æŸ¥å››å¤§é‡‘åˆš è¿™æ—¶å‘ç° kube-controller-manager 2023-05-15T06:05:01.346Z | W0515 06:05:01.346004 1 garbagecollector.go:703] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request] 2023-05-15T06:05:30.134Z | E0515 06:05:30.134484 1 resource_quota_controller.go:409] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request 2023-05-15T06:05:31.374Z | W0515 06:05:31.373915 1 garbagecollector.go:703] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request] 2023-05-15T06:06:00.149Z | E0515 06:06:00.148786 1 resource_quota_controller.go:409] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request 2023-05-15T06:06:01.406Z | W0515 06:06:01.406088 1 garbagecollector.go:703] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request] 2023-05-15T06:06:30.163Z | E0515 06:06:30.162904 1 resource_quota_controller.go:409] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request 2023-05-15T06:06:31.435Z | W0515 06:06:31.435710 1 garbagecollector.go:703] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request] 2023-05-15T06:07:00.233Z | E0515 06:07:00.233046 1 resource_quota_controller.go:409] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the requestkube-scheduler 2023-05-15T05:47:31.747Z | E0515 05:47:31.746995 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1beta1.CSIStorageCapacity: failed to list *v1beta1.CSIStorageCapacity: Unauthorized 2023-05-15T05:47:37.761Z | E0515 05:47:37.761643 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Unauthorized 2023-05-15T05:47:38.024Z | E0515 05:47:38.024302 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Unauthorized 2023-05-15T05:47:41.673Z | E0515 05:47:41.673742 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: Unauthorized 2023-05-15T05:47:44.933Z | E0515 05:47:44.933850 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Unauthorized 2023-05-15T05:47:46.148Z | E0515 05:47:46.148038 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Unauthorized 2023-05-15T05:47:51.624Z | E0515 05:47:51.624779 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Unauthorized 2023-05-15T05:47:55.284Z | E0515 05:47:55.284566 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Unauthorized 2023-05-15T05:47:55.736Z | E0515 05:47:55.736620 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Unauthorized 2023-05-15T05:47:56.893Z | E0515 05:47:56.893650 1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Unauthorizedkube-apiserver 2023-05-15T05:20:00.977Z | E0515 05:20:00.976949 1 authentication.go:63] \"Unable to authenticate the request\" err=\"[x509: certificate has expired or is not yet valid: current time 2023-05-15T05:20:00Z is after 2023-05-14T05:49:22Z, verifying certificate SN=7385935559219004232, SKID=, AKID=9A:A4:90:20:28:E3:8C:F6:35:07:07:0F:17:AA:73:39:B5:8","date":"2023-05-16","objectID":"/posts/notes/k8s-certificate-missery/:3:0","tags":["Kubernetes"],"title":"K8Sé›†ç¾¤è¯ä¹¦åˆ°æœŸé—®é¢˜","uri":"/posts/notes/k8s-certificate-missery/"},{"categories":["å°è®°"],"content":"è§£å†³æ–¹æ³• ç»è¿‡ä»¥ä¸Šæ—¥å¿—åˆ†æåº”è¯¥æ˜¯è¯ä¹¦æ›´æ–°æˆåŠŸäº†ï¼Œä½†æ˜¯æœåŠ¡ç»„ä»¶å¼€å‘æ²¡é‡å¯åˆ°ä½ã€‚ å¹²è„†åœ¨æ¥ä¸€éã€‚ ","date":"2023-05-16","objectID":"/posts/notes/k8s-certificate-missery/:4:0","tags":["Kubernetes"],"title":"K8Sé›†ç¾¤è¯ä¹¦åˆ°æœŸé—®é¢˜","uri":"/posts/notes/k8s-certificate-missery/"},{"categories":["å°è®°"],"content":"ä¸€ã€æ£€æŸ¥è¯ä¹¦æœ‰æ•ˆæœŸ 1.é€šè¿‡ kubeadm å®‰è£…çš„ Kubernetes é›†ç¾¤çš„è¯ä¹¦æœ‰æ•ˆæœŸä¸º 1 å¹´ï¼Œå¯ä»¥ä½¿ç”¨ç›¸å…³å‘½ä»¤æŸ¥çœ‹è¯ä¹¦çš„æœ‰æ•ˆæœŸï¼š [root@master-01 kubernetes]# realkubeadm certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml' CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf May 14, 2024 04:15 UTC 364d no apiserver May 14, 2024 03:18 UTC 364d ca no apiserver-etcd-client May 14, 2024 03:18 UTC 364d etcd-ca no apiserver-kubelet-client May 14, 2024 03:18 UTC 364d ca no controller-manager.conf May 14, 2024 04:15 UTC 364d no etcd-healthcheck-client May 14, 2024 03:18 UTC 364d etcd-ca no etcd-peer May 14, 2024 03:18 UTC 364d etcd-ca no etcd-server May 14, 2024 03:18 UTC 364d etcd-ca no front-proxy-client May 14, 2024 03:18 UTC 364d front-proxy-ca no scheduler.conf May 14, 2024 04:15 UTC 364d no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca May 28, 2031 15:52 UTC 8y no etcd-ca May 28, 2031 15:52 UTC 8y no front-proxy-ca May 28, 2031 15:52 UTC 8y no å¯ä»¥çœ‹åˆ°é™¤äº† ca è¯ä¹¦ï¼Œå…¶ä»–è¯ä¹¦çš„æœ‰æ•ˆæœŸéƒ½æ˜¯ä¸€å¹´ã€‚å¦‚æœè¯ä¹¦åˆ°æœŸï¼Œåˆ™æ•´ä¸ªé›†ç¾¤éƒ½ä¼šæŒ‚æ‰ã€‚ è§£å†³è¿™ä¸ªé—®é¢˜çš„åŠæ³•ä¸€èˆ¬æœ‰ä¸¤ç§ï¼š å¦‚æœè¿˜æ²¡æœ‰å®‰è£…é›†ç¾¤ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹æºç è®¾ç½®è¯ä¹¦æœ‰æ•ˆæœŸã€‚ å¦‚æœé›†ç¾¤å·²ç»è¿è¡Œï¼Œå¯ä»¥é€šè¿‡é‡æ–°ç­¾å‘æœ‰æ•ˆæœŸæ›´é•¿çš„è¯ä¹¦ã€‚ ","date":"2023-05-16","objectID":"/posts/notes/k8s-certificate-missery/:4:1","tags":["Kubernetes"],"title":"K8Sé›†ç¾¤è¯ä¹¦åˆ°æœŸé—®é¢˜","uri":"/posts/notes/k8s-certificate-missery/"},{"categories":["å°è®°"],"content":"äºŒã€æ›´æ–°è¯ä¹¦ ä¸ºäº†æ›´æ–°çš„å®‰å…¨æ€§ï¼Œæ›´æ–°ä¹‹å‰å¯ä»¥å°†æ‰€æœ‰ Master èŠ‚ç‚¹çš„é…ç½®ç›®å½•åšä¸€ä¸ªå¤‡ä»½ï¼š cp -r /etc/kubernetes /etc/kubernetes_$(date +%F) cp -r /var/lib/etcd /var/lib/etcd_$(date +%F)é€šè¿‡æ‰§è¡Œè¯ä¹¦æ›´æ–°å‘½ä»¤æŸ¥çœ‹ï¼š kubeadm certs renew --helpå¯ä»¥çœ‹åˆ°è¯ä¹¦æ›´æ–°æ˜¯æ”¯æŒæ›´æ–°æŒ‡å®šæœåŠ¡çš„è¯ä¹¦ï¼Œä¹Ÿå¯ä»¥æ›´æ–°å•ä¸ªæœåŠ¡çš„è¯ä¹¦ï¼Œä½†éƒ½æ˜¯é›†ç¾¤æœåŠ¡çš„è¯ä¹¦ã€‚ # æ‰€æœ‰ Master èŠ‚ç‚¹æ›´æ–°æ‰€æœ‰è¯ä¹¦\rkubeadm certs renew all\rsystemctl restart kubelet systremctl restart containerd å¯ä»¥çœ‹åˆ°æç¤ºè®©é‡å¯ kube-apiserver, kube-controller-manager, kube-scheduler å’Œ etcd æœåŠ¡è¯ä¹¦æ‰èƒ½ç”Ÿæ•ˆã€‚ # é‡å¯ç»„ä»¶ for i in $(kubectl get pods -A | grep -E \"etcd|kube-apiserver|kube-controller-manager|kube-scheduler\" | awk '{print $2}');do kubectl delete pod $i -n kube-system sleep 3 doneæ­¤æ—¶æŸ¥çœ‹è¯ä¹¦å·²ç»æ˜¯æ–°çš„äº†ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å‘½ä»¤æŸ¥çœ‹ï¼š echo | openssl s_client -showcerts -connect 127.0.0.1:6443 -servername api 2\u003e/dev/null | openssl x509 -noout -enddateåŒæ—¶ï¼Œç”±äºåœ¨åˆå§‹åŒ– Master é›†ç¾¤çš„æ—¶å€™é‡‡ç”¨çš„æ˜¯è®¾ç½®ç¯å¢ƒå˜é‡ export KUBECONFIG=/etc/kubernetes/admin.conf çš„æ–¹æ³•ï¼Œä¸éœ€è¦å†æ›´æ–°è¯¥æ–‡ä»¶ã€‚å¦‚æœä¸æ˜¯è¯¥æ–¹æ³•ï¼Œè¿˜éœ€è¦ä½¿ç”¨æ–°çš„ admin.conf æ›¿æ¢æ‰å¤åˆ¶çš„ /root/.kube/config é…ç½®æ–‡ä»¶ã€‚ é‡å¯containerd è¿è¡Œé•œåƒ crictl stop 9731cb9e5b723\rcrictl stop 977896873866e\rcrictl stop 24430601db1d1\rcrictl stop 7a7bad1c7dd70é‡å¯å,æŸ¥çœ‹ç›¸å…³æ—¥å¿— æœåŠ¡æ­£å¸¸äº† tokenä¹Ÿå‡ºæ¥äº† Jenkins æ„å»ºä¹ŸæˆåŠŸäº† ğŸ˜† ","date":"2023-05-16","objectID":"/posts/notes/k8s-certificate-missery/:4:2","tags":["Kubernetes"],"title":"K8Sé›†ç¾¤è¯ä¹¦åˆ°æœŸé—®é¢˜","uri":"/posts/notes/k8s-certificate-missery/"},{"categories":["å°è®°"],"content":"ä¸€ã€å®‰è£… Oh My Posh for PowerShell winget install JanDeDobbeleer.OhMyPosh -s winget","date":"2023-05-16","objectID":"/posts/notes/powerline/:0:1","tags":["Terminal"],"title":"Windows 11 Terminal å®‰è£…PowerLineæ•™ç¨‹","uri":"/posts/notes/powerline/"},{"categories":["å°è®°"],"content":"äºŒã€é€‰æ‹©ä¸»é¢˜ ä¸»é¢˜åˆ—è¡¨ï¼šhttps://ohmyposh.dev/docs/themes é€‰æ‹©ä¸»é¢˜ï¼Œå¹¶ä½¿ç”¨æ­¤å‘½ä»¤æ›´æ–° PowerShell é…ç½®æ–‡ä»¶ã€‚ ï¼ˆå¯ä»¥å°† notepad æ›¿æ¢ä¸ºä½ é€‰æ‹©çš„æ–‡æœ¬ç¼–è¾‘å™¨ã€‚ï¼‰ notepad $PROFILEå°†ä»¥ä¸‹é¡¹æ·»åŠ åˆ° PowerShell é…ç½®æ–‡ä»¶çš„æœ«å°¾ï¼Œä»¥è®¾ç½® cloud-native-azure ä¸»é¢˜ã€‚ ï¼ˆå¦‚æœæƒ³æ›¿æ¢å°† cloud-native-azure æ›¿æ¢ä¸ºä½ é€‰æ‹©çš„ä¸»é¢˜ã€‚ï¼‰ oh-my-posh init pwsh --config \"$env:POSH_THEMES_PATH\\cloud-native-azure.omp.json\" | Invoke-Expression","date":"2023-05-16","objectID":"/posts/notes/powerline/:0:2","tags":["Terminal"],"title":"Windows 11 Terminal å®‰è£…PowerLineæ•™ç¨‹","uri":"/posts/notes/powerline/"},{"categories":["å°è®°"],"content":"ä¸‰ã€å®‰è£… Nerd Font å¦‚æœä½ çš„å­—ä½“ä¸åŒ…å«ç›¸åº”å­—å½¢ï¼Œåˆ™åœ¨æ•´ä¸ªæç¤ºç¬¦ä¸­ï¼Œä½ å¯èƒ½ä¼šçœ‹åˆ°è‹¥å¹² Unicode æ›¿æ¢å­—ç¬¦â€œâ–¯â€ã€‚ è‹¥è¦åœ¨ç»ˆç«¯ä¸­æŸ¥çœ‹æ‰€æœ‰å­—å½¢ï¼Œå»ºè®®å®‰è£… Nerd Font å®˜æ–¹æ¨èå­—ä½“ï¼šMesloLGM NF #å®‰è£…å­—ä½“ oh-my-posh font install ç»“æœè€æ˜¯timeout åœ¨å­—ä½“åº“ç›´æ¥ä¸‹è½½ https://www.nerdfonts.com/font-downloads #ç›´æ¥å¯¼å…¥å­—ä½“ oh-my-posh font install .\\Meslo.zip ä¿®æ”¹é…ç½®æ–‡ä»¶ä½¿ç”¨ \"profiles\": { \"defaults\": { \"font\": { \"face\": \"MesloLGM NF\" }, },æ‰¾ä¸åˆ°æ‰€é€‰å­—ä½“ MesloLGM NF ğŸ¤® æ‰¾ä¸åˆ°ï¼Ÿ å­—ä½“åç§°æ˜¯ MesloLGM Nerd Font æ›¿æ¢ä¸€ä¸‹ ï¼Ÿ \"profiles\": {\r\"defaults\": {\r\"font\":\r{\r\"face\": \"MesloLGM Nerd Font\" },\r},å¯ä»¥çœ‹åˆ°å·²ç»æ­£å¸¸æ˜¾ç¤ºäº† ","date":"2023-05-16","objectID":"/posts/notes/powerline/:0:3","tags":["Terminal"],"title":"Windows 11 Terminal å®‰è£…PowerLineæ•™ç¨‹","uri":"/posts/notes/powerline/"},{"categories":["å°è®°"],"content":"å››ã€Oh My Posh ä¸ Clink é›†æˆ Windows CMD æ²¡æœ‰å¼€ç®±å³ç”¨çš„æ”¯æŒã€‚ç„¶è€Œï¼Œæœ‰ä¸€ç§æ–¹æ³•å¯ä»¥ä½¿ç”¨Clinkæ¥å®ç°ï¼ŒåŒæ—¶å¯ä»¥å¢å¼ºæ‚¨çš„ cmd ä½“éªŒã€‚æŒ‰ç…§å®‰è£…è¯´æ˜è¿›è¡Œæ“ä½œï¼Œå¹¶ç¡®ä¿é€‰æ‹©è‡ªåŠ¨å¯åŠ¨ã€‚ å°† Oh My Posh ä¸ Clink é›†æˆå¾ˆå®¹æ˜“ï¼šåœ¨ Clink è„šæœ¬ç›®å½•ä¸­åˆ›å»ºä¸€ä¸ªåä¸º oh-my-posh.lua çš„æ–°æ–‡ä»¶ï¼ˆåœ¨clink infocmd ä¸­è¿è¡Œä»¥æ‰¾åˆ°è¯¥æ–‡ä»¶çš„ä½ç½®ï¼‰ã€‚ load(io.popen('oh-my-posh init cmd'):read(\"*a\"))()æ·»åŠ åï¼Œé‡æ–°å¯åŠ¨ cmd ä»¥ä½¿æ›´æ”¹ç”Ÿæ•ˆã€‚ ","date":"2023-05-16","objectID":"/posts/notes/powerline/:0:4","tags":["Terminal"],"title":"Windows 11 Terminal å®‰è£…PowerLineæ•™ç¨‹","uri":"/posts/notes/powerline/"},{"categories":["å°è®°"],"content":"å®‰è£… Jenkins é‡åˆ°çš„é—®é¢˜ ","date":"2023-05-16","objectID":"/posts/notes/jenkins-error/:1:0","tags":["Jenkins"],"title":"å®‰è£… Jenkins é‡åˆ°çš„é—®é¢˜","uri":"/posts/notes/jenkins-error/"},{"categories":["å°è®°"],"content":"é—®é¢˜ä¸€ root@server:/apps# systemctl restart jenkins.service Job for jenkins.service failed because the control process exited with error code. See \"systemctl status jenkins.service\" and \"journalctl -xe\" for details. root@server:/apps# root@server:/apps# systemctl status jenkins.service â— jenkins.service - Jenkins Continuous Integration Server Loaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Tue 2023-05-16 16:36:43 CST; 5s ago Process: 168567 ExecStart=/usr/bin/jenkins (code=exited, status=1/FAILURE) Main PID: 168567 (code=exited, status=1/FAILURE) May 16 16:36:43 server systemd[1]: jenkins.service: Scheduled restart job, restart counter is at 5. May 16 16:36:43 server systemd[1]: Stopped Jenkins Continuous Integration Server. May 16 16:36:43 server systemd[1]: jenkins.service: Start request repeated too quickly. May 16 16:36:43 server systemd[1]: jenkins.service: Failed with result 'exit-code'. May 16 16:36:43 server systemd[1]: Failed to start Jenkins Continuous Integration Server.ç½‘ä¸ŠæŸ¥è¯¢è§£å†³æ–¹æ³• ä¿®æ”¹/lib/systemd/system/jenkins.service # The Java home directory. When left empty, JENKINS_JAVA_CMD and PATH are consulted. Environment=\"JAVA_HOME=/usr/local/jdk/\" systemctl daemon-reload ä¿®æ”¹åä»ç„¶Failed to start Jenkins Continuous Integration Server ç»è¿‡åœ¨å®˜ç½‘æŸ¥è¯¢ 2.361.1 ä»¥åçš„ç‰ˆæœ¬éœ€è¦ java 11 æˆ– java 17 ï¼Œjava 8 æ— æ³•æ­£å¸¸ä½¿ç”¨ã€‚ æ›´æ¢java 17 root@server:/apps# rm /usr/local/jdk root@server:/apps# rm /usr/bin/java root@server:/apps# ln -sv /apps/jdk-17.0.6/ /usr/local/jdk '/usr/local/jdk' -\u003e '/apps/jdk-17.0.6/' root@server:/apps# ln -sv /apps/jdk-17.0.6/bin/java /usr/bin/java '/usr/bin/java' -\u003e '/apps/jdk-17.0.6/bin/java' #æŸ¥çœ‹ç‰ˆæœ¬ java version \"17.0.6\" 2023-01-17 LTS Java(TM) SE Runtime Environment (build 17.0.6+9-LTS-190) Java HotSpot(TM) 64-Bit Server VM (build 17.0.6+9-LTS-190, mixed mode, sharing)","date":"2023-05-16","objectID":"/posts/notes/jenkins-error/:2:0","tags":["Jenkins"],"title":"å®‰è£… Jenkins é‡åˆ°çš„é—®é¢˜","uri":"/posts/notes/jenkins-error/"},{"categories":["å°è®°"],"content":"é—®é¢˜äºŒï¼š å¯åŠ¨ ç›´æ¥å¡ä½åŠå¤© ğŸ¤£ root@server:/apps# systemctl start jenkins.service\r^C æŸ¥çœ‹æ—¥å¿— ä¹Ÿçœ‹ä¸å‡ºæ¥å•¥ root@server:/apps# journalctl -xe May 16 16:53:44 server jenkins[300962]: at java.desktop/sun.font.SunFontManager$2.run(SunFontManager.java:358) May 16 16:53:44 server jenkins[300962]: at java.desktop/sun.font.SunFontManager$2.run(SunFontManager.java:315) May 16 16:53:44 server jenkins[300962]: at java.base/java.security.AccessController.doPrivileged(AccessController.java:318) May 16 16:53:44 server jenkins[300962]: at java.desktop/sun.font.SunFontManager.\u003cinit\u003e(SunFontManager.java:315) May 16 16:53:44 server jenkins[300962]: at java.desktop/sun.awt.FcFontManager.\u003cinit\u003e(FcFontManager.java:35) May 16 16:53:44 server jenkins[300962]: at java.desktop/sun.awt.X11FontManager.\u003cinit\u003e(X11FontManager.java:56) May 16 16:53:44 server jenkins[300962]: Caused: java.lang.reflect.InvocationTargetException May 16 16:53:44 server jenkins[300962]: at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) May 16 16:53:44 server jenkins[300962]: at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77) May 16 16:53:44 server jenkins[300962]: at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) May 16 16:53:44 server jenkins[300962]: at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499) May 16 16:53:44 server jenkins[300962]: at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480) May 16 16:53:44 server jenkins[300962]: at java.desktop/sun.font.FontManagerFactory$1.run(FontManagerFactory.java:85) May 16 16:53:44 server jenkins[300962]: Caused: java.lang.InternalError May 16 16:53:44 server jenkins[300962]: at java.desktop/sun.font.FontManagerFactory$1.run(FontManagerFactory.java:87) May 16 16:53:44 server jenkins[300962]: at java.base/java.security.AccessController.doPrivileged(AccessController.java:318) May 16 16:53:44 server jenkins[300962]: at java.desktop/sun.font.FontManagerFactory.getInstance(FontManagerFactory.java:75) May 16 16:53:44 server jenkins[300962]: at java.desktop/java.awt.Font.getFont2D(Font.java:526) May 16 16:53:44 server jenkins[300962]: at java.desktop/java.awt.Font.getFamily(Font.java:1436) May 16 16:53:44 server jenkins[300962]: at java.desktop/java.awt.Font.getFamily_NoClientCode(Font.java:1410) May 16 16:53:44 server jenkins[300962]: at java.desktop/java.awt.Font.getFamily(Font.java:1402) May 16 16:53:44 server jenkins[300962]: at java.desktop/java.awt.Font.toString(Font.java:1895) May 16 16:53:44 server jenkins[300962]: at hudson.util.ChartUtil.\u003cclinit\u003e(ChartUtil.java:270) May 16 16:53:44 server jenkins[300962]: at hudson.WebAppMain.contextInitialized(WebAppMain.java:217) May 16 16:53:44 server jenkins[300962]: Caused: hudson.util.AWTProblem May 16 16:53:44 server jenkins[300962]: at hudson.WebAppMain.contextInitialized(WebAppMain.java:218) May 16 16:53:44 server jenkins[300962]: at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:1048) May 16 16:53:44 server jenkins[300962]: at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:624) May 16 16:53:44 server jenkins[300962]: at org.eclipse.jetty.server.handler.ContextHandler.contextInitialized(ContextHandler.java:983) May 16 16:53:44 server jenkins[300962]: at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:740) May 16 16:53:44 server jenkins[300962]: at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:392) May 16 16:53:44 server jenkins[300962]: at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1304) May 16 16:53:44 server jenkins[300962]: at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:900) May 16 16:53:44 server jenkins[300962]: at org.eclipse.jetty.servlet.ServletContextHan","date":"2023-05-16","objectID":"/posts/notes/jenkins-error/:3:0","tags":["Jenkins"],"title":"å®‰è£… Jenkins é‡åˆ°çš„é—®é¢˜","uri":"/posts/notes/jenkins-error/"},{"categories":["å°è®°"],"content":"é—®é¢˜ä¸‰ï¼š Jenkins ä¸€ç›´å¡åœ¨ Please wait while Jenkins is getting ready to work â€¦ find / -name *.UpdateCenter.xml /var/lib/jenkins/hudson.model.UpdateCenter.xml find: â€˜/proc/1834928â€™: No such file or directory find: â€˜/proc/1834940â€™: No such file or directory find: â€˜/proc/1834942â€™: No such file or directoryhttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json è¯¥urlæ˜¯å›½å†…çš„æ¸…åå¤§å­¦çš„é•œåƒåœ°å€ï¼ˆå»ºè®®ä½¿ç”¨æ¸…åå¤§å­¦çš„é•œåƒæœåŠ¡å™¨ï¼Œä¿®æ”¹ååˆ·æ–°é¡µé¢å³å¯. vim /var/lib/jenkins/hudson.model.UpdateCenter.xml \u003c?xml version='1.1' encoding='UTF-8'?\u003e \u003csites\u003e \u003csite\u003e \u003cid\u003edefault\u003c/id\u003e \u003curl\u003ehttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json\u003c/url\u003e \u003c/site\u003e \u003c/sites\u003e","date":"2023-05-16","objectID":"/posts/notes/jenkins-error/:4:0","tags":["Jenkins"],"title":"å®‰è£… Jenkins é‡åˆ°çš„é—®é¢˜","uri":"/posts/notes/jenkins-error/"},{"categories":["Kubernetes"],"content":"1.ä¸ºä»€ä¹ˆéœ€è¦å®¹å™¨ç¼–æ’ç³»ç»Ÿï¼Ÿ Dockeråœ¨ç®¡ç†å•ä¸ªå®¹å™¨æ—¶è¡¨ç°å‡ºè‰²ï¼Œå¯¹äºä¸€äº›ç”±æœ‰é™å‡ ä¸ªæˆ–åå‡ ä¸ªå®¹å™¨æ„å»ºçš„åº”ç”¨ç¨‹åºæ¥è¯´ï¼Œç›´æ¥åœ¨Dockerå¼•æ“ä¸Šè‡ªä¸»è¿è¡Œã€éƒ¨ç½²å’Œç®¡ç†æ˜¯ç›¸å¯¹å®¹æ˜“çš„ã€‚ç„¶è€Œï¼Œå½“æ¶‰åŠåˆ°ä¼ä¸šçº§åº”ç”¨ç¨‹åºï¼Œå…¶ä¸­åŒ…å«æ•°ç™¾ç”šè‡³ä¸Šåƒä¸ªå®¹å™¨æ—¶ï¼Œä»…ä¾èµ–Dockerå¼•æ“æ¥è¿›è¡Œç®¡ç†å°†å˜å¾—å¼‚å¸¸å¤æ‚ï¼Œç”šè‡³éš¾ä»¥å®ç°ã€‚ å®¹å™¨ç¼–æ’æ˜¯ä¸€å¥—è‡ªåŠ¨åŒ–ç®¡ç†å®¹å™¨åº”ç”¨çš„æµç¨‹ï¼ŒåŒ…æ‹¬éƒ¨ç½²ã€ç®¡ç†ã€æ‰©å±•å’Œè”ç½‘ç­‰å„ç§æ“ä½œï¼Œæ—¨åœ¨åº”å¯¹å¤§è§„æ¨¡å®¹å™¨é›†ç¾¤çš„æŒ‘æˆ˜ã€‚å®ƒèƒ½å¤Ÿè‡ªåŠ¨åŒ–è®¸å¤šä»»åŠ¡ï¼Œä¾‹å¦‚å®¹å™¨çš„è°ƒåº¦å’Œéƒ¨ç½²ã€èµ„æºçš„åˆ†é…ã€åº”ç”¨è§„æ¨¡çš„å¼¹æ€§æ‰©ç¼©ã€åœ¨ä¸»æœºæ•…éšœæˆ–èµ„æºä¸è¶³æ—¶çš„å®¹å™¨è¿ç§»ã€è´Ÿè½½å‡è¡¡ï¼Œä»¥åŠå¯¹å®¹å™¨å’Œä¸»æœºè¿è¡ŒçŠ¶å†µçš„ç›‘æ§ç­‰ã€‚ å¯¹äºä¼ä¸šçº§åº”ç”¨ç¨‹åºï¼Œå…¶ä¸­å®¹å™¨æ•°é‡åºå¤§ã€å¤æ‚æ€§é«˜ï¼Œå®¹å™¨ç¼–æ’æˆä¸ºä¸å¯æˆ–ç¼ºçš„å·¥å…·ã€‚é€šè¿‡å®¹å™¨ç¼–æ’å¹³å°ï¼Œå¦‚Kubernetesï¼Œå¯ä»¥å®ç°é«˜åº¦è‡ªåŠ¨åŒ–çš„å®¹å™¨ç®¡ç†å’Œåè°ƒï¼Œæ— è®ºæ˜¯åœ¨å¤šå°ä¸»æœºä¸Šè¿˜æ˜¯è·¨å¤šä¸ªæ•°æ®ä¸­å¿ƒä¸­ã€‚å®¹å™¨ç¼–æ’èƒ½å¤Ÿå®ç°å¤æ‚çš„ä»»åŠ¡è°ƒåº¦ã€è´Ÿè½½å‡è¡¡ã€æ•…éšœæ¢å¤ï¼ŒåŒæ—¶æä¾›çµæ´»çš„æ‰©å±•æ€§å’Œèµ„æºç®¡ç†ã€‚ å› æ­¤ï¼Œå®¹å™¨ç¼–æ’åœ¨å¤„ç†å¤§è§„æ¨¡å®¹å™¨é›†ç¾¤æ—¶å˜å¾—è‡³å…³é‡è¦ã€‚å®ƒæä¾›äº†ä¸€ç§ç»“æ„åŒ–çš„æ–¹å¼æ¥ç®¡ç†å¤§é‡å®¹å™¨ï¼Œä½¿å¾—ä¼ä¸šèƒ½å¤Ÿæ›´é«˜æ•ˆã€å¯é åœ°è¿è¡Œå¤æ‚çš„åº”ç”¨ç¨‹åºï¼Œä»è€Œå…‹æœäº†ä»…ä»…ä¾èµ–Dockerå¼•æ“è¿›è¡Œç®¡ç†æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚ 2.Kubernetes é›†ç¾¤æ¦‚è¿° Kubernetes æ˜¯ä¸€ä¸ªè·¨å¤šä¸»æœºçš„å®¹å™¨ç¼–æ’å¹³å°ï¼Œå®ƒä½¿ç”¨å…±äº«ç½‘ç»œå°†å¤šä¸ªä¸»æœºæ„å»ºæˆç»Ÿä¸€çš„é›†ç¾¤ï¼Œå…¶ä¸­masterä½œä¸ºæ§åˆ¶ä¸­å¿ƒè´Ÿè½½æ•´ä¸ªé›†ç¾¤ç³»ç»Ÿï¼Œä½™ä¸‹çš„ä¸»æœºè¿è¡Œä¸ºworkerèŠ‚ç‚¹ï¼Œè¿™äº›å·¥ä½œèŠ‚ç‚¹ä½¿ç”¨æœ¬åœ°å’Œå¤–éƒ¨èµ„æºæ¥æ”¶è¯·æ±‚å¹¶ä»¥podå½¢å¼è¿è¡Œå·¥ä½œè´Ÿè½½ã€‚ MasterèŠ‚ç‚¹\rMasterèŠ‚ç‚¹ï¼šMasterèŠ‚ç‚¹æ˜¯Kubernetesé›†ç¾¤çš„æ§åˆ¶ä¸­å¿ƒï¼Œè´Ÿè´£ç®¡ç†å’Œç›‘æ§æ•´ä¸ªé›†ç¾¤çš„çŠ¶æ€å’Œæ“ä½œã€‚å®ƒåŒ…æ‹¬ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š API Serverï¼ˆAPIæœåŠ¡å™¨ï¼‰ï¼šæä¾›äº†é›†ç¾¤å†…éƒ¨çš„APIï¼Œç”¨äºä¸Kubernetesè¿›è¡Œé€šä¿¡ï¼Œæäº¤å’Œç®¡ç†æ“ä½œè¯·æ±‚ã€‚ Controller Managerï¼ˆæ§åˆ¶å™¨ç®¡ç†å™¨ï¼‰ï¼šè´Ÿè´£ç›‘æ§é›†ç¾¤çŠ¶æ€ï¼Œå¹¶æ ¹æ®æœŸæœ›çŠ¶æ€å¯¹é›†ç¾¤è¿›è¡Œè°ƒæ•´å’Œæ§åˆ¶ã€‚ Schedulerï¼ˆè°ƒåº¦å™¨ï¼‰ï¼šè´Ÿè´£å°†æ–°çš„Podåˆ†é…åˆ°WorkerèŠ‚ç‚¹ä¸Šï¼Œä»¥å®ç°è´Ÿè½½å‡è¡¡å’Œèµ„æºåˆ©ç”¨çš„æœ€ä½³åŒ–ã€‚ etcdï¼ˆåˆ†å¸ƒå¼é”®å€¼å­˜å‚¨ï¼‰ï¼šç”¨äºä¿å­˜é›†ç¾¤çš„é…ç½®æ•°æ®å’ŒçŠ¶æ€ä¿¡æ¯ã€‚ WorkerèŠ‚ç‚¹\rWorkerèŠ‚ç‚¹ï¼šWorkerèŠ‚ç‚¹æ˜¯é›†ç¾¤ä¸­å®é™…è¿è¡Œå®¹å™¨çš„åœ°æ–¹ï¼Œå®ƒä»¬æ¥æ”¶MasterèŠ‚ç‚¹çš„æŒ‡ä»¤å¹¶æ‰§è¡Œç›¸å…³æ“ä½œã€‚æ¯ä¸ªWorkerèŠ‚ç‚¹åŒ…æ‹¬ä»¥ä¸‹ç»„ä»¶ï¼š Kubeletï¼ˆèŠ‚ç‚¹ä»£ç†ï¼‰ï¼šè´Ÿè´£ç®¡ç†èŠ‚ç‚¹ä¸Šçš„å®¹å™¨ï¼Œç¡®ä¿PodæŒ‰ç…§é¢„æœŸçŠ¶æ€è¿è¡Œã€‚ Kube Proxyï¼ˆä»£ç†ï¼‰ï¼šè´Ÿè´£ç»´æŠ¤ç½‘ç»œè§„åˆ™ï¼Œå®ç°Podä¹‹é—´å’Œå¤–éƒ¨çš„ç½‘ç»œé€šä¿¡ã€‚ Container Runtimeï¼ˆå®¹å™¨è¿è¡Œæ—¶ï¼‰ï¼šè´Ÿè´£åœ¨èŠ‚ç‚¹ä¸Šè¿è¡Œå®¹å™¨ï¼Œå¸¸ç”¨çš„åŒ…æ‹¬Dockerã€containerdç­‰ã€‚ Podï¼šPodæ˜¯Kubernetesä¸­çš„æœ€å°éƒ¨ç½²å•å…ƒï¼Œå®ƒå¯ä»¥åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨ï¼Œå¹¶å…±äº«ç›¸åŒçš„ç½‘ç»œå’Œå­˜å‚¨ç©ºé—´ã€‚Podä½œä¸ºéƒ¨ç½²ã€æ‰©å±•å’Œç®¡ç†çš„åŸºæœ¬å•ä½ï¼Œå¯ä»¥å®¹çº³åº”ç”¨åŠå…¶ä¾èµ–ï¼Œå¹¶æä¾›äº†æ›´å¥½çš„èµ„æºéš”ç¦»å’Œçµæ´»æ€§ã€‚ 3.Kubernetes APIå¯¹è±¡ Kubernetesçš„RESTful APIä»¥èµ„æºçš„å½¢å¼æŠ½è±¡äº†å¤šç§æ¦‚å¿µæ¥æè¿°åº”ç”¨ç¨‹åºåŠå…¶å‘¨è¾¹ç»„ä»¶ã€‚è¿™äº›æŠ½è±¡å‡ºçš„ç¨‹åºå’Œç»„ä»¶è¢«ç»Ÿç§°ä¸ºAPIå¯¹è±¡ï¼Œå®ƒä»¬éƒ½æœ‰ç‰¹å®šçš„ç±»å‹å’Œå±æ€§ï¼Œæ¯ä¸ªAPIå¯¹è±¡éƒ½ä½¿ç”¨â€åç§°â€œä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦ã€‚ å¯¹è±¡ç±»å‹\rä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„Kubernetes APIå¯¹è±¡ç±»å‹å’Œå®ƒä»¬çš„ä¸€äº›å±æ€§ï¼š Podï¼ˆPodï¼‰ï¼šPodæ˜¯æœ€å°çš„å¯éƒ¨ç½²å•å…ƒï¼Œå¯ä»¥åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨ï¼Œå®ƒä»¬å…±äº«ç½‘ç»œå’Œå­˜å‚¨èµ„æºã€‚Podé€šå¸¸ç”¨äºå°è£…ç´§å¯†è€¦åˆçš„åº”ç”¨ç»„ä»¶ã€‚ ReplicaSetï¼ˆå‰¯æœ¬é›†ï¼‰ï¼šReplicaSetç¡®ä¿æŒ‡å®šæ•°é‡çš„Podå‰¯æœ¬åœ¨é›†ç¾¤ä¸­è¿è¡Œã€‚å®ƒé€‚ç”¨äºåº”ç”¨éƒ¨ç½²å’Œæ‰©å±•ã€‚ Deploymentï¼ˆéƒ¨ç½²ï¼‰ï¼šDeploymentå»ºç«‹åœ¨ReplicaSetä¹‹ä¸Šï¼Œæä¾›äº†å£°æ˜å¼çš„æ–¹å¼æ¥ç®¡ç†Podå‰¯æœ¬çš„åˆ›å»ºå’Œæ›´æ–°ã€‚å®ƒç”¨äºåº”ç”¨çš„æ»šåŠ¨æ›´æ–°å’Œç‰ˆæœ¬æ§åˆ¶ã€‚ Serviceï¼ˆæœåŠ¡ï¼‰ï¼šServiceå®šä¹‰äº†ä¸€ç»„Podçš„ç½‘ç»œè®¿é—®æ–¹å¼ï¼Œä¸ºPodæä¾›äº†ç¨³å®šçš„IPåœ°å€å’ŒDNSåç§°ã€‚å®ƒç”¨äºå†…éƒ¨æˆ–å¤–éƒ¨ç½‘ç»œè®¿é—®ã€‚ Ingressï¼ˆå…¥å£ï¼‰ï¼šIngresså…è®¸ä»é›†ç¾¤å¤–éƒ¨è®¿é—®Serviceï¼Œæä¾›äº†HTTPå’ŒHTTPSè·¯ç”±çš„è§„åˆ™ã€‚ ConfigMapï¼ˆé…ç½®æ˜ å°„ï¼‰ï¼šConfigMapç”¨äºå°†é…ç½®æ•°æ®ä»åº”ç”¨ä»£ç ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œä½¿é…ç½®çš„ç®¡ç†æ›´åŠ çµæ´»ã€‚ Secretï¼ˆå¯†é’¥ï¼‰ï¼šSecretç”¨äºå­˜å‚¨æ•æ„Ÿä¿¡æ¯ï¼Œå¦‚å¯†ç ã€APIå¯†é’¥ç­‰ï¼Œä»¥å®‰å…¨åœ°ä¼ é€’ç»™Podã€‚ Namespaceï¼ˆå‘½åç©ºé—´ï¼‰ï¼šNamespaceç”¨äºå°†é›†ç¾¤åˆ†å‰²ä¸ºå¤šä¸ªè™šæ‹Ÿé›†ç¾¤ï¼Œæ¯ä¸ªå‘½åç©ºé—´ä¸­çš„å¯¹è±¡ç›¸äº’éš”ç¦»ï¼Œæœ‰åŠ©äºå¤šç§Ÿæˆ·çš„ç®¡ç†ã€‚ StatefulSetï¼ˆæœ‰çŠ¶æ€å‰¯æœ¬é›†ï¼‰ï¼šç±»ä¼¼äºReplicaSetï¼Œä½†ç”¨äºæœ‰çŠ¶æ€åº”ç”¨ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªPodåˆ†é…ç¨³å®šçš„ç½‘ç»œæ ‡è¯†å’Œå­˜å‚¨ã€‚ DaemonSetï¼ˆå®ˆæŠ¤è¿›ç¨‹é›†ï¼‰ï¼šDaemonSetç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹ä¸Šéƒ½è¿è¡Œä¸€ä¸ªPodå‰¯æœ¬ï¼Œé€‚ç”¨äºåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œç‰¹å®šä»»åŠ¡çš„æƒ…å†µã€‚ Jobï¼ˆä»»åŠ¡ï¼‰ï¼šJobç”¨äºè¿è¡Œä¸€æ¬¡æ€§çš„ä»»åŠ¡ï¼Œç¡®ä¿ä»»åŠ¡æˆåŠŸå®Œæˆï¼Œä¾‹å¦‚æ‰¹é‡å¤„ç†ä»»åŠ¡ã€‚ Kubernetesä½¿ç”¨å‘½åç©ºé—´ï¼ˆNamespaceï¼‰ä¸ºèµ„æºæä¾›äº†ä½œç”¨åŸŸï¼Œå¹¶å°†å¤§å¤šæ•°èµ„æºç±»å‹åˆ’åˆ†åˆ°å‘½åç©ºé—´çº§åˆ«ã€‚å‘½åç©ºé—´å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªè™šæ‹Ÿçš„é›†ç¾¤ï¼Œç”¨äºåœ¨ç‰©ç†é›†ç¾¤å†…éƒ¨åˆ’åˆ†ä¸åŒçš„é€»è¾‘å·¥ä½œå•å…ƒï¼Œä»è€Œå°†ä¸åŒçš„èµ„æºéš”ç¦»å¼€æ¥ã€‚è¿™å¯¹äºå¤šç§Ÿæˆ·ç¯å¢ƒã€å¤šä¸ªé¡¹ç›®çš„éš”ç¦»å’Œèµ„æºç®¡ç†éå¸¸æœ‰ç”¨ã€‚ åœ¨Kubernetesä¸­ï¼Œæ¯ä¸ªèµ„æºå¯¹è±¡éƒ½å±äºä¸€ä¸ªç‰¹å®šçš„å‘½åç©ºé—´ã€‚ä¸€äº›èµ„æºé»˜è®¤åœ¨\"default\"å‘½åç©ºé—´ä¸­ï¼Œä½†ä¹Ÿå¯ä»¥åˆ›å»ºè‡ªå®šä¹‰çš„å‘½åç©ºé—´ï¼Œå°†èµ„æºæ”¾ç½®åœ¨å…¶ä¸­ã€‚ é€šè¿‡ä½¿ç”¨å‘½åç©ºé—´ï¼ŒKuberneteså¯ä»¥å®ç°èµ„æºçš„é€»è¾‘éš”ç¦»ï¼Œä»è€Œä¸åŒé¡¹ç›®ã€å›¢é˜Ÿæˆ–åº”ç”¨å¯ä»¥åœ¨åŒä¸€ä¸ªé›†ç¾¤ä¸­è¿è¡Œï¼Œè€Œå½¼æ­¤ä¹‹é—´ä¸ä¼šå¹²æ‰°ã€‚åŒæ—¶ï¼Œå‘½åç©ºé—´è¿˜æœ‰åŠ©äºå¯¹èµ„æºè¿›è¡Œåˆ†ç±»ã€ç®¡ç†å’Œç›‘æ§ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸æ˜¯æ‰€æœ‰çš„èµ„æºéƒ½æ”¯æŒå‘½åç©ºé—´ï¼Œä¸€äº›æ ¸å¿ƒèµ„æºå¦‚Nodeså’ŒPersistentVolumeså¹¶ä¸å±äºå‘½åç©ºé—´ã€‚ 4.Kubernetes é…ç½®æ¸…å• Manifest åœ¨Kubernetesä¸­ï¼Œåº”ç”¨ç¨‹åºçš„éƒ¨ç½²å’Œç®¡ç†éœ€è¦é€šè¿‡é…ç½®æ¸…å•ï¼ˆä¹Ÿç§°ä¸ºèµ„æºæ¸…å•æˆ–èµ„æºé…ç½®ï¼‰æ¥æŒ‡å®šæ‰€éœ€çš„çŠ¶æ€ï¼Œå¹¶å°†å…¶æäº¤ç»™Kubernetesçš„APIæœåŠ¡å™¨ã€‚è¿™äº›é…ç½®æ¸…å•æè¿°äº†è¦åˆ›å»ºçš„èµ„æºå¯¹è±¡çš„å±æ€§å’Œè§„æ ¼ï¼ŒåŒ…æ‹¬å…ƒæ•°æ®ã€æœŸæœ›çŠ¶æ€ä»¥åŠè§‚å¯ŸçŠ¶æ€ç­‰ä¿¡æ¯ã€‚ é…ç½®æ¸…å•æ˜¯ä¸€ä¸ªåŒ…å«èµ„æºå¯¹è±¡å®šä¹‰çš„æ–‡ä»¶ï¼Œé€šå¸¸é‡‡ç”¨JSONæˆ–YAMLæ ¼å¼ç¼–ç ã€‚è¿™äº›æ¸…å•æ–‡ä»¶æŒ‡å®šäº†è¦éƒ¨ç½²çš„åº”ç”¨ç¨‹åºã€æœåŠ¡ã€å‰¯æœ¬é›†ç­‰çš„ç‰¹æ€§å’Œé…ç½®ã€‚ å½“ä½ æƒ³åœ¨Kubernetesä¸­è¿è¡Œåº”ç”¨ç¨‹åºï¼Œé‚£ä¹ˆå°±éœ€è¦åˆ›å»ºä¸€ä¸ªé…ç½®æ¸…å•æ–‡ä»¶ï¼Œå…¶ä¸­æè¿°äº†åº”ç”¨ç¨‹åºçš„å±æ€§å’Œè§„æ ¼ï¼Œæ¯”å¦‚åç§°ã€é•œåƒã€ç«¯å£ç­‰ã€‚è¿™ä¸ªæ¸…å•å¯ä»¥ä½¿ç”¨JSONæˆ–YAMLæ ¼å¼ç¼–å†™ã€‚ç„¶åï¼Œéœ€è¦å°†è¿™ä¸ªé…ç½®æ¸…å•æ–‡ä»¶æäº¤ç»™Kubernetesçš„APIæœåŠ¡å™¨ã€‚ Kubernetesçš„APIæœåŠ¡å™¨ä¼šæ¥æ”¶å¹¶å­˜å‚¨è¿™ä¸ªé…ç½®æ¸…å•ï¼Œç„¶åæ ¹æ®æ¸…å•ä¸­çš„ä¿¡æ¯ï¼Œåœ¨é›†ç¾¤ä¸­åˆ›å»ºç›¸åº”çš„èµ„æºï¼Œå¦‚Podã€æœåŠ¡ç­‰ã€‚APIæœåŠ¡å™¨ä¼šç¡®ä¿æè¿°çš„æœŸæœ›çŠ¶æ€ï¼ˆæ¯”å¦‚è¿è¡Œ3ä¸ªå‰¯æœ¬ï¼‰ä¸è§‚å¯ŸçŠ¶æ€ï¼ˆå®é™…è¿è¡Œçš„å‰¯æœ¬æ•°ï¼‰ä¿æŒä¸€è‡´ã€‚ æäº¤é…ç½®æ¸…å•é€šå¸¸ä½¿ç”¨HTTP/HTTPSåè®®ä¸Kubernetesçš„APIæœåŠ¡å™¨é€šä¿¡ã€‚APIæœåŠ¡å™¨ä¼šéªŒè¯å’Œå¤„ç†è¯·æ±‚ï¼Œå¹¶å°†æ¸…å•ä¸­å®šä¹‰çš„èµ„æºåˆ›å»ºæˆ–æ›´æ–°åˆ°é›†ç¾¤ä¸­ã€‚Kubernetes APIæœåŠ¡å™¨é€šè¿‡HTTP GETè¯·æ±‚æŸ¥è¯¢èµ„æºå¯¹è±¡çš„çŠ¶æ€ï¼Œé€šå¸¸ä»¥JSONæ ¼å¼è¿›è¡Œåºåˆ—åŒ–ã€‚åŒæ—¶ï¼ŒKubernetesæ”¯æŒæ›´é«˜æ•ˆçš„protobufæ ¼å¼æ¥å‡å°‘æ•°æ®ä¼ è¾“å’Œè§£æå¼€é”€ã€‚ Kubernetesæä¾›äº†ä¸€ç§å£°æ˜å¼çš„æ–¹æ³•æ¥ç®¡ç†åº”ç”¨ç¨‹åºå’Œèµ„æºå¯¹è±¡ï¼Œä½¿å¾—éƒ¨ç½²å’Œç®¡ç†å˜å¾—æ›´åŠ å¯é ã€å¯é‡å¤å’Œå¯è‡ªåŠ¨åŒ–ã€‚ ","date":"2023-04-24","objectID":"/posts/kubernetes/primary/1.kubernetes%E5%9F%BA%E7%A1%80/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes åŸºç¡€","uri":"/posts/kubernetes/primary/1.kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["Kubernetes"],"content":"1ã€å®‰è£…docker harborä¾èµ–äºdocker å’Œdocker-compose ","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"2ã€å®‰è£…docker-compose wget https://github.com/docker/compose/releases/download/v2.17.3/docker-compose-linux-x86_64 [root@harbor ~]# cp docker-compose-linux-x86_64 /usr/local/bin/docker-compose [root@harbor ~]# chmod +x /usr/local/bin/docker-compose","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"3ã€å®‰è£…harbor https://github.com/goharbor/harbor/releases è§£å‹harbor tar -xvf harbor-offline-installer-v2.6.1.tgz -C /apps/harbor","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"4ã€è‡ªç­¾è¯ä¹¦ https://goharbor.io/docs/2.4.0/install-config/configure-https/ å¦‚æœä½¿ç”¨containerdéƒ¨ç½²å®¹å™¨ä½¿ç”¨harboråˆ™éœ€è¦å‚è€ƒå®˜ç½‘è¯´æ˜ï¼Œä¸ä¼ ç»Ÿdockeréƒ¨ç½²çš„Harborè‡ªç­¾å‘ SSLè¯ä¹¦ä¸åŒéœ€è¦ä½¿ç”¨SANåŒ…å«å¤šåŸŸåç­¾å‘å¯¹è±¡ï¼š ","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"4.1 ç”Ÿæˆè¯ä¹¦é¢å‘æœºæ„è¯ä¹¦ åˆ›å»ºè¯ä¹¦ä¿å­˜ç›®å½• $ mkdir -p /apps/harbor/certs \u0026\u0026 cd /apps/harbor/certsç”ŸæˆCAè¯ä¹¦ç§é’¥ openssl genrsa -out ca.key 4096åŸºäºCAè¯ä¹¦ç§é’¥ç”ŸæˆCAè¯ä¹¦ openssl req -x509 -new -nodes -sha512 -days 3650 \\ -subj \"/C=CN/ST=Beijing/L=Beijing/O=ceamg/OU=it/CN=harbor.ceamg.com\" \\ -key ca.key \\ -out ca.crtCï¼ŒCountryï¼Œä»£è¡¨å›½å®¶ STï¼ŒSTateï¼Œä»£è¡¨çœä»½ Lï¼ŒLocationï¼Œä»£è¡¨åŸå¸‚ Oï¼ŒOrganizationï¼Œä»£è¡¨ç»„ç»‡ï¼Œå…¬å¸ OUï¼ŒOrganization Unitï¼Œä»£è¡¨éƒ¨é—¨ CNï¼ŒCommon Nameï¼Œä»£è¡¨æœåŠ¡å™¨åŸŸå emailAddressï¼Œä»£è¡¨è”ç³»äººé‚®ç®±åœ°å€ã€‚","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:4:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"4.2 ç”ŸæˆæœåŠ¡è¯ä¹¦ åˆ›å»ºè¯ä¹¦ç§é’¥ openssl genrsa -out harbor.ceamg.com.key 4096åŸºäºæœåŠ¡è¯ä¹¦ç§é’¥ç”Ÿæˆè¯ä¹¦ç­¾åè¯·æ±‚CSR openssl req -sha512 -new \\ -subj \"/C=CN/ST=Hanan/L=Zhengzhou/O=cib/OU=it/CN=harbor.ceamg.com\" \\ -key harbor.ceamg.com.key \\ -out harbor.ceamg.com.csrç”Ÿæˆx509 v3æ‰©å±•æ–‡ä»¶ cat \u003e v3.ext \u003c\u003c-EOF authorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment extendedKeyUsage = serverAuth subjectAltName = @alt_names [alt_names] DNS.1=harbor.ceamg.com DNS.2=harbor.ceamg DNS.3=harbor01 EOFä½¿ç”¨v3æ–‡ä»¶ä¸ºharborç­¾å‘è¯ä¹¦ openssl x509 -req -sha512 -days 3650 \\ -extfile v3.ext \\ -CA ca.crt -CAkey ca.key -CAcreateserial \\ -in harbor.ceamg.com.csr \\ -out harbor.ceamg.com.crt","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:4:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"5ã€é…ç½®è¯ä¹¦ ","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:5:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"5.1 ä¿®æ”¹harboré…ç½®æ–‡ä»¶ ä¿®æ”¹åŸŸåå’Œhttps SSLç­¾å‘çš„ç§é’¥å’Œè¯ä¹¦è·¯å¾„ # Configuration file of Harbor # The IP address or hostname to access admin UI and registry service. # DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients. hostname: harbor.ceamg.com # http related config http: # port for http, default is 80. If https enabled, this port will redirect to https port port: 80 # https related config https: # https port for harbor, default is 443 port: 443 # The path of cert and key files for nginx certificate: /data/cert/harbor.ceamg.com.crt private_key: /data/cert/harbor.ceamg.com.key","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:5:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"5.2 æ ¹æ®æ–°é…ç½®é‡æ–°ç”Ÿæˆå„ç±»èµ„æºå’Œé…ç½® ./prepare --with-notary --with-trivy --with-chartmuseum","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:5:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"5.3 å¯åŠ¨æœåŠ¡ docker-compose up -d","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:5:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"5.4 æŸ¥çœ‹è¯ä¹¦ ","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:5:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"å…­ã€é…ç½®containerdä½¿ç”¨è¯ä¹¦è®¿é—®harbor ","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:5:5","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"6.1 HOSTSæ–¹å¼å¯¹æ¥ ç›´æ¥åœ¨config.tomlä¸­é…ç½®ç›¸å…³çš„è¯ä¹¦å‚æ•°å¯¹äºContainerdé»˜è®¤ä½¿ç”¨çš„ctræ˜¯ä¸ç”Ÿæ•ˆçš„å› ä¸ºcträ¸ä½¿ç”¨CRIï¼›å› æ­¤å®ƒä¸è¯»å–é…ç½®ä¸­[plugins.\"io.containerd.grpc.v1.cri]é…ç½®çš„è®¤è¯å†…å®¹ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨Containerdæ”¯æŒçš„hostsæ–¹å¼å»è¿›è¡Œé…ç½®ï¼Œå¯ä»¥å®ç°ctrå’Œnerdctlå»å¯¹æ¥Harbor åˆ›å»ºhosts.tomlæ–‡ä»¶æˆ–è€…è¯ä¹¦æ–‡ä»¶å­˜å‚¨çš„ç›®å½•ï¼Œæ³¨æ„è¿™ä¸ªåˆ›å»ºçš„ç›®å½•åç§°å¿…é¡»æ˜¯Harborçš„åŸŸå(å¦‚æœä¸æ˜¯åˆ™æŠ¥x509)ï¼›ç„¶åå°†è¯ä¹¦æ–‡ä»¶æˆ–è€…hosts.tomlæ–‡ä»¶æ”¾å…¥è¯¥ç›®å½•ä¸‹æ‰ä¼šç”Ÿæ•ˆã€‚ containerdèŠ‚ç‚¹åˆ›å»ºè¯ä¹¦å­˜å‚¨ç›®å½• mkdir -p /etc/containerd/certs.d/harbor.ceamg.com/åˆ›å»º**hosts.toml**æ–‡ä»¶ [host.\"https://harbor.ceamg.com\"] capabilities = [\"pull\", \"resolve\",\"push\"] ca = [\"harbor.ceamg.com.crt\"]å°†harboræœåŠ¡è¯ä¹¦å‘é€åˆ°containerdèŠ‚ç‚¹ #!/bin/bash #ç›®æ ‡ä¸»æœºåˆ—è¡¨ IP=\" 10.1.0.32 10.1.0.33 \" for node in ${IP};do sshpass -p ceamg.com ssh-copy-id ${node} -o StrictHostKeyChecking=no if [ $? -eq 0 ];then echo \"${node} ç§˜é’¥copyå®Œæˆ\" echo \"${node} ç§˜é’¥copyå®Œæˆ,å‡†å¤‡ç¯å¢ƒåˆå§‹åŒ–.....\" ssh ${node} \"mkdir /etc/containerd/certs.d/harbor.ceamg.com -p\" echo \"Harbor è¯ä¹¦åˆ›å»ºæˆåŠŸ!\" scp /etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.crt ${node}:/etc/containerd/certs.d/harbor.ceamg.com/ echo \"Harbor è¯ä¹¦æ‹·è´æˆåŠŸ!\" ssh ${node} \"echo \"10.1.0.38 harbor.ceamg.com\" \u003e\u003e /etc/hosts\" echo \"host è§£ææ·»åŠ å®Œæˆ\" #scp -r /root/.docker ${node}:/root/ #echo \"Harbor è®¤è¯ä»¶æ‹·å®Œæˆ!\" else echo \"${node} ç§˜é’¥copyå¤±è´¥\" fi done ","date":"2023-02-22","objectID":"/posts/kubernetes/primary/kubernetes-17/:5:6","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Harbor ä½¿ç”¨è‡ªç­¾è¯ä¹¦æ”¯æŒ Https è®¿é—® (åä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-17/"},{"categories":["Kubernetes"],"content":"å‰è¨€ è¯´åˆ°å…è´¹çš„SSLè¯ä¹¦ï¼Œå¤§å®¶é¦–å…ˆæƒ³åˆ°çš„è‚¯å®šæ˜¯Letâ€™s Encryptï¼Œè€Œä½¿ç”¨è¿‡Letâ€™s Encryptçš„åŒå­¦åº”è¯¥ä¹ŸçŸ¥é“ï¼Œå…¶æœ‰æ•ˆæœŸåªæœ‰ä¸‰ä¸ªæœˆï¼Œä¸‰ä¸ªæœˆåè¦é‡æ–°ç»­æœŸã€‚githubä¸Šä¹Ÿæœ‰ç±»ä¼¼çš„è„šæœ¬å¯ä»¥åšåˆ°è‡ªåŠ¨ç»­æœŸã€‚é‚£å¦‚æœæ˜¯åœ¨k8sä¸Šä½¿ç”¨è¯¥å…è´¹è¯ä¹¦ï¼Œåˆå¦‚ä½•æ“ä½œçš„å‘¢ï¼Ÿè¿™é‡Œcert-managerå°±æ´¾ä¸Šç”¨åœºäº†ã€‚ ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"ä»€ä¹ˆæ˜¯cert-manager ? ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"1.ç®€ä»‹ cert-manager æ˜¯ä¸€ä¸ªäº‘åŸç”Ÿè¯ä¹¦ç®¡ç†å¼€æºé¡¹ç›®ï¼Œå®ƒç®€åŒ–äº†åœ¨ Kubernetes é›†ç¾¤ä¸­webæœåŠ¡ç®¡ç†Httpsè¯ä¹¦çš„è¿‡ç¨‹ã€‚ æ”¯æŒä»å¤šç§è¯ä¹¦ç­¾å‘æœºæ„ç”³è¯·è¯ä¹¦ï¼ŒåŒ…æ‹¬ Letâ€™s Encryptã€HashiCorp Vault å’Œ Venafiã€‚ å®ƒå°†è¯ä¹¦å’Œè¯ä¹¦é¢å‘æœºæ„æ·»åŠ ä¸º Kubernetes èµ„æºç±»å‹ï¼Œå¹¶ä¸”ç®€åŒ–è·å–ã€æ›´æ–°å’Œä½¿ç”¨è¿™äº›è¯ä¹¦ï¼Œå¹¶åœ¨è¯ä¹¦åˆ°æœŸå‰çš„å°è¯•ç»­è®¢è¯ä¹¦ï¼Œç¡®ä¿è¯ä¹¦æœ‰æ•ˆå¹¶åŠæ—¶æ›´æ–°ã€‚ åœ¨Kubernetesé›†ç¾¤ä¸­ä½¿ç”¨ HTTPS åè®®ï¼Œéœ€è¦ä¸€ä¸ªè¯ä¹¦ç®¡ç†å™¨ã€ä¸€ä¸ªè¯ä¹¦è‡ªåŠ¨ç­¾å‘æœåŠ¡ï¼Œä¸»è¦é€šè¿‡ Ingress æ¥å‘å¸ƒ HTTPS æœåŠ¡ï¼Œå› æ­¤éœ€è¦Ingress Controllerå¹¶è¿›è¡Œé…ç½®ï¼Œå¯ç”¨ HTTPS åŠå…¶è·¯ç”±ã€‚ è§’è‰² Issuer/ClusterIssuer: ç”¨äºæŒ‡ç¤º cert-manager ç”¨ä»€ä¹ˆæ–¹å¼ç­¾å‘è¯ä¹¦ï¼Œæœ¬æ–‡ä¸»è¦è®²è§£ç­¾å‘å…è´¹è¯ä¹¦çš„ ACME æ–¹å¼ã€‚ClusterIssuer ä¸ Issuer çš„å”¯ä¸€åŒºåˆ«å°±æ˜¯ Issuer åªèƒ½ç”¨æ¥ç­¾å‘è‡ªå·±æ‰€åœ¨ namespace ä¸‹çš„è¯ä¹¦ï¼ŒClusterIssuer å¯ä»¥ç­¾å‘ä»»æ„ namespace ä¸‹çš„è¯ä¹¦ã€‚ Certificate: ç”¨äºå‘Šè¯‰ cert-manager æˆ‘ä»¬æƒ³è¦ä»€ä¹ˆåŸŸåçš„è¯ä¹¦ä»¥åŠç­¾å‘è¯ä¹¦æ‰€éœ€è¦çš„ä¸€äº›é…ç½®ï¼ŒåŒ…æ‹¬å¯¹ Issuer/ClusterIssuer çš„å¼•ç”¨ã€‚ ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"2. è®¾è®¡ç†å¿µ Cert-Manager æ˜¯å°† TLS è¯ä¹¦è§†ä¸ºä¸€ç§èµ„æºï¼Œå°±åƒ Podã€Service å’Œ Deployment ä¸€æ ·ï¼Œå¯ä»¥ä½¿ç”¨ Kubernetes API è¿›è¡Œç®¡ç†ã€‚å®ƒä½¿ç”¨äº†è‡ªå®šä¹‰èµ„æºå®šä¹‰ï¼ˆCRDï¼‰æœºåˆ¶ï¼Œé€šè¿‡æ‰©å±• Kubernetes APIï¼Œä¸ºè¯ä¹¦çš„ç”Ÿå‘½å‘¨æœŸæä¾›äº†æ ‡å‡†åŒ–çš„ç®¡ç†æ–¹å¼ã€‚ ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:2:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"3.æ¶æ„è®¾è®¡ Cert-Manager çš„æ¶æ„åˆ†ä¸ºä¸¤å±‚ï¼šæ§åˆ¶å±‚å’Œæ•°æ®å±‚ã€‚ æ§åˆ¶å±‚: è´Ÿè´£è¯ä¹¦çš„ç®¡ç†ï¼ŒåŒ…æ‹¬è¯ä¹¦çš„åˆ›å»ºã€æ›´æ–°å’Œåˆ é™¤ç­‰ï¼› æ•°æ®å±‚: è´Ÿè´£å­˜å‚¨è¯ä¹¦ç›¸å…³çš„æ•°æ®ï¼ŒåŒ…æ‹¬è¯ä¹¦çš„ç§é’¥ã€è¯ä¹¦è¯·æ±‚ã€è¯ä¹¦é¢å‘æœºæ„ç­‰ã€‚ Cert-Manager æ”¯æŒå¤šç§è¯ä¹¦é¢å‘æœºæ„ï¼ŒåŒ…æ‹¬è‡ªç­¾åè¯ä¹¦selfSignedã€Letâ€™s Encryptã€HashiCorp Vaultã€Venafi ç­‰ã€‚å®ƒè¿˜æ”¯æŒå¤šç§éªŒè¯æ–¹å¼ï¼ŒåŒ…æ‹¬ HTTP éªŒè¯ã€DNS éªŒè¯å’Œ TLS-SNI éªŒè¯ç­‰ã€‚è¿™äº›éªŒè¯æ–¹å¼å¯ä»¥å¸®åŠ©ç¡®ä¿è¯ä¹¦çš„é¢å‘æœºæ„æ˜¯å¯ä¿¡çš„ï¼Œå¹¶ä¸”ç¡®ä¿è¯ä¹¦çš„ç§é’¥ä¸ä¼šæ³„éœ²ã€‚ ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:2:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"4.ç­¾å‘æµç¨‹ åœ¨ Kubernetes ä¸­ï¼Œcert-manager é€šè¿‡ä»¥ä¸‹æµç¨‹åˆ›å»ºèµ„æºå¯¹è±¡ä»¥ç­¾å‘è¯ä¹¦ï¼š åˆ›å»ºä¸€ä¸ª CertificateRequest å¯¹è±¡ï¼ŒåŒ…å«è¯ä¹¦çš„ç›¸å…³ä¿¡æ¯ï¼Œä¾‹å¦‚è¯ä¹¦åç§°ã€åŸŸåç­‰ã€‚è¯¥å¯¹è±¡æŒ‡å®šäº†ä½¿ç”¨çš„ Issuer æˆ– ClusterIssuerï¼Œä»¥åŠè¯ä¹¦ç­¾å‘å®Œæˆåï¼Œéœ€è¦å­˜å‚¨çš„ Secret çš„åç§°ã€‚ Issuer æˆ– ClusterIssuer ä¼šæ ¹æ®è¯ä¹¦è¯·æ±‚çš„ç›¸å…³ä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ª Order å¯¹è±¡ï¼Œè¡¨ç¤ºéœ€è¦ç­¾å‘ä¸€ä¸ªè¯ä¹¦ã€‚è¯¥å¯¹è±¡åŒ…å«äº†ç­¾å‘è¯ä¹¦æ‰€éœ€çš„åŸŸååˆ—è¡¨ã€è¯ä¹¦ç­¾å‘æœºæ„çš„åç§°ç­‰ä¿¡æ¯ã€‚ è¯ä¹¦ç­¾å‘æœºæ„æ ¹æ® Order å¯¹è±¡ä¸­çš„ä¿¡æ¯åˆ›å»ºä¸€ä¸ªæˆ–å¤šä¸ª Challenge å¯¹è±¡ï¼Œç”¨äºéªŒè¯è¯ä¹¦ç”³è¯·è€…å¯¹è¯¥åŸŸåçš„æ§åˆ¶æƒã€‚Challenge å¯¹è±¡åŒ…å«ä¸€ä¸ª DNS è®°å½•æˆ– HTTP æœåŠ¡ï¼Œè¯æ˜åŸŸåçš„æ‰€æœ‰æƒã€‚ cert-manager æ¥æ”¶åˆ° Challenge å¯¹è±¡çš„å›åº”ChallengeResponseåï¼Œä¼šå°†å…¶æ›´æ–°ä¸ºå·²è§£å†³çŠ¶æ€ã€‚è¯ä¹¦ç­¾å‘æœºæ„ä¼šæ£€æŸ¥æ‰€æœ‰çš„ Challenge å¯¹è±¡ï¼Œå¦‚æœå…¨éƒ¨é€šè¿‡éªŒè¯ï¼Œåˆ™ä¼šç­¾å‘è¯ä¹¦ã€‚ ç­¾å‘è¯ä¹¦å®Œæˆåï¼Œè¯ä¹¦ç­¾å‘æœºæ„ä¼šå°†è¯ä¹¦ä¿¡æ¯å†™å…¥ Secret å¯¹è±¡ï¼ŒåŒæ—¶å°† Order å¯¹è±¡æ ‡è®°ä¸ºå·²å®Œæˆã€‚è¯ä¹¦ä¿¡æ¯ç°åœ¨å¯ä»¥è¢«å…¶ä»–éƒ¨ç½²å¯¹è±¡ä½¿ç”¨ã€‚ +-------------+ | | | Ingress/ | | annotations | | | +------+------+ | | watch ingress change | v +-------------+ | | | Issuer/ | | ClusterIssuer | | | +------+------+ | | Create CertificateRequest | v +------+------+ | | |CertificateRequest| | | +------+------+ | | Create Order | v +------+------+ | | | Order | | | +------+------+ | | Create Challenges | v +------+------+ | | | Challenge | | | +------+------+ | | Respond to Challenge | v +------+------+ | | |ChallengeResponse| | | +------+------+ | | Issue Certificate | v +------+------+ | | | Secret | | | +------+------+","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:2:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"ä¸€ã€å®‰è£…cert-manager https://cert-manager.io/docs/installation/ wget https://github.com/cert-manager/cert-manager/releases/download/v1.12.0/cert-manager.yamlæŸ¥çœ‹yamlæ–‡ä»¶ä¸­çš„é•œåƒ quay.io/jetstack/cert-manager-cainjector:v1.12.0 quay.io/jetstack/cert-manager-webhook:v1.12.0 quay.io/jetstack/cert-manager-controller:v1.12.0 quay.io/jetstack/cert-manager-acmesolver:v1.12.0","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"1.æ›¿æ¢é•œåƒæ–‡ä»¶ sed -i 's#quay.io\\/jetstack#harbor.ceamg.com\\/baseimages#g' /yaml/cert-manager/cert-manager.yaml","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:3:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"2.æ‰§è¡Œyamlæ–‡ä»¶å®‰è£… kubectl apply -f cert-manager.yaml","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:3:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"3.æŸ¥çœ‹podè¿è¡Œæƒ…å†µ root@k8s-made-01-32:/yaml/cert-manager# kubectl get pod -n cert-manager NAME READY STATUS RESTARTS AGE cert-manager-5c458b9858-gkxzv 1/1 Running 0 21s cert-manager-cainjector-6fd86f6d9d-w4vhv 1/1 Running 0 21s cert-manager-webhook-5f6c479b6b-mcs4r 1/1 Running 0 21s","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:3:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"äºŒã€åˆ›å»º cert-manager çš„è¯ä¹¦é¢å‘å®ä½“å¯¹è±¡ cert-manager çš„ Issuer å’Œ ClusterIssuer éƒ½æ˜¯ç”¨æ¥å®šä¹‰è¯ä¹¦é¢å‘çš„å®ä½“çš„èµ„æºå¯¹è±¡ã€‚ Issuer æ˜¯å‘½åç©ºé—´çº§åˆ«çš„èµ„æºï¼Œç”¨äºåœ¨å‘½åç©ºé—´å†…é¢å‘è¯ä¹¦ã€‚ä¾‹å¦‚ï¼Œå½“æ‚¨éœ€è¦ä½¿ç”¨è‡ªç­¾åè¯ä¹¦æ¥ä¿æŠ¤æ‚¨çš„æœåŠ¡ï¼Œæˆ–è€…ä½¿ç”¨ Letâ€™s Encrypt ç­‰å…¬å…±è¯ä¹¦é¢å‘æœºæ„æ¥é¢å‘è¯ä¹¦æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ Issuerã€‚ ClusterIssuer æ˜¯é›†ç¾¤çº§åˆ«çš„èµ„æºï¼Œç”¨äºåœ¨æ•´ä¸ªé›†ç¾¤å†…é¢å‘è¯ä¹¦ã€‚ä¾‹å¦‚ï¼Œå½“æ‚¨éœ€è¦ä½¿ç”¨å…¬å¸çš„å†…éƒ¨ CA æ¥é¢å‘è¯ä¹¦æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ ClusterIssuerã€‚ çŸ¥é“ä¸¤è€…ä¹‹é—´çš„åŒºåˆ«ä¹‹åï¼Œä½ å°±å¯ä»¥æ ¹æ®è‡ªå·±çš„ä½¿ç”¨æƒ…å†µæ¥å†³å®šè‡ªå·±çš„ issuer çš„ç±»å‹ã€‚ è¿™é‡Œåˆ—å‡ºå‡ ç§å¸¸ç”¨çš„ issuer ä½¿ç”¨æ¨¡æ¿ï¼š ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"1.åˆ›å»º staging ç¯å¢ƒçš„è¯ä¹¦é¢å‘è€… issuer apiVersion: cert-manager.io/v1 kind: Issuer metadata: name: letsencrypt-staging spec: acme: # The ACME server URL server: https://acme-staging-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: xxx@qq.com #æ­¤å¤„å¡«å†™ä½ çš„é‚®ç®±åœ°å€ # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-staging # Enable the HTTP-01 challenge provider solvers: - http01: ingress: class: nginx ä½¿ç”¨ staging ç¯å¢ƒé¢å‘çš„è¯ä¹¦æ— æ³•æ­£å¸¸åœ¨å…¬ç½‘ä½¿ç”¨ï¼Œéœ€è¦æœ¬åœ°æ·»åŠ å—ä¿¡ä»»æ ¹è¯ä¹¦ ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:4:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"2.åˆ›å»º prod ç¯å¢ƒçš„è¯ä¹¦é¢å‘è€… issuer apiVersion: cert-manager.io/v1 kind: Issuer metadata: name: letsencrypt-prod spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration æ¬¢è¿å…³æ³¨Â·äº‘åŸç”Ÿç”Ÿæ€åœˆ email: xxx@qq.com # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-prod # Enable the HTTP-01 challenge provider solvers: - http01: ingress: class: nginx","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:4:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"3.åˆ›å»º staging ç¯å¢ƒçš„è¯ä¹¦é¢å‘è€… ClusterIssuer apiVersion: cert-manager.io/v1 kind: ClusterIssuer metadata: name: letsencrypt-staging spec: acme: # The ACME server URL server: https://acme-staging-v02.api.letsencrypt.org/directory # Email address used for ACME registration æ¬¢è¿å…³æ³¨Â·äº‘åŸç”Ÿç”Ÿæ€åœˆ email: xxx@qq.com # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-staging # Enable the HTTP-01 challenge provider solvers: - http01: ingress: class: nginx","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:4:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"4.åˆ›å»º Prod ç¯å¢ƒçš„è¯ä¹¦é¢å‘è€… ClusterIssuer apiVersion: cert-manager.io/v1 kind: ClusterIssuer metadata: name: letsencrypt-prod spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration æ¬¢è¿å…³æ³¨Â·äº‘åŸç”Ÿç”Ÿæ€åœˆ email: xxx@qq.com # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-prod # Enable the HTTP-01 challenge provider solvers: - http01: ingress: class: nginx","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:4:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"ä¸‰ã€åº”ç”¨å®è·µæµ‹è¯• ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:5:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"1.åˆ›å»ºä¸€ä¸ªé›†ç¾¤çº§çš„ç­¾å‘æœºæ„ apiVersion: cert-manager.io/v1 kind: ClusterIssuer metadata: name: letsencrypt-prod1234 spec: acme: server: https://acme-v02.api.letsencrypt.org/directory email: zxx@ceamg.com privateKeySecretRef: name: letsencrypt-prod1234 solvers: - http01: ingress: class: nginxè¯´æ˜ï¼š metadata.name æ˜¯æˆ‘ä»¬åˆ›å»ºçš„ç­¾å‘æœºæ„çš„åç§°ï¼Œåé¢æˆ‘ä»¬åˆ›å»ºè¯ä¹¦çš„æ—¶å€™ä¼šå¼•ç”¨å®ƒ spec.acme.email æ˜¯ä½ è‡ªå·±çš„é‚®ç®±ï¼Œè¯ä¹¦å¿«è¿‡æœŸçš„æ—¶å€™ä¼šæœ‰é‚®ä»¶æé†’ï¼Œä¸è¿‡ cert-manager ä¼šåˆ©ç”¨ acme åè®®è‡ªåŠ¨ç»™æˆ‘ä»¬é‡æ–°é¢å‘è¯ä¹¦æ¥ç»­æœŸ spec.acme.server æ˜¯ acme åè®®çš„æœåŠ¡ç«¯ï¼Œæˆ‘ä»¬è¿™é‡Œç”¨ Letâ€™s Encryptï¼Œè¿™ä¸ªåœ°å€å°±å†™æ­»æˆè¿™æ ·å°±è¡Œ spec.acme.privateKeySecretRef æŒ‡ç¤ºæ­¤ç­¾å‘æœºæ„çš„ç§é’¥å°†è¦å­˜å‚¨åˆ°å“ªä¸ª Secret å¯¹è±¡ä¸­ï¼Œåç§°ä¸é‡è¦ spec.acme.http01 è¿™é‡ŒæŒ‡ç¤ºç­¾å‘æœºæ„ä½¿ç”¨ HTTP-01 çš„æ–¹å¼è¿›è¡Œ acme åè®® (è¿˜å¯ä»¥ç”¨ DNS æ–¹å¼ï¼Œacme åè®®çš„ç›®çš„æ˜¯è¯æ˜è¿™å°æœºå™¨å’ŒåŸŸåéƒ½æ˜¯å±äºä½ çš„ï¼Œç„¶åæ‰å‡†è®¸ç»™ä½ é¢å‘è¯ä¹¦) æ‰§è¡Œå‘å¸ƒå‘½ä»¤ kubectl apply -f cluster-issuer.yaml","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:5:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"2.é…ç½®dnsåŸŸåè§£æ ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:5:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"3. åˆ›å»ºè¯ä¹¦èµ„æº apiVersion: cert-manager.io/v1 kind: Certificate metadata: name: k8s-ceamg-com-cert namespace: default annotations: cert-manager.io/issue-temporary-certificate: \"true\" spec: secretName: k8s-ceamg-com-tls issuerRef: name: letsencrypt-prod1234 kind: ClusterIssuer duration: 2160h renewBefore: 360h dnsNames: - k8s.ceamg.comè¯´æ˜ï¼š spec.secretName æŒ‡ç¤ºè¯ä¹¦æœ€ç»ˆå­˜åˆ°å“ªä¸ª Secret ä¸­ spec.issuerRef.kind å€¼ä¸º ClusterIssuer è¯´æ˜ç­¾å‘æœºæ„ä¸åœ¨æœ¬ namespace ä¸‹ï¼Œè€Œæ˜¯åœ¨å…¨å±€ spec.issuerRef.name æˆ‘ä»¬åˆ›å»ºçš„ç­¾å‘æœºæ„çš„åç§° (ClusterIssuer.metadata.name) spec.dnsNames æŒ‡ç¤ºè¯¥è¯ä¹¦çš„å¯ä»¥ç”¨äºå“ªäº›åŸŸå,ä¸åŸŸåè§£æçš„ä¸€è‡´ renewBefore å­—æ®µæ¥æ§åˆ¶è¯ä¹¦åˆ°æœŸå‰å¤šä¹…ä¼šè¢«æ›´æ–° durationå­—æ®µæ¥æŒ‡å®šè‡ªç­¾åè¯ä¹¦çš„æœŸé™ kubectl apply -f Certificate.yaml ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:5:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"4. æŸ¥çœ‹cert-managerè¿è¡Œæƒ…å†µ kubectl logs -f $(kubectl get pods -n cert-manager | grep cert-manager | grep -v 'cainjector\\|webhook' | awk '{print $1}') -n cert-managerå½“ç„¶ï¼Œä¹Ÿå¯ä»¥æŸ¥çœ‹ä¸´æ—¶ç”Ÿæˆçš„ä¸“é—¨éªŒè¯è¯ä¹¦çš„ Ingress å¯¹è±¡çš„è¿è¡Œæƒ…å†µ ä¸´æ—¶å¯¹è±¡cm-acme-http-solver-xxxxä»åˆ›å»ºåˆ°æ¶ˆäº¡çš„è¿‡ç¨‹ kubectl get pod -A | grep \"cm*\"æŸ¥çœ‹certificateåˆ›å»ºç»“æœ root@k8s-made-01-32:/etc/kubeasz/clusters/xx-prod# kubectl get certificate NAME READY SECRET AGE k8s-ceamg-com-cert True k8s-ceamg-com-tls 1hå½“READYä¸ºTrueæ—¶å³ä¸ºæˆåŠŸï¼Œè¯¦ç»†å¯çœ‹cert-managerè¿è¡Œæ—¥å¿—ã€‚ ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:5:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"5.é—®é¢˜æ’æŸ¥ é—®é¢˜1ï¼š kubectl logs -n cert-manager cert-manager-webhook-5f6c479b6b-mcs4r I0616 06:12:56.720433 1 logs.go:59] http: TLS handshake error from 10.48.87.0:34244: EOFè§£å†³æ–¹æ³• åœ¨Ingress æˆ– Certificate resource æ·»åŠ å£°æ˜ cert-manager.io/issue-temporary-certificate: \"true\" acme.cert-manager.io/http01-edit-in-place: \"true\" #é¢å‘ä¸€ä¸ªä¸´æ—¶çš„è‡ªç­¾åè¯ä¹¦åœ¨ï¼Œä¾›ingress controller åœ¨é¢å‘å®é™…è¯ä¹¦ä¹‹å‰ä½¿ç”¨é—®é¢˜2ï¼š kubectl logs -n cert-manager cert-manager-5c458b9858-gkxzv\rE0616 06:12:27.072543 1 sync.go:190] \"cert-manager/challenges: propagation check failed\" err=\"failed to perform self check GET request 'http://k8s.ceamg.com/.well-known/acme-challenge/OvQFFmEAO5016nAu1YC20RcgDtU2CsCPuoporE13ekw': Get \\\"http://k8s.ceamg.com/.well-known/acme-challenge/OvQFFmEAO5016nAu1YC20RcgDtU2CsCPuoporE13ekw\\\": dial tcp 10.1.0.32:80: connect: connection refused\" resource_name=\"k8s-ceamg-com-cert-9rw4s-2953330747-2092136088\" resource_namespace=\"default\" resource_kind=\"Challenge\" resource_version=\"v1\" dnsName=\"k8s.ceamg.com\" type=HTTP-01è§£å†³æ–¹æ³• 1.æ’æŸ¥DNSè§£æ 2.æ’æŸ¥å®¹å™¨å†…DNSæ˜¯å¦å¯ä»¥è§£æåˆ°åŸŸå #å¯ç”¨ä¸€ä¸ªbusybox pod æµ‹è¯•podç¯å¢ƒå†…æ˜¯å¦å¯ä»¥è§£æåˆ°åŸŸå\rkubectl run --image=busybox:1.28.1 --rm -it -- sh\r/ # ping k8s.ceamg.com\rPING k8s.ceamg.com (10.1.0.91): 56 data bytes\r64 bytes from 10.1.0.91: seq=0 ttl=63 time=0.377 ms\r64 bytes from 10.1.0.91: seq=1 ttl=63 time=0.366 ms3.æ’æŸ¥å¤–ç½‘é˜²ç«å¢™NATåœ°å€è½¬æ¢ç­–ç•¥ å°†å…¬ç½‘åœ°å€è½¬å‘åˆ°åç«¯Haproxyä»£ç†èŠ‚ç‚¹ï¼Œä¸”æœ‰åŒ¹é…æ•°ã€‚ 4.æ’æŸ¥WAFé˜²ç«å¢™ç«¯å£ç­–ç•¥ ACME è®¤è¯åªéœ€è¦æ”¾é€š80å’Œ443ç«¯å£å³å¯ 5.ä¾æ¬¡æ£€æŸ¥certificateã€challengesã€certificaterequests kubectl describe certificate k8s-ceamg-com-certkubectl describe challenges.acme.cert-manager.iokubectl describe certificaterequests.cert-manager.io","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:5:5","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"6.éƒ¨ç½²ä¸€ä¸ªæœåŠ¡æµ‹è¯•è¯ä¹¦ 1.å®‰è£…ingress-nginx Ingress-nginxè¯¦ç»†å®‰è£…è¿‡ç¨‹ è¿™é‡Œå› ä¸ºk8sç‰ˆæœ¬ä¸º1.26.2æ‰€ä»¥é€‰æ‹© V1.71ç‰ˆæœ¬ wget https://github.com/kubernetes/ingress-nginx/archive/refs/tag/controller-v1.7.1.tar.gz tar xvf controller-v1.7.1.tar.gz cd ingress-nginx-controller-v1.7.1/deploy/static/provider/baremetal/ #ä¿®æ”¹å½“å‰ç›®å½•ä¸‹çš„deploy.yamlï¼Œå°†é•œåƒä¿®æ”¹æœªå›½å†…é•œåƒæº cat deploy.yaml |grep image image: harbor.ceamg.com/k8s-base/ingress-nginx-controller:v1.7.1 image: harbor.ceamg.com/k8s-base/kube-webhook-certgen:v20230312 image: harbor.ceamg.com/k8s-base/kube-webhook-certgen:v202303121.1 æŒ‡å®šæ§åˆ¶å™¨NodePortåœ°å€ vim deploy.yaml apiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.7.1 name: ingress-nginx-controller namespace: ingress-nginx spec: ipFamilies: - IPv4 ipFamilyPolicy: SingleStack ports: - appProtocol: http name: http port: 80 protocol: TCP targetPort: http nodePort: 30020 - appProtocol: https name: https port: 443 protocol: TCP targetPort: https nodePort: 300211.2 æ‰§è¡Œå®‰è£… kubectl apply -f deploy.yaml amespace/ingress-nginx created serviceaccount/ingress-nginx created serviceaccount/ingress-nginx-admission created role.rbac.authorization.k8s.io/ingress-nginx created role.rbac.authorization.k8s.io/ingress-nginx-admission created clusterrole.rbac.authorization.k8s.io/ingress-nginx created clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created rolebinding.rbac.authorization.k8s.io/ingress-nginx created rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created configmap/ingress-nginx-controller created service/ingress-nginx-controller created service/ingress-nginx-controller-admission created deployment.apps/ingress-nginx-controller created job.batch/ingress-nginx-admission-create created job.batch/ingress-nginx-admission-patch created ingressclass.networking.k8s.io/nginx created validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created1.3 æŸ¥çœ‹podçŠ¶æ€ root@k8s-made-01-32:/etc/kubeasz/clusters/xx-prod# kubectl get pod -n ingress-nginx NAME READY STATUS RESTARTS AGE ingress-nginx-admission-create-qhk5g 0/1 Completed 0 12s ingress-nginx-admission-patch-qn9kc 0/1 Completed 0 12s ingress-nginx-controller-589f4f6875-drvlp 1/1 Running 0 12sroot@k8s-made-01-32:/etc/kubeasz/clusters/xx-prod# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller NodePort 10.68.201.220 \u003cnone\u003e 80:30020/TCP,443:30021/TCP 15s ingress-nginx-controller-admission ClusterIP 10.68.72.129 \u003cnone\u003e 443/TCP 15s1.4 è°ƒæ•´controller å‰¯æœ¬æ•° é»˜è®¤æƒ…å†µä¸‹ï¼Œingress-nginx-controlleråªæœ‰ä¸€ä¸ªå‰¯æœ¬ï¼Œå¯ä»¥æŒ‰éœ€è°ƒæ•´ã€‚ kubectl scale -n ingress-nginx deployment ingress-nginx-controller --replicas=3 deployment.apps/ingress-nginx-controller scaled -------------------------------------------------- kubectl get pod -n ingress-nginx NAME READY STATUS RESTARTS AGE ingress-nginx-admission-create-qhk5g 0/1 Completed 0 74s ingress-nginx-admission-patch-qn9kc 0/1 Completed 0 74s ingress-nginx-controller-589f4f6875-drvlp 1/1 Running 0 74s ingress-nginx-controller-589f4f6875-kw5t6 1/1 Running 0 34s ingress-nginx-controller-589f4f6875-pj6g2 1/1 Running 0 74sæŸ¥çœ‹pod è¿è¡Œä½ç½®åˆ†å¸ƒæƒ…å†µ kubectl get pod -n ingress-nginx -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES ingress-nginx-admission-create-qhk5g 0/1 Completed 0 3d12h 10.48.150.71 10.1.0.37 \u003cnone\u003e \u003cnone\u003e ingress-nginx-admission-patch-qn9kc 0/1 Completed 0 3d12h 10.48.245.19 10.1.0.35 \u003cnone\u003e \u003cnone\u003e ingress-nginx-controller-589f4f6875-drvlp 1/1 Running 0 2d22h 10.48.150.72 10.1.0.37 \u003cnone\u003e \u003cnone\u003e ingress-nginx-controller-589f4f6875-kw5t6 1/1 Running 0 5m22s 10.48.245.21 10.1.0.35 \u003cnone\u003e \u003cnone\u003e ingress-nginx-controller-589f4f6875-pj6g2 1/1 Running 0 3d12h 10.48.35.142 10.1.0.34 \u003cnone\u003e \u003cnone\u003eingress-ng","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:5:6","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"7.é€šè¿‡åŸŸåè®¿é—®æµ‹è¯• ","date":"2023-02-21","objectID":"/posts/kubernetes/primary/kubernetes-16/:5:7","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-Cert-Manager å®ç° K8s æœåŠ¡åŸŸåè¯ä¹¦è‡ªåŠ¨åŒ–ç»­ç­¾ (åå…­)","uri":"/posts/kubernetes/primary/kubernetes-16/"},{"categories":["Kubernetes"],"content":"1.å‘å¸ƒæ–¹å¼è§£è¯» ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"1.1 é‡‘ä¸é›€å‘å¸ƒ é‡‘ä¸é›€å‘å¸ƒè¿™ä¸ªæœ¯è¯­æºè‡ª20ä¸–çºªåˆæœŸï¼Œå½“æ—¶è‹±å›½çš„ç…¤çŸ¿å·¥äººåœ¨ä¸‹äº•é‡‡çŸ¿ä¹‹å‰ï¼Œä¼šæŠŠç¬¼å…»çš„é‡‘ä¸é›€æºå¸¦åˆ°çŸ¿äº•ä¸­ï¼Œå¦‚æœçŸ¿äº•ä¸­ä¸€æ°§åŒ–ç¢³ç­‰æœ‰æ¯’æ°”ä½“çš„æµ“åº¦è¿‡é«˜ï¼Œåœ¨å½±å“çŸ¿å·¥ä¹‹å‰ï¼Œé‡‘ä¸é›€ç›¸æ¯”äººç±»è¡¨ç°çš„æ›´åŠ æ•æ„Ÿå¿«é€Ÿï¼Œé‡‘ä¸é›€ä¸­æ¯’ä¹‹åï¼Œç…¤çŸ¿å·¥äººå°±çŸ¥é“è¯¥ç«‹åˆ»æ’¤ç¦»ã€‚é‡‘ä¸é›€å‘å¸ƒæ˜¯åœ¨å°†æ•´ä¸ªè½¯ä»¶çš„æ–°ç‰ˆæœ¬å‘å¸ƒç»™æ‰€æœ‰ç”¨æˆ·ä¹‹å‰ï¼Œå…ˆå‘å¸ƒç»™éƒ¨åˆ†ç”¨æˆ·ï¼Œç”¨çœŸå®çš„å®¢æˆ·æµé‡æ¥æµ‹è¯•ï¼Œä»¥ä¿è¯è½¯ä»¶ä¸ä¼šå‡ºç°ä¸¥é‡é—®é¢˜ï¼Œé™ä½å‘å¸ƒé£é™©ã€‚ åœ¨å®è·µä¸­ï¼Œé‡‘ä¸é›€å‘å¸ƒä¸€èˆ¬ä¼šå…ˆå‘å¸ƒåˆ°ä¸€ä¸ªå°æ¯”ä¾‹çš„æœºå™¨ï¼Œæ¯”å¦‚ 2% çš„æœåŠ¡å™¨åšæµé‡éªŒè¯ï¼Œç„¶åä»ä¸­å¿«é€Ÿè·å¾—åé¦ˆï¼Œæ ¹æ®åé¦ˆå†³å®šæ˜¯æ‰©å¤§å‘å¸ƒè¿˜æ˜¯å›æ»šã€‚é‡‘ä¸é›€å‘å¸ƒé€šå¸¸ä¼šç»“åˆç›‘æ§ç³»ç»Ÿï¼Œé€šè¿‡ç›‘æ§æŒ‡æ ‡ï¼Œè§‚å¯Ÿé‡‘ä¸é›€æœºå™¨çš„å¥åº·çŠ¶å†µã€‚å¦‚æœé‡‘ä¸é›€æµ‹è¯•é€šè¿‡ï¼Œåˆ™æŠŠå‰©ä½™çš„æœºå™¨å…¨éƒ¨å‡çº§æˆæ–°ç‰ˆæœ¬ï¼Œå¦åˆ™å›æ»šä»£ç ã€‚ ä¼˜åŠ¿ï¼š å¯¹ç”¨æˆ·ä½“éªŒå½±å“è¾ƒå°ï¼Œåœ¨é‡‘ä¸é›€å‘å¸ƒè¿‡ç¨‹ä¸­ï¼Œåªæœ‰å°‘é‡ç”¨æˆ·ä¼šå—å½±å“ å‘å¸ƒå®‰å…¨èƒ½å¤Ÿå¾—åˆ°ä¿éšœ åŠ£åŠ¿ï¼š é‡‘ä¸é›€çš„æœºå™¨æ•°é‡æ¯”è¾ƒå°‘, æœ‰ä¸€äº›é—®é¢˜å¹¶ä¸èƒ½å¤Ÿæš´éœ²å‡ºæ¥ é€‚ç”¨åœºæ™¯ï¼š ç›‘æ§æ¯”è¾ƒå®Œå¤‡ä¸”ä¸å‘å¸ƒç³»ç»Ÿé›†æˆ ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:1:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"1.2 ç°åº¦/æ»šåŠ¨å‘å¸ƒ ç°åº¦å‘å¸ƒæ˜¯é‡‘ä¸é›€å‘å¸ƒçš„å»¶ä¼¸ï¼Œæ˜¯å°†å‘å¸ƒåˆ†æˆä¸åŒçš„é˜¶æ®µ/æ‰¹æ¬¡ï¼Œæ¯ä¸ªé˜¶æ®µ/æ‰¹æ¬¡çš„ç”¨æˆ·æ•°é‡é€çº§å¢åŠ ã€‚å¦‚æœæ–°ç‰ˆæœ¬åœ¨å½“å‰é˜¶æ®µæ²¡æœ‰å‘ç°é—®é¢˜ï¼Œå°±å†å¢åŠ ç”¨æˆ·æ•°é‡è¿›å…¥ä¸‹ä¸€ä¸ªé˜¶æ®µï¼Œç›´è‡³æ‰©å±•åˆ°å…¨éƒ¨ç”¨æˆ·ã€‚ ç°åº¦å‘å¸ƒå¯ä»¥å‡å°å‘å¸ƒé£é™©ï¼Œæ˜¯ä¸€ç§é›¶å®•æœºæ—¶é—´çš„å‘å¸ƒç­–ç•¥ã€‚å®ƒé€šè¿‡åˆ‡æ¢çº¿ä¸Šå¹¶å­˜ç‰ˆæœ¬ä¹‹é—´çš„è·¯ç”±æƒé‡ï¼Œé€æ­¥ä»ä¸€ä¸ªç‰ˆæœ¬åˆ‡æ¢ä¸ºå¦ä¸€ä¸ªç‰ˆæœ¬ã€‚æ•´ä¸ªå‘å¸ƒè¿‡ç¨‹ä¼šæŒç»­æ¯”è¾ƒé•¿çš„æ—¶é—´, åœ¨è¿™æ®µæ—¶é—´å†…ï¼Œæ–°æ—§ä»£ç å…±å­˜ï¼Œæ‰€ä»¥åœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œéœ€è¦è€ƒè™‘ç‰ˆæœ¬ä¹‹é—´çš„å…¼å®¹æ€§ï¼Œæ–°æ—§ä»£ç å…±å­˜ä¸èƒ½å½±å“åŠŸèƒ½å¯ç”¨æ€§å’Œç”¨æˆ·ä½“éªŒã€‚å½“æ–°ç‰ˆæœ¬ä»£ç å‡ºç°é—®é¢˜æ—¶ï¼Œç°åº¦å‘å¸ƒèƒ½å¤Ÿæ¯”è¾ƒå¿«çš„å›æ»šåˆ°è€ç‰ˆæœ¬çš„ä»£ç ä¸Šã€‚ ç»“åˆç‰¹æ€§å¼€å…³ç­‰æŠ€æœ¯ï¼Œç°åº¦å‘å¸ƒå¯ä»¥å®ç°æ›´å¤æ‚çµæ´»çš„å‘å¸ƒç­–ç•¥ã€‚ ä¼˜åŠ¿ï¼š ç”¨æˆ·ä½“éªŒå½±å“æ¯”è¾ƒå°, ä¸éœ€è¦åœæœºå‘å¸ƒ èƒ½å¤Ÿæ§åˆ¶å‘å¸ƒé£é™© åŠ£åŠ¿ï¼š å‘å¸ƒæ—¶é—´ä¼šæ¯”è¾ƒé•¿ éœ€è¦å¤æ‚çš„å‘å¸ƒç³»ç»Ÿå’Œè´Ÿè½½å‡è¡¡å™¨ éœ€è¦è€ƒè™‘æ–°æ—§ç‰ˆæœ¬å…±å­˜æ—¶çš„å…¼å®¹æ€§ é€‚ç”¨åœºæ™¯ï¼š é€‚åˆå¯ç”¨æ€§è¾ƒé«˜çš„ç”Ÿäº§ç¯å¢ƒå‘å¸ƒ ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:1:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"1.3 æ»šåŠ¨å‘å¸ƒ kubernetesé»˜è®¤çš„æ›´æ–°ç­–ç•¥ä¹Ÿå°±æ˜¯ä¸»æµå‘å¸ƒæ–¹æ¡ˆæ˜¯æ»šåŠ¨æ›´æ–°ã€‚ æ¯æ¬¡åªå‡çº§ä¸€ä¸ªæˆ–å¤šä¸ªæœåŠ¡ï¼Œå‡çº§å®ŒæˆååŠ å…¥ç”Ÿäº§ç¯å¢ƒï¼Œ ä¸æ–­æ‰§è¡Œè¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°é›†ç¾¤ä¸­çš„å…¨éƒ¨æ—§ç‰ˆå‡çº§æ–°ç‰ˆæœ¬ã€‚ Kubernetesçš„é»˜è®¤å‘å¸ƒç­–ç•¥ã€‚ ç‰¹ç‚¹ï¼šç”¨æˆ·æ— æ„ŸçŸ¥ï¼Œå¹³æ»‘è¿‡æ¸¡ ç¼ºç‚¹ï¼š éƒ¨ç½²å‘¨æœŸé•¿ï¼ˆéœ€è¦å¥åº·æ£€æŸ¥ï¼Œç­‰å®ƒå‡†å¤‡å°±ç»ªï¼Œç„¶åå‡çº§ä¸‹ä¸€ä¸ªï¼Œå¥åº·æ£€æŸ¥è¿˜æ˜¯éœ€è¦èŠ±è´¹ä¸€äº›æ—¶é—´çš„ï¼‰ å‘å¸ƒç­–ç•¥è¾ƒå¤æ‚ ä¸æ˜“å›æ»š æœ‰å½±å“èŒƒå›´è¾ƒå¤§ ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:1:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"2.ç‰ˆæœ¬å‡çº§åŠå›æ»š ** åŸç†**ï¼šåœ¨æŒ‡å®šçš„deployment æ§åˆ¶å™¨ä¸­é€šè¿‡kubectl set image æŒ‡å®šæ–°ç‰ˆæœ¬çš„é•œåƒtag,æ¥å®ç°ä»£ç æ›´æ–°çš„ç›®çš„ã€‚** ä¾‹å¦‚**:æ›´æ–°deploymentä¸­çš„2ä¸ªpod,busybox ï¼Œpodæ›´æ–°åˆ°2.1ç‰ˆæœ¬,nginx podæ›´æ–°åˆ°1.21.1ç‰ˆæœ¬ ã€‚ kubectl set image deployment/nginx busybox=busybox:v2.1 nginx=nginx:1.21.1æ›´æ–°æ–¹æ³•æœ‰2ç§: rolling update æ»šåŠ¨æ›´æ–° å…ˆåˆ›å»ºä¸€æ‰¹æ–°PODå†åˆ é™¤ä¸€æ‰¹æ—§Pod,å‡çº§å®Œæˆåå†å‡çº§ä¸‹ä¸€æ‰¹pod.(ä¸€æ‰¹çš„é»˜è®¤å€¼æ˜¯25%çš„podæ•°) ä¼˜ç‚¹:ä¸šåŠ¡ä¸ä¼šä¸­æ–­. ç¼ºç‚¹:åŒä¸€æ—¶é—´å†…ä¼šæœ‰2ä¸ªä¸åŒç‰ˆæœ¬åŒæ—¶å­˜åœ¨ã€‚ recreate é‡å»ºæ›´æ–° å…ˆåˆ é™¤æ‰€æœ‰Podå†é‡æ–°åˆ›å»ºPod. ä¼˜ç‚¹:ä¸ä¼šåŒæ—¶æœ‰å¤šä¸ªç‰ˆæœ¬å­˜åœ¨ ç¼ºç‚¹:åœ¨æ—§ç‰ˆæœ¬åˆ é™¤,æ–°ç‰ˆæœ¬åˆ›å»ºå®Œæˆä¹‹å‰,è¯¥æœåŠ¡æ— æ³•è®¿é—®ã€‚ ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"1.1 æ›´æ–°ç¤ºä¾‹ç¯å¢ƒå‡†å¤‡ å‡†å¤‡10ä¸ªpodçš„deployment,å‘½åç©ºé—´ä¸ºcicd kind: Deployment apiVersion: apps/v1 metadata: labels: app: tomcat-app1-deployment-update name: tomcat-app1-deployment namespace: cicd spec: replicas: 10 selector: matchLabels: app: update-tomcat-app1-selector template: metadata: labels: app: update-tomcat-app1-selector spec: containers: - name: update-tomcat-app1-container image: harbor.ceamg.com/xinweb11/tomcat-app1:V2.0 ports: - containerPort: 8080 protocol: TCP name: http --- kind: Service apiVersion: v1 metadata: labels: app: update-tomcat-app1-service-label name: update-tomcat-app1-service namespace: cicd spec: type: NodePort ports: - name: http port: 80 protocol: TCP targetPort: 8080 nodePort: 30022 selector: app: update-tomcat-app1-selectorå¯ä»¥çœ‹åˆ°tomcat-app1-deployment å‰¯æœ¬æ•°æ˜¯10/10 root@master01[15:50:47]~/cicd #:vim test-tomcatapp1-deploy.yaml root@master01[15:51:10]~/cicd #:kubectl apply -f test-tomcatapp1-deploy.yaml deployment.apps/tomcat-app1-deployment created service/update-tomcat-app1-service created root@master01[15:51:12]~/cicd #: root@master01[15:51:12]~/cicd #: root@master01[15:51:12]~/cicd #:kubectl get pod -n cicd NAME READY STATUS RESTARTS AGE tomcat-app1-deployment-64bd79b5b7-49t6g 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-4gz9n 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-829jc 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-fclsh 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-jnkk6 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-ngxsl 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-nscqt 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-td72k 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-wh98d 1/1 Running 0 7s tomcat-app1-deployment-64bd79b5b7-wr8q6 1/1 Running 0 7s root@master01[15:51:19]~/cicd #:kubectl get deployments.apps -n cicd NAME READY UP-TO-DATE AVAILABLE AGE tomcat-app1-deployment 10/10 10 10 2m1s","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:2:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"1.2 æ›´æ–°ç‰ˆæœ¬ æ»šåŠ¨ç­–ç•¥ maxSurge: deploy åœ¨æ›´æ–°è¿‡ç¨‹ä¸­ï¼ŒPod æ•°é‡å¯ä»¥è¶…è¿‡å®šä¹‰çš„æ•°é‡ï¼Œè¶…è¿‡çš„æœ€å¤§çš„å€¼å°±å« maxSurgeã€‚è¯¥å€¼å¯ä»¥æ˜¯ä¸€ä¸ªç™¾åˆ†æ¯”ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªå…·ä½“çš„æ•°å­—ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¥å€¼ä¸º 25%ã€‚ maxUnavailable: å’ŒæœŸæœ›readyçš„å‰¯æœ¬æ•°æ¯”ï¼Œä¸å¯ç”¨å‰¯æœ¬æ•°æœ€å¤§æ¯”ä¾‹ï¼ˆæˆ–æœ€å¤§å€¼ï¼‰ï¼Œè¿™ä¸ªå€¼è¶Šå°ï¼Œè¶Šèƒ½ä¿è¯æœåŠ¡ç¨³å®šï¼Œæ›´æ–°è¶Šå¹³æ»‘ï¼› kind: Deployment apiVersion: apps/v1 metadata: labels: app: tomcat-app1-deployment-update name: tomcat-app1-deployment namespace: cicd spec: strategy: rollingUpdate: maxSurge: 0 #åœ¨æ›´æ–°è¿‡ç¨‹ä¸­,Pod æ•°é‡å¯ä»¥è¶…è¿‡å®šä¹‰çš„æ•°é‡5ä¸ª maxUnavailable: 1 #åœ¨æ›´æ–°è¿‡ç¨‹ä¸­ï¼Œä¸å¯ç”¨å‰¯æœ¬æ•° replicas: 10 selector: matchLabels: app: update-tomcat-app1-selector template: metadata: labels: app: update-tomcat-app1-selector spec: containers: - name: update-tomcat-app1-container image: harbor.ceamg.com/xinweb11/tomcat-app1:1.9 ports: - containerPort: 8080 protocol: TCP name: http --- kind: Service apiVersion: v1 metadata: labels: app: update-tomcat-app1-service-label name: update-tomcat-app1-service namespace: cicd spec: type: NodePort ports: - name: http port: 80 protocol: TCP targetPort: 8080 nodePort: 30022 selector: app: update-tomcat-app1-selectorkubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.1 --namespace=cicd --record=true root@master01[16:16:23]~/cicd #:kubectl get pod -n cicd NAME READY STATUS RESTARTS AGE tomcat-app1-deployment-64bd79b5b7-2q7mk 1/1 Running 0 3m49s tomcat-app1-deployment-64bd79b5b7-4mnhr 1/1 Running 0 4m51s tomcat-app1-deployment-64bd79b5b7-55x5h 1/1 Running 0 4m51s tomcat-app1-deployment-64bd79b5b7-csxs2 1/1 Running 0 3m49s tomcat-app1-deployment-64bd79b5b7-h76pj 1/1 Running 0 3m49s tomcat-app1-deployment-64bd79b5b7-h9qcw 1/1 Running 0 4m51s tomcat-app1-deployment-64bd79b5b7-hvv2w 1/1 Running 0 4m51s tomcat-app1-deployment-64bd79b5b7-l6hxc 1/1 Running 0 3m49s tomcat-app1-deployment-64bd79b5b7-wlhzx 1/1 Running 0 4m51s tomcat-app1-deployment-788dbfc749-hjlg2 0/1 ContainerCreating 0 2så› ä¸ºå°† maxSurgeï¼Œæœ€å¤§è¶…å‡ºæ•°é‡è®¾ç½®æˆäº† 0ï¼Œæ‰€ä»¥æ— è®ºå¦‚ä½•éƒ½ä¸ä¼šè¶…è¿‡å®šä¹‰çš„æ•°é‡ã€‚éƒ½æ˜¯å…ˆå‡å°‘å†æ–°å¢ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ›´æ–°è¿‡ç¨‹ä¸­ï¼Œåªä¼šå‡ºç°ç¼ºå°‘æœåŠ¡æ•°é‡çš„æƒ…å†µï¼Œä¸ä¼šå¤šã€‚ ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:2:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"1.3 å›æ»šç‰ˆæœ¬ é€šè¿‡å‘½ä»¤kubectl rollout historyæŸ¥çœ‹æ›´æ–°å†å²,å¯ä»¥çœ‹åˆ°é™¤äº†ç¬¬ä¸€æ¬¡éƒ¨ç½²å¤–æˆ‘ä»¬è¿˜åšäº†3æ¬¡å‡çº§.å½“å‰ç‰ˆæœ¬æ˜¯v3. root@master01[10:26:06]~ #:kubectl rollout history deployment -n cicd tomcat-app1-deployment deployment.apps/tomcat-app1-deployment REVISION CHANGE-CAUSE 2 \u003cnone\u003e 3 \u003cnone\u003e 4 \u003cnone\u003e 5 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.1 --namespace=cicd --record=true 6 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.2 --namespace=cicd --record=true 7 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.3 --namespace=cicd --record=true1.3.1 å›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬ å‡è®¾ç°åœ¨çš„V3ç‰ˆæœ¬æœ‰é—®é¢˜,éœ€è¦å›æ»šåˆ°v2çš„çŠ¶æ€ root@master01[10:26:14]~ #:kubectl rollout undo deployment -n cicd tomcat-app1-deployment deployment.apps/tomcat-app1-deployment rolled back root@master01[10:42:21]~ #:kubectl rollout history deployment -n cicd tomcat-app1-deployment deployment.apps/tomcat-app1-deployment REVISION CHANGE-CAUSE 2 \u003cnone\u003e 3 \u003cnone\u003e 4 \u003cnone\u003e 5 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.1 --namespace=cicd --record=true 7 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.3 --namespace=cicd --record=true 8 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.2 --namespace=cicd --record=true å¯è§æœ€æ–°ç‰ˆæœ¬åˆå›åˆ°äº†2.2ç‰ˆæœ¬ root@master01[10:44:28]~ #:kubectl describe pod -n cicd tomcat-app1-deployment-b6bbbdfd7-f7r74 | grep \"Image\" Image: harbor.ceamg.com/xinweb11/tomcat-app1:2.21.3.2 å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬ é‚£ä¹ˆæœ‰æ²¡æœ‰åŠæ³•ç›´æ¥å›æ»šåˆ°2.1çš„ç‰ˆæœ¬å‘¢?é™¤äº†ç”¨set imageå°†ç‰ˆæœ¬æŒ‡å®šåˆ°æƒ³è¦çš„ç‰ˆæœ¬å¤–æ˜¯å¦å¯ä»¥ç”¨rolloutå®ç°å›æ»šå‘¢? deployment.apps/tomcat-app1-deployment REVISION CHANGE-CAUSE 2 \u003cnone\u003e 3 \u003cnone\u003e 4 \u003cnone\u003e 5 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.1 --namespace=cicd --record=true 7 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.3 --namespace=cicd --record=true 8 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.2 --namespace=cicd --record=trueç­”æ¡ˆæ˜¾ç„¶æ˜¯å¯ä»¥çš„,ä½¿ç”¨å‚æ•°--to-versionå°±å¯å°†ç‰ˆæœ¬å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬ root@master01[10:54:49]~ #:kubectl rollout undo --to-revision=5 deploy tomcat-app1-deployment -n cicd deployment.apps/tomcat-app1-deployment rolled back ----------------------------------------------------------------------------------------------------- root@master01[10:59:23]~ #:kubectl rollout history deployment -n cicd tomcat-app1-deployment deployment.apps/tomcat-app1-deployment REVISION CHANGE-CAUSE 2 \u003cnone\u003e 3 \u003cnone\u003e 4 \u003cnone\u003e 7 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.3 --namespace=cicd --record=true 8 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.2 --namespace=cicd --record=true 9 kubectl set image deployment/tomcat-app1-deployment update-tomcat-app1-container=harbor.ceamg.com/xinweb11/tomcat-app1:2.1 --namespace=cicd --record=true ------------------------------------------------------------------------------------------------------ #æŸ¥çœ‹ç‰ˆæœ¬ root@master01[11:00:50]~ #:kubectl describe pod -n cicd tomcat-app1-deployment-6c57484478-2h4d6 | grep \"Image\" Image: harbor.ceamg.com/xinweb11/tomcat-app1:2.1 root@master01[11:01:14]~ #:kubectl rollout undo --to-revision=7 deploy tomcat-app1-deployment -n cicd deployment.apps/tomcat-app1-deployment rolled backhttp://10.1.0.101/mi/ ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:2:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"3. K8S åŸºäºJenkins CICD ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"3.1 å®‰è£…Gitlab 3.1.1å‡†å¤‡ç¯å¢ƒ 3.1.1.1 åˆ›å»ºnfså…±äº«ç›®å½• åœ¨nfsæœåŠ¡å™¨åˆ›å»ºå…±äº«ç›®å½•ï¼Œéƒ¨ç½²çš„gitlibä½¿ç”¨å…±äº«ç›®å½•æ¥è¿›è¡ŒæŒä¹…åŒ– $ mkdir -p /data/k8s/gitlab/config $ mkdir -p /data/k8s/gitlab/logs $ mkdir -p /data/k8s/gitlab/data3.1.1.2 æ·»åŠ åˆ°å…±äº«ç›®å½• $ vim /etc/exports /data/k8s/gitlab/config 10.1.0.0/8(rw,sync,no_root_squash) /data/k8s/gitlab/logs 10.1.0.0/8(rw,sync,no_root_squash) /data/k8s/gitlab/data 10.1.0.0/8(rw,sync,no_root_squash)3.1.1.2 é‡å¯æœåŠ¡ $ /data/k8s/gitlab #:systemctl restart nfs-server.service #æˆ–è€… $ exportfs -r3.1.2 éƒ¨ç½²Gitlab 3.1.2.1 å‡†å¤‡éƒ¨ç½²yamlæ–‡ä»¶ apiVersion: v1 kind: Service metadata: name: gitlab-cicd namespace: cicd spec: type: NodePort ports: # Portä¸Šçš„æ˜ å°„ç«¯å£ - port: 443 targetPort: 34443 name: gitlab443 - port: 80 targetPort: 38880 name: gitlab80 - port: 22 targetPort: 32220 name: gitlab22 selector: app: gitlab --- apiVersion: apps/v1 kind: Deployment metadata: name: gitlab-deploy spec: selector: matchLabels: app: gitlab revisionHistoryLimit: 2 #revisionHistoryLimit å¯ä»¥å®šä¹‰ä¿ç•™çš„å‡çº§è®°å½•æ•°ã€‚ template: metadata: labels: app: gitlab spec: containers: # åº”ç”¨çš„é•œåƒ - image: harbor.ceamg.com/k8s-base/gitlab-ce:15.6.8 name: gitlab imagePullPolicy: IfNotPresent # åº”ç”¨çš„å†…éƒ¨ç«¯å£ ports: - containerPort: 443 name: gitlab443 - containerPort: 80 name: gitlab80 - containerPort: 22 name: gitlab22 volumeMounts: # gitlabæŒä¹…åŒ– - name: gitlab-persistent-config mountPath: /etc/gitlab - name: gitlab-persistent-logs mountPath: /var/log/gitlab - name: gitlab-persistent-data mountPath: /var/opt/gitlab volumes: # ä½¿ç”¨nfsäº’è”ç½‘å­˜å‚¨ - name: gitlab-persistent-config nfs: server: 10.1.0.38 path: /data/k8s/gitlab/config - name: gitlab-persistent-logs nfs: server: 10.1.0.38 path: /data/k8s/gitlab/logs - name: gitlab-persistent-data nfs: server: 10.1.0.38 path: /data/k8s/gitlab/data3.1.2.2 æ‰§è¡Œéƒ¨ç½² $ kubectl apply -f gitlib-ce.yaml3.1.2.3 æŸ¥çœ‹éƒ¨ç½²ç»“æœ $ kubectl get svc -n cicd NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE gitlab-cicd NodePort 10.10.138.150 \u003cnone\u003e 443:34443/TCP,80:38880/TCP,22:32220/TCP 16s update-tomcat-app1-service NodePort 10.10.31.155 \u003cnone\u003e 80:30022/TCP 6d23hhttp://10.1.0.31:38880/users/sign_in 3.1.2.4 åˆå§‹ç”¨æˆ·åå’Œå¯†ç  åˆå§‹ç”¨æˆ·åä¸ºrootï¼Œåˆå§‹å¯†ç gitlibè‡ªåŠ¨åˆ›å»ºï¼Œåœ¨å¦‚ä¸‹æ–‡ä»¶ä¸­ï¼š $ cat /etc/gitlab/initial_root_passwordç”±äºæ˜¯å®¹å™¨éƒ¨ç½²ï¼Œæ‰€ä»¥ï¼Œéœ€è¦è¿›å…¥åˆ°å®¹å™¨ä¸­ï¼Œæ‰¾åˆ°å¯¹åº”æ–‡ä»¶ï¼Œæ‹·è´å¯†ç è¿›è¡Œç™»å½•ã€‚æ–‡ä»¶å†…å®¹ç±»ä¼¼ï¼š # WARNING: This value is valid only in the following conditions\r# 1. If provided manually (either via `GITLAB_ROOT_PASSWORD` environment variable or via `gitlab_rails['initial_root_password']` setting in `gitlab.rb`, it was provided before database was seeded for the first time (usually, the first reconfigure run).\r# 2. Password hasn't been changed manually, either via UI or via command line.\r#\r# If the password shown here doesn't work, you must reset the admin password following https://docs.gitlab.com/ee/security/reset_user_password.html#reset-your-root-password.\rPassword: F5o6JeW+jH2qmgyc/yXwlp++DiKX0XchafdYvKB7cdo=\r# NOTE: This file will be automatically deleted in the first reconfigure run after 24 hoursè¿›å…¥åä¿®æ”¹adminå¯†ç  3.1.2 debåŒ…å®‰è£… 3.1.2.1 ä¸‹è½½debåŒ… 3.1.2.2 ä¿®æ”¹é…ç½®æ–‡ä»¶ $ dpkg -i gitlab-ce_15.7.8-ce.0_amd64.deb $ vim /etc/gitlab/gitlab.rb external_url 'http://10.1.0.35' #ç”Ÿæˆé…ç½® $ gitlab-ctl reconfigure Notes: Default admin account has been configured with following details: Username: root Password: You didn't opt-in to print initial root password to STDOUT. Password stored to /etc/gitlab/initial_root_password. This file will be cleaned up in first reconfigure run after 24 hours. NOTE: Because these credentials might be present in your log files in plain text, it is highly recommended to reset the password following https://docs.gitlab.com/ee/security/reset_user_password.html#reset-your-root-password. gitlab Reconfigured! #æŸ¥çœ‹å¯†ç  $ cat /etc/gitlab/initial_root_password # WARNING: This value is valid only in the following conditions # 1. If provided manually (either via `GITLAB_ROOT_PASSWORD` environment variable or via `gitlab_rails['initial_root_password']` setting in `gitlab.rb`, it was provided before database was seeded for the first time (usually, the first reconfigure run). # 2. Password hasn't been changed ma","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:3:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"3.2 å®‰è£…Jenkins 3.2.1 jenkins ä»‹ç» Jenkins æ˜¯ä¸€æ¬¾è‘—åçš„å¯æ‰©å±•çš„ç”¨äºè‡ªåŠ¨åŒ–éƒ¨ç½²çš„å¼€æº CI/CD å·¥å…·ã€‚Jenkins æ˜¯å®Œå…¨ç”¨ Java ç¼–å†™çš„ï¼Œæ˜¯åœ¨ MIT è®¸å¯ä¸‹å‘å¸ƒçš„ã€‚å®ƒæœ‰ä¸€ç»„å¼ºå¤§çš„åŠŸèƒ½ï¼Œå¯ä»¥å°†è½¯ä»¶çš„æ„å»ºã€æµ‹è¯•ã€éƒ¨ç½²ã€é›†æˆå’Œå‘å¸ƒç­‰ç›¸å…³ä»»åŠ¡è‡ªåŠ¨åŒ–ã€‚ è¿™æ¬¾ç”¨äºæµ‹è¯•çš„è‡ªåŠ¨åŒ– CI/CD å·¥å…·å¯ä»¥åœ¨ macOSã€Windows å’Œå„ç§ UNIX ç‰ˆæœ¬ï¼ˆä¾‹å¦‚ OpenSUSEã€Ubuntuã€Red Hat ç­‰ï¼‰ç³»ç»Ÿä¸Šä½¿ç”¨ã€‚é™¤äº†é€šè¿‡æœ¬åœ°å®‰è£…åŒ…å®‰è£…ï¼Œå®ƒè¿˜å¯ä»¥ä½¿ç”¨waråŒ…åœ¨ä»»ä½•å®‰è£…è¿‡ Java è¿è¡Œæ—¶ç¯å¢ƒï¼ˆJava Runtime Environmentï¼ŒJREï¼‰çš„æœºå™¨ä¸Šå•ç‹¬å®‰è£…æˆ–è€…ä½œä¸ºä¸€ä¸ª Docker å®‰è£…ã€‚ Jenkins å›¢é˜Ÿå·²ç»å¼€å‘äº†è¿‘ 1000 ä¸ªæ’ä»¶ï¼Œä½¿å¾—åº”ç”¨ç¨‹åºå¯ä»¥ä¸å…¶å®ƒç†Ÿæ‚‰çš„æŠ€æœ¯æ··åˆä½¿ç”¨ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ Credentials Command ä¹‹ç±»çš„æ’ä»¶ã€‚è¿™ä½¿å¾—å‘è„šæœ¬ä¸­æ·»åŠ éšè—çš„èº«ä»½éªŒè¯å‡­è¯ç­‰å˜å¾—ç®€å•å¯è¡Œã€‚ä¸€æ—¦ Jenkins pipeline å¼€å§‹è¿è¡Œï¼Œä½ è¿˜å¯ä»¥éªŒè¯æ¯ä¸ªé˜¶æ®µé€šè¿‡ä¸å¦ä»¥åŠæ¯ä¸ªé˜¶æ®µçš„æ€»æ•°ã€‚ä½†æ˜¯ï¼Œä½ ä¸èƒ½åœ¨æä¾›çš„å›¾å½¢åŒ–æ¦‚è§ˆä¸­æ£€æŸ¥ç‰¹å®šä½œä¸šçš„çŠ¶æ€ã€‚ä½ å¯ä»¥åšçš„æ˜¯è·Ÿè¸ªç»ˆç«¯ä¸­çš„ä½œä¸šè¿›åº¦ã€‚ ç¯å¢ƒéœ€æ±‚ æœ€å°ç¡¬ä»¶éœ€æ±‚ï¼š256Mã€1Gç£ç›˜ç©ºé—´ï¼Œé€šå¸¸æ ¹æ®éœ€è¦JenkinsæœåŠ¡å™¨è‡³å°‘1Gå†…å­˜ï¼Œ50G+çš„ç£ç›˜ç©ºé—´ã€‚ è½¯ä»¶éœ€æ±‚ï¼šç”±äºjenkinsæ˜¯ä½¿ç”¨javaè¯­è¨€ç¼–å†™çš„ï¼Œæ‰€ä»¥éœ€è¦å®‰è£…javaè¿è¡Œæ—¶ç¯å¢ƒ(jdk)3.2.2 å®‰è£…JDK ä» Jenkins 2.357 ç‰ˆæœ¬å¼€å§‹ï¼ŒJenkinsåªæ”¯æŒJava 11 å’Œ Java 17 3.2.2.1 ä¸‹è½½æºç åŒ… JDK ä¸‹è½½åœ°å€ï¼š 11ï¼šhttps://www.oracle.com/java/technologies/downloads/#java11 17ï¼šhttps://www.oracle.com/java/technologies/downloads/#java17 3.2.2.2 è§£å‹å‹ç¼©åŒ… root@etcd01[13:24:27]~ #:mkdir /apps/jdk17 -p root@etcd01[13:24:37]~ #:cd /apps/jdk17 root@etcd01[13:25:06]/apps/jdk17 #:tar -zxvf jdk-17_linux-x64_bin.tar.gz -C /apps/jdk17/3.2.2.3 é…ç½®ç¯å¢ƒå˜é‡ vim /etc/profile.d/jdk11.sh export JAVA_HOME=/jdk11/jdk-11.0.18 export PATH=/jdk11/jdk-11.0.18/bin:$PATH source /etc/profile.d/jdk11.sh3.2.2.4 æµ‹è¯•java root@etcd01[13:40:02]/jdk11 #:java --version java 17.0.6 2023-01-17 LTS Java(TM) SE Runtime Environment (build 17.0.6+9-LTS-190) Java HotSpot(TM) 64-Bit Server VM (build 17.0.6+9-LTS-190, mixed mode, sharing)3.2.3 warå½¢å¼å®‰è£…å¯åŠ¨Jenkins 3.2.3.1 ä¸‹è½½waråŒ… 3.2.3.2 æŒ‡å®šJenkinsæ–‡ä»¶ä¿å­˜è·¯å¾„ å¦‚æœä¸è®¾ç½®è¯¥å˜é‡ï¼ŒJenkinsé…ç½®æ–‡ä»¶ç­‰éƒ½ä¿å­˜åœ¨ ~/.jenkins/ ç›®å½•ä¸‹ï¼Œä¸æ¨è vim /etc/profile.d/jenkins.sh export JENKINS_HOME=/data/jenkins source /etc/profile.d/jenkins.sh 3.2.3.3 å¯åŠ¨Jenkins root@etcd01[13:46:22]/data #:mkdir /apps/jenkins -p root@etcd01[13:46:22]/data #:mkdir -p /data/jenkins/log nohup java -jar -Xms512m -Xmx2048m /apps/jenkins/jenkins.war --httpPort=8181 \u003e /data/jenkins/log/jenkins.log 2\u003e\u00261 \u0026 #nohup è‹±æ–‡å…¨ç§° no hang upï¼ˆä¸æŒ‚èµ·ï¼‰ï¼Œç”¨äºåœ¨ç³»ç»Ÿåå°ä¸æŒ‚æ–­åœ°è¿è¡Œå‘½ä»¤ï¼Œé€€å‡ºç»ˆç«¯ä¸ä¼šå½±å“ç¨‹åºçš„è¿è¡Œã€‚ #-Xms æŒ‡å®šjvmè¿è¡Œæœ€å°è¿è¡Œå †å†…å­˜ï¼Œé»˜è®¤ä¸ºç‰©ç†å†…å­˜1/64ï¼Œç”¨æ³• ï¼š-Xmx512m æ³¨æ„ï¼šXmxå’Œ512mä¸­é—´ä¸ç”¨æ·»åŠ ç©ºæ ¼ #-Xmx æŒ‡å®šjvmè¿è¡Œæœ€å¤§è¿è¡Œå †å†…å­˜ï¼Œè®¤ç‰©ç†å†…å­˜1/4ï¼Œç”¨æ³•ï¼š -Xmx1024m æ³¨æ„ï¼šXmxå’Œ1024mä¸­é—´ä¸ç”¨æ·»åŠ ç©ºæ ¼ #--server.port æŒ‡å®šjarè¿è¡Œçš„portç«¯å£ï¼Œç”¨æ³•ï¼š--server.port=80853.2.3.4 æ£€æŸ¥æœåŠ¡å¯åŠ¨æƒ…å†µ #æŸ¥çœ‹ç«¯å£æ˜¯å¦å¯åŠ¨ root@etcd01[13:56:40]/data/jenkins #:lsof -i :8181 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME java 1914938 root 109u IPv6 290105770 0t0 TCP *:8181 (LISTEN) # æŸ¥çœ‹æ—¥å¿— root@etcd01[13:56:52]/data/jenkins #:tail -f /data/jenkins/log/jenkins.log at Main.main(Main.java:117) WARNING: An illegal reflective access operation has occurred WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/data/jenkins/war/WEB-INF/lib/groovy-all-2.4.21.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int) WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1 WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations WARNING: All illegal access operations will be denied in a future release 2023-02-28 05:56:43.644+0000 [id=1] INFO o.e.j.s.handler.ContextHandler#doStart: Started w.@68ac9ec5{Jenkins v2.346.3,/,file:///data/jenkins/war/,AVAILABLE}{/data/jenkins/war} 2023-02-28 05:56:43.670+0000 [id=1] INFO o.e.j.server.AbstractConnector#doStart: Started ServerConnector@6492fab5{HTTP/1.1, (http/1.1)}{0.0.0.0:8181} 2023-02-28 05:56:43.671+0000 [id=1] INFO org.eclipse.jetty.server.Server#doStart: Started @3925ms 2023-02-28 05:56:43.672+0000 [id=24] INFO winstone.Logger#logInternal: Winstone Servlet Engine running: controlPort=disabled3.2.3.5 æµè§ˆå™¨è®¿é—®æŸ¥çœ‹ http://10.1.0.34:8181 ::: warning AWT is not properly configured on this server. Perhaps you need to run your container with â€œ-Djava.awt.headless=trueâ€? See also: https://www.jenkins.io/redirect/troubleshooting/java.awt.headless\\ ::: ç”±äºç¼ºå°‘AWTç›¸å…³æ–‡ä»¶å¯¼è‡´JenkinsæŠ¥é”™ï¼Œåœ¨è¯¥å‚è€ƒé“¾æ¥ï¼ˆhttps://wiki.jenkins.io/display/JENKINS/Jenkins+got+java.awt.headless+problemï¼‰ä¸­ï¼Œç»™å‡ºçš„è§£å†³æ–¹æ¡ˆæ˜¯å®‰è£…ttf-dejavuå­—ä½“ã€‚ è§£å†³æ–¹æ³•ï¼š å®‰è£…fontconfigå’Œå­—ä½“ ttf-dejavu sudo apt-get install fontconfig ttf-dejavu é‡å¯jvmè¿›ç¨‹æ¥è®©å…¶ç”Ÿæ•ˆ root@etcd01[14:11:30]/data/jenkins #:p","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:3:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"3.3 å¯¹æ¥Jenkinsæ‹‰å–ä»£ç  3.3.1 æœåŠ¡å™¨ä¹‹é—´å…å¯† éœ€æ±‚ï¼šæœåŠ¡å™¨ä¹‹é—´å…å¯† ç›®çš„ï¼šæ‹‰å–ä»£ç æ—¶å…å¯† å¯¼å‡ºJenkinsæœåŠ¡å™¨ç§˜é’¥åˆ°gitlabæœåŠ¡å™¨ä¸­ã€‚ root@etcd01[16:20:31]~ #:ssh-keygen -t rsa -q -P \"\" -f ~/.ssh/id_rsa root@etcd01[16:20:31]~ #:cat /root/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCvFuqsriXcIcyRQG7KpYbwtM+Fn5BSyJSvfGdDIbOymHt7eFlWPQ/qmsnzdey2V28InALJIBJkQcfRwjmG3OTPsYpcP+ea0jhQ1GJHcamERwDJDxcg7jyk+r+dRwGhxLlWeHdiORGZGdqM2LPp7L3FqkDIKko0WMoL490kmAUMgjICrd3pjAQ7iV66YHxB2Y+w9EdWdj3d3GewtYhfnBlrn1bSaEx73y1KBhf3oy4pNOTeFPb2R5IIBllKiuD1r6J7AznRpVxihiQUadYLVFU4eCnXBHTRgiFTtd8oCghRxfrWgFpm0liBikeaawxM0wDQfYoWjZmKobxgvi47+OxS9xhvOn+yy4Iif2MqbH+V0go+eoAKwUE/FiaqqG0P/J5b6ZKx3ZrBF1FS6JztjI5PnzufizbgetvCqHf58+P4MKl8SuKHEI6SXbVzdf9KNmEpiK15m/flQUmYYIUba1nOiBiRFmZ+bLGvRRqUKLf+4P9XZTU1a0zIYXRaseq9QzU= root@etcd01 æµ‹è¯•å…å¯†å…‹éš†é¡¹ç›®ä»£ç  3.3.2 æµ‹è¯•å…å¯†å…‹éš† ä½¿ç”¨httpæ–¹å¼å…‹éš† root@etcd01[15:42:17]/pr #:git clone http://10.1.0.35/cy1/test.git Cloning into 'test'... Username for 'http://10.1.0.35': ryanxin Password for 'http://ryanxin@10.1.0.35': remote: Enumerating objects: 3, done. remote: Counting objects: 100% (3/3), done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 2.77 KiB | 2.77 MiB/s, done.ä½¿ç”¨ssh æ–¹å¼å…‹éš† root@etcd01[15:43:37]/pr #:git clone git@10.1.0.35:cy1/test.git Cloning into 'test'... The authenticity of host '10.1.0.35 (10.1.0.35)' can't be established. ECDSA key fingerprint is SHA256:lhRjKQBhgEhjbqcfKBb6oyle8C9EIOzu48QUoaeISIE. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added '10.1.0.35' (ECDSA) to the list of known hosts. remote: Enumerating objects: 3, done. remote: Counting objects: 100% (3/3), done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Receiving objects: 100% (3/3), done.","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:3:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"ä½¿ç”¨Jenkinså¯¹å‰ç«¯å·¥ç¨‹vueä»£ç æ‰“åŒ… ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"å®‰è£…npm å›½å†…æ·˜å®æº https://registry.npmmirror.com/binary.html?path=node/ $ tar -zxvf node-v18.14.2-linux-x64.tar.gz $ ln -s node-v18.14.2-linux-x64 node $ vim /etc/profile.d/npm.sh export PATH=$PATH:/software/npm/node/bin $ source /etc/profile.d/npm.sh $ npm -v 9.5.0 #æ›¿æ¢npmä»“åº“åœ°å€ä¸ºæ·˜å®é•œåƒåœ°å€ï¼ˆæ¨èï¼‰ $ npm config set registry https://registry.npm.taobao.org $ npm config get registry https://registry.npm.taobao.org/ npm config set registry http://r.cnpmjs.org #é…ç½®åå¯é€šè¿‡ä¸‹é¢æ–¹å¼æ¥éªŒè¯æ˜¯å¦æˆåŠŸ npm config get registry # æˆ–è€… npm info express #æ•…éœ€è¦å›½å†…å¯é çš„npmæºå¯ä»¥ä½¿ç”¨ ä¸€ã€å›½å†…é•œåƒ 1ã€æ·˜å®NPMé•œåƒ æœç´¢åœ°å€ï¼šhttp://npm.taobao.org registryåœ°å€ï¼šhttp://registry.npm.taobao.org 2ã€cnpmjsé•œåƒ æœç´¢åœ°å€ï¼šhttp://cnpmjs.org registryåœ°å€ï¼šhttp://r.cnpmjs.orgæµ‹è¯•å‰ç«¯å·¥ç¨‹ç¼–è¯‘ cd /xxlog git init Initialized empty Git repository in /xxlog/.git/ git config --global user.name ryanxin7 git config --global user.email xinxincn0506@outlook.com git remote add origin git@github.com:ryanxin7/xxlog.git root@etcd01[15:18:55]/xxlog #:cat /root/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCvFuqsriXcIcyRQG7KpYbwtM+Fn5BSyJSvfGdDIbOymHt7eFlWPQ/qmsnzdey2V28InALJIBJkQcfRwjmG3OTPsYpcP+ea0jhQ1GJHcamERwDJDxcg7jyk+r+dRwGhxLlWeHdiORGZGdqM2LPp7L3FqkDIKko0WMoL490kmAUMgjICrd3pjAQ7iV66YHxB2Y+w9EdWdj3d3GewtYhfnBlrn1bSaEx73y1KBhf3oy4pNOTeFPb2R5IIBllKiuD1r6J7AznRpVxihiQUadYLVFU4eCnXBHTRgiFTtd8oCghRxfrWgFpm0liBikeaawxM0wDQfYoWjZmKobxgvi47+OxS9xhvOn+yy4Iif2MqbH+V0go+eoAKwUE/FiaqqG0P/J5b6ZKx3ZrBF1FS6JztjI5PnzufizbgetvCqHf58+P4MKl8SuKHEI6SXbVzdf9KNmEpiK15m/flQUmYYIUba1nOiBiRFmZ+bLGvRRqUKLf+4P9XZTU1a0zIYXRaseq9QzU= root@etcd01 æ‹‰å–ä»£ç  $ git pull origin main The authenticity of host 'github.com (20.205.243.166)' can't be established. ECDSA key fingerprint is SHA256:p2QAMXNIC1TJYWeIOttrVc98/R1BUFWu3/LiyKgUfQM. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'github.com,20.205.243.166' (ECDSA) to the list of known hosts. remote: Enumerating objects: 1219, done. remote: Counting objects: 100% (1219/1219), done. remote: Compressing objects: 100% (794/794), done. remote: Total 1219 (delta 532), reused 1073 (delta 397), pack-reused 0 Receiving objects: 100% (1219/1219), 16.95 MiB | 5.16 MiB/s, done. Resolving deltas: 100% (532/532), done. From github.com:ryanxin7/xxlog * branch main -\u003e FETCH_HEAD * [new branch] main -\u003e origin/main $ git checkout main Branch 'main' set up to track remote branch 'main' from 'origin'. Switched to a new branch 'main' root@etcd01[15:22:34]/xxlog #:git branch -a * main master remotes/origin/main #åˆå§‹åŒ–é¡¹ç›®æ‰€éœ€çš„nodeæ¨¡å— $ npm install -g cnpm npm WARN deprecated @npmcli/move-file@2.0.1: This functionality has been moved to @npmcli/fs changed 420 packages in 2m 11 packages are looking for funding run `npm fund` for details $ npm install up to date in 3s 122 packages are looking for funding run `npm fund` for details $ ls LICENSE node_modules package.json package-lock.json README.md src #æµ‹è¯•è¿è¡Œ $ npm run docs:dev \u003e xxlog@2.0.0 docs:dev \u003e vuepress dev src âœ” Initializing and preparing data - done in 3.95s vite v4.0.4 dev server running at: âœ Local: http://localhost:8080/ âœ Network: http://10.1.0.34:8080/","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-14/:4:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8S æŒç»­é›†æˆä¸éƒ¨ç½² (åå››)","uri":"/posts/kubernetes/primary/kubernetes-14/"},{"categories":["Kubernetes"],"content":"æ›´æ–°è¯ä¹¦ ä¸ºäº†æ›´æ–°çš„å®‰å…¨æ€§ï¼Œæ›´æ–°ä¹‹å‰å¯ä»¥å°†æ‰€æœ‰ Master èŠ‚ç‚¹çš„é…ç½®ç›®å½•åšä¸€ä¸ªå¤‡ä»½ï¼š cp -r /etc/kubernetes /etc/kubernetes_$(date +%F) cp -r /var/lib/etcd /var/lib/etcd_$(date +%F)é€šè¿‡æ‰§è¡Œè¯ä¹¦æ›´æ–°å‘½ä»¤æŸ¥çœ‹ï¼š kubeadm certs renew --helpå¯ä»¥çœ‹åˆ°è¯ä¹¦æ›´æ–°æ˜¯æ”¯æŒæ›´æ–°æŒ‡å®šæœåŠ¡çš„è¯ä¹¦ï¼Œä¹Ÿå¯ä»¥æ›´æ–°å•ä¸ªæœåŠ¡çš„è¯ä¹¦ï¼Œä½†éƒ½æ˜¯é›†ç¾¤æœåŠ¡çš„è¯ä¹¦ã€‚ # æ‰€æœ‰ Master èŠ‚ç‚¹æ›´æ–°æ‰€æœ‰è¯ä¹¦ kubeadm certs renew all å¯ä»¥çœ‹åˆ°æç¤ºè®©é‡å¯ kube-apiserver, kube-controller-manager, kube-scheduler å’Œ etcd æœåŠ¡è¯ä¹¦æ‰èƒ½ç”Ÿæ•ˆã€‚ é‡å¯ç»„ä»¶è„šæœ¬ #é‡å¯ç»„ä»¶ for i in $(kubectl get pods -A | grep -E \"etcd|kube-apiserver|kube-controller-manager|kube-scheduler\" | awk '{print $2}');do kubectl delete pod $i -n kube-system sleep 3 done #é‡å¯æœåŠ¡ systemctl restart kubelet systemctl restart containerdæŸ¥çœ‹ç»„ä»¶è¿è¡Œæƒ…å†µ kubectl get pods -A | grep -E \"etcd|kube-apiserver|kube-controller-manager|kube-scheduler\" kube-system etcd-tj-master-01 1/1 Running 32 15m kube-system kube-apiserver-tj-master-01 1/1 Running 39 15m kube-system kube-controller-manager-tj-master-01 1/1 Running 163 15m kube-system kube-scheduler-tj-master-01 å¯ä»¥çœ‹åˆ°è¯ä¹¦æ—¶é—´å·²ç»æ›´æ–° åŒæ—¶ï¼Œç”±äºåœ¨åˆå§‹åŒ– Master é›†ç¾¤çš„æ—¶å€™é‡‡ç”¨çš„æ˜¯è®¾ç½®ç¯å¢ƒå˜é‡ export KUBECONFIG=/etc/kubernetes/admin.conf çš„æ–¹æ³•ï¼Œä¸éœ€è¦å†æ›´æ–°è¯¥æ–‡ä»¶ã€‚å¦‚æœä¸æ˜¯è¯¥æ–¹æ³•ï¼Œè¿˜éœ€è¦ä½¿ç”¨æ–°çš„ admin.conf æ›¿æ¢æ‰å¤åˆ¶çš„ /root/.kube/config é…ç½®æ–‡ä»¶ã€‚ cp /etc/kubernetes/admin.conf /root/.kube/configé‡å¯containerd è¿è¡Œé•œåƒ crictl stop 9731cb9e5b723 crictl stop 977896873866e crictl stop 24430601db1d1 crictl stop 7a7bad1c7dd70é‡å¯å,æŸ¥çœ‹ç›¸å…³æ—¥å¿— ","date":"2023-02-17","objectID":"/posts/kubernetes/primary/kubernetes-15/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"K8Sé›†ç¾¤è¯ä¹¦æ›´æ–° (åäº”)","uri":"/posts/kubernetes/primary/kubernetes-15/"},{"categories":["Kubernetes"],"content":"1.HPAç®€ä»‹ HPAï¼ˆHorizontal Pod Autoscalerï¼‰ï¼ŒPodæ°´å¹³è‡ªåŠ¨ç¼©æ”¾å™¨ï¼Œå¯ä»¥æ ¹æ®Podçš„è´Ÿè½½åŠ¨æ€è°ƒæ•´Podçš„å‰¯æœ¬æ•°é‡ï¼Œä¸šåŠ¡é«˜å³°æœŸè‡ªåŠ¨æ‰©å®¹Podå‰¯æœ¬ä»¥æ»¡è¶³ä¸šåŠ¡è¯·æ±‚ã€‚åœ¨ä¸šåŠ¡ä½å³°æœŸè‡ªåŠ¨ç¼©å®¹Podï¼Œå®ç°èŠ‚çº¦èµ„æºçš„ç›®çš„ã€‚ ä¸HPAç›¸å¯¹çš„æ˜¯VPA ï¼ˆVertical Pod Autoscalerï¼‰ï¼ŒPodå‚ç›´è‡ªåŠ¨ç¼©æ”¾å™¨ï¼Œå¯ä»¥åŸºäºPodçš„èµ„æºåˆ©ç”¨ç‡ï¼Œè°ƒæ•´å¯¹å•ä¸ªPodçš„æœ€å¤§èµ„æºé™åˆ¶ï¼Œä¸èƒ½ä¸HPAåŒæ—¶ä½¿ç”¨ã€‚ HPAéš¶å±äºautoscaling APIç¾¤ç»„ç›®å‰ä¸»è¦æœ‰v1å’Œv2ä¸¤ä¸ªç‰ˆæœ¬ï¼š ç‰ˆæœ¬ æè¿° autoscaling/v1 åªæ”¯æŒåŸºäºCPUæŒ‡æ ‡çš„ç¼©æ”¾ autoscaling/v2 æ”¯æŒåŸºäºResource Metricsï¼ˆèµ„æºæŒ‡æ ‡ï¼Œä¾‹å¦‚Pod çš„CPUå’Œå†…å­˜ï¼‰ã€Custom Metricsï¼ˆè‡ªå®šä¹‰æŒ‡æ ‡ï¼‰å’ŒExternal Metricsï¼ˆé¢å¤–æŒ‡æ ‡ï¼‰çš„ç¼©æ”¾ ","date":"2023-02-16","objectID":"/posts/kubernetes/primary/kubernetes-13/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"HPAè‡ªåŠ¨ä¼¸ç¼©podæ•°é‡ (åä¸‰)","uri":"/posts/kubernetes/primary/kubernetes-13/"},{"categories":["Kubernetes"],"content":"2.éƒ¨ç½² metrics Server HPAéœ€è¦é€šè¿‡Metrics Serveræ¥è·å–Podçš„èµ„æºåˆ©ç”¨ç‡ï¼Œæ‰€ä»¥éœ€è¦å…ˆéƒ¨ç½²Metrics Serverã€‚ Metrics Serveræ˜¯Kubernetes é›†ç¾¤æ ¸å¿ƒç›‘æ§æ•°æ®çš„èšåˆå™¨ï¼Œå®ƒè´Ÿè´£ä»kubeletæ”¶é›†èµ„æºæŒ‡æ ‡ï¼Œç„¶åå¯¹è¿™äº›æŒ‡æ ‡ç›‘æ§æ•°æ®è¿›è¡Œèšåˆï¼Œå¹¶é€šè¿‡Metrics APIå°†å®ƒä»¬æš´éœ²åœ¨Kubernetes apiserverä¸­ï¼Œä¾›æ°´å¹³Pod Autoscalerå’Œå‚ç›´Pod Autoscalerä½¿ç”¨ã€‚ä¹Ÿå¯ä»¥é€šè¿‡kubectl top node/podæŸ¥çœ‹æŒ‡æ ‡æ•°æ®ã€‚ ","date":"2023-02-16","objectID":"/posts/kubernetes/primary/kubernetes-13/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"HPAè‡ªåŠ¨ä¼¸ç¼©podæ•°é‡ (åä¸‰)","uri":"/posts/kubernetes/primary/kubernetes-13/"},{"categories":["Kubernetes"],"content":"2.1 å‡†å¤‡é•œåƒ #ä»ä»£ç†æœåŠ¡å™¨ä¸Šä¸‹è½½å¥½é•œåƒ root@harbor01[13:32:22]/proxy-images #:docker tag k8s.gcr.io/metrics-server/metrics-server:v0.6.2 harbor.ceamg.com/k8s-base/metrics-server:v0.6.2 root@harbor01[13:32:59]/proxy-images #:docker push harbor.ceamg.com/k8s-base/metrics-server:v0.6.2 The push refers to repository [harbor.ceamg.com/k8s-base/metrics-server] dc5ecd167a15: Pushed 9fce6bd02a21: Pushed v0.6.2: digest: sha256:0542aeb0025f6dd4f75e100ca14d7abdbe0725c75783d13c35e82d391f4735bc size: 739ä¸‹è½½yamlæ–‡ä»¶ Metrics Server releases. V6.0.2 https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.6.2/components.yaml ä¿®æ”¹æ–‡ä»¶ä¸­çš„é•œåƒåœ°å€ä¸ºç§æœ‰ä»“åº“ apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: k8s-app: metrics-server rbac.authorization.k8s.io/aggregate-to-admin: \"true\" rbac.authorization.k8s.io/aggregate-to-edit: \"true\" rbac.authorization.k8s.io/aggregate-to-view: \"true\" name: system:aggregated-metrics-reader rules: - apiGroups: - metrics.k8s.io resources: - pods - nodes verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: k8s-app: metrics-server name: system:metrics-server rules: - apiGroups: - \"\" resources: - nodes/metrics verbs: - get - apiGroups: - \"\" resources: - pods - nodes verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: labels: k8s-app: metrics-server name: metrics-server-auth-reader namespace: kube-system roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: extension-apiserver-authentication-reader subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: k8s-app: metrics-server name: metrics-server:system:auth-delegator roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:auth-delegator subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: k8s-app: metrics-server name: system:metrics-server roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:metrics-server subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: v1 kind: Service metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: ports: - name: https port: 443 protocol: TCP targetPort: https selector: k8s-app: metrics-server --- apiVersion: apps/v1 kind: Deployment metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: selector: matchLabels: k8s-app: metrics-server strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: k8s-app: metrics-server spec: containers: - args: - --cert-dir=/tmp - --secure-port=4443 - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname - --kubelet-use-node-status-port - --metric-resolution=15s image: harbor.ceamg.com/k8s-base/metrics-server:v0.6.2 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: path: /livez port: https scheme: HTTPS periodSeconds: 10 name: metrics-server ports: - containerPort: 4443 name: https protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /readyz port: https scheme: HTTPS initialDelaySeconds: 20 periodSeconds: 10 resources: requests: cpu: 100m memory: 200Mi securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsNonRoot: true runAsUser: 1000 volumeMounts: - mountPath: /tmp name: tmp-dir nodeSelector: kubernetes.io/os: linux priorityClassName: system-cluster-critical serviceAccountName: metrics-server volumes: - emptyDir: {} name: tmp-dir --- apiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: labels: k8s-app: metrics-server name: v1beta1.metrics.k8s.io spec: group: metrics.k8s.io groupPriorityMinimum: ","date":"2023-02-16","objectID":"/posts/kubernetes/primary/kubernetes-13/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"HPAè‡ªåŠ¨ä¼¸ç¼©podæ•°é‡ (åä¸‰)","uri":"/posts/kubernetes/primary/kubernetes-13/"},{"categories":["Kubernetes"],"content":"2.2 åˆ›å»ºpod åˆ›å»ºä¹‹åæŸ¥çœ‹PodçŠ¶æ€ï¼š root@master01[13:41:51]~/metrics #:kubectl apply -f metrics-v6.0.2.yaml serviceaccount/metrics-server created clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created clusterrole.rbac.authorization.k8s.io/system:metrics-server created rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created service/metrics-server created deployment.apps/metrics-server created apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io createdroot@master01[13:41:55]~/metrics #:kubectl get pod -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-5c8bb696bb-hf2cp 1/1 Running 1 (42d ago) 43d calico-node-4ntd2 1/1 Running 0 42d calico-node-dwnq5 1/1 Running 0 42d calico-node-nskdq 1/1 Running 0 42d calico-node-slx2b 1/1 Running 0 42d coredns-6c496b89f6-hd8vf 1/1 Running 0 42d metrics-server-5cd7bd59b4-tzx2b 1/1 Running 0 2m24s","date":"2023-02-16","objectID":"/posts/kubernetes/primary/kubernetes-13/:2:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"HPAè‡ªåŠ¨ä¼¸ç¼©podæ•°é‡ (åä¸‰)","uri":"/posts/kubernetes/primary/kubernetes-13/"},{"categories":["Kubernetes"],"content":"2.3 éªŒè¯èµ„æºæŒ‡æ ‡ éªŒè¯metrics-serveræ˜¯å¦å·¥ä½œ root@master01[13:44:57]~/metrics #:kubectl top node NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% 10.1.0.30 229m 2% 3731Mi 51% 10.1.0.31 323m 4% 3481Mi 47% 10.1.0.32 417m 5% 4713Mi 64% 10.1.0.33 331m 4% 5453Mi 75% å¯ä»¥è·å–nodeå’Œpodçš„èµ„æºæŒ‡æ ‡å°±è¡¨ç¤ºmetrics-serverå¯ä»¥æ­£å¸¸å·¥ä½œ ","date":"2023-02-16","objectID":"/posts/kubernetes/primary/kubernetes-13/:2:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"HPAè‡ªåŠ¨ä¼¸ç¼©podæ•°é‡ (åä¸‰)","uri":"/posts/kubernetes/primary/kubernetes-13/"},{"categories":["Kubernetes"],"content":"3. HPAé…ç½®å‚æ•° HPAæ§åˆ¶å™¨æœ‰ä¸€äº›é‡è¦é…ç½®å‚æ•°ï¼Œç”¨äºæ§åˆ¶Podç¼©æ”¾çš„è¡Œä¸ºï¼Œè¿™äº›å‚æ•°éƒ½å¯ä»¥åœ¨kube-controllerçš„å¯åŠ¨å‚æ•°ä¸­é…ç½®ï¼š **â€“horizontal-pod-autoscaler-sync-period**ï¼šæŸ¥è¯¢Podèµ„æºåˆ©ç”¨ç‡çš„æ—¶é—´é—´éš”ï¼Œé»˜è®¤15sæŸ¥è¯¢ä¸€æ¬¡ **â€“horizontal-pod-autoscaler-downscale-stabilization**ï¼šä¸¤æ¬¡ç¼©å®¹æ“ä½œä¹‹é—´çš„æœ€å°é—´éš”å‘¨æœŸï¼Œé»˜è®¤5m **â€“horizontal-pod-autoscaler-cpu-initialization-period**ï¼šåˆå§‹åŒ–å»¶è¿Ÿæ—¶é—´ï¼Œåœ¨æ­¤æœŸé—´å†…Podçš„CPUæŒ‡æ ‡å°†ä¸ç”Ÿæ•ˆï¼Œé»˜è®¤5m **â€“horizontal-pod-autoscaler-initial-readiness-delay**ï¼šç”¨äºè®¾ç½®Podåˆå§‹åŒ–æ—¶é—´ï¼Œåœ¨æ­¤æœŸé—´å†…å†…çš„Podè¢«è®¤ä¸ºæœªå°±ç»ªä¸ä¼šè¢«é‡‡é›†æ•°æ®ï¼Œé»˜è®¤30s **â€“horizontal-pod-autoscaler-tolerance**ï¼šHPAæ§åˆ¶å™¨èƒ½å®¹å¿çš„æ•°æ®å·®å¼‚ï¼ˆæµ®ç‚¹æ•°ï¼Œé»˜è®¤0.1ï¼‰ï¼Œå³å½“å‰æŒ‡æ ‡ä¸é˜ˆå€¼çš„å·®å¼‚è¦åœ¨0.1ä¹‹å†…ï¼Œæ¯”å¦‚é˜ˆå€¼è®¾ç½®çš„æ˜¯CPUåˆ©ç‡50%ï¼Œå¦‚æœå½“å‰CPUåˆ©ç”¨ç‡ä¸º80%ï¼Œé‚£ä¹ˆ80/50=1.6\u003e1.1ï¼Œå°±ä¼šè§¦å‘æ‰©å®¹ï¼›å¦‚æœå½“å‰CPUåˆ©ç”¨ç‡ä¸º40%ï¼Œ40/50=0.8\u003c0.9ï¼Œå°±ä¼šè§¦å‘ç¼©å®¹ã€‚å¤§äº1.1æ‰©å®¹ï¼Œå°äº0.9ç¼©å®¹ ","date":"2023-02-16","objectID":"/posts/kubernetes/primary/kubernetes-13/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"HPAè‡ªåŠ¨ä¼¸ç¼©podæ•°é‡ (åä¸‰)","uri":"/posts/kubernetes/primary/kubernetes-13/"},{"categories":["Kubernetes"],"content":"3.1 HPAç¤ºä¾‹ ä¸‹é¢ä½¿ç”¨HAP v1ç‰ˆæœ¬é€šè¿‡CPUæŒ‡æ ‡å®ç°Podè‡ªåŠ¨æ‰©ç¼©å®¹ã€‚ 3.1.1 è‡ªåŠ¨ç¼©å®¹ç¤ºä¾‹ å…ˆéƒ¨ç½²ä¸€ä¸ª5å‰¯æœ¬çš„nginx deploymentï¼Œå†é€šè¿‡HPAå®ç°ç¼©å®¹ï¼š apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deploy labels: app: nginx spec: replicas: 5 selector: matchExpressions: - {key: \"app\", operator: In, values: [\"nginx\"]} template: metadata: labels: app: nginx spec: containers: - name: nginx image: harbor.ceamg.com/pub-images/nginx-base:1.22.1 ports: - name: http containerPort: 80 resources: #å¦‚æœè¦é€šè¿‡hpaå®ç°podçš„è‡ªåŠ¨æ‰©ç¼©å®¹ï¼Œåœ¨å¿…é¡»å¯¹Podè®¾ç½®èµ„æºé™åˆ¶ï¼Œå¦åˆ™podä¸ä¼šè¢«hpaç»Ÿè®¡ requests: cpu: 500m memory: 512Mi limits: cpu: 1 memory: 1Giroot@master01[13:56:32]~/metrics/test #:kubectl get pod NAME READY STATUS RESTARTS AGE emptydirtest 1/1 Running 4 (6h40m ago) 16d net-test2 1/1 Running 10 (31h ago) 42d net-test3 1/1 Running 10 (31h ago) 42d net-test4 1/1 Running 10 (31h ago) 42d nginx-deploy-74d4966b8c-2qs8m 1/1 Running 0 33s nginx-deploy-74d4966b8c-7fcpl 1/1 Running 0 33s nginx-deploy-74d4966b8c-pn6nx 1/1 Running 0 33s nginx-deploy-74d4966b8c-qtdps 1/1 Running 0 33s nginx-deploy-74d4966b8c-rhgm4 1/1 Running 0 33shpaéƒ¨ç½²æ–‡ä»¶å¦‚ä¸‹ï¼Œåœ¨hpaä¸­å®šä¹‰äº†Pod cpuåˆ©ç”¨ç‡é˜ˆå€¼ä¸º80%ï¼Œæœ€å°å‰¯æœ¬æ•°ä¸º3ï¼Œæœ€å¤§å‰¯æœ¬æ•°ä¸º10ï¼š apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: pod-autoscaler-demo spec: minReplicas: 3 #æœ€å°å‰¯æœ¬æ•° maxReplicas: 10 #æœ€å¤§å‰¯æœ¬æ•° scaleTargetRef: #hpaç›‘æ§çš„èµ„æºå¯¹è±¡ apiVersion: apps/v1 kind: Deployment name: nginx-deploy targetCPUUtilizationPercentage: 80 #cpuåˆ©ç”¨ç‡é˜ˆå€¼åˆ›å»ºå®Œæˆåï¼ŒæŸ¥çœ‹hpaèµ„æºï¼š root@master01[15:23:46]~/metrics/test #:kubectl get hpa -o wide NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE pod-autoscaler-demo Deployment/nginx-deploy 0%/80% 3 10 5 21så› ä¸ºä¹‹å‰åˆ›å»ºçš„nginx podè®¿é—®é‡è¾ƒä½ï¼Œcpulåˆ©ç”¨ç‡è‚¯å®šä¸è¶…è¿‡80%ï¼Œæ‰€ä»¥ç­‰å¾…ä¸€æ®µæ—¶é—´å°±ä¼šè§¦å‘ç¼©å®¹ å› ä¸ºåœ¨hpaä¸­å®šä¹‰çš„æœ€å°å‰¯æœ¬æ•°ä¸º3ï¼Œæ‰€ä»¥ç¼©å®¹åˆ°3ä¸ªPodå°±ä¸ä¼šç¼©å®¹äº† 3.1.2 è‡ªåŠ¨æ‰©å®¹ç¤ºä¾‹ ä½¿ç”¨stress-ngé•œåƒéƒ¨ç½²3ä¸ªpodæ¥æµ‹è¯•è‡ªåŠ¨æ‰©å®¹ï¼Œstress-ngæ˜¯ä¸€ä¸ªå‹æµ‹å·¥å…· apiVersion: apps/v1 kind: Deployment metadata: name: stress-ng-deploy labels: app: stress-ng spec: replicas: 3 selector: matchExpressions: - {key: \"app\", operator: In, values: [\"stress-ng\"]} template: metadata: labels: app: stress-ng spec: containers: - name: stress-ng image: lorel/docker-stress-ng args: [\"--vm\", \"2\", \"--vm-bytes\", \"512M\"] resources: requests: cpu: 500m memory: 512Mi limits: cpu: 1 memory: 1Gi``` root@master01[16:34:20]~/metrics/test #:kubectl get pod NAME READY STATUS RESTARTS AGE stress-ng-deploy-5c9d6db588-dmwh8 1/1 Running 0 30s stress-ng-deploy-5c9d6db588-mfr7m 1/1 Running 0 30s stress-ng-deploy-5c9d6db588-vg82w 1/1 Running 0 30shpaéƒ¨ç½²æ–‡ä»¶å¦‚ä¸‹ï¼š apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: pod-autoscaler-demo1 spec: minReplicas: 3 maxReplicas: 10 scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: stress-ng-deploy targetCPUUtilizationPercentage: 80æŸ¥çœ‹hpaèµ„æºï¼š stress-ngä¼šå°†Podçš„cpuåˆ©ç”¨ç‡æ‰“æ»¡ï¼Œæ‰€ä»¥ç­‰å¾…ä¸€æ®µæ—¶é—´hpaå°±ä¼šé€æ­¥æé«˜podçš„å‰¯æœ¬æ•°ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä½†æ˜¯åœ¨hpaä¸­å®šä¹‰çš„æœ€å¤§å‰¯æœ¬æ•°ä¸º10ï¼Œæ‰€ä»¥æœ€å¤šæ‰©å®¹åˆ°10ä¸ªPodå°±ä¸ä¼šæ‰©å®¹äº† åˆ é™¤ä¸€ç›´å¤„äºTerminating çŠ¶æ€çš„pod root@master01[16:54:36]~/metrics/test #:kubectl get pod NAME READY STATUS RESTARTS AGE emptydirtest 1/1 Terminating 4 (9h ago) 17d net-test2 1/1 Terminating 10 (34h ago) 43d net-test3 1/1 Terminating 10 (34h ago) 43d net-test4 1/1 Running 10 (35h ago) 43d nginx-deploy-74d4966b8c-2qs8m 1/1 Running 0 3h5m nginx-deploy-74d4966b8c-k28hh 1/1 Running 0 14m nginx-deploy-74d4966b8c-pn6nx 1/1 Terminating 0 3h5m nginx-deploy-74d4966b8c-rhgm4 1/1 Running 0 3h5m stress-ng-deploy-5c9d6db588-7q4hq 1/1 Terminating 0 24m stress-ng-deploy-5c9d6db588-dmwh8 1/1 Terminating 0 27m stress-ng-deploy-5c9d6db588-m952t 1/1 Terminating 0 24m stress-ng-deploy-5c9d6db588-mwbgd 1/1 Terminating 0 24m stress-ng-deploy-5c9d6db588-vg82w 1/1 Terminating 0 27m stress-ng-deploy-5c9d6db588-z8n2r 0/1 Terminating 0 24m tomcat-app1-6fd79cfbd4-8tg64 1/1 Terminating 0 2d tomcat-app1-6fd79cfbd4-sts9v 1/1 Running 0 14m tomcat-app2-54b548dfbf-zsgpd 1/1 Running 0 2droot@etcd01[17:03:05]~ #:/usr/local/bin/etcdctl get /registry/pods/default/stress --prefix --keys-only /registry/pods/default/stress-ng-deploy-5c9d6db588-7q4hq /registry/pods/default/stress-ng-deploy-5c9d6db588-dmwh8 /registry/pods/default/stress-ng-deploy-5c9d6db588-m952t /registry/pods/default/stress-ng-deploy-5c9d6db588-m","date":"2023-02-16","objectID":"/posts/kubernetes/primary/kubernetes-13/:3:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"HPAè‡ªåŠ¨ä¼¸ç¼©podæ•°é‡ (åä¸‰)","uri":"/posts/kubernetes/primary/kubernetes-13/"},{"categories":["Kubernetes"],"content":" Author: Ryan title: 12.ingress å®ç°åŸºäºåŸŸåçš„å¤šè™šæ‹Ÿä¸»æœº,URLè½¬å‘åŠå¤šåŸŸåHTTPSå®ç°æ¡ˆä¾‹ tag: - k8sè¿›é˜¶è®­ç»ƒè¥ category: k8s date: 2022-6-12 12:12:22 lastUpdated: true #sidebar: false breadcrumb: false #contributors: false ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"Ingresså’ŒIngressæ§åˆ¶å™¨ä»‹ç» åœ¨k8sä¸­å°†ä¸€ä¸ªæœåŠ¡æš´éœ²å‡ºå»é€šå¸¸ä¼šä½¿ç”¨NodePortæˆ–LoadBalancerç±»å‹çš„Serviceï¼Œä½†éšç€æœåŠ¡æ•°é‡çš„å¢å¤šï¼Œä½¿ç”¨NodePortä¼šå­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå¯ç”¨ä½œNodePortçš„ç«¯å£æ˜¯ä¸€ä¸ªæœ‰é™çš„èŒƒå›´ï¼Œä¸å®¹æ˜“è®°å¿†ï¼Œä¸å¥½ç®¡ç†ã€‚å¦å¤–ï¼Œ å¦‚æœåœ¨å…¬æœ‰äº‘ä½¿ç”¨LoadBalancerç±»å‹çš„Serviceä¸Šä¼šäº§ç”Ÿé¢å¤–çš„æˆæœ¬ã€‚ æ‰€ä»¥k8sæä¾›äº†å¦ä¸€ç§æ–¹å¼ï¼Œä½¿ç”¨Ingresså’ŒIngressæ§åˆ¶å™¨æ¥å¯¹å¤–æš´éœ²æœåŠ¡ï¼ŒIngressæ§åˆ¶å™¨ä½œä¸ºç»Ÿä¸€çš„æµé‡å…¥å£ï¼Œç®¡ç†å†…éƒ¨å„ç§å¿…è¦çš„æœåŠ¡ï¼Œå¹¶é€šè¿‡Ingressèµ„æºæ¥æè¿°å¦‚ä½•åŒºåˆ†æµé‡åŠå†…éƒ¨çš„è·¯ç”±é€»è¾‘ã€‚æœ‰äº†Ingresså’ŒIngressæ§åˆ¶å™¨ï¼Œå°±å¯ä»¥é€šè¿‡å®šä¹‰è·¯ç”±æµé‡çš„è§„åˆ™æ¥å®ç°æœåŠ¡å‘å¸ƒï¼Œè€Œæ— éœ€åˆ›å»ºNodePortæˆ–LoadBalancerç±»å‹çš„Serviceï¼Œå¹¶ä¸”æµé‡ä¹Ÿä¼šç”±Ingressæ§åˆ¶å™¨ç›´è¾¾Podï¼Œä¸éœ€è¦å†ç”±Serviceè½¬å‘ã€‚ :::info Ingressèµ„æºå°±æ˜¯åŸºäºHTTPè™šæ‹Ÿä¸»æœºæˆ–URLè·¯å¾„çš„æµé‡è½¬å‘è§„åˆ™ï¼ˆç±»ä¼¼äºnginxä¸­çš„è™šæ‹Ÿä¸»æœºå®šä¹‰æˆ–locationè½¬å‘è§„åˆ™å®šä¹‰ï¼‰ï¼Œå®ƒæŠŠéœ€è¦æš´éœ²ç»™é›†ç¾¤å¤–çš„æ¯ä¸ªServiceå¯¹è±¡ï¼Œæ˜ å°„ä¸ºIngressæ§åˆ¶å™¨ä¸Šçš„ä¸€ä¸ªè™šæ‹Ÿä¸»æœºæˆ–æŸè™šæ‹Ÿä¸»æœºçš„ä¸€ä¸ªURLè·¯å¾„ã€‚ ::: å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š Ingresså®˜æ–¹æ–‡æ¡£ï¼šhttps://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress/Ingressæ§åˆ¶å™¨å®˜æ–¹æ–‡æ¡£ï¼šhttps://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress-controllers/ ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"Ingressæ§åˆ¶å™¨ ä½†Ingressèµ„æºæœ¬èº«åªæ˜¯ä¸€ç»„è·¯ç”±è§„åˆ™å®šä¹‰ï¼Œè¿™äº›è§„åˆ™æƒ³è¦çœŸæ­£çš„ç”Ÿæ•ˆè¿˜éœ€è¦å€ŸåŠ©å…¶å®ƒåŠŸèƒ½çš„è¾…åŠ©ï¼Œä¾‹å¦‚ç›‘å¬æŸå¥—æ¥å­—ã€æ ¹æ®è·¯ç”±è§„åˆ™åŒ¹é…æœºåˆ¶å°†å®¢æˆ·ç«¯è¯·æ±‚è¿›è¡Œè½¬å‘ç­‰ã€‚å®ç°è¿™äº›åŠŸèƒ½çš„ç»„ä»¶å°±æ˜¯Ingressæ§åˆ¶å™¨(Ingress Controller)ã€‚Ingress Controlleræ˜¯Kubernetesçš„ä¸€ä¸ªé™„ä»¶éœ€è¦å•ç‹¬éƒ¨ç½²ã€‚ ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:1:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"Ingress Controlleréƒ¨ç½² ç›®å‰å¯é€‰æ‹©ä½¿ç”¨çš„Ingressæ§åˆ¶å™¨æœ‰å¾ˆå¤šï¼Œå¯ä»¥å‚è€ƒå®˜æ–¹ä»‹ç»ï¼šhttps://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress-controllers/ ï¼Œä¸‹é¢ä»¥nginx Ingressæ§åˆ¶å™¨ä¸ºä¾‹è¿›è¡Œéƒ¨ç½²ã€‚ nginx Ingressæ§åˆ¶å™¨githubåœ°å€ï¼šhttps://github.com/kubernetes/ingress-nginxnginx Ingressæ§åˆ¶å™¨å®˜æ–¹æ–‡æ¡£ï¼šhttps://kubernetes.github.io/ingress-nginx/ **å¸¸ç”¨çš„çš„Ingressæ§åˆ¶å™¨éƒ¨ç½²æ–¹å¼æœ‰ä¸¤ç§ï¼š ** ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"1. ä»¥Deploymentæ–¹å¼éƒ¨ç½²Ingressæ§åˆ¶å™¨Podèµ„æº é€šè¿‡NodePortæˆ–LoadBalancerç±»å‹çš„Serviceæˆ–è€…é€šè¿‡æ‹¥æœ‰å¤–éƒ¨IPåœ°å€ï¼ˆexternalIPï¼‰çš„Serviceå¯¹è±¡ä¸ºå…¶æ¥å…¥é›†ç¾¤å¤–éƒ¨çš„å®¢æˆ·ç«¯è¯·æ±‚æµé‡ã€‚è¿™æ„å‘³ç€ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä»¥è¿™ç§æ–¹å¼éƒ¨ç½²ä¸€ä¸ªIngressæ§åˆ¶å™¨æ—¶ï¼Œå¿…é¡»åœ¨å…¶å‰ç«¯å®šä¹‰ä¸€ä¸ªè´Ÿè½½å‡è¡¡å™¨ï¼Œè¿™ä¸ªè´Ÿè½½å‡è¡¡å™¨å¯ä»¥æ˜¯LoadBalancerç±»å‹çš„Serviceï¼Œä¹Ÿå¯ä»¥æ˜¯ç”¨æˆ·è‡ªè¡Œç®¡ç†çš„è´Ÿè½½å‡è¡¡å™¨ã€‚ ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"2.ä»¥DaemonSetæ–¹å¼éƒ¨ç½²Ingressæ§åˆ¶å™¨ Podèµ„æºIngressæ§åˆ¶å™¨çš„å„Podåˆ†åˆ«ä»¥å•ä¸€å®ä¾‹çš„æ–¹å¼è¿è¡Œåœ¨é›†ç¾¤çš„æ‰€æœ‰èŠ‚ç‚¹æˆ–éƒ¨åˆ†ä¸“ç”¨èŠ‚ç‚¹ä¹‹ä¸Šï¼Œå¹¶é…ç½®è¿™äº›Podå¯¹è±¡ä»¥hostPortæˆ–hostNetworkçš„æ–¹å¼åœ¨å½“å‰èŠ‚ç‚¹æ¥å…¥å¤–éƒ¨æµé‡ã€‚åœ¨è¿™ç§æ–¹å¼ä¸‹ï¼Œå‰ç«¯è¿˜æ˜¯éœ€è¦ä¸€ä¸ªè´Ÿè½½å‡è¡¡å™¨ï¼Œä½œä¸ºå®¢æˆ·ç«¯æµé‡çš„ç»Ÿä¸€å…¥å£ï¼Œç„¶åè½¬å‘ç»™Ingressæ§åˆ¶å™¨Pod åœ¨nginx Ingressæ§åˆ¶å™¨å®˜æ–¹æä¾›çš„éƒ¨ç½²æ–‡ä»¶ä¸­ï¼Œé»˜è®¤ä½¿ç”¨ç¬¬ä¸€ç§æ–¹å¼ï¼Œä½¿ç”¨Deployment+NodePort Serviceæ¥éƒ¨ç½²ã€‚ ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:2:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"3. Deploymentæ–¹å¼éƒ¨ç½² é€‰å®šå¥½ç‰ˆæœ¬ï¼Œä¸‹è½½å¯¹åº”çš„éƒ¨ç½²æ–‡ä»¶ wget https://github.com/kubernetes/ingress-nginx/archive/refs/tag/controller-v1.3.1.tar.gz tar xvf controller-v1.3.1.tar.gz cd ingress-nginx-controller-v1.3.1/deploy/static/provider/baremetal/ #ä¿®æ”¹å½“å‰ç›®å½•ä¸‹çš„deploy.yamlï¼Œå°†é•œåƒä¿®æ”¹æœªå›½å†…é•œåƒæº cat deploy.yaml |grep image image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.3.1 imagePullPolicy: IfNotPresent image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.3.0 imagePullPolicy: IfNotPresent image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.3.0 imagePullPolicy: IfNotPresentä¿®æ”¹nodeportåœ°å€ apiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.3.1 name: ingress-nginx-controller namespace: ingress-nginx spec: ipFamilies: - IPv4 ipFamilyPolicy: SingleStack ports: - appProtocol: http name: http port: 80 protocol: TCP targetPort: http nodePort: 30020 - appProtocol: https name: https port: 443 protocol: TCP targetPort: https nodePort: 30021å®‰è£… kubectl apply -f deploy.yaml amespace/ingress-nginx created serviceaccount/ingress-nginx created serviceaccount/ingress-nginx-admission created role.rbac.authorization.k8s.io/ingress-nginx created role.rbac.authorization.k8s.io/ingress-nginx-admission created clusterrole.rbac.authorization.k8s.io/ingress-nginx created clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created rolebinding.rbac.authorization.k8s.io/ingress-nginx created rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created configmap/ingress-nginx-controller created service/ingress-nginx-controller created service/ingress-nginx-controller-admission created deployment.apps/ingress-nginx-controller created job.batch/ingress-nginx-admission-create created job.batch/ingress-nginx-admission-patch created ingressclass.networking.k8s.io/nginx created validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission createdæŸ¥çœ‹çŠ¶æ€ NAME READY STATUS RESTARTS AGE ingress-nginx-admission-create-cnccm 0/1 Completed 0 21s ingress-nginx-admission-patch-j4l68 0/1 Completed 0 21s ingress-nginx-controller-79658555f4-r2pz5 0/1 Running 0 21sroot@master01[14:23:04]~ #:kubectl get service -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller NodePort 10.10.79.136 \u003cnone\u003e 80:30020/TCP,443:30021/TCP 74m ingress-nginx-controller-admission ClusterIP 10.10.133.115 \u003cnone\u003e 443/TCP 74mé»˜è®¤æƒ…å†µä¸‹ï¼Œingress-nginx-controlleråªæœ‰ä¸€ä¸ªå‰¯æœ¬ï¼Œå¯ä»¥æŒ‰éœ€è°ƒæ•´ root@master01[14:54:09]~ #:kubectl scale -n ingress-nginx deployment ingress-nginx-controller --replicas=3 root@master01[14:54:09]~ #:kubectl get pod -n ingress-nginx NAME READY STATUS RESTARTS AGE ingress-nginx-admission-create-cnccm 0/1 Completed 0 105m ingress-nginx-admission-patch-j4l68 0/1 Completed 0 105m ingress-nginx-controller-79658555f4-gd2zj 1/1 Running 0 22s ingress-nginx-controller-79658555f4-r2pz5 1/1 Running 0 105m ingress-nginx-controller-79658555f4-r6l8s 0/1 Running 0 22skubectl scale -n ingress-nginx deployment ingress-nginx-controller --replicas=3 root@master01[15:44:40]~ #:kubectl get pod -n ingress-nginx NAME READY STATUS RESTARTS AGE ingress-nginx-admission-create-cnccm 0/1 Completed 0 6d2h ingress-nginx-admission-patch-j4l68 0/1 Completed 0 6d2h ingress-nginx-controller-79658555f4-gd2zj 1/1 Running 0 6d ingress-nginx-controller-79658555f4-r2pz5 1/1 Running 0 6d2h ingress-nginx-controller-79658555f4-r6l8s 1/1 Running 0 6dåœ¨è´Ÿè½½å‡è¡¡å™¨ä¸­æ·»åŠ ingress-nginx-controlleråç«¯ï¼Œä»¥haproxyä¸ºä¾‹ cat /etc/haproxy/harpoxy.cfg ################################# listen ingress-nginx-controller-80 bind 10.1.0.6:80 option tcplog mode tcp balance source server ingress-controller-server1 10.1.0.31:300","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:2:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"4.DaemonSetæ–¹å¼éƒ¨ç½² å¯¹å‰é¢çš„deploy.yamlè¿›è¡Œä¿®æ”¹ï¼Œä¸»è¦ä¿®æ”¹3ä¸ªé…ç½® åˆ é™¤æ‰ingress-ingress-controller Serviceèµ„æºå®šä¹‰ å°†Deploymentä¿®æ”¹æœªDaemonSet é…ç½®Podä½¿ç”¨hostNetworkå’ŒhostPID apiVersion: apps/v1 kind: DaemonSet #ç±»å‹ä¿®æ”¹ä¸ºDaemonSet metadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.3.1 name: ingress-nginx-controller namespace: ingress-nginx spec: minReadySeconds: 0 revisionHistoryLimit: 10 selector: matchLabels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx template: metadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx spec: hostPID: true #Podä½¿ç”¨ä¸»æœºPIDåç§°ç©ºé—´ hostNetwork: true #Podä½¿ç”¨ä¸»æœºç½‘ç»œ containers:åŒæ ·çš„ï¼Œä¹Ÿéœ€è¦åœ¨è´Ÿè½½å‡è¡¡å™¨ä¸­æ·»åŠ ingress-nginx-controlleråç«¯ï¼Œä»¥haproxyä¸ºä¾‹ cat /etc/haproxy/harpoxy.cfg ################################# listen ingress-nginx-controller-80 bind 10.1.0.6:80 option tcplog mode tcp balance source server ingress-controller-server1 10.1.0.31:30020 check inter 2000 fall 3 rise 5 server ingress-controller-server2 10.1.0.32:30020 check inter 2000 fall 3 rise 5 listen ingress-nginx-controller-443 bind 10.1.0.6:443 option tcplog mode tcp balance source server ingress-controller-server1 10.1.0.31:30021 check inter 2000 fall 3 rise 5 server ingress-controller-server2 10.1.0.32:30021 check inter 2000 fall 3 rise 5","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:2:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"3.Ingressç¤ºä¾‹ ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"3.1 Ingressèµ„æºè§„èŒƒ Ingressèµ„æºçš„å¯ç”¨å­—æ®µå’Œå«ä¹‰å¦‚ä¸‹ï¼š apiVersion: networkking.k8s.io/v1 kind: Ingress metadata: name: ... namespace: ... annotations: #èµ„æºæ³¨è§£ kubernetes.io/ingress.class: \u003cstring\u003e #æŒ‡æ˜æ­¤Ingressèµ„æºç”±å“ªä¸ªIngressæ§åˆ¶å™¨æ¥è§£æï¼Œç›®å‰ä¹Ÿå¯ä»¥ä½¿ç”¨spec.ingressClassNameå­—æ®µä»£æ›¿ spec: rules: #Ingressè·¯ç”±è§„åˆ™åˆ—è¡¨ - host: \u003cstring\u003e #è™šæ‹Ÿä¸»æœºçš„åŸŸåï¼Œæ”¯æŒ*å‰ç¼€åŒ¹é…ï¼Œä½†ä¸æ”¯æŒIPï¼Œä¸æ”¯æŒç«¯å£ http: paths: #è™šæ‹Ÿä¸»æœºçš„PATHè·¯å¾„åˆ—è¡¨ï¼Œç”±pathå’Œbackendç»„æˆ - path: \u003cstring\u003e #æµé‡åŒ¹é…çš„HTTP URLè·¯å¾„ï¼Œå¿…é¡»ä»¥/å¼€å¤´ pathType: \u003cstring\u003e #URLè·¯å¾„åŒ¹é…æ–¹å¼ï¼Œæ”¯æŒExact(ç²¾å‡†åŒ¹é…)ã€Prefix(å‰ç¼€åŒ¹é…)å’ŒImplementationSpecificï¼Œè¯¦ç»†ä»‹ç»å¯ä»¥å‚è€ƒå®˜ç½‘æ–‡æ¡£ backend: #åŒ¹é…åˆ°çš„æµé‡è¦è½¬å‘åˆ°çš„åç«¯å®šä¹‰ service: #åç«¯å…³è”çš„Serviceå¯¹è±¡å®šä¹‰ name: \u003cstring\u003e #Serviceå¯¹è±¡åç§° port: #Serviceå¯¹è±¡ç«¯å£ number: \u003cint\u003e #ç«¯å£å· name: \u003cstring\u003e #ç«¯å£åç§° tls: #tlsé…ç½®ï¼Œç”¨äºæŒ‡å®šä¸Šè¾¹ruleså­—æ®µä¸‹å“ªäº›hostéœ€è¦ä½¿ç”¨https - hosts: \u003c[]string\u003e #ä½¿ç”¨åŒä¸€ç»„è¯ä¹¦çš„ä¸»æœºåç§°åˆ—è¡¨ secretName: \u003cstring\u003e #ä¿å­˜è¯ä¹¦çš„Secretèµ„æºåç§° defaultBackend: \u003cObject\u003e #é»˜è®¤åç«¯å®šä¹‰ï¼Œå¯åµŒå¥—ä½¿ç”¨å­—æ®µä¸ä¸Šé¢çš„backendå­—æ®µç›¸åŒ ingressClassName: \u003cstring\u003e #ingressClassèµ„æºåç§°ï¼Œä½œç”¨ç±»ä¼¼äºä¸Šé¢çš„æ³¨è§£ä¿¡æ¯ï¼Œç”¨äºæŒ‡å®šé€‚é…çš„Ingressæ§åˆ¶å™¨","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:3:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"3.2 å•åŸŸåè®¿é—®ç¤ºä¾‹ å…ˆåˆ›å»ºä¸€ä¸‹èµ„æºï¼Œç”¨äºæµ‹è¯•IngressåŠŸèƒ½ï¼Œéƒ¨ç½²æ–‡ä»¶å¦‚ä¸‹ï¼ŒåŒ…å«ä¸¤ä¸ªtomcat-podå’Œä¸¤ä¸ªå¯¹åº”çš„Svc apiVersion: apps/v1 kind: Deployment metadata: name: tomcat-app1 spec: replicas: 1 selector: matchLabels: app: tomcat-app1 template: metadata: labels: app: tomcat-app1 spec: containers: - name: tomcat image: harbor.ceamg.com/xinweb11/tomcat-app1:1.9 ports: - name: http containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: tomcat-app1-svc spec: selector: app: tomcat-app1 ports: - name: http port: 8080 targetPort: 8080 protocol: TCP --- apiVersion: apps/v1 kind: Deployment metadata: name: tomcat-app2 spec: replicas: 1 selector: matchLabels: app: tomcat-app2 template: metadata: labels: app: tomcat-app2 spec: containers: - name: tomcat image: harbor.ceamg.com/xinweb11/tomcat-app1:1.9 ports: - name: http containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: tomcat-app2-svc spec: selector: app: tomcat-app2 ports: - name: http port: 8080 targetPort: 8080 protocol: TCPpodåˆ›å»ºæˆåŠŸå åˆ°é‡Œé¢åˆ›å»ºä¸€ä¸ªæµ‹è¯•é¡µé¢ --------------------------------tomcat-app1--------------------------------------------------- root@tomcat-app1-6fd79cfbd4-8tg64:/data/tomcat/webapps/myapp1# echo \"tomcat app1 ingress\" \u003e index.jsp root@tomcat-app1-6fd79cfbd4-8tg64:/data/tomcat/webapps/myapp1# ls index.jsp root@master01[17:13:13]~/ingress-test #:curl 10.10.103.87:8080/myapp1/ tomcat app1 ingress --------------------------------tomcat-app2--------------------------------------------------- root@tomcat-app2-54b548dfbf-zsgpd:/apps/tomcat/bin# mkdir /data/tomcat/webapps/myapp2 root@tomcat-app2-54b548dfbf-zsgpd:/apps/tomcat/bin# echo \"tomcat app2 ingress\" \u003e /data/tomcat/webapps/myapp2/index.jsp root@tomcat-app2-54b548dfbf-zsgpd:/apps/tomcat/bin# ./catalina.sh stop root@tomcat-app2-54b548dfbf-zsgpd:/apps/tomcat/bin# ./catalina.sh start root@master01[17:19:14]~/ingress-test #:curl 10.10.219.108:8080/myapp2/ tomcat app2 ingress3.2.1 å•åŸŸå ingress èµ„æº å°†è®¿é—®www.app1.com åŸŸåçš„æµé‡è½¬å‘è‡³tomcat-app1-svcï¼ŒIngresséƒ¨ç½²æ–‡ä»¶å¦‚ä¸‹ï¼š apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-tomcat-app1 annotations: kubernetes.io/ingress.class: \"nginx\" #æŒ‡å®šç”±å“ªä¸ªIngress Controllerè§£æ nginx.ingress.kubernetes.io/use-regex: \"true\" ##æŒ‡å®šåé¢ruleså®šä¹‰çš„pathå¯ä»¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ nginx.ingress.kubernetes.io/proxy-connect-timeout: \"600\" ##è¿æ¥è¶…æ—¶æ—¶é—´,é»˜è®¤ä¸º5s nginx.ingress.kubernetes.io/proxy-send-timeout: \"600\" ##åç«¯æœåŠ¡å™¨å›è½¬æ•°æ®è¶…æ—¶æ—¶é—´,é»˜è®¤ä¸º60s nginx.ingress.kubernetes.io/proxy-read-timeout: \"600\" ##åç«¯æœåŠ¡å™¨å“åº”è¶…æ—¶æ—¶é—´,é»˜è®¤ä¸º60s nginx.ingress.kubernetes.io/proxy-body-size: \"50m\" ##å®¢æˆ·ç«¯ä¸Šä¼ æ–‡ä»¶ï¼Œæœ€å¤§å¤§å°ï¼Œé»˜è®¤ä¸º20m #nginx.ingress.kubernetes.io/rewrite-target: / ##URLé‡å†™ nginx.ingress.kubernetes.io/app-root: /index.html spec: rules: - host: www.app1.com http: paths: - path: / pathType: Prefix backend: service: name: tomcat-app1-svc port: number: 80803.2.2 å¤šåŸŸå ingress èµ„æº apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-tomcat-app annotations: kubernetes.io/ingress.class: \"nginx\" nginx.ingress.kubernetes.io/use-regex: \"true\" nginx.ingress.kubernetes.io/proxy-connect-timeout: \"600\" nginx.ingress.kubernetes.io/proxy-send-timeout: \"600\" nginx.ingress.kubernetes.io/proxy-read-timeout: \"600\" nginx.ingress.kubernetes.io/proxy-body-size: \"50m\" #nginx.ingress.kubernetes.io/rewrite-target: / #nginx.ingress.kubernetes.io/app-root: /index.html spec: rules: - host: www.myapp1.com http: paths: - path: / pathType: Prefix backend: service: name: tomcat-app1-svc port: number: 8080 - host: www.myapp2.com http: paths: - path: / pathType: Prefix backend: service: name: tomcat-app2-svc port: number: 8080root@master01[17:24:26]~/ingress-test #:kubectl apply -f tomcat-app-ingress1-ingress.yaml ingress.networking.k8s.io/ingress-tomcat-app1 created root@master01[17:24:34]~/ingress-test #:kubectl get ingress NAME CLASS HOSTS ADDRESS PORTS AGE ingress-tomcat-app \u003cnone\u003e www.myapp1.com,www.myapp2.com 10.1.0.32,10.1.0.33 80 4m34s3.2.3 é…ç½®Haproxy+ keepalived å®ç°è´Ÿè½½å‡è¡¡ apt install keepalived haproxy -ykeepalived é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š ##################################Master################################## global_defs { n","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:3:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"3.3 Ingress é…ç½®TLS 3.3.1 åˆ›å»ºè¯ä¹¦ é¦–å…ˆå‡†å¤‡www.myapp1.com åŸŸåçš„è¯ä¹¦ï¼Œç„¶åå°†è¯ä¹¦ä¿å­˜ä¸ºSecret mkdir ingress-cert \u0026\u0026 cd ingress-cert openssl genrsa -out ca.key 4096 openssl req -x509 -new -nodes -sha512 -days 100 \\ -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=www.myapp1.com\" \\ -key ca.key \\ -out ca.crt openssl genrsa -out www.myapp1.com.key 4096 openssl req -sha512 -new \\ -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=www.myapp1.com\" \\ -key www.myapp1.com.key \\ -out www.myapp1.com.csr openssl x509 -req -sha512 -days 3650 \\ -CA ca.crt -CAkey ca.key -CAcreateserial \\ -in www.myapp1.com.csr \\ -out www.myapp1.com.crt rm -f www.myapp1.com.csr kubectl create secret tls cert-www.myapp1.com --cert ./www.myapp1.com.crt --key ./www.myapp1.com.keyæŸ¥çœ‹Secret root@master01[14:41:14]~/ingress-cert #:kubectl describe secrets cert-www.myapp1.com Name: cert-www.myapp1.com Namespace: default Labels: \u003cnone\u003e Annotations: \u003cnone\u003e Type: kubernetes.io/tls Data ==== tls.crt: 1931 bytes tls.key: 3243 bytes3.3.2 Ingressä½¿ç”¨TLSè¯ä¹¦ç¤ºä¾‹ apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-tls-url annotations: kubernetes.io/ingress.class: \"nginx\" nginx.ingress.kubernetes.io/use-regex: \"true\" nginx.ingress.kubernetes.io/proxy-connect-timeout: \"600\" nginx.ingress.kubernetes.io/proxy-send-timeout: \"600\" nginx.ingress.kubernetes.io/proxy-read-timeout: \"600\" nginx.ingress.kubernetes.io/proxy-body-size: \"50m\" #nginx.ingress.kubernetes.io/rewrite-target: / nginx.ingress.kubernetes.io/app-root: /index.html spec: rules: - host: www.myapp1.com http: paths: - path: /tls1 pathType: Prefix backend: service: name: tomcat-app1-svc port: number: 8080 - path: /tls2 pathType: Prefix backend: service: name: tomcat-app2-svc port: number: 8080 tls: #å¦‚æœå¤šä¸ªåŸŸåéƒ½ä½¿ç”¨httpsï¼Œå†æ·»åŠ ä¸€ä¸ªåˆ—è¡¨é¡¹å³å¯ - hosts: [\"www.myapp1.com\"] #å¦‚æœå¤šä¸ªåŸŸåä½¿ç”¨ç›¸åŒçš„è¯ä¹¦ï¼Œåœ¨è¿™é‡Œçš„åˆ—è¡¨æ·»åŠ ä¸€ä¸ªåŸŸåå³å¯ secretName: cert-www.myapp1.com3.3.3 pod ä¸­åˆ›å»ºç”¨äºæµ‹è¯•çš„ç›®å½•å’Œé¡µé¢ mkdir /data/tomcat/webapps/tls1 echo \"www.myapp1.com/tls1/index.html\" \u003e /data/tomcat/webapps/tls1/index.html mkdir /data/tomcat/webapps/tls2 echo \"www.myapp1.com/tls2/index.html\" \u003e /data/tomcat/webapps/tls2/index.html3.3.4 è®¿é—®æµ‹è¯• ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:3:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["Kubernetes"],"content":"3.4 è¯ä¹¦æ›´æ–° å‡è®¾ç½‘ç«™çš„httpsè¯ä¹¦å³å°†è¿‡æœŸï¼Œåœ¨ä¸å½±å“ä¸šåŠ¡çš„å‰æä¸‹ï¼Œå¯ä»¥ç›´æ¥æ›´æ–°å…¶å¼•ç”¨çš„Secretä¸­ä¿å­˜çš„è¯ä¹¦æ¥å®ç°ç½‘ç«™httpsè¯ä¹¦æ›´æ–°ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒéœ€è¦æå‰åšå¥½è®¡åˆ’ï¼Œå¹¶é€‰æ‹©åˆé€‚æ—¶é—´æ‰§è¡Œã€‚ é¦–å…ˆé‡æ–°ç­¾å‘ä¸€å¥—è¯ä¹¦ openssl genrsa -out www.myapp1.com-new.key 4096 openssl req -sha512 -new \\ -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=www.linux.io\" \\ -key www.myapp1.com-new.key \\ -out www.myapp1.com-new.csr openssl x509 -req -sha512 -days 100 \\ -CA ca.crt -CAkey ca.key -CAcreateserial \\ -in www.myapp1.com-new.csr \\ -out www.myapp1.com-new.crt rm -f www.myapp1.com-new.csrå°†è¯ä¹¦å’Œkeyçš„å†…å®¹è¿›è¡Œbase64ç¼–ç ï¼Œç„¶åç¼–è¾‘ç›¸åº”çš„Secretå¯¹è±¡ï¼Œä¿®æ”¹tls.keyå’Œtls.crtçš„å€¼ä¸ºç¼–ç åçš„å†…å®¹ root@master-01:~/resources/ingress-cert# base64 www.myapp1.com-new.key -w 0 LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS.............ZLS0tLS0K root@master-01:~/resources/ingress-cert# base64 www.myapp1.com-new.crt -w 0 LS0tLS1CRUdJTiBDRVJ..............FTkQgQ0VSVElGSUNBVEUtLS0tLQo= root@master-01:~# kubectl edit secret/cert-www.myapp1.com å’Œä¹‹å‰çš„è®¿é—®ç»“æœè¿›è¡Œå¯¹æ¯”ï¼Œå¯ä»¥çœ‹åˆ°è¯ä¹¦å·²ç»è¢«æ›´æ–° ","date":"2023-02-15","objectID":"/posts/kubernetes/primary/kubernetes-12/:3:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åäºŒ)","uri":"/posts/kubernetes/primary/kubernetes-12/"},{"categories":["HAProxy"],"content":"å…­ã€HAProxy httpså®ç° #é…ç½®HAProxyæ”¯æŒhttpsåè®®ï¼Œæ”¯æŒsslä¼šè¯ï¼› bind *:443 ssl crt /PATH/TO/SOME_PEM_FILE #crt åè¯ä¹¦æ–‡ä»¶ä¸ºPEMæ ¼å¼ï¼Œä¸”åŒæ—¶åŒ…å«è¯ä¹¦å’Œæ‰€æœ‰ç§é’¥ cat demo.crt demo.key \u003e demo.pem #æŠŠ80ç«¯å£çš„è¯·æ±‚é‡å‘å®š443 bind *:80 redirect scheme https if !{ ssl_fc } #å‘åç«¯ä¼ é€’ç”¨æˆ·è¯·æ±‚çš„åè®®å’Œç«¯å£ï¼ˆfrontendæˆ–backendï¼‰ http_request set-header X-Forwarded-Port %[dst_port] http_request add-header X-Forwared-Proto https if { ssl_fc }","date":"2023-02-07","objectID":"/posts/haproxy/haproxy-4/:1:0","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-httpså®ç°ï¼ˆå››ï¼‰","uri":"/posts/haproxy/haproxy-4/"},{"categories":["HAProxy"],"content":"6.1 è¯ä¹¦åˆ¶ä½œ #æ–¹æ³•1 [root@centos7 ~]mkdir /etc/haproxy/certs/ [root@centos7 ~]cd /etc/haproxy/certs/ [root@centos7 certs]#openssl genrsa -out haproxy.key 2048 [root@centos7 certs]#openssl req -new -x509 -key haproxy.key -out haproxy.crt -subj \"/CN=www.xinblog.org\" #æˆ–è€…ç”¨ä¸‹ä¸€æ¡å‘½ä»¤å®ç° [root@centos7 certs]#openssl req -x509 -newkey rsa:2048 -subj \"/CN=www.magedu.org\" -keyout haproxy.key -nodes -days 365 -out haproxy.crt [root@centos7 certs]#cat haproxy.key haproxy.crt \u003e haproxy.pem [root@centos7 certs]#openssl x509 -in haproxy.pem -noout -text #æŸ¥çœ‹è¯ä¹¦","date":"2023-02-07","objectID":"/posts/haproxy/haproxy-4/:1:1","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-httpså®ç°ï¼ˆå››ï¼‰","uri":"/posts/haproxy/haproxy-4/"},{"categories":["HAProxy"],"content":"6.2 httpsé…ç½®ç¤ºä¾‹ [root@centos7 ~]#cat /etc/haproxy/conf.d/test.cfg frontend magedu_http_port bind 10.0.0.7:80 bind 10.0.0.7:443 ssl crt /etc/haproxy/certs/haproxy.pem redirect scheme https if !{ ssl_fc } # æ³¨æ„{ }å†…çš„ç©ºæ ¼ http-request set-header X-forwarded-Port %[dst_port] http-request add-header X-forwarded-Proto https if { ssl_fc } mode http balance roundrobin log global option httplog ###################### acl setting ############################### acl mobile_domain hdr_dom(host) -i mobile.magedu.org ###################### acl hosts ################################# default_backend pc_hosts ################### backend hosts ################################# backend mobile_hosts mode http server web1 10.0.0.17:80 check inter 2000 fall 3 rise 5 backend pc_hosts mode http #http-request set-header X-forwarded-Port %[dst_port] ä¹Ÿå¯åŠ åœ¨æ­¤å¤„ #http-request add-header X-forwarded-Proto https if { ssl_fc } server web2 10.0.0.27:80 check inter 2000 fall 3 rise 5 [root@centos7 ~]#ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 10.0.0.7:443 *:* LISTEN 0 128 *:9999 *:* LISTEN 0 128 10.0.0.7:80 *:* LISTEN 0 128 *:22 *:* LISTEN 0 128 [::]:22 [::]:* global maxconn 100000 chroot /var/lib/haproxy stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin #uid 99 #gid 99 user haproxy group haproxy daemon #nbproc 4 #cpu-map 1 0 #cpu-map 2 1 #cpu-map 3 2 #cpu-map 4 3 pidfile /var/lib/haproxy/haproxy.pid log 127.0.0.1 local2 info defaults option http-keep-alive maxconn 100000 option forwardfor mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:123456 listen http_80 mode http bind 10.1.0.6:30013 bind 10.1.0.6:443 ssl crt /etc/haproxy/certs/haproxy.pem redirect scheme https if !{ ssl_fc } http-request set-header X-forwarded-Port %[dst_port] http-request add-header X-forwarded-Proto https if { ssl_fc } balance roundrobin log global option forwardfor server web1 10.1.0.31:30013 check inter 2000 fall 3 rise 5 server web2 10.1.0.32:30013 check inter 2000 fall 3 rise 5 ","date":"2023-02-07","objectID":"/posts/haproxy/haproxy-4/:1:2","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-httpså®ç°ï¼ˆå››ï¼‰","uri":"/posts/haproxy/haproxy-4/"},{"categories":["HAProxy"],"content":"äº”ã€HAProxyè°ƒåº¦ç®—æ³• HAProxyé€šè¿‡å›ºå®šå‚æ•° **balance ** æŒ‡æ˜å¯¹åç«¯æœåŠ¡å™¨çš„è°ƒåº¦ç®—æ³•ï¼Œè¯¥å‚æ•°å¯ä»¥é…ç½®åœ¨listenæˆ–backendé€‰é¡¹ä¸­ã€‚ HAProxyçš„è°ƒåº¦ç®—æ³•åˆ†ä¸ºé™æ€å’ŒåŠ¨æ€è°ƒåº¦ç®—æ³•ï¼Œä½†æ˜¯æœ‰äº›ç®—æ³•å¯ä»¥æ ¹æ®å‚æ•°åœ¨é™æ€å’ŒåŠ¨æ€ç®—æ³•ä¸­ç›¸äº’è½¬æ¢ã€‚ å®˜æ–¹æ–‡æ¡£ï¼šhttp://cbonte.github.io/haproxy-dconv/2.6/configuration.html#balance ","date":"2023-02-06","objectID":"/posts/haproxy/haproxy-3/:1:0","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-è°ƒåº¦ç®—æ³•(ä¸‰)","uri":"/posts/haproxy/haproxy-3/"},{"categories":["HAProxy"],"content":"5.1 é™æ€ç®—æ³• :::info ** é™æ€ç®—æ³•**ï¼šæŒ‰ç…§äº‹å…ˆå®šä¹‰å¥½çš„è§„åˆ™è½®è¯¢å…¬å¹³è°ƒåº¦ï¼Œä¸å…³å¿ƒåç«¯æœåŠ¡å™¨çš„å½“å‰è´Ÿè½½ã€é“¾æ¥æ•°å’Œå“åº”é€Ÿåº¦ç­‰ï¼Œä¸”æ— æ³•å®æ—¶ä¿®æ”¹æƒé‡ï¼Œåªèƒ½é é‡å¯HAProxyç”Ÿæ•ˆã€‚ ::: å¯ä»¥åˆ©ç”¨ socatå·¥å…·å¯¹æœåŠ¡å™¨åŠ¨æ€æƒé‡å’Œå…¶å®ƒçŠ¶æ€çš„è°ƒæ•´ï¼ŒSocat æ˜¯ Linux ä¸‹çš„ä¸€ä¸ªå¤šåŠŸèƒ½çš„ç½‘ç»œå·¥å…·ï¼Œåå­—æ¥ç”±æ˜¯Socket CATï¼ŒSocat çš„ä¸»è¦ç‰¹ç‚¹å°±æ˜¯åœ¨ä¸¤ä¸ªæ•°æ®æµä¹‹é—´å»ºç«‹é€šé“ï¼Œä¸”æ”¯æŒä¼—å¤šåè®®å’Œé“¾æ¥æ–¹å¼ã€‚å¦‚ IPã€TCPã€ UDPã€IPv6ã€Socketæ–‡ä»¶ç­‰ **åˆ©ç”¨å·¥å…·socat å¯¹æœåŠ¡å™¨åŠ¨æ€æƒé‡è°ƒæ•´ ** [root@centos7 ~]#yum -y install socat [root@centos7 ~]#echo \"show info\" | socat stdio /var/lib/haproxy/haproxy.sock Name: HAProxy Version: 2.1.3 Release_date: 2020/02/12 Nbthread: 4 Nbproc: 1 Process_num: 1 Pid: 2279 Uptime: 0d 0h46m07s Uptime_sec: 2767 Memmax_MB: 0 PoolAlloc_MB: 0 PoolUsed_MB: 0 PoolFailed: 0 Ulimit-n: 200041 Maxsock: 200041 Maxconn: 100000 Hard_maxconn: 100000 CurrConns: 0 CumConns: 1 CumReq: 1 MaxSslConns: 0 CurrSslConns: 0 CumSslConns: 0 Maxpipes: 0 PipesUsed: 0 PipesFree: 0 ConnRate: 0 ConnRateLimit: 0 MaxConnRate: 0 SessRate: 0 SessRateLimit: 0 MaxSessRate: 0 SslRate: 0 SslRateLimit: 0 MaxSslRate: 0 SslFrontendKeyRate: 0 SslFrontendMaxKeyRate: 0 SslFrontendSessionReuse_pct: 0 SslBackendKeyRate: 0 SslBackendMaxKeyRate: 0 SslCacheLookups: 0 SslCacheMisses: 0 CompressBpsIn: 0 CompressBpsOut: 0 CompressBpsRateLim: 0 ZlibMemUsage: 0 MaxZlibMemUsage: 0 Tasks: 19 Run_queue: 1 Idle_pct: 100 node: centos7.wangxiaochun.com Stopping: 0 Jobs: 7 Unstoppable Jobs: 0 Listeners: 6 ActivePeers: 0 ConnectedPeers: 0 DroppedLogs: 0 BusyPolling: 0 FailedResolutions: 0 TotalBytesOut: 0 BytesOutRate: 0 DebugCommandsIssued: 0 [root@centos7 ~]#echo \"show servers state\" | socat stdio /var/lib/haproxy/haproxy.sock1 # be_id be_name srv_id srv_name srv_addr srv_op_state srv_admin_state srv_uweight srv_iweight srv_time_since_last_change srv_check_status srv_check_result srv_check_health srv_check_state srv_agent_state bk_f_forced_id srv_f_forced_id srv_fqdn srv_port srvrecord 2 magedu-test-80 1 web1 10.0.0.17 2 0 2 1 812 6 3 7 6 0 0 0 - 80 - 2 magedu-test-80 2 web2 10.0.0.27 2 0 2 3 812 6 3 4 6 0 0 0 - 80 - 4 web_port 1 web1 127.0.0.1 0 0 1 1 810 8 2 0 6 0 0 0 - 8080 - [root@centos7 ~]#echo \"get weight magedu-test-80/web2\" | socat stdio /var/lib/haproxy/haproxy.sock 3 (initial 3) #ä¿®æ”¹weightï¼Œæ³¨æ„åªé’ˆå¯¹å•è¿›ç¨‹æœ‰æ•ˆ [root@centos7 ~]#echo \"set weight magedu-test-80/web2 2\" | socat stdio /var/lib/haproxy/haproxy.sock [root@centos7 ~]#echo \"get weight magedu-test-80/web2\" | socat stdio /var/lib/haproxy/haproxy.sock 2 (initial 3) #å°†åç«¯æœåŠ¡å™¨ç¦ç”¨ï¼Œæ³¨æ„åªé’ˆå¯¹å•è¿›ç¨‹æœ‰æ•ˆ [root@centos7 ~]#echo \"disable server magedu-test-80/web2\" | socat stdio /var/lib/haproxy/haproxy.sock #å°†åç«¯æœåŠ¡å™¨è½¯ä¸‹çº¿ï¼Œå³weightè®¾ä¸º0 [root@centos7 ~]#echo \"set weight magedu-test-80/web1 0\" | socat stdio /var/lib/haproxy/haproxy.sock #å°†åç«¯æœåŠ¡å™¨ç¦ç”¨ï¼Œé’ˆå¯¹å¤šè¿›ç¨‹ [root@centos7 ~]#vim /etc/haproxy/haproxy.cfg ...... stats socket /var/lib/haproxy/haproxy1.sock mode 600 level admin process 1 stats socket /var/lib/haproxy/haproxy2.sock mode 600 level admin process 2 nbproc 2 ..... [root@centos7 ~]#echo \"disable server magedu-test-80/web2\" | socat stdio /var/lib/haproxy/haproxy1.sock [root@centos7 ~]#echo \"disable server magedu-test-80/web2\" | socat stdio /var/lib/haproxy/haproxy2.sock [root@haproxy ~]#for i in {1..2};do echo \"set weight magedu-test-80/web$i 10\" | socat stdio /var/lib/haproxy/haproxy$i.sock;done #å¦‚æœé™æ€ç®—æ³•ï¼Œå¦‚:static-rrï¼Œå¯ä»¥æ›´æ”¹weightä¸º0æˆ–1ï¼Œä½†ä¸æ”¯æŒåŠ¨æ€æ›´æ”¹weightä¸ºå…¶å®ƒå€¼ï¼Œå¦åˆ™ä¼šæç¤ºä¸‹é¢ä¿¡æ¯ [root@centos7 ~]#echo \"set weight magedu-test-80/web1 0\" | socat stdio /var/lib/haproxy/haproxy.sock [root@centos7 ~]#echo \"set weight magedu-test-80/web1 1\" | socat stdio /var/lib/haproxy/haproxy.sock [root@centos7 ~]#echo \"set weight magedu-test-80/web1 2\" | socat stdio /var/lib/haproxy/haproxy.sock Backend is using a static LB algorithm and only accepts weights '0%' and '100%'.5.1.1 static-rr :::info static-rrï¼šåŸºäºæƒé‡çš„è½®è¯¢è°ƒåº¦ï¼Œä¸æ”¯æŒæƒé‡çš„è¿è¡Œæ—¶åˆ©ç”¨socatè¿›è¡ŒåŠ¨æ€è°ƒæ•´åŠåç«¯æœåŠ¡å™¨æ…¢å¯åŠ¨ï¼Œå…¶åç«¯ä¸»æœºæ•°é‡æ²¡æœ‰é™åˆ¶ï¼Œç›¸å½“äºLVSä¸­çš„ wrr ::: listen web_host bind 10.0.0.7:80,:8801-8810,10.0.0.7:9001-9010 mode http log global balance static-rr server web1 10.0.0.17:80 weight 1 check inter 3000 fall 2 rise 5 server web2 10.0.0.27:80 weight 2 check inter 3000 fall 2 rise 55.1.2 first :::warning firstï¼šæ ¹æ®æœåŠ¡å™¨åœ¨åˆ—è¡¨ä¸­çš„ä½ç½®ï¼Œè‡ªä¸Šè€Œä¸‹è¿›è¡Œè°ƒåº¦ï¼Œä½†æ˜¯å…¶åªä¼šå½“ç¬¬ä¸€å°æœåŠ¡å™¨çš„è¿æ¥æ•°è¾¾åˆ°ä¸Šé™ï¼Œæ–°è¯·æ±‚æ‰ä¼šåˆ†é…ç»™ä¸‹ä¸€å°æœåŠ¡ï¼Œå› æ­¤ä¼šå¿½ç•¥æœåŠ¡å™¨çš„æƒ","date":"2023-02-06","objectID":"/posts/haproxy/haproxy-3/:1:1","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-è°ƒåº¦ç®—æ³•(ä¸‰)","uri":"/posts/haproxy/haproxy-3/"},{"categories":["HAProxy"],"content":"5.2 åŠ¨æ€ç®—æ³• :::success åŠ¨æ€ç®—æ³•ï¼šåŸºäºåç«¯æœåŠ¡å™¨çŠ¶æ€è¿›è¡Œè°ƒåº¦é€‚å½“è°ƒæ•´ï¼Œä¼˜å…ˆè°ƒåº¦è‡³å½“å‰è´Ÿè½½è¾ƒä½çš„æœåŠ¡å™¨ï¼Œä¸”æƒé‡å¯ä»¥åœ¨haproxyè¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´æ— éœ€é‡å¯ã€‚ ::: 5.2.1 roundrobin roundrobinï¼šåŸºäºæƒé‡çš„è½®è¯¢åŠ¨æ€è°ƒåº¦ç®—æ³•ï¼Œæ”¯æŒæƒé‡çš„è¿è¡Œæ—¶è°ƒæ•´ï¼Œä¸åŒäºlvsä¸­çš„rrè½®è®­æ¨¡å¼ï¼ŒHAProxyä¸­çš„roundrobinæ”¯æŒæ…¢å¯åŠ¨(æ–°åŠ çš„æœåŠ¡å™¨ä¼šé€æ¸å¢åŠ è½¬å‘æ•°)ï¼Œå…¶æ¯ä¸ªåç«¯backendä¸­æœ€å¤šæ”¯æŒ4095ä¸ªreal serverï¼Œæ”¯æŒå¯¹real serveræƒé‡åŠ¨æ€è°ƒæ•´ï¼Œroundrobinä¸ºé»˜è®¤è°ƒåº¦ç®—æ³•ã€‚ listen web_host bind 10.0.0.7:80,:8801-8810,10.0.0.7:9001-9010 mode http log global balance roundrobin server web1 10.0.0.17:80 weight 1 check inter 3000 fall 2 rise 5 server web2 10.0.0.27:80 weight 2 check inter 3000 fall 2 rise 5æ”¯æŒåŠ¨æ€è°ƒæ•´æƒé‡: # echo \"get weight web_host/web1\" | socat stdio /var/lib/haproxy/haproxy.sock 1 (initial 1) # echo \"set weight web_host/web1 3\" | socat stdio /var/lib/haproxy/haproxy.sock # echo \"get weight web_host/web1\" | socat stdio /var/lib/haproxy/haproxy.sock 3 (initial 1)5.2.2 leastconn leastconnåŠ æƒçš„æœ€å°‘è¿æ¥çš„åŠ¨æ€ï¼Œæ”¯æŒæƒé‡çš„è¿è¡Œæ—¶è°ƒæ•´å’Œæ…¢å¯åŠ¨ï¼Œå³å½“å‰åç«¯æœåŠ¡å™¨è¿æ¥æœ€å°‘çš„ä¼˜å…ˆè°ƒåº¦(æ–°å®¢æˆ·ç«¯è¿æ¥)ï¼Œæ¯”è¾ƒé€‚åˆé•¿è¿æ¥çš„åœºæ™¯ä½¿ç”¨ï¼Œæ¯”å¦‚ï¼šMySQLç­‰åœºæ™¯ã€‚ listen web_host bind 10.0.0.7:80,:8801-8810,10.0.0.7:9001-9010 mode http log global balance leastconn server web1 10.0.0.17:80 weight 1 check inter 3000 fall 2 rise 5 server web2 10.0.0.27:80 weight 1 check inter 3000 fall 2 rise 55.2.3 random åœ¨1.9ç‰ˆæœ¬å¼€å§‹å¢åŠ ä¸€ä¸ªå«åšrandomçš„è´Ÿè½½å¹³è¡¡ç®—æ³•ï¼Œå…¶åŸºäºéšæœºæ•°ä½œä¸ºä¸€è‡´æ€§hashçš„keyï¼Œéšæœºè´Ÿè½½å¹³è¡¡å¯¹äºå¤§å‹æœåŠ¡å™¨åœºæˆ–ç»å¸¸æ·»åŠ æˆ–åˆ é™¤æœåŠ¡å™¨éå¸¸æœ‰ç”¨ï¼Œæ”¯æŒweightçš„åŠ¨æ€è°ƒæ•´ï¼Œweightè¾ƒå¤§çš„ä¸»æœºæœ‰æ›´å¤§æ¦‚ç‡è·å–æ–°è¯·æ±‚ã€‚ listen web_host bind 10.0.0.7:80,:8801-8810,10.0.0.7:9001-9010 mode http log global balance random server web1 10.0.0.17:80 weight 1 check inter 3000 fall 2 rise 5 server web2 10.0.0.27:80 weight 1 check inter 3000 fall 2 rise 5","date":"2023-02-06","objectID":"/posts/haproxy/haproxy-3/:1:2","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-è°ƒåº¦ç®—æ³•(ä¸‰)","uri":"/posts/haproxy/haproxy-3/"},{"categories":["HAProxy"],"content":"5.3 å…¶ä»–ç®—æ³• å…¶å®ƒç®—æ³•å³å¯ä½œä¸ºé™æ€ç®—æ³•ï¼Œåˆå¯ä»¥é€šè¿‡é€‰é¡¹æˆä¸ºåŠ¨æ€ç®—æ³• 5.3.1 source æºåœ°å€hashï¼ŒåŸºäºç”¨æˆ·æºåœ°å€hashå¹¶å°†è¯·æ±‚è½¬å‘åˆ°åç«¯æœåŠ¡å™¨ï¼Œåç»­åŒä¸€ä¸ªæºåœ°å€è¯·æ±‚å°†è¢«è½¬å‘è‡³åŒä¸€ä¸ªåç«¯webæœåŠ¡å™¨ã€‚ æ­¤æ–¹å¼å½“åç«¯æœåŠ¡å™¨æ•°æ®é‡å‘ç”Ÿå˜åŒ–æ—¶ï¼Œä¼šå¯¼è‡´å¾ˆå¤šç”¨æˆ·çš„è¯·æ±‚è½¬å‘è‡³æ–°çš„åç«¯æœåŠ¡å™¨ï¼Œé»˜è®¤ä¸ºé™æ€æ–¹å¼ï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡hash-typeæ”¯æŒçš„é€‰é¡¹æ›´æ”¹ã€‚ è¿™ä¸ªç®—æ³•ä¸€èˆ¬æ˜¯åœ¨ä¸æ’å…¥Cookieçš„TCPæ¨¡å¼ä¸‹ä½¿ç”¨ï¼Œä¹Ÿå¯ç»™æ‹’ç»ä¼šè¯cookieçš„å®¢æˆ·æä¾›æœ€å¥½çš„ä¼šè¯ç²˜æ€§ï¼Œé€‚ç”¨äºsessionä¼šè¯ä¿æŒä½†ä¸æ”¯æŒcookieå’Œç¼“å­˜çš„åœºæ™¯ æºåœ°å€æœ‰ä¸¤ç§è½¬å‘å®¢æˆ·ç«¯è¯·æ±‚åˆ°åç«¯æœåŠ¡å™¨çš„æœåŠ¡å™¨é€‰å–è®¡ç®—æ–¹å¼ï¼Œåˆ†åˆ«æ˜¯å–æ¨¡æ³•å’Œä¸€è‡´æ€§hash 5.3.2 map-baseå–æ¨¡æ³• map-basedï¼šå–æ¨¡æ³•ï¼Œå¯¹sourceåœ°å€è¿›è¡Œhashè®¡ç®—ï¼Œå†åŸºäºæœåŠ¡å™¨æ€»æƒé‡çš„å–æ¨¡ï¼Œæœ€ç»ˆç»“æœå†³å®šå°†æ­¤è¯·æ±‚è½¬å‘è‡³å¯¹åº”çš„åç«¯æœåŠ¡å™¨ã€‚ æ­¤æ–¹æ³•æ˜¯é™æ€çš„ï¼Œå³ä¸æ”¯æŒåœ¨çº¿è°ƒæ•´æƒé‡ï¼Œä¸æ”¯æŒæ…¢å¯åŠ¨ï¼Œå¯å®ç°å¯¹åç«¯æœåŠ¡å™¨å‡è¡¡è°ƒåº¦ã€‚ ç¼ºç‚¹æ˜¯å½“æœåŠ¡å™¨çš„æ€»æƒé‡å‘ç”Ÿå˜åŒ–æ—¶ï¼Œå³æœ‰æœåŠ¡å™¨ä¸Šçº¿æˆ–ä¸‹çº¿ï¼Œéƒ½ä¼šå› æ€»æƒé‡å‘ç”Ÿå˜åŒ–è€Œå¯¼è‡´è°ƒåº¦ç»“æœæ•´ä½“æ”¹å˜ï¼Œhash-type æŒ‡å®šçš„é»˜è®¤å€¼ä¸ºæ­¤ç®—æ³• ã€‚ æ‰€è°“å–æ¨¡è¿ç®—ï¼Œå°±æ˜¯è®¡ç®—ä¸¤ä¸ªæ•°ç›¸é™¤ä¹‹åçš„ä½™æ•°ï¼Œ**10%7=3, 7%4=3 ** map-basedç®—æ³•ï¼šåŸºäºæƒé‡å–æ¨¡ï¼Œhash(source_ip)%æ‰€æœ‰åç«¯æœåŠ¡å™¨ç›¸åŠ çš„æ€»æƒé‡ listen web_host bind 10.0.0.7:80,:8801-8810,10.0.0.7:9001-9010 mode tcp log global balance source hash-type map-based server web1 10.0.0.17:80 weight 1 check inter 3000 fall 2 rise 3 server web2 10.0.0.27:80 weight 1 check inter 3000 fall 2 rise 3 [root@haproxy ~]#echo \"set weight web_host/10.0.0.27 10\" | socat stdio /var/lib/haproxy/haproxy.sock Backend is using a static LB algorithm and only accepts weights '0%' and '100%'. [root@haproxy ~]#echo \"set weight web_host/10.0.0.27 0\" | socat stdio /var/lib/haproxy/haproxy.sock [root@haproxy conf.d]#echo \"get weight web_host/10.0.0.27\" | socat stdio /var/lib/haproxy/haproxy.sock 0 (initial 1)5.3.3 ä¸€è‡´æ€§hash ä¸€è‡´æ€§å“ˆå¸Œï¼Œå½“æœåŠ¡å™¨çš„æ€»æƒé‡å‘ç”Ÿå˜åŒ–æ—¶ï¼Œå¯¹è°ƒåº¦ç»“æœå½±å“æ˜¯å±€éƒ¨çš„ï¼Œä¸ä¼šå¼•èµ·å¤§çš„å˜åŠ¨ï¼Œhashï¼ˆoï¼‰mod n ï¼Œè¯¥hashç®—æ³•æ˜¯åŠ¨æ€çš„ï¼Œæ”¯æŒä½¿ç”¨ socatç­‰å·¥å…·è¿›è¡Œåœ¨çº¿æƒé‡è°ƒæ•´ï¼Œæ”¯æŒæ…¢å¯åŠ¨ ã€‚ ç®—æ³•ï¼š 1ã€key1=hash(source_ip)%(2^32) [0---4294967295] 2ã€keyA=hash(åç«¯æœåŠ¡å™¨è™šæ‹Ÿip)%(2^32) 3ã€å°†key1å’ŒkeyAéƒ½æ”¾åœ¨hashç¯ä¸Šï¼Œå°†ç”¨æˆ·è¯·æ±‚è°ƒåº¦åˆ°ç¦»key1æœ€è¿‘çš„keyAå¯¹åº”çš„åç«¯æœåŠ¡å™¨** hashç¯åæ–œé—®é¢˜ ** å¢åŠ è™šæ‹ŸæœåŠ¡å™¨IPæ•°é‡ï¼Œæ¯”å¦‚ï¼šä¸€ä¸ªåç«¯æœåŠ¡å™¨æ ¹æ®æƒé‡ä¸º1ç”Ÿæˆ1000ä¸ªè™šæ‹ŸIPï¼Œå†hashã€‚è€Œåç«¯æœåŠ¡å™¨æƒé‡ä¸º2åˆ™ç”Ÿæˆ2000çš„è™šæ‹ŸIPï¼Œå†hash,æœ€ç»ˆåœ¨hashç¯ä¸Šç”Ÿæˆ3000ä¸ªèŠ‚ç‚¹ï¼Œä»è€Œè§£å†³hashç¯åæ–œé—®é¢˜hashå¯¹è±¡ Hashå¯¹è±¡åˆ°åç«¯æœåŠ¡å™¨çš„æ˜ å°„å…³ç³»ï¼š ä¸€è‡´æ€§hashç¤ºæ„å›¾ åç«¯æœåŠ¡å™¨åœ¨çº¿ä¸ç¦»çº¿çš„è°ƒåº¦æ–¹å¼ ä¸€è‡´æ€§hashé…ç½®ç¤ºä¾‹ listen web_host bind 10.0.0.7:80,:8801-8810,10.0.0.7:9001-9010 mode tcp log global balance source hash-type consistent server web1 10.0.0.17:80 weight 1 check inter 3000 fall 2 rise 5 server web2 10.0.0.27:80 weight 1 check inter 3000 fall 2 rise 5","date":"2023-02-06","objectID":"/posts/haproxy/haproxy-3/:1:3","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-è°ƒåº¦ç®—æ³•(ä¸‰)","uri":"/posts/haproxy/haproxy-3/"},{"categories":["HAProxy"],"content":"å››ã€åŸºç¡€é…ç½®è¯¦è§£ å®˜æ–¹æ–‡æ¡£ï¼šhttp://cbonte.github.io/haproxy-dconv/2.6/configuration.html HAProxy çš„é…ç½®æ–‡ä»¶haproxy.cfgç”±ä¸¤å¤§éƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«æ˜¯globalå’Œproxieséƒ¨åˆ† **global ï¼šå…¨å±€é…ç½®æ®µ ** è¿›ç¨‹åŠå®‰å…¨é…ç½®ç›¸å…³çš„å‚æ•° æ€§èƒ½è°ƒæ•´ç›¸å…³å‚æ•° Debugå‚æ•°** proxiesï¼šä»£ç†é…ç½®æ®µ ** defaultsï¼šä¸ºfrontend, backend, listenæä¾›é»˜è®¤é…ç½® frontendï¼šå‰ç«¯ï¼Œç›¸å½“äºnginxä¸­çš„server {} backendï¼šåç«¯ï¼Œç›¸å½“äºnginxä¸­çš„upstream {} listenï¼šåŒæ—¶æ‹¥æœ‰å‰ç«¯å’Œåç«¯é…ç½®","date":"2023-02-05","objectID":"/posts/haproxy/haproxy-2/:1:0","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-åŸºç¡€é…ç½®è¯¦è§£ ï¼ˆäºŒï¼‰","uri":"/posts/haproxy/haproxy-2/"},{"categories":["HAProxy"],"content":"4.1 globalé…ç½® 4.1.1 global é…ç½®å‚æ•°è¯´æ˜ å®˜æ–¹æ–‡æ¡£ï¼šhttp://cbonte.github.io/haproxy-dconv/2.6/configuration.html chroot #é”å®šè¿è¡Œç›®å½• deamon #ä»¥å®ˆæŠ¤è¿›ç¨‹è¿è¡Œ stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin process 1 #é“¾æ¥æœ¬æœºçš„socketæ–‡ä»¶ï¼Œå®šä¹‰æƒé™æ–¹ä¾¿å¯¹è´Ÿè½½è¿›è¡ŒåŠ¨æ€è°ƒæ•´ user, group, uid, gid #è¿è¡Œhaproxyçš„ç”¨æˆ·èº«ä»½ nbproc n #å¤šè¿›ç¨‹æ¨¡å¼ï¼Œå¼€å¯workerè¿›ç¨‹æ•°ï¼Œå»ºè®®ä¸cpuä¸ªæ•°ç›¸åŒï¼Œé»˜è®¤ä¸º1ã€‚å¼€å¯æ—¶å°±ä¸åœ¨æ”¯æŒçº¿ç¨‹æ¨¡å¼ï¼Œæ²¡å¼€å¯æ—¶ï¼Œä¸€ä¸ªè¿›ç¨‹ä¸‹é¢æœ‰å¤šä¸ªçº¿ç¨‹ #nbthread 1 #æŒ‡å®šæ¯ä¸ªhaproxyè¿›ç¨‹å¼€å¯çš„çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸ºæ¯ä¸ªè¿›ç¨‹ä¸€ä¸ªçº¿ç¨‹,å’Œnbprocäº’æ–¥ï¼ˆç‰ˆæœ¬æœ‰å…³ï¼‰ #å¦‚æœåŒæ—¶å¯ç”¨nbprocå’Œnbthread ä¼šå‡ºç°ä»¥ä¸‹æ—¥å¿—çš„é”™è¯¯ï¼Œæ— æ³•å¯åŠ¨æœåŠ¡ Apr 7 14:46:23 haproxy haproxy: [ALERT] 097/144623 (1454) : config : cannot enable multiple processes if multiple threads are configured. Please use either nbproc or nbthread but not both. cpu-map 1 0 #ç»‘å®šhaproxy è¿›ç¨‹è‡³æŒ‡å®šCPUï¼Œå°†ç¬¬ä¸€ä¸ªworkè¿›ç¨‹ç»‘å®šè‡³0å·CPU cpu-map 2 1 #ç»‘å®šhaproxy è¿›ç¨‹è‡³æŒ‡å®šCPUï¼Œå°†ç¬¬äºŒä¸ªworkè¿›ç¨‹ç»‘å®šè‡³1å·CPU maxconn 100000 #æ¯ä¸ªhaproxyè¿›ç¨‹çš„æœ€å¤§å¹¶å‘è¿æ¥æ•° maxsslconn n #æ¯ä¸ªhaproxyè¿›ç¨‹sslæœ€å¤§è¿æ¥æ•°,ç”¨äºhaproxyé…ç½®äº†è¯ä¹¦çš„åœºæ™¯ä¸‹ maxconnrate n #æ¯ä¸ªè¿›ç¨‹æ¯ç§’åˆ›å»ºçš„æœ€å¤§è¿æ¥æ•°é‡ spread-checks n #åç«¯serverçŠ¶æ€checkéšæœºæå‰æˆ–å»¶è¿Ÿç™¾åˆ†æ¯”æ—¶é—´ï¼Œå»ºè®®2-5(20%-50%)ä¹‹é—´ï¼Œé»˜è®¤å€¼0 pidfile #æŒ‡å®špidæ–‡ä»¶è·¯å¾„ log 127.0.0.1 local2 info #å®šä¹‰å…¨å±€çš„syslogæœåŠ¡å™¨ï¼›æ—¥å¿—æœåŠ¡å™¨éœ€è¦å¼€å¯UDPåè®®ï¼Œæœ€å¤šå¯ä»¥å®šä¹‰ä¸¤ä¸ª4.4.2 å¤šè¿›ç¨‹å’Œçº¿ç¨‹ èŒƒä¾‹ï¼šå¤šè¿›ç¨‹å’Œsocketæ–‡ä»¶ æŸ¥çœ‹CPUæ ¸å¿ƒæ•°é‡ [root@localhost haproxy]# cat /proc/cpuinfo | grep \"cores\" | uniq cpu cores : 8[root@centos7 ~]#vim /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /apps/haproxy stats socket /var/lib/haproxy/haproxy.sock1 mode 600 level admin process 1 stats socket /var/lib/haproxy/haproxy.sock2 mode 600 level admin process 2 uid 99 gid 99 daemon nbproc 2 [root@centos7 ~]#systemctl restart haproxy [root@centos7 ~]#pstree -p |grep haproxy |-haproxy(2634)-+-haproxy(2637) | `-haproxy(2638) [root@centos7 ~]#ll /var/lib/haproxy/ total 4 -rw-r--r-- 1 root root 5 Mar 31 18:49 haproxy.pid srw------- 1 root root 0 Mar 31 18:49 haproxy.sock1 srw------- 1 root root 0 Mar 31 18:49 haproxy.sock24.4.3 é…ç½®HAProxyè®°å½•æ—¥å¿—åˆ°æŒ‡å®šæ—¥å¿—æ–‡ä»¶ä¸­ #åœ¨globalé…ç½®é¡¹å®šä¹‰ï¼š log 127.0.0.1 local{1-7} info #åŸºäºsyslogè®°å½•æ—¥å¿—åˆ°æŒ‡å®šè®¾å¤‡ï¼Œçº§åˆ«æœ‰(errã€warningã€infoã€debug) listen web_port bind 127.0.0.1:80 mode http log global #å¼€å¯å½“å‰web_portçš„æ—¥å¿—åŠŸèƒ½ï¼Œé»˜è®¤ä¸è®°å½•æ—¥å¿— server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5 # systemctl restart haproxyRsyslogé…ç½® vim /etc/rsyslog.conf $ModLoad imudp $UDPServerRun 514 # Save boot messages also to boot.log local7.* /var/log/boot.log local5.* /var/log/haproxy.log local0.* /var/log/haproxy.log # systemctl restart rsyslogéªŒè¯HAProxyæ—¥å¿— é‡å¯syslogæœåŠ¡å¹¶è®¿é—®appé¡µé¢ï¼Œç„¶åéªŒè¯æ˜¯å¦ç”Ÿæˆæ—¥å¿— [root@localhost log]# tail -f haproxy.log Feb 13 11:11:57 localhost haproxy[3127]: Connect from 172.16.32.242:64058 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:57 localhost haproxy[3127]: Connect from 172.16.32.242:64058 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:59 localhost haproxy[3127]: Connect from 172.16.32.242:64058 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:59 localhost haproxy[3127]: Connect from 172.16.32.242:64058 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:59 localhost haproxy[3127]: Connect from 172.16.32.242:64058 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:59 localhost haproxy[3127]: Connect from 172.16.32.242:64058 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:59 localhost haproxy[3127]: Connect from 172.16.32.242:64061 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:59 localhost haproxy[3127]: Connect from 172.16.32.242:64061 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:59 localhost haproxy[3127]: Connect from 172.16.32.242:64061 to 10.1.0.6:30013 (web_port/HTTP) Feb 13 11:11:59 localhost haproxy[3127]: Connect from 172.16.32.242:64061 to 10.1.0.6:30013 (web_port/HTTP)","date":"2023-02-05","objectID":"/posts/haproxy/haproxy-2/:1:1","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-åŸºç¡€é…ç½®è¯¦è§£ ï¼ˆäºŒï¼‰","uri":"/posts/haproxy/haproxy-2/"},{"categories":["HAProxy"],"content":"4.2 Proxiesé…ç½® å®˜æ–¹æ–‡æ¡£ï¼šhttp://docs.haproxy.org/2.6/configuration.html#4 defaults [\u003cname\u003e] #é»˜è®¤é…ç½®é¡¹ï¼Œé’ˆå¯¹ä»¥ä¸‹çš„frontendã€backendå’Œlistenç”Ÿæ•ˆï¼Œå¯ä»¥å¤šä¸ªnameä¹Ÿå¯ä»¥æ²¡æœ‰name frontend \u003cname\u003e #å‰ç«¯servernameï¼Œç±»ä¼¼äºNginxçš„ä¸€ä¸ªè™šæ‹Ÿä¸»æœº serverå’ŒLVSæœåŠ¡é›†ç¾¤ã€‚ backend \u003cname\u003e #åç«¯æœåŠ¡å™¨ç»„ï¼Œç­‰äºnginxçš„upstreamå’ŒLVSä¸­çš„RSæœåŠ¡å™¨ listen \u003cname\u003e #å°†frontendå’Œbackendåˆå¹¶åœ¨ä¸€èµ·é…ç½®ï¼Œç›¸å¯¹äºfrontendå’Œbackendé…ç½®æ›´ç®€æ´ï¼Œç”Ÿäº§å¸¸ç”¨**æ³¨æ„ï¼šnameå­—æ®µåªèƒ½ä½¿ç”¨å¤§å°å†™å­—æ¯ï¼Œæ•°å­—ï¼Œâ€˜-â€™(dash)ï¼Œâ€™_â€˜(underscore)ï¼Œâ€™.â€™ (dot)å’Œ â€˜:â€™(colon)ï¼Œå¹¶ä¸”ä¸¥æ ¼åŒºåˆ†å¤§å°å†™ ** 4.2.1 Proxiesé…ç½®-frontend frontend é…ç½®å‚æ•°ï¼š bindï¼š #æŒ‡å®šHAProxyçš„ç›‘å¬åœ°å€ï¼Œå¯ä»¥æ˜¯IPV4æˆ–IPV6ï¼Œå¯ä»¥åŒæ—¶ç›‘å¬å¤šä¸ªIPæˆ–ç«¯å£ï¼Œå¯åŒæ—¶ç”¨äºlistenå­—æ®µä¸­ #æ ¼å¼ï¼š bind [\u003caddress\u003e]:\u003cport_range\u003e [, ...] [param*] #æ³¨æ„ï¼šå¦‚æœéœ€è¦ç»‘å®šåœ¨éæœ¬æœºçš„IPï¼Œéœ€è¦å¼€å¯å†…æ ¸å‚æ•°ï¼šnet.ipv4.ip_nonlocal_bind=1èŒƒä¾‹ï¼š listen http_proxy #ç›‘å¬httpçš„å¤šä¸ªIPçš„å¤šä¸ªç«¯å£å’Œsockæ–‡ä»¶ bind :80,:443,:8801-8810 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy listen http_https_proxy #httpsç›‘å¬ bind :80 bind :443 ssl crt /etc/haproxy/site.pem #å…¬é’¥å’Œç§é’¥å…¬å…±æ–‡ä»¶ listen http_https_proxy_explicit #ç›‘å¬ipv6ã€ipv4å’Œunix sockæ–‡ä»¶ bind ipv6@:80 bind ipv4@public_ssl:443 ssl crt /etc/haproxy/site.pem bind unix@ssl-frontend.sock user root mode 600 accept-proxy listen external_bind_app1 #ç›‘å¬file descriptor bind \"fd@${FD_APP1}\"** ç”Ÿäº§ç¤ºä¾‹ï¼š** frontend magedu_web_port #å¯ä»¥é‡‡ç”¨åé¢å½¢å¼å‘½åï¼šä¸šåŠ¡-æœåŠ¡-ç«¯å£å· bind :80,:8080 bind 10.0.0.7:10080,:8801-8810,10.0.0.17:9001-9010 mode http|tcp #æŒ‡å®šè´Ÿè½½åè®®ç±»å‹ use_backend \u003cbackend_name\u003e #è°ƒç”¨çš„åç«¯æœåŠ¡å™¨ç»„åç§°4.2.2 Proxiesé…ç½®-backend å®šä¹‰ä¸€ç»„åç«¯æœåŠ¡å™¨ï¼ŒbackendæœåŠ¡å™¨å°†è¢«frontendè¿›è¡Œè°ƒç”¨ã€‚ mode http|tcp #æŒ‡å®šè´Ÿè½½åè®®ç±»å‹,å’Œå¯¹åº”çš„frontendå¿…é¡»ä¸€è‡´ option #é…ç½®é€‰é¡¹ server #å®šä¹‰åç«¯real serveræ³¨æ„ï¼šoptionåé¢åŠ ** httpchkï¼Œsmtpchk,mysql-check,pgsql-checkï¼Œssl-hello-chk**æ–¹æ³•ï¼Œå¯ç”¨äºå®ç°æ›´å¤šåº”ç”¨å±‚æ£€æµ‹åŠŸèƒ½ã€‚ option é…ç½® check #å¯¹æŒ‡å®šrealè¿›è¡Œå¥åº·çŠ¶æ€æ£€æŸ¥ï¼Œå¦‚æœä¸åŠ æ­¤è®¾ç½®ï¼Œé»˜è®¤ä¸å¼€å¯æ£€æŸ¥ addr \u003cIP\u003e #å¯æŒ‡å®šçš„å¥åº·çŠ¶æ€ç›‘æµ‹IPï¼Œå¯ä»¥æ˜¯ä¸“é—¨çš„æ•°æ®ç½‘æ®µï¼Œå‡å°‘ä¸šåŠ¡ç½‘ç»œçš„æµé‡ port \u003cnum\u003e #æŒ‡å®šçš„å¥åº·çŠ¶æ€ç›‘æµ‹ç«¯å£ inter \u003cnum\u003e #å¥åº·çŠ¶æ€æ£€æŸ¥é—´éš”æ—¶é—´ï¼Œé»˜è®¤2000 ms fall \u003cnum\u003e #åç«¯æœåŠ¡å™¨ä»çº¿ä¸Šè½¬ä¸ºçº¿ä¸‹çš„æ£€æŸ¥çš„è¿ç»­å¤±æ•ˆæ¬¡æ•°ï¼Œé»˜è®¤ä¸º3 rise \u003cnum\u003e #åç«¯æœåŠ¡å™¨ä»ä¸‹çº¿æ¢å¤ä¸Šçº¿çš„æ£€æŸ¥çš„è¿ç»­æœ‰æ•ˆæ¬¡æ•°ï¼Œé»˜è®¤ä¸º2 weight \u003cweight\u003e #é»˜è®¤ä¸º1ï¼Œæœ€å¤§å€¼ä¸º256ï¼Œ0è¡¨ç¤ºä¸å‚ä¸è´Ÿè½½å‡è¡¡ï¼Œä½†ä»æ¥å—æŒä¹…è¿æ¥ backup #å°†åç«¯æœåŠ¡å™¨æ ‡è®°ä¸ºå¤‡ä»½çŠ¶æ€,åªåœ¨æ‰€æœ‰éå¤‡ä»½ä¸»æœºdownæœºæ—¶æä¾›æœåŠ¡ï¼Œç±»ä¼¼Sorry Server disabled #å°†åç«¯æœåŠ¡å™¨æ ‡è®°ä¸ºä¸å¯ç”¨çŠ¶æ€ï¼Œå³ç»´æŠ¤çŠ¶æ€ï¼Œé™¤äº†æŒä¹…æ¨¡å¼ï¼Œå°†ä¸å†æ¥å—è¿æ¥ redirect prefix http://www.baidu.com/ #å°†è¯·æ±‚ä¸´æ—¶(302)é‡å®šå‘è‡³å…¶å®ƒURLï¼Œåªé€‚ç”¨äºhttpæ¨¡å¼ redir http://www.baidu.com #å°†è¯·æ±‚ä¸´æ—¶(302)é‡å®šå‘è‡³å…¶å®ƒURLï¼Œåªé€‚ç”¨äºhttpæ¨¡å¼ maxconn \u003cmaxconn\u003e #å½“å‰åç«¯serverçš„æœ€å¤§å¹¶å‘è¿æ¥æ•° backlog \u003cbacklog\u003e #å½“å‰ç«¯æœåŠ¡å™¨çš„è¿æ¥æ•°è¾¾åˆ°ä¸Šé™åçš„åæ´é˜Ÿåˆ—é•¿åº¦ï¼Œæ³¨æ„ï¼šä¸æ”¯æŒbackend4.2.3 frontend+backendé…ç½®å®ä¾‹ èŒƒä¾‹1ï¼š frontend xin-test-http bind :80,:8080 mode tcp use_backend magedu-test-http-nodes backend magedu-test-http-nodes mode tcp default-server inter 1000 weight 6 server web1 10.0.0.17:80 check weight 2 addr 10.0.0.117 port 8080 server web1 10.0.0.27:80 checkèŒƒä¾‹2ï¼š #å®˜ç½‘ä¸šåŠ¡è®¿é—®å…¥å£ frontend WEB_PORT_80 bind 10.0.0.7:80 mode http use_backend web_prot_http_nodes backend web_prot_http_nodes mode http option forwardfor server 10.0.0.17 10.0.0.17:8080 check inter 3000 fall 3 rise 5 server 10.0.0.27 10.0.0.27:8080 check inter 3000 fall 3 rise 54.2.4 Proxiesé…ç½®-listenæ›¿ä»£frontend+backend ä½¿ç”¨listenæ›¿æ¢ä¸Šé¢çš„frontendå’Œbackendçš„é…ç½®æ–¹å¼ï¼Œå¯ä»¥ç®€åŒ–è®¾ç½®ï¼Œé€šå¸¸åªç”¨äºTCPåè®®çš„åº”ç”¨ #å®˜ç½‘ä¸šåŠ¡è®¿é—®å…¥å£ listen WEB_PORT_80 bind 10.0.0.7:80 mode http option forwardfor server web1 10.0.0.17:8080 check inter 3000 fall 3 rise 5 server web2 10.0.0.27:8080 check inter 3000 fall 3 rise 5","date":"2023-02-05","objectID":"/posts/haproxy/haproxy-2/:1:2","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-åŸºç¡€é…ç½®è¯¦è§£ ï¼ˆäºŒï¼‰","uri":"/posts/haproxy/haproxy-2/"},{"categories":["HAProxy"],"content":"4.3 ä½¿ç”¨å­é…ç½®æ–‡ä»¶ä¿å­˜é…ç½® å½“ä¸šåŠ¡ä¼—å¤šæ—¶ï¼Œå°†æ‰€æœ‰é…ç½®éƒ½æ”¾åœ¨ä¸€ä¸ªé…ç½®æ–‡ä»¶ä¸­ï¼Œä¼šé€ æˆç»´æŠ¤å›°éš¾ã€‚å¯ä»¥è€ƒè™‘æŒ‰ä¸šåŠ¡åˆ†ç±»ï¼Œå°†é…ç½®ä¿¡æ¯æ‹†åˆ†ï¼Œæ”¾åœ¨ä¸åŒçš„å­é…ç½®æ–‡ä»¶ä¸­ï¼Œä»è€Œè¾¾åˆ°æ–¹ä¾¿ç»´æŠ¤çš„ç›®çš„ã€‚ #åˆ›å»ºå­é…ç½®ç›®å½• [root@centos7 ~]#mkdir /etc/haproxy/conf.d/ #åˆ›å»ºå­é…ç½®æ–‡ä»¶ï¼Œæ³¨æ„ï¼šå¿…é¡»ä¸ºcfgåç¼€ [root@centos7 ~]#vim /etc/haproxy/conf.d/test.cfg listen WEB_PORT_80 bind 10.0.0.7:80 mode http balance roundrobin server web1 10.0.0.17:80 check inter 3000 fall 2 rise 5 server web2 10.0.0.27:80 check inter 3000 fall 2 rise 5 #æ·»åŠ å­é…ç½®ç›®å½•åˆ°unitæ–‡ä»¶ä¸­ [root@centos7 ~]#vim /lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=syslog.target network.target [Service] ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/conf.d/ -c -q ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/conf.d/ -p /var/lib/haproxy/haproxy.pid ExecReload=/bin/kill -USR2 $MAINPID [Install] WantedBy=multi-user.target [root@centos7 ~]#systemctl daemon-reload [root@centos7 ~]#systemctl restart haproxy","date":"2023-02-05","objectID":"/posts/haproxy/haproxy-2/:1:3","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-åŸºç¡€é…ç½®è¯¦è§£ ï¼ˆäºŒï¼‰","uri":"/posts/haproxy/haproxy-2/"},{"categories":["docker"],"content":"1.ä¸‹è½½DockeräºŒè¿›åˆ¶åŒ… Docker ä¸‹è½½åœ°å€ï¼š https://download.docker.com/win/static/stable/x86_64/ https://mirrors.aliyun.com/docker-ce/linux/static/stable/x86_64/ Docker-compos ä¸‹è½½åœ°å€ï¼š https://github.com/docker/compose/releases https://github.com/docker/compose/releases/download/v2.20.3/docker-compose-linux-x86_64 ","date":"2023-02-04","objectID":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/:1:0","tags":["docker"],"title":"Docker äºŒè¿›åˆ¶æ–¹å¼å®‰è£…","uri":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/"},{"categories":["docker"],"content":"2.å®‰è£…Docker tar xvf docker-24.0.5.zip cp docker/* /usr/bin cp containerd.service /lib/systemd/system/containerd.service cp docker.service /lib/systemd/system/docker.service cp docker.socket /lib/systemd/system/docker.socket cp docker-compose-Linux-x86_64_2.20.3 /usr/bin/docker-compose groupadd docker \u0026\u0026 useradd docker -g docker systemctl enable containerd.service \u0026\u0026 systemctl restart containerd.service systemctl enable docker.service \u0026\u0026 systemctl restart docker.service systemctl enable docker.socket \u0026\u0026 systemctl restart docker.socket ","date":"2023-02-04","objectID":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/:2:0","tags":["docker"],"title":"Docker äºŒè¿›åˆ¶æ–¹å¼å®‰è£…","uri":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/"},{"categories":["docker"],"content":"2.1 containerd.service containerd æ˜¯ Docker çš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œè´Ÿè´£ç®¡ç†å®¹å™¨çš„ç”Ÿå‘½å‘¨æœŸã€é•œåƒä¼ è¾“ä»¥åŠå®¹å™¨è¿›ç¨‹çš„æ‰§è¡Œ,å¦‚åˆ›å»ºå‘½åç©ºé—´ã€æ§åˆ¶ç»„ã€æ–‡ä»¶ç³»ç»Ÿç­‰ã€‚ Docker åœ¨å…¶æ¶æ„ä¸­ä½¿ç”¨äº†å®¹å™¨è¿è¡Œæ—¶ï¼ˆContainer Runtimeï¼‰æ¥ç®¡ç†å®¹å™¨çš„ç”Ÿå‘½å‘¨æœŸã€‚containerd å®ç°äº† OCIï¼ˆOpen Container Initiativeï¼‰æ ‡å‡†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾çš„è¡Œä¸šæ ‡å‡†ï¼Œæ—¨åœ¨å®šä¹‰å®¹å™¨å’Œå®¹å™¨è¿è¡Œæ—¶çš„è§„èŒƒã€‚è¿™ä½¿å¾— containerd èƒ½å¤Ÿä¸å…¶ä»–ç¬¦åˆ OCI æ ‡å‡†çš„å·¥å…·å’Œåº“ååŒå·¥ä½œã€‚ åœ¨ Linux ç³»ç»Ÿä¸­ï¼Œcontainerd ä»¥å®ˆæŠ¤è¿›ç¨‹çš„å½¢å¼è¿è¡Œã€‚ä¸ºäº†ç¡®ä¿ containerd åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨å¯åŠ¨ï¼Œå¹¶èƒ½å¤Ÿå—åˆ° systemdï¼ˆä¸€ä¸ªå¸¸ç”¨çš„åˆå§‹åŒ–ç³»ç»Ÿå’ŒæœåŠ¡ç®¡ç†å™¨ï¼‰çš„ç®¡ç†ï¼Œéœ€è¦åˆ›å»ºå¹¶é…ç½®ä¸€ä¸ª containerd.service å•å…ƒã€‚ è¿™ä¸ªæœåŠ¡å•å…ƒå®šä¹‰äº† containerd å®ˆæŠ¤è¿›ç¨‹çš„å¯åŠ¨æ–¹å¼ã€å‚æ•°ä»¥åŠå…¶ä»–ç›¸å…³è®¾ç½®ã€‚ [Unit] Description=containerd container runtime Documentation=https://containerd.io After=network.target local-fs.target [Service] ExecStartPre=-/sbin/modprobe overlay ExecStart=/usr/bin/containerd Type=notify Delegate=yes KillMode=process Restart=always # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNPROC=infinity LimitCORE=infinity LimitNOFILE=1048576 # Comment TasksMax if your systemd version does not supports it. # Only systemd 226 and above support this version. TasksMax=infinity [Install] WantedBy=multi-user.target","date":"2023-02-04","objectID":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/:2:1","tags":["docker"],"title":"Docker äºŒè¿›åˆ¶æ–¹å¼å®‰è£…","uri":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/"},{"categories":["docker"],"content":"2.2 docker.service docker.service æ˜¯ä¸€ä¸ª Systemd æœåŠ¡å•å…ƒï¼Œç”¨äºç®¡ç† Docker å®ˆæŠ¤è¿›ç¨‹ï¼ˆdockerdï¼‰çš„è¿è¡Œã€‚Systemd æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„åˆå§‹åŒ–ç³»ç»Ÿå’ŒæœåŠ¡ç®¡ç†å™¨ï¼Œè€ŒæœåŠ¡å•å…ƒåˆ™å®šä¹‰äº†å¦‚ä½•å¯åŠ¨ã€åœæ­¢å’Œç®¡ç†ç‰¹å®šçš„æœåŠ¡ã€‚ åœ¨ Docker çš„æ¶æ„ä¸­ï¼Œdockerd æ˜¯ Docker å®ˆæŠ¤è¿›ç¨‹ï¼Œè´Ÿè´£ç®¡ç†å®¹å™¨çš„åˆ›å»ºã€è¿è¡Œã€åœæ­¢ç­‰ä»»åŠ¡ã€‚docker.service çš„ä½œç”¨æ˜¯ç®¡ç† dockerd è¿›ç¨‹çš„ç”Ÿå‘½å‘¨æœŸï¼Œä½¿å¾— Docker å®ˆæŠ¤è¿›ç¨‹å¯ä»¥åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨å¯åŠ¨ï¼Œå¹¶åœ¨éœ€è¦æ—¶æä¾›ç®¡ç†å’Œç›‘æ§ã€‚ [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com BindsTo=containerd.service After=network-online.target firewalld.service containerd.service Wants=network-online.target Requires=docker.socket [Service] Type=notify # the default is not to use systemd for cgroups because the delegate issues still # exists and systemd currently does not support the cgroup feature set required # for containers run by docker ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ExecReload=/bin/kill -s HUP $MAINPID TimeoutSec=0 RestartSec=2 Restart=always # Note that StartLimit* options were moved from \"Service\" to \"Unit\" in systemd 229. # Both the old, and new location are accepted by systemd 229 and up, so using the old location # to make them work for either version of systemd. StartLimitBurst=3 # Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230. # Both the old, and new name are accepted by systemd 230 and up, so using the old name to make # this option work for either version of systemd. StartLimitInterval=60s # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNOFILE=infinity LimitNPROC=infinity LimitCORE=infinity # Comment TasksMax if your systemd version does not support it. # Only systemd 226 and above support this option. TasksMax=infinity # set delegate yes so that systemd does not reset the cgroups of docker containers Delegate=yes # kill only the docker process, not all processes in the cgroup KillMode=process [Install] WantedBy=multi-user.target Description æä¾›äº†å…³äºæœåŠ¡çš„ç®€è¦æè¿°ã€‚ Documentation å¯ä»¥æä¾›æŒ‡å‘ Docker æ–‡æ¡£çš„é“¾æ¥ã€‚ ExecStart æŒ‡å®šäº†å¦‚ä½•å¯åŠ¨ dockerd è¿›ç¨‹ï¼Œè¿™é‡Œçš„ -H fd:// å‘Šè¯‰ Docker å®ˆæŠ¤è¿›ç¨‹é€šè¿‡æ–‡ä»¶æè¿°ç¬¦è¿›è¡Œé€šä¿¡ã€‚ Restart è§„å®šäº†åœ¨å‘ç”Ÿé”™è¯¯æ—¶å¦‚ä½•é‡å¯æœåŠ¡ã€‚ StartLimitIntervalSec å’Œ StartLimitBurst è§„å®šäº†åœ¨ä¸€æ®µæ—¶é—´å†…å°è¯•å¯åŠ¨æœåŠ¡çš„æ¬¡æ•°é™åˆ¶ï¼Œä»¥é¿å…è¿‡å¤šçš„é‡è¯•ã€‚ WantedBy=multi-user.target è¡¨ç¤ºè¯¥æœåŠ¡ä¼šåœ¨å¤šç”¨æˆ·æ¨¡å¼ä¸‹å¯åŠ¨ï¼Œå³åœ¨ç³»ç»Ÿå¼•å¯¼åçš„ä¸€èˆ¬æ“ä½œçŠ¶æ€ä¸‹ã€‚ ","date":"2023-02-04","objectID":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/:2:2","tags":["docker"],"title":"Docker äºŒè¿›åˆ¶æ–¹å¼å®‰è£…","uri":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/"},{"categories":["docker"],"content":"2.3 docker.socket docker.socket æ˜¯ä¸€ä¸ª Systemd å¥—æ¥å­—ï¼ˆsocketï¼‰å•å…ƒï¼Œç”¨äºä¸ Docker å®ˆæŠ¤è¿›ç¨‹ï¼ˆdockerdï¼‰ä¹‹é—´çš„é€šä¿¡ã€‚ å…·ä½“æ¥è¯´ï¼Œdocker.socket é€šè¿‡ç›‘å¬ä¸€ä¸ªç‰¹å®šçš„ç½‘ç»œç«¯å£æˆ–è€… Unix åŸŸå¥—æ¥å­—ï¼ˆUnix Domain Socketï¼‰ï¼Œç­‰å¾…æ¥è‡ª Docker å®¢æˆ·ç«¯çš„è¿æ¥è¯·æ±‚ã€‚ä¸€æ—¦æœ‰è¯·æ±‚è¿æ¥ï¼Œdocker.socket å°±ä¼šå°†è¯·æ±‚è½¬å‘ç»™ dockerd è¿›ç¨‹ï¼Œç„¶å dockerd å¤„ç†è¿™äº›è¯·æ±‚å¹¶æ‰§è¡Œç›¸åº”çš„æ“ä½œï¼Œå¦‚åˆ›å»ºæˆ–ç®¡ç†å®¹å™¨ã€‚ [Unit] Description=Docker Socket for the API PartOf=docker.service [Socket] ListenStream=/var/run/docker.sock SocketMode=0660 SocketUser=root SocketGroup=docker [Install] WantedBy=sockets.target","date":"2023-02-04","objectID":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/:2:3","tags":["docker"],"title":"Docker äºŒè¿›åˆ¶æ–¹å¼å®‰è£…","uri":"/posts/docker/docker%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85/"},{"categories":["HAProxy"],"content":"ä¸‰ã€HAProxyå®‰è£…åŠåŸºç¡€é…ç½® ä»‹ç»HAProxyçš„åŸºç¡€å®‰è£…åŠåŸºç¡€é…ç½® ","date":"2023-02-04","objectID":"/posts/haproxy/haproxy-1/:1:0","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-å®‰è£…åŠåŸºç¡€é…ç½®ï¼ˆä¸€ï¼‰","uri":"/posts/haproxy/haproxy-1/"},{"categories":["HAProxy"],"content":"3.1 æºç åŒ…å®‰è£… å®˜æ–¹æä¾›äº†Ubuntuå’ŒDebiançš„åŒ…ï¼Œæ²¡æœ‰Centosçš„åŒ… ubuntu å®‰è£… apt-get install --no-install-recommends software-properties-common #--no-install-recommends å‚æ•°æ¥é¿å…å®‰è£…éå¿…é¡»çš„æ–‡ä»¶ï¼Œä»è€Œå‡å°é•œåƒçš„ä½“ç§¯ add-apt-repository ppa:vbernat/haproxy-2.6 apt-get install haproxy=2.6.\\*#å®‰è£…å¸¸ç”¨è½¯ä»¶åŒ… apt-get install --no-install-recommends software-properties-common -y #--no-install-recommends å‚æ•°æ¥é¿å…å®‰è£…éå¿…é¡»çš„æ–‡ä»¶ï¼Œä»è€Œå‡å°é•œåƒçš„ä½“ç§¯ #å®‰è£…æº root@etcd01[11:10:22]~ #:add-apt-repository ppa:vbernat/haproxy-2.6 HAProxy is a free, very fast and reliable solution offering high availability, load balancing, and proxying for TCP and HTTP-based applications. It is particularly suited for web sites crawling under very high loads while needing persistence or Layer7 processing. Supporting tens of thousands of connections is clearly realistic with todays hardware. Its mode of operation makes its integration into existing architectures very easy and riskless, while still offering the possibility not to expose fragile web servers to the Net. This PPA contains packages for HAProxy 2.6. More info: https://launchpad.net/~vbernat/+archive/ubuntu/haproxy-2.6 Press [ENTER] to continue or Ctrl-c to cancel adding it. Get:1 http://ppa.launchpad.net/vbernat/haproxy-2.6/ubuntu focal InRelease [23.8 kB] Hit:2 http://cn.archive.ubuntu.com/ubuntu focal InRelease Hit:3 http://cn.archive.ubuntu.com/ubuntu focal-updates InRelease Hit:4 http://cn.archive.ubuntu.com/ubuntu focal-backports InRelease Hit:5 http://cn.archive.ubuntu.com/ubuntu focal-security InRelease Get:6 http://ppa.launchpad.net/vbernat/haproxy-2.6/ubuntu focal/main amd64 Packages [1,000 B] Get:7 http://ppa.launchpad.net/vbernat/haproxy-2.6/ubuntu focal/main Translation-en [704 B] Fetched 25.5 kB in 2s (14.0 kB/s) Reading package lists... Done #æŸ¥çœ‹å¯ç”¨ç‰ˆæœ¬ root@etcd01[11:11:01]~ #:apt-cache madison haproxy haproxy | 2.6.8-1ppa1~focal | http://ppa.launchpad.net/vbernat/haproxy-2.6/ubuntu focal/main amd64 Packages haproxy | 2.0.29-0ubuntu1.1 | http://cn.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages haproxy | 2.0.29-0ubuntu1.1 | http://cn.archive.ubuntu.com/ubuntu focal-security/main amd64 Packages haproxy | 2.0.13-2 | http://cn.archive.ubuntu.com/ubuntu focal/main amd64 Packages #å®‰è£…2.6 apt-get install haproxy=2.6.\\* -y #éªŒè¯haproxyç‰ˆæœ¬ root@etcd01[13:50:48]~ #:haproxy -v HAProxy version 2.6.8-1ppa1~focal 2023/01/24 - https://haproxy.org/ Status: long-term supported branch - will stop receiving fixes around Q2 2027. Known bugs: http://www.haproxy.org/bugs/bugs-2.6.8.html Running on: Linux 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022 x86_64Centoså®‰è£… åœ¨centosç³»ç»Ÿä¸Šé€šè¿‡yumã€ç¼–è¯‘ç­‰å¤šç§å®‰è£…æ–¹å¼ã€‚é»˜è®¤yumæºé»˜è®¤çš„baseä»“åº“ä¸­åŒ…å«haproxyçš„å®‰è£…åŒ…æ–‡ä»¶ï¼Œä½†æ˜¯ç‰ˆæœ¬æ¯”è¾ƒæ—§ï¼Œæ˜¯1.5.18çš„ç‰ˆæœ¬ï¼Œè·ç¦»å½“å‰ç‰ˆæœ¬å·²ç»æœ‰è¾ƒé•¿æ—¶é—´æ²¡æœ‰æ›´æ–°ï¼Œç”±äºç‰ˆæœ¬æ¯”è¾ƒæ—§æ‰€ä»¥æœ‰å¾ˆå¤šåŠŸèƒ½ä¸æ”¯æŒï¼Œå¦‚æœå¯¹åŠŸèƒ½å’Œæ€§èƒ½æ²¡æœ‰è¦æ±‚å¯ä»¥ä½¿ç”¨æ­¤ç‰ˆæœ¬ï¼Œå¦åˆ™æ¨èä½¿ç”¨æ–°ç‰ˆæœ¬ã€‚ # yum install haproxy -y #éªŒè¯haproxyç‰ˆæœ¬ # haproxy -v HA-Proxy version 1.5.18 2016/05/10 Copyright 2000-2016 Willy Tarreau \u003cwilly@haproxy.org\u003e","date":"2023-02-04","objectID":"/posts/haproxy/haproxy-1/:1:1","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-å®‰è£…åŠåŸºç¡€é…ç½®ï¼ˆä¸€ï¼‰","uri":"/posts/haproxy/haproxy-1/"},{"categories":["HAProxy"],"content":"3.2 ç¼–è¯‘å®‰è£…HAProxy ç¼–è¯‘å®‰è£…HAProxy 2.0 LTSç‰ˆæœ¬ï¼Œæºç åŒ…ä¸‹è½½åœ°å€ï¼šhttp://www.haproxy.org/download/ 3.2.1 è§£å†³luaç¯å¢ƒ HAProxyæ”¯æŒåŸºäºluaå®ç°åŠŸèƒ½æ‰©å±•ï¼Œluaæ˜¯ä¸€ç§å°å·§çš„è„šæœ¬è¯­è¨€ï¼Œäº1993å¹´ç”±å·´è¥¿é‡Œçº¦çƒ­å†…å¢å¤©ä¸»æ•™å¤§å­¦ï¼ˆPontiï¬cal Catholic University of Rio de Janeiroï¼‰é‡Œçš„ä¸€ä¸ªç ”ç©¶å°ç»„å¼€å‘ï¼Œå…¶è®¾è®¡ç›®çš„æ˜¯ä¸ºäº†åµŒå…¥åº”ç”¨ç¨‹åºä¸­ï¼Œä»è€Œä¸ºåº”ç”¨ç¨‹åºæä¾›çµæ´»çš„æ‰©å±•å’Œå®šåˆ¶åŠŸèƒ½ã€‚ Lua å®˜ç½‘ï¼šwww.lua.org Luaåº”ç”¨åœºæ™¯ æ¸¸æˆå¼€å‘ ç‹¬ç«‹åº”ç”¨è„šæœ¬ Webåº”ç”¨è„šæœ¬ æ‰©å±•å’Œæ•°æ®åº“æ’ä»¶ï¼Œå¦‚MySQL Proxy å®‰å…¨ç³»ç»Ÿï¼Œå¦‚å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ Centos ç¯å¢ƒï¼šç”±äºcentosè‡ªå¸¦çš„luaç‰ˆæœ¬æ¯”è¾ƒä½å¹¶ä¸ç¬¦åˆHAProxyè¦æ±‚çš„luaæœ€ä½ç‰ˆæœ¬(5.3)çš„è¦æ±‚ï¼Œå› æ­¤éœ€è¦ç¼–è¯‘å®‰è£…è¾ƒæ–°ç‰ˆæœ¬çš„luaç¯å¢ƒï¼Œç„¶åæ‰èƒ½ç¼–è¯‘å®‰è£…HAProxyï¼Œè¿‡ç¨‹å¦‚ä¸‹ï¼š #å½“å‰ç³»ç»Ÿç‰ˆæœ¬ [root@centos7 ~]#lua -v Lua 5.1.4 Copyright (C) 1994-2008 Lua.org, PUC-Rio #å®‰è£…åŸºç¡€å‘½ä»¤åŠç¼–è¯‘ä¾èµ–ç¯å¢ƒ [root@centos7 ~]# yum install gcc readline-devel [root@centos7 ~]# wget http://www.lua.org/ftp/lua-5.3.5.tar.gz [root@centos7 ~]# tar xvf lua-5.3.5.tar.gz -C /usr/local/src [root@centos7 ~]# cd /usr/local/src/lua-5.3.5 [root@centos7 lua-5.3.5]# make linux test [root@localhost lua-5.3.5]# make linux test cd src \u0026\u0026 make linux make[1]: è¿›å…¥ç›®å½•â€œ/usr/local/src/lua-5.3.5/srcâ€ make all SYSCFLAGS=\"-DLUA_USE_LINUX\" SYSLIBS=\"-Wl,-E -ldl -lreadline\" make[2]: è¿›å…¥ç›®å½•â€œ/usr/local/src/lua-5.3.5/srcâ€ gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lapi.o lapi.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lcode.o lcode.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lctype.o lctype.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o ldebug.o ldebug.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o ldo.o ldo.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o ldump.o ldump.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lfunc.o lfunc.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lgc.o lgc.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o llex.o llex.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lmem.o lmem.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lobject.o lobject.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lopcodes.o lopcodes.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lparser.o lparser.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lstate.o lstate.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lstring.o lstring.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o ltable.o ltable.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o ltm.o ltm.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lundump.o lundump.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lvm.o lvm.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lzio.o lzio.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lauxlib.o lauxlib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lbaselib.o lbaselib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lbitlib.o lbitlib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lcorolib.o lcorolib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o ldblib.o ldblib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o liolib.o liolib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lmathlib.o lmathlib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o loslib.o loslib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lstrlib.o lstrlib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o ltablib.o ltablib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o lutf8lib.o lutf8lib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o loadlib.o loadlib.c gcc -std=gnu99 -O2 -Wall -Wextra -DLUA_COMPAT_5_2 -DLUA_USE_LINUX -c -o linit.o linit.c ar rcu liblua.a lapi.o lcode.o l","date":"2023-02-04","objectID":"/posts/haproxy/haproxy-1/:1:2","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-å®‰è£…åŠåŸºç¡€é…ç½®ï¼ˆä¸€ï¼‰","uri":"/posts/haproxy/haproxy-1/"},{"categories":["HAProxy"],"content":"3.3 éªŒè¯haproxyçŠ¶æ€ 3.3.1 éªŒè¯ç›‘å¬ç«¯å£ [root@localhost haproxy]# ss -tnl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.1:631 *:* LISTEN 0 100 *:8088 *:* LISTEN 0 3 127.0.0.1:31769 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 *:1883 *:* LISTEN 0 128 *:30013 *:* LISTEN 0 50 *:8161 *:* LISTEN 0 1 127.0.0.1:8005 *:* LISTEN 0 128 *:5672 *:* LISTEN 0 50 *:43178 *:* LISTEN 0 128 *:6379 *:* LISTEN 0 128 *:61613 *:* LISTEN 0 50 *:61614 *:* LISTEN 0 128 *:9999 *:* 3.3.2 æŸ¥çœ‹haproxyçš„çŠ¶æ€é¡µé¢ æµè§ˆå™¨è®¿é—®ï¼šhttp://haproxy-server:9999/haproxy-status 3.3.3 æµ‹è¯•è½¬å‘ 10.1.0.6:30013 è½¬å‘åˆ° 10.1.0.31:30013 âœ… ","date":"2023-02-04","objectID":"/posts/haproxy/haproxy-1/:1:3","tags":["è´Ÿè½½å‡è¡¡"],"title":"HAProxy-å®‰è£…åŠåŸºç¡€é…ç½®ï¼ˆä¸€ï¼‰","uri":"/posts/haproxy/haproxy-1/"},{"categories":["Kubernetes"],"content":"Apache Dubbo æœ€åˆåœ¨ 2008 å¹´ç”± Alibaba æçŒ®å¼€æºï¼Œå¾ˆå¿«æˆä¸ºäº†å›½å†…å¼€æºæœåŠ¡æ¡†æ¶é€‰å‹çš„äº‹å®æ ‡å‡†æ¡†æ¶ ï¼Œå¾—åˆ°äº†å„è¡Œå„ä¸šçš„å¹¿æ³›åº”ç”¨ã€‚åœ¨ 2017 å¹´ï¼ŒDubbo æ­£å¼æçŒ®åˆ° Apache è½¯ä»¶åŸºé‡‘ä¼šå¹¶æˆä¸º Apache é¡¶çº§é¡¹ç›® ã€‚ Apache Dubbo æ˜¯ä¸€æ¬¾ RPC æœåŠ¡å¼€å‘æ¡†æ¶ï¼Œç”¨äºè§£å†³å¾®æœåŠ¡æ¶æ„ä¸‹çš„æœåŠ¡æ²»ç†ä¸é€šä¿¡é—®é¢˜ï¼Œå®˜æ–¹æä¾›äº† Javaã€Golang ç­‰å¤šè¯­è¨€ SDK å®ç°ã€‚ä½¿ç”¨ Dubbo å¼€å‘çš„å¾®æœåŠ¡åŸç”Ÿå…·å¤‡ç›¸äº’ä¹‹é—´çš„è¿œç¨‹åœ°å€å‘ç°ä¸é€šä¿¡èƒ½åŠ›ï¼Œ åˆ©ç”¨ Dubbo æä¾›çš„ä¸°å¯ŒæœåŠ¡æ²»ç†ç‰¹æ€§ï¼Œå¯ä»¥å®ç°è¯¸å¦‚æœåŠ¡å‘ç°ã€è´Ÿè½½å‡è¡¡ã€æµé‡è°ƒåº¦ç­‰æœåŠ¡æ²»ç†è¯‰æ±‚ã€‚Dubbo è¢«è®¾è®¡ä¸ºé«˜åº¦å¯æ‰©å±•ï¼Œç”¨æˆ·å¯ä»¥æ–¹ä¾¿çš„å®ç°æµé‡æ‹¦æˆªã€é€‰å€çš„å„ç§å®šåˆ¶é€»è¾‘ã€‚ dubbo ç®€ä»‹ **dubbo æ¶æ„ ** ","date":"2023-01-31","objectID":"/posts/kubernetes/primary/kubernetes-11/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åä¸€)","uri":"/posts/kubernetes/primary/kubernetes-11/"},{"categories":["Kubernetes"],"content":"1.æ„å»ºProvideré•œåƒ #Dubbo provider FROM harbor.ceamg.com/pub-images/jdk8:3411 MAINTAINER XXXXXXXX RUN mkdir -p /apps/dubbo/provider ADD dubbo-demo-provider-2.1.5/ /apps/dubbo/provider/ ADD run_java.sh /apps/dubbo/provider/bin/ RUN useradd nginx -u 2023 RUN chown -R nginx.nginx /apps/ \u0026\u0026 chmod +x /apps/dubbo/provider/bin/*.sh CMD [\"/apps/dubbo/provider/bin/run_java.sh\"]dubbo-demo-consumer-2.1.5æ˜¯dubbo consumerçš„ä»£ç ï¼Œä¹Ÿéœ€è¦ä¿®æ”¹ä¸‹é…ç½®ï¼ŒæŒ‡å®šzookeeperçš„åœ°å€ï¼š ## # Copyright 1999-2011 Alibaba Group. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. ## dubbo.container=log4j,spring dubbo.application.name=demo-provider dubbo.application.owner= dubbo.registry.address=zookeeper://zookeeper1.xin-zk.svc.ceamg.local:2181 | zookeeper://zookeeper2.xin-zk.svc.ceamg.local:2181 | zookeeper://zookeeper3.xin-zk.svc.ceamg.local:2181 #dubbo.registry.address=zookeeper://127.0.0.1:2181 #dubbo.registry.address=redis://127.0.0.1:6379 #dubbo.registry.address=dubbo://127.0.0.1:9090 dubbo.monitor.protocol=registry dubbo.protocol.name=dubbo dubbo.protocol.port=20880 dubbo.log4j.file=logs/dubbo-demo-provider.log dubbo.log4j.level=WARNzké›†ç¾¤æµ‹è¯•è¿é€šæ€§ --- zookeeper1.xin-zk.svc.ceamg.local:2181 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.076/0.097/0.118 ms bash-4.3# ping zookeeper2.xin-zk.svc.ceamg.local:2181 PING zookeeper2.xin-zk.svc.ceamg.local:2181 (10.10.101.183): 56 data bytes 64 bytes from 10.10.101.183: seq=0 ttl=64 time=0.059 ms 64 bytes from 10.10.101.183: seq=1 ttl=64 time=0.134 ms ^C --- zookeeper2.xin-zk.svc.ceamg.local:2181 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.059/0.096/0.134 ms bash-4.3# ping zookeeper3.xin-zk.svc.ceamg.local:2181 PING zookeeper3.xin-zk.svc.ceamg.local:2181 (10.10.176.183): 56 data bytes 64 bytes from 10.10.176.183: seq=0 ttl=64 time=0.049 ms 64 bytes from 10.10.176.183: seq=1 ttl=64 time=0.151 ms --- zookeeper3.xin-zk.svc.ceamg.local:2181 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.049/0.100/0.151 msrun_java.shå†…å®¹å¦‚ä¸‹ï¼š #!/bin/bash su - nginx -c \"/apps/dubbo/provider/bin/start.sh\" tail -f /etc/hosts#!/bin/bash TAG=$1 docker build -t harbor.ceamg.com/pub-images/dubbo-provider:${TAG} . docker push harbor.ceamg.com/pub-images/dubbo-provider:${TAG}root@harbor01[21:28:43]~/dubbo/dubbo-demo-consumer-2.1.5/conf #:chmod +x ./*.shæ‰§è¡Œæ„å»ºï¼Œä¸Šä¼ é•œåƒ root@harbor01[21:37:19]~/dubbo/provider #:bash build_image_command.sh v1 Sending build context to Docker daemon 11.56MB Step 1/8 : FROM harbor.ceamg.com/pub-images/jdk8:3411 ---\u003e 1328b4d79a67 Step 2/8 : MAINTAINER XXXXXXXX ---\u003e Using cache ---\u003e d68f684b20d3 Step 3/8 : RUN mkdir -p /apps/dubbo/provider ---\u003e Using cache ---\u003e 1eee7aae68c2 Step 4/8 : ADD dubbo-demo-provider-2.1.5/ /apps/dubbo/provider/ ---\u003e Using cache ---\u003e 7d305495d592 Step 5/8 : ADD run_java.sh /apps/dubbo/provider/bin/ ---\u003e 93a53e745acc Step 6/8 : RUN useradd nginx -u 2023 ---\u003e Running in 6ce3cb1b6065 Removing intermediate container 6ce3cb1b6065 ---\u003e 5f0402802b5c Step 7/8 : RUN chown -R nginx.nginx /apps/ \u0026\u0026 chmod +x /apps/dubbo/provider/bin/*.sh ---\u003e Running in 5e52acec648e Removing intermediate container 5e52acec648e ---\u003e 464dd347a8e2 Step 8/8 : CMD [\"/apps/dubbo/provider/bin/run_java.sh\"] ---\u003e Running in 3ae6dd4ef0d7 Removing intermediate container 3ae6dd4ef0d7 ---\u003e c79f2c1a9fd3 Successfully built c79f2c1a9fd3 Successfully tagged harbor.ceamg.com/pub-images/dubbo-provider:v1 The push refers to rep","date":"2023-01-31","objectID":"/posts/kubernetes/primary/kubernetes-11/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºzookeeperå®ç°å¾®æœåŠ¡åŠ¨æ€æ³¨å†Œå’Œå‘ç° (åä¸€)","uri":"/posts/kubernetes/primary/kubernetes-11/"},{"categories":["Kubernetes"],"content":"https://cn.wordpress.org/download/releases/ ","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"1.å‡†å¤‡PHPé•œåƒ ","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"å®˜æ–¹PHPé•œåƒ root@harbor01[09:20:39]/dockerfile/web/wordpress #:docker pull php:5.6.40-fpm root@harbor01[09:21:35]/dockerfile/web/wordpress #:docker tag php:5.6.40-fpm harbor.ceamg.com/baseimages/php-fpm:5.6.40 root@harbor01[09:23:12]/dockerfile/web/wordpress #:docker push harbor.ceamg.com/baseimages/php-fpm:5.6.40","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:1:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"è‡ªåˆ¶PHPé•œåƒ root@harbor01[12:28:25]/dockerfile/web/php #:ls build_image_command.sh Dockerfile php.ini run_php.sh sources.list www.confç¼–å†™Dockerfile #PHP Base Image FROM harbor.ceamg.com/baseimages/ubuntu:20.04 RUN apt update -y \\ \u0026\u0026 apt install ca-certificates -y \\ \u0026\u0026 useradd nginx -u 2023 -s /sbin/nologin \\ \u0026\u0026 mkdir /run/php COPY sources.list /etc/apt/sources.list RUN apt update -y \u0026\u0026 apt-get install php7.4-fpm php7.4-mysql -y COPY www.conf /etc/php/7.4/fpm/pool.d/ COPY php.ini /etc/php/7.4/fpm/ ADD run_php.sh /usr/local/bin/run_php.sh EXPOSE 9000 CMD [\"/usr/local/bin/run_php.sh\"] #!/bin/bash TAG=$1 docker build -t harbor.ceamg.com/baseimages/php7.4-wordpress:${TAG} . docker push harbor.ceamg.com/baseimages/php7.4-wordpress:${TAG}#!/bin/bash php-fpm7.4 --nodaemonize[PHP] ;;;;;;;;;;;;;;;;;;; ; About php.ini ; ;;;;;;;;;;;;;;;;;;; ; PHP's initialization file, generally called php.ini, is responsible for ; configuring many of the aspects of PHP's behavior. ; PHP attempts to find and load this configuration from a number of locations. ; The following is a summary of its search order: ; 1. SAPI module specific location. ; 2. The PHPRC environment variable. (As of PHP 5.2.0) ; 3. A number of predefined registry keys on Windows (As of PHP 5.2.0) ; 4. Current working directory (except CLI) ; 5. The web server's directory (for SAPI modules), or directory of PHP ; (otherwise in Windows) ; 6. The directory from the --with-config-file-path compile time option, or the ; Windows directory (usually C:\\windows) ; See the PHP docs for more specific information. ; http://php.net/configuration.file ; The syntax of the file is extremely simple. Whitespace and lines ; beginning with a semicolon are silently ignored (as you probably guessed). ; Section headers (e.g. [Foo]) are also silently ignored, even though ; they might mean something in the future. ; Directives following the section heading [PATH=/www/mysite] only ; apply to PHP files in the /www/mysite directory. Directives ; following the section heading [HOST=www.example.com] only apply to ; PHP files served from www.example.com. Directives set in these ; special sections cannot be overridden by user-defined INI files or ; at runtime. Currently, [PATH=] and [HOST=] sections only work under ; CGI/FastCGI. ; http://php.net/ini.sections ; Directives are specified using the following syntax: ; directive = value ; Directive names are *case sensitive* - foo=bar is different from FOO=bar. ; Directives are variables used to configure PHP or PHP extensions. ; There is no name validation. If PHP can't find an expected ; directive because it is not set or is mistyped, a default value will be used. ; The value can be a string, a number, a PHP constant (e.g. E_ALL or M_PI), one ; of the INI constants (On, Off, True, False, Yes, No and None) or an expression ; (e.g. E_ALL \u0026 ~E_NOTICE), a quoted string (\"bar\"), or a reference to a ; previously set variable or directive (e.g. ${foo}) ; Expressions in the INI file are limited to bitwise operators and parentheses: ; | bitwise OR ; ^ bitwise XOR ; \u0026 bitwise AND ; ~ bitwise NOT ; ! boolean NOT ; Boolean flags can be turned on using the values 1, On, True or Yes. ; They can be turned off using the values 0, Off, False or No. ; An empty string can be denoted by simply not writing anything after the equal ; sign, or by using the None keyword: ; foo = ; sets foo to an empty string ; foo = None ; sets foo to an empty string ; foo = \"None\" ; sets foo to the string 'None' ; If you use constants in your value, and these constants belong to a ; dynamically loaded extension (either a PHP extension or a Zend extension), ; you may only use these constants *after* the line that loads the extension. ;;;;;;;;;;;;;;;;;;; ; About this file ; ;;;;;;;;;;;;;;;;;;; ; PHP comes packaged with two INI files. One that is recommended to be used ; in production environments and one that is recommended to be used in ; development environments. ; php.ini-production contains settings which hold","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:1:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":" æ‰“åŒ…é•œåƒ root@harbor01[12:32:54]/dockerfile/web/php #:bash build_image_command.sh v1 Sending build context to Docker daemon 99.84kB Step 1/9 : FROM harbor.ceamg.com/baseimages/ubuntu:20.04 ---\u003e d5447fc01ae6 Step 2/9 : RUN apt update -y \u0026\u0026 apt install ca-certificates -y \u0026\u0026 useradd nginx -u 2023 -s /sbin/nologin \u0026\u0026 mkdir /run/php ---\u003e Using cache ---\u003e d00499d15478 Step 3/9 : COPY sources.list /etc/apt/sources.list ---\u003e Using cache ---\u003e 4b22bb5df136 Step 4/9 : RUN apt update -y \u0026\u0026 apt-get install php7.4-fpm php7.4-mysql -y ---\u003e Using cache ---\u003e 1d827f2430fe Step 5/9 : COPY www.conf /etc/php/7.4/fpm/pool.d/ ---\u003e Using cache ---\u003e 47bb226c528b Step 6/9 : COPY php.ini /etc/php/7.4/fpm/ ---\u003e Using cache ---\u003e 4e1d1d47bb8e Step 7/9 : ADD run_php.sh /usr/local/bin/run_php.sh ---\u003e Using cache ---\u003e b8b7aacc06e0 Step 8/9 : EXPOSE 9000 ---\u003e Using cache ---\u003e a3a4c49d3987 Step 9/9 : CMD [\"/usr/local/bin/run_php.sh\"] ---\u003e Using cache ---\u003e 167baff20de6 Successfully built 167baff20de6 Successfully tagged harbor.ceamg.com/baseimages/php7.4-wordpress:v1 The push refers to repository [harbor.ceamg.com/baseimages/php7.4-wordpress] e3b90ad599ab: Layer already exists 861aac09aa7f: Layer already exists 77abd2e639b1: Layer already exists 5020b1aebc94: Layer already exists 301ecd0cc403: Layer already exists 6df28fa92c54: Layer already exists 0002c93bdb37: Layer already exists v1: digest: sha256:4a5236c50f567e10cbe90f5b8b4eaf7b93261ecf6191838741aa5c4e729fe66c size: 1784æµ‹è¯•é•œåƒ root@harbor01[12:24:31]/dockerfile/web/php #:docker run --rm -it harbor.ceamg.com/baseimages/php7.4-wordpress:v1 [01-Feb-2023 04:25:02] NOTICE: fpm is running, pid 6 [01-Feb-2023 04:25:02] NOTICE: ready to handle connections [01-Feb-2023 04:25:02] NOTICE: systemd monitor interval set to 10000ms","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:1:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"2. å‡†å¤‡nginxé•œåƒ root@harbor01[09:50:02]/dockerfile/web/nginx #:ls build_image_command.sh Dockerfile nginx.conf run_nginx.sh","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"ç¼–å†™ Dockefile #nginx wordpress FROM harbor.ceamg.com/pub-images/nginx-base:1.22.1 MAINTAINER admin@163.com COPY nginx.conf /usr/local/nginx/conf/ ADD run_nginx.sh /usr/local/nginx/sbin/ RUN useradd nginx -u 2023 RUN mkdir /usr/local/nginx/html/wordpress RUN chown nginx:nginx /usr/local/nginx/html/wordpress/ EXPOSE 80 443 CMD [\"/usr/local/nginx/sbin/run_nginx.sh\"]#!/bin/bash TAG=$1 echo \"å¼€å§‹é•œåƒæ„å»º\" docker build -t harbor.ceamg.com/wordpress/nginx-wordpress:${TAG} . if [ $? -eq 0 ];then echo \"é•œåƒæ„å»ºæˆåŠŸï¼Œå¼€å§‹ä¸Šä¼ é•œåƒ\" docker push harbor.ceamg.com/wordpress/nginx-wordpress:${TAG} if [ $? -eq 0 ];then echo \"é•œåƒä¸Šä¼ æˆåŠŸ\" else echo \"é•œåƒä¸Šä¼ å¤±è´¥\" fi else echo \"é•œåƒæ„å»ºå¤±è´¥,è¯·æ£€æŸ¥è¾“å‡º\" fiuser nginx nginx; worker_processes auto; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; #daemon off; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; client_max_body_size 10M; client_body_buffer_size 16k; client_body_temp_path /usr/local/nginx/tmp 1 2 2; gzip on; server { listen 80; server_name blog.ceamg.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root /usr/local/nginx/html/wordpress; index index.php index.html index.htm; #if ($http_user_agent ~ \"ApacheBench|WebBench|TurnitinBot|Sogou web spider|Grid Service\") { # proxy_pass http://www.baidu.com; # #return 403; #} } location ~ \\.php$ { root /usr/local/nginx/html/wordpress; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; #fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } }#!/bin/bash nginx tail -f /etc/hosts","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"æ‰“åŒ…é•œåƒ root@harbor01[09:45:23]/dockerfile/web/nginx #:bash build_image_command.sh v1.1 å¼€å§‹é•œåƒæ„å»º Sending build context to Docker daemon 6.656kB Step 1/9 : FROM harbor.ceamg.com/pub-images/nginx-base:1.22.1 ---\u003e c055772e4c77 Step 2/9 : MAINTAINER admin@163.com ---\u003e Using cache ---\u003e c339760b111a Step 3/9 : COPY nginx.conf /usr/local/nginx/conf/ ---\u003e Using cache ---\u003e fd62ef4ba6d3 Step 4/9 : ADD run_nginx.sh /usr/local/nginx/sbin/ ---\u003e 0333f9c88d67 Step 5/9 : RUN useradd nginx -u 2023 ---\u003e Running in b477510d6ec6 Removing intermediate container b477510d6ec6 ---\u003e 18217eeee991 Step 6/9 : RUN mkdir /usr/local/nginx/html/wordpress ---\u003e Running in 0b3fa2320f66 Removing intermediate container 0b3fa2320f66 ---\u003e 0d05360ddcfc Step 7/9 : RUN chown nginx:nginx /usr/local/nginx/html/wordpress/ ---\u003e Running in 16e255057567 Removing intermediate container 16e255057567 ---\u003e 5acd10a728cd Step 8/9 : EXPOSE 80 443 ---\u003e Running in 09164687f69f Removing intermediate container 09164687f69f ---\u003e c65586dcb037 Step 9/9 : CMD [\"/usr/local/nginx/sbin/run_nginx.sh\"] ---\u003e Running in ffe14b4816df Removing intermediate container ffe14b4816df ---\u003e 657c22de8b70 Successfully built 657c22de8b70 Successfully tagged harbor.ceamg.com/wordpress/nginx-wordpress:v1.1 é•œåƒæ„å»ºæˆåŠŸï¼Œå¼€å§‹ä¸Šä¼ é•œåƒ The push refers to repository [harbor.ceamg.com/wordpress/nginx-wordpress] 591ed3250639: Pushed 04c9fd3db048: Pushed 0252a86a3ed5: Pushed f771a2872392: Pushed 644965591cf9: Layer already exists d8949178f619: Layer already exists da95977bca7c: Layer already exists 03477dd36445: Layer already exists fb82b029bea0: Layer already exists v1.1: digest: sha256:c5bce69a5ec505fac1424a33abca32713cf5844eaabfaba4e4338f3bdbc0514d size: 2200 é•œåƒä¸Šä¼ æˆåŠŸ","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:2:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"3. åˆ›å»ºPV/PVC ","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"NFSæœåŠ¡å™¨ root@harbor01[09:52:06]/data/k8s/wordpress #:mkdir /data/k8s/wordpress/ -p root@harbor01[09:52:21]/data/k8s/wordpress #:vim /etc/exports /data/k8s/wordpress *(rw,sync,no_root_squash) root@harbor01[09:53:34]/data/k8s/wordpress #:systemctl restart nfs-server.service ","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:3:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"pv/pvc yamlæ–‡ä»¶ apiVersion: v1 kind: PersistentVolume metadata: name: wordpress-data-pv spec: accessModes: [\"ReadWriteMany\"] capacity: storage: 50Gi nfs: server: 10.1.0.38 path: /data/k8s/wordpress/ --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: wordpress-data-pvc spec: accessModes: [\"ReadWriteMany\"] resources: requests: storage: 40Gi limits: storage: 40Gi volumeName: wordpress-data-pvroot@master01[09:57:42]~/wordpress-yaml #:kubectl create namespace wordpress-xin namespace/wordpress-xin created root@master01[09:55:58]~/wordpress-yaml #:vim wordpress-pv-pvc.yaml root@master01[09:56:14]~/wordpress-yaml #:kubectl apply -f wordpress-pv-pvc.yaml persistentvolume/wordpress-data-pv created persistentvolumeclaim/wordpress-data-pvc created","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:3:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"æŸ¥çœ‹pvçŠ¶æ€ root@master01[09:58:21]~/wordpress-yaml #:kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE jenkins-datadir-pv 100Gi RWO Retain Bound jenkins-xin/jenkins-datadir-pvc 2d17h jenkins-root-datadir-pv 100Gi RWO Retain Bound jenkins-xin/jenkins-root-datadir-pvc 2d17h mysql-datadir-1 50Gi RWO Retain Bound mysql-sts/data-mysql-1 2d20h mysql-datadir-2 50Gi RWO Retain Bound mysql-sts/data-mysql-2 2d20h mysql-datadir-3 50Gi RWO Retain Bound mysql-sts/data-mysql-0 2d20h wordpress-data-pv 50Gi RWX Retain Bound wordpress-xin/wordpress-data-pvc 74s","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:3:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"éƒ¨ç½²wordpress éƒ¨ç½²æ–‡ä»¶å¦‚ä¸‹ apiVersion: apps/v1 kind: Deployment metadata: name: wordpress-deploy spec: replicas: 1 selector: matchLabels: app: wordpress-server template: metadata: labels: app: wordpress-server spec: containers: - name: nginx image: harbor.ceamg.com/wordpress/nginx-wordpress:v1.1 imagePullPolicy: Always ports: - name: http containerPort: 80 - name: https containerPort: 443 volumeMounts: - name: wordpress-data mountPath: /usr/local/nginx/html/wordpress - name: php image: harbor.ceamg.com/baseimages/php7.4-wordpress:v1 imagePullPolicy: Always ports: - name: php containerPort: 9000 volumeMounts: - name: wordpress-data mountPath: /usr/local/nginx/html/wordpress readOnly: false volumes: - name: wordpress-data persistentVolumeClaim: claimName: wordpress-data-pvc --- apiVersion: v1 kind: Service metadata: name: wordpress-svc spec: selector: app: wordpress-server type: NodePort ports: - name: http port: 80 targetPort: 80 nodePort: 30013 protocol: TCP - name: https port: 443 targetPort: 443 nodePort: 30014 protocol: TCP","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"æŸ¥çœ‹PodçŠ¶æ€ root@master01[10:19:10]~/wordpress-yaml #:kubectl apply -f wordpress-server.yaml deployment.apps/wordpress-deploy created service/wordpress-svc created root@master01[10:19:22]~/wordpress-yaml #:kubectl get pod -n wordpress-xin NAME READY STATUS RESTARTS AGE wordpress-deploy-dd645ccf9-v4k7j 2/2 Running 0 11s root@master01[10:20:06]~/wordpress-yaml #:kubectl get svc -n wordpress-xin NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE wordpress-svc NodePort 10.10.165.34 \u003cnone\u003e 80:30013/TCP,443:30014/TCP 64s","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:4:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"åˆå§‹åŒ–å®‰è£…é…ç½®wordpress ä¸‹è½½wordpresså®‰è£…åŒ…ï¼Œå°†å®‰è£…åŒ…ä¸­æ–‡ä»¶æ”¾ç½®åˆ°Podä½¿ç”¨çš„nfs pvå¯¹åº”çš„ç›®å½•å®‰è£…åŒ…ä¸‹è½½åœ°å€ï¼šhttps://cn.wordpress.org/download/releases/ root@harbor01[10:48:28]/data/k8s/wordpress #:tar -xf wordpress-5.9.2-zh_CN.tar.gz root@harbor01[10:48:43]/data/k8s/wordpress #:mv wordpress/* ./ root@harbor01[10:49:05]/data/k8s/wordpress #:rm wordpress -rf root@harbor01[10:49:37]/data/k8s/wordpress #:ls index.php wordpress-5.9.2-zh_CN.tar.gz wp-blog-header.php wp-content wp-links-opml.php wp-mail.php wp-trackback.php license.txt wp-activate.php wp-comments-post.php wp-cron.php wp-load.php wp-settings.php xmlrpc.php readme.html wp-admin wp-config-sample.php wp-includes wp-login.php wp-signup.php chown -R 2023.2023 /data/k8s/wordpress #ä¿®æ”¹ç›®å½•æ‰€å±è€…ä¸ºPodçš„å®¹å™¨é‡Œçš„nginxç”¨æˆ·ï¼Œå¦åˆ™å¯èƒ½ä¼šå‡ºç°æƒé™ä¸è¶³æ— æ³•è¯»å†™çš„é—®é¢˜ ","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:5:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"åˆå§‹åŒ–æ•°æ®åº“ mysql\u003e create database wordpress; mysql\u003e grant all on wordpress.* to \"wordpress\"@\"%\" identified by 'wordpresspassword@123'; Query OK, 0 rows affected, 1 warning (0.01 sec) mysql\u003e flush privileges; Query OK, 0 rows affected (0.03 sec) mysql-sts wordpress æ•°æ®åº“å¡«ä¸ºä¸»åº“mysql.mysql-sts.svc.ceamg.local mysql.mysql-sts.svc.ceamg.local ","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:5:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"æµ‹è¯•ä¸Šä¼ å›¾ç‰‡ ","date":"2023-01-29","objectID":"/posts/kubernetes/primary/kubernetes-10/:5:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-WordPress (å)","uri":"/posts/kubernetes/primary/kubernetes-10/"},{"categories":["Kubernetes"],"content":"æœ¬æ¬¡ä»¥jenkins.war åŒ…éƒ¨ç½²â½…å¼ä¸ºä¾‹è¿â¾ ï¼Œjava waråŒ…æˆ–jaråŒ…ï¼Œä¸”è¦æ±‚jenkinsçš„æ•°æ®ä¿å­˜â¾„å¤–éƒ¨å­˜å‚¨(NFSæˆ–è€…PVC)ï¼Œå…¶ä»–javaåº”â½¤çœ‹å®é™…éœ€æ±‚æ˜¯å¦éœ€è¦å°†æ•°æ®ä¿å­˜â¾„å¤–éƒ¨å­˜å‚¨ã€‚ ","date":"2023-01-24","objectID":"/posts/kubernetes/primary/kubernetes-9/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-è¿è¡Œjavaåº”ç”¨ (ä¹)","uri":"/posts/kubernetes/primary/kubernetes-9/"},{"categories":["Kubernetes"],"content":"æ„å»ºé•œåƒ #Jenkins Version 2.319.3 FROM harbor.ceamg.com/pub-images/jdk8:3411 MAINTAINER zcc zcc@qq.com ADD jenkins-2.319.3.war /apps/jenkins/ ADD run_jenkins.sh /usr/bin/ EXPOSE 8080 CMD [\"/usr/bin/run_jenkins.sh\"]#!/bin/bash cd /apps/jenkins \u0026\u0026 jave -server -Xms1024m -Xmx1024m -Xss512k -jar jenkins-2.319.3.war --webroot=/apps/jenkins/jenkins-data --httpPort=8080æŸ¥çœ‹Jenkins æ”¯æŒçš„å‚æ•° java -jar jenkins.war --help#!/bin/bash docker build -t harbor.ceamg.com/pub-images/jenkins:v2.319.3 . echo \"é•œåƒåˆ¶ä½œå®Œæˆï¼Œå³å°†ä¸Šä¼ è‡³HarboræœåŠ¡å™¨\" sleep 1 docker push harbor.ceamg.com/pub-images/jenkins:v2.319.3 echo \"é•œåƒä¸Šä¼ å®Œæˆ\"root@harbor01[16:45:23]/dockerfile/jenkins #:bash build-command.sh Sending build context to Docker daemon 72.26MB Step 1/6 : FROM harbor.ceamg.com/pub-images/jdk8:3411 ---\u003e 1328b4d79a67 Step 2/6 : MAINTAINER zcc zcc@qq.com ---\u003e Using cache ---\u003e 35ad6bb5a267 Step 3/6 : ADD jenkins-2.319.3.war /apps/jenkins/ ---\u003e d83e0dff6896 Step 4/6 : ADD run_jenkins.sh /usr/bin/ ---\u003e 4f60478bd327 Step 5/6 : EXPOSE 8080 ---\u003e Running in 84bcd1400981 Removing intermediate container 84bcd1400981 ---\u003e d01106084f38 Step 6/6 : CMD [\"/usr/bin/run_jenkins.sh\"] ---\u003e Running in 9eaaf7204543 Removing intermediate container 9eaaf7204543 ---\u003e 0c48f0d81550 Successfully built 0c48f0d81550 Successfully tagged harbor.ceamg.com/pub-images/jenkins:v2.319.3 é•œåƒåˆ¶ä½œå®Œæˆï¼Œå³å°†ä¸Šä¼ è‡³HarboræœåŠ¡å™¨ The push refers to repository [harbor.ceamg.com/pub-images/jenkins] d74d542bfbb2: Pushed ba3e041a4025: Pushed 3ad8c5bef187: Mounted from pub-images/tomcat-base f4442a8d89b4: Mounted from pub-images/tomcat-base c185ef053da5: Mounted from pub-images/tomcat-base 0002c93bdb37: Mounted from pub-images/tomcat-base v2.319.3: digest: sha256:fbaa1f61491042ddc6ab2dc3e2183900daaeee1d57ecc772c33ac7dfb39f895a size: 1575 é•œåƒä¸Šä¼ å®Œæˆ","date":"2023-01-24","objectID":"/posts/kubernetes/primary/kubernetes-9/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-è¿è¡Œjavaåº”ç”¨ (ä¹)","uri":"/posts/kubernetes/primary/kubernetes-9/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºpv --- apiVersion: v1 kind: PersistentVolume metadata: name: jenkins-datadir-pv spec: capacity: storage: 100Gi accessModes: - ReadWriteOnce nfs: server: 10.1.0.38 path: /data/k8s/jenkins/jenkins-data --- apiVersion: v1 kind: PersistentVolume metadata: name: jenkins-root-datadir-pv spec: capacity: storage: 100Gi accessModes: - ReadWriteOnce nfs: server: 10.1.0.38 path: /data/k8s/jenkins/jenkins-root-data","date":"2023-01-24","objectID":"/posts/kubernetes/primary/kubernetes-9/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-è¿è¡Œjavaåº”ç”¨ (ä¹)","uri":"/posts/kubernetes/primary/kubernetes-9/"},{"categories":["Kubernetes"],"content":"NFSæœåŠ¡å™¨åˆ›å»ºåº”ç”¨æ•°æ®ç›®å½• root@harbor01[16:52:33]/data/k8s #:mkdir /data/k8s/jenkins/jenkins-data -p root@harbor01[16:52:47]/data/k8s #:mkdir /data/k8s/jenkins/jenkins-root-data -p vim /etx/exports /data/k8s/jenkins *(rw,sync,no_root_squash) root@harbor01[16:54:13]/data/k8s/jenkins #:systemctl restart nfs-server.serviceroot@master01[16:57:33]~/jenkins-yaml #:kubectl apply -f jenkins-pv.yaml persistentvolume/jenkins-datadir-pv created persistentvolume/jenkins-root-datadir-pv created root@master01[16:57:38]~/jenkins-yaml #:kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE jenkins-datadir-pv 100Gi RWO Retain Available 5s jenkins-root-datadir-pv 100Gi RWO Retain Available 5s","date":"2023-01-24","objectID":"/posts/kubernetes/primary/kubernetes-9/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-è¿è¡Œjavaåº”ç”¨ (ä¹)","uri":"/posts/kubernetes/primary/kubernetes-9/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºPVC --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: jenkins-datadir-pvc namespace: jenkins-xin spec: volumeName: jenkins-datadir-pv accessModes: - ReadWriteOnce resources: requests: storage: 80Gi --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: jenkins-root-datadir-pvc namespace: jenkins-xin spec: volumeName: jenkins-root-datadir-pv accessModes: - ReadWriteOnce resources: requests: storage: 80Giroot@master01[16:58:41]~/jenkins-yaml #:kubectl apply -f jenkins-pvc.yaml persistentvolumeclaim/jenkins-datadir-pvc created persistentvolumeclaim/jenkins-root-datadir-pvc created root@master01[16:58:28]~/jenkins-yaml #:kubectl create namespace jenkins-xin namespace/jenkins-xin created root@master01[16:58:52]~/jenkins-yaml #:kubectl get pvc -n jenkins-xin NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE jenkins-datadir-pvc Bound jenkins-datadir-pv 100Gi RWO 23s jenkins-root-datadir-pvc Bound jenkins-root-datadir-pv 100Gi RWO 23s","date":"2023-01-24","objectID":"/posts/kubernetes/primary/kubernetes-9/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-è¿è¡Œjavaåº”ç”¨ (ä¹)","uri":"/posts/kubernetes/primary/kubernetes-9/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºJenkins PodæœåŠ¡ kind: Deployment apiVersion: apps/v1 metadata: labels: app: jenkins-319 name: jenkins-319-deployment namespace: jenkins-xin spec: replicas: 1 selector: matchLabels: app: jenkins-319 template: metadata: labels: app: jenkins-319 spec: containers: - name: jenkins-319-container image: harbor.ceamg.com/pub-images/jenkins:v2.319.3 imagePullPolicy: IfNotPresent #imagePullPolicy: Always ports: - containerPort: 8080 protocol: TCP name: http volumeMounts: - mountPath: \"/apps/jenkins/jenkins-data/\" name: jenkins-app-datadir - mountPath: \"/root/.jenkins\" name: jenkins-root-datadir volumes: - name: jenkins-app-datadir persistentVolumeClaim: claimName: jenkins-datadir-pvc - name: jenkins-root-datadir persistentVolumeClaim: claimName: jenkins-root-datadir-pvc --- kind: Service apiVersion: v1 metadata: labels: app: jenkins-319 name: jenkins-319-service namespace: jenkins-xin spec: type: NodePort ports: - name: http port: 80 protocol: TCP targetPort: 8080 nodePort: 38080 selector: app: jenkins-319","date":"2023-01-24","objectID":"/posts/kubernetes/primary/kubernetes-9/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-è¿è¡Œjavaåº”ç”¨ (ä¹)","uri":"/posts/kubernetes/primary/kubernetes-9/"},{"categories":["Kubernetes"],"content":"éªŒè¯æœåŠ¡çŠ¶æ€ root@master01[10:36:43]~/jenkins-yaml #:kubectl apply -f jenkins-deployment.yaml deployment.apps/jenkins-319-deployment created service/jenkins-319-service created root@master01[10:39:03]~/jenkins-yaml #:kubectl get pod -n jenkins-xin NAME READY STATUS RESTARTS AGE jenkins-319-deployment-67cb4bf4c9-wnvqb 1/1 Running 0 24s","date":"2023-01-24","objectID":"/posts/kubernetes/primary/kubernetes-9/:4:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-è¿è¡Œjavaåº”ç”¨ (ä¹)","uri":"/posts/kubernetes/primary/kubernetes-9/"},{"categories":["Kubernetes"],"content":"service root@master01[10:39:16]~/jenkins-yaml #:kubectl get service -n jenkins-xin NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE jenkins-319-service NodePort 10.10.24.94 \u003cnone\u003e 80:38080/TCP 41s è·å–å¯†ç  ","date":"2023-01-24","objectID":"/posts/kubernetes/primary/kubernetes-9/:4:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-è¿è¡Œjavaåº”ç”¨ (ä¹)","uri":"/posts/kubernetes/primary/kubernetes-9/"},{"categories":["Kubernetes"],"content":"https://kubernetes.io/zh-cn/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/Podè°ƒåº¦è¿â¾æ—¶ï¼Œå¦‚æœåº”â½¤ä¸éœ€è¦ä»»ä½•ç¨³å®šçš„æ ‡ç¤ºã€æœ‰åºçš„éƒ¨ç½²ã€åˆ é™¤å’Œæ‰©å±•ï¼Œåˆ™åº”è¯¥ä½¿â½¤â¼€ç»„â½†çŠ¶æ€å‰¯æœ¬çš„æ§åˆ¶å™¨æ¥éƒ¨ç½²åº”â½¤ï¼Œä¾‹å¦‚ Deployment æˆ– ReplicaSetæ›´é€‚åˆâ½†çŠ¶æ€æœåŠ¡éœ€æ±‚ï¼Œâ½½StatefulSeté€‚åˆç®¡ç†æ‰€æœ‰æœ‰çŠ¶æ€çš„æœåŠ¡ï¼Œâ½å¦‚MySQLã€ MongoDBé›†ç¾¤ç­‰ã€‚ è¿è¡Œä¸€ä¸ªæœ‰çŠ¶æ€çš„åº”ç”¨ç¨‹åºï¼šhttps://kubernetes.io/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/ **StatefulSet **æœ¬è´¨ä¸Šæ˜¯Deploymentçš„â¼€ç§å˜ä½“ï¼Œåœ¨v1.9ç‰ˆæœ¬ä¸­å·²æˆä¸ºGAç‰ˆæœ¬ï¼Œå®ƒä¸ºäº†è§£å†³æœ‰çŠ¶æ€æœåŠ¡çš„é—®é¢˜ï¼Œå®ƒæ‰€ç®¡ç†çš„Podæ‹¥æœ‰å›ºå®šçš„Podåç§°ï¼Œå¯åœé¡ºåºï¼Œåœ¨StatefulSetä¸­ï¼Œ Podåå­—ç§°ä¸ºâ½¹ç»œæ ‡è¯†(hostname)ï¼Œè¿˜å¿…é¡»è¦â½¤åˆ°å…±äº«å­˜å‚¨ã€‚ åœ¨Deploymentä¸­ï¼Œä¸ä¹‹å¯¹åº”çš„æœåŠ¡æ˜¯serviceï¼Œâ½½åœ¨StatefulSetä¸­ä¸ä¹‹å¯¹åº”çš„headless serviceï¼Œ headlessserviceï¼Œå³â½†å¤´æœåŠ¡ï¼Œä¸serviceçš„åŒºåˆ«å°±æ˜¯å®ƒæ²¡æœ‰Cluster IPï¼Œè§£æå®ƒçš„åç§°æ—¶å°†è¿”å›è¯¥Headless Service å¯¹åº”çš„å…¨éƒ¨Podçš„Endpointåˆ—è¡¨ã€‚ StatefulSet ç‰¹ç‚¹ ç»™æ¯ä¸ªpodåˆ†é…å›ºå®šä¸”å”¯â¼€çš„â½¹ç»œæ ‡è¯†ç¬¦ ç»™æ¯ä¸ªpodåˆ†é…å›ºå®šä¸”æŒä¹…åŒ–çš„å¤–éƒ¨å­˜å‚¨ å¯¹podè¿›â¾æœ‰åºçš„éƒ¨ç½²å’Œæ‰©å±• å¯¹podè¿›æœ‰åºçš„åˆ é™¤å’Œç»ˆâ½Œ å¯¹podè¿›æœ‰åºçš„â¾ƒåŠ¨æ»šåŠ¨æ›´æ–° ","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":"StatefulSet çš„ç»„æˆéƒ¨åˆ† :::info Headless Serviceï¼šâ½¤æ¥å®šä¹‰Podâ½¹ç»œæ ‡è¯†( DNS domain)ï¼ŒæŒ‡çš„æ˜¯çŸ­çš„serfvice(ä¸¢å¤±äº†domainname)ã€‚ç›´æ¥è§£æåˆ°podã€‚StatefulSetï¼šå®šä¹‰å…·ä½“åº”â½¤ï¼Œæœ‰å¤šå°‘ä¸ªPodå‰¯æœ¬ï¼Œå¹¶ä¸ºæ¯ä¸ªPodå®šä¹‰äº†â¼€ä¸ªåŸŸåã€‚ volumeClaimTemplatesï¼š å­˜å‚¨å·ç”³è¯·æ¨¡æ¿ï¼Œåˆ›å»ºPVCï¼ŒæŒ‡å®špvcåç§°â¼¤â¼©ï¼Œå°†â¾ƒåŠ¨åˆ›å»ºpvcï¼Œä¸”pvcå¿…é¡»ç”±å­˜å‚¨ç±»ä¾›åº”ã€‚ ::: ","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":" é•œåƒå‡†å¤‡ #å‡†å¤‡xtrabackupé•œåƒ root@harbor01[11:17:56]~ #:docker pull registry.cn-hangzhou.aliyuncs.com/hxpdocker/xtrabackup:1.0 root@harbor01[10:27:39]~ #:docker tag registry.cn-hangzhou.aliyuncs.com/hxpdocker/xtrabackup:1.0 harbor.ceamg.com/databases/xtrabackup:1.0 root@harbor01[10:29:24]~ #:docker push harbor.ceamg.com/databases/xtrabackup:1.0 #å‡†å¤‡mysql é•œåƒ root@harbor01[10:30:00]~ #:docker pull mysql:5.7 root@harbor01[10:31:09]~ #:docker tag mysql:5.7 harbor.ceamg.com/databases/mysql:5.7 root@harbor01[10:31:42]~ #:docker push harbor.ceamg.com/databases/mysql:5.7","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºPV pvcä¼šâ¾ƒåŠ¨åŸºäºPVåˆ›å»ºï¼Œåªéœ€è¦æœ‰å¤šä¸ªå¯â½¤çš„PVå³å¯ï¼Œ PVæ•°é‡å–å†³äºè®¡åˆ’å¯åŠ¨å¤šå°‘ä¸ªmysql podï¼Œæœ¬æ¬¡åˆ›å»º5ä¸ªPVï¼Œä¹Ÿå°±æ˜¯æœ€å¤šå¯åŠ¨5ä¸ªmysql pod ã€‚ ","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºnfså…±äº«å­˜å‚¨ç›®å½• root@harbor01[10:35:02]/data/k8s #:mkdir /data/k8s/mysqldata/mysql-datadir-1 root@harbor01[10:35:20]/data/k8s #:mkdir /data/k8s/mysqldata/mysql-datadir-2 root@harbor01[10:35:22]/data/k8s #:mkdir /data/k8s/mysqldata/mysql-datadir-3 root@harbor01[10:35:23]/data/k8s #:mkdir /data/k8s/mysqldata/mysql-datadir-4 root@harbor01[10:35:24]/data/k8s #:mkdir /data/k8s/mysqldata/mysql-datadir-5 vim /etc/exports /data/k8s/xinzk *(rw,sync,no_root_squash) /data/k8s/web1 *(rw,sync,no_root_squash) /data/k8s/mysqldata *(rw,sync,no_root_squash) root@harbor01[10:36:33]/data/k8s #:systemctl restart nfs-server.service root@harbor01[10:36:41]/data/k8s #:showmount -e Export list for harbor01: /data/k8s/mysqldata * /data/k8s/web1 * /data/k8s/xinzk *","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:4:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":" åˆ›å»ºPV yamlæ–‡ä»¶ --- apiVersion: v1 kind: PersistentVolume metadata: name: mysql-datadir-1 spec: capacity: storage: 50Gi accessModes: - ReadWriteOnce nfs: path: /data/k8s/mysqldata/mysql-datadir-1 server: 10.1.0.38 --- apiVersion: v1 kind: PersistentVolume metadata: name: mysql-datadir-2 spec: capacity: storage: 50Gi accessModes: - ReadWriteOnce nfs: path: /data/k8s/mysqldata/mysql-datadir-2 server: 10.1.0.38 --- apiVersion: v1 kind: PersistentVolume metadata: name: mysql-datadir-3 spec: capacity: storage: 50Gi accessModes: - ReadWriteOnce nfs: path: /data/k8s/mysqldata/mysql-datadir-3 server: 10.1.0.38æ£€æŸ¥pvçŠ¶æ€ root@master01[12:06:23]~/mysql-sts-yaml #:kubectl apply -f mysql-persistentvolume.yaml persistentvolume/mysql-datadir-1 created persistentvolume/mysql-datadir-2 created persistentvolume/mysql-datadir-3 created root@master01[12:06:51]~/mysql-sts-yaml #:kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE mysql-datadir-1 50Gi RWO Retain Available 27s mysql-datadir-2 50Gi RWO Retain Available 27s mysql-datadir-3 50Gi RWO Retain Available 27s","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:4:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":"åˆ›å»º ConfigMap apiVersion: v1 kind: ConfigMap metadata: name: mysql namespace: mysql-sts labels: app: mysql app.kubernetes.io/name: mysql data: primary.cnf: | [mysqld] log-bin replica.cnf: | [mysqld] super-read-only $ kubectl apply -f mysql-configmap.yaml è¿™ä¸ª ConfigMap æä¾› my.cnf è¦†ç›–è®¾ç½®ï¼Œä½¿ä½ å¯ä»¥ç‹¬ç«‹æ§åˆ¶ MySQL ä¸»æœåŠ¡å™¨å’Œå‰¯æœ¬æœåŠ¡å™¨çš„é…ç½®ã€‚ åœ¨è¿™é‡Œï¼Œä½ å¸Œæœ›ä¸»æœåŠ¡å™¨èƒ½å¤Ÿå°†å¤åˆ¶æ—¥å¿—æä¾›ç»™å‰¯æœ¬æœåŠ¡å™¨ï¼Œ å¹¶ä¸”å¸Œæœ›å‰¯æœ¬æœåŠ¡å™¨æ‹’ç»ä»»ä½•ä¸æ˜¯é€šè¿‡å¤åˆ¶è¿›è¡Œçš„å†™æ“ä½œã€‚ ","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:5:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":"åˆ›å»º æ— å¤´æœåŠ¡ Headless Serviceâ½†å¤´æœåŠ¡ï¼Œä¸serviceçš„åŒºåˆ«å°±æ˜¯å®ƒæ²¡æœ‰Cluster IPï¼Œè§£æå®ƒçš„åç§°æ—¶å°†è¿”å›è¯¥Headless Serviceå¯¹åº”çš„å…¨éƒ¨Podçš„Endpointåˆ—è¡¨ã€‚ å®¢æˆ·ç«¯ Service ä¸º mysql-readï¼Œæ˜¯ä¸€ç§å¸¸è§„ Serviceï¼Œå…·æœ‰å…¶è‡ªå·±çš„é›†ç¾¤ IPã€‚ è¯¥é›†ç¾¤ IP åœ¨æŠ¥å‘Šå°±ç»ªçš„æ‰€æœ‰ MySQL Pod ä¹‹é—´åˆ†é…è¿æ¥ã€‚ å¯èƒ½çš„ç«¯ç‚¹é›†åˆåŒ…æ‹¬ MySQL ä¸»èŠ‚ç‚¹å’Œæ‰€æœ‰å‰¯æœ¬èŠ‚ç‚¹ã€‚ **mysql-readæ˜¯ç»™slave podä½¿ç”¨çš„mysqlåªè¯»æœåŠ¡ï¼Œä»¥æ­¤å®ç°è¯»å†™åˆ†ç¦»ã€‚ ** apiVersion: v1 kind: Service metadata: name: mysql namespace: mysql-sts labels: app: mysql app.kubernetes.io/name: mysql spec: ports: - name: mysql port: 3306 clusterIP: None selector: app: mysql --- apiVersion: v1 kind: Service metadata: name: mysql-read namespace: mysql-sts labels: app: mysql app.kubernetes.io/name: mysql readonly: \"true\" spec: ports: - name: mysql port: 3306 selector: app: mysqlkubectl apply -f mysql-services.yaml","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:6:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":"åˆ›å»º StatefulSet åˆ›å»ºMySQLä¸€ä¸»å¤šä»é›†ç¾¤ï¼Œæ¯ä¸ªpodåˆ†åˆ«æ‰§è¡Œ4ä¸ªå®¹å™¨ã€‚å…·ä½“ä½œç”¨å¦‚ä¸‹ï¼š åˆå§‹åŒ–å®¹å™¨1ï¼šæ ¹æ®mysql-0æ•°å­—æ ‡è®°ä¸ºmasterï¼Œå…¶å®ƒä¸ºslaveï¼Œå¹¶åˆ†å‘ä¸åŒé…ç½®æ–‡ä»¶ã€‚ åˆå§‹åŒ–å®¹å™¨2ï¼šmysql-0ä¸åŠ¨ï¼Œmysql-1ä»mysql-0å…¨é‡æ‹·è´æ•°æ®ï¼Œmysql-2å†ä»mysql-1å…¨é‡æ‹·è´ï¼Œä»¥æ­¤ç±»æ¨ã€‚ ä¸»å®¹å™¨mysqlï¼šæ•°æ®åº“ä¸»ç¨‹åºï¼Œéƒ½æœ‰è¯»å†™åŠŸèƒ½ã€‚è¯»å†™åˆ†ç¦»ä¾é mysqlå’Œmysql-readæœåŠ¡å®ç°ã€‚ ä¸»å®¹å™¨xtrabackupï¼šå®ç°ä¸»ä»å¤åˆ¶è‡ªåŠ¨å¤‡ä»½ï¼Œé™¤åˆšåˆ›å»ºå¤–éƒ½ä»mysql-0æ‹·è´ã€‚å¼€æ”¾3307ç«¯å£ä¾›åä¸€ä½podå…¨é‡å¤åˆ¶ã€‚ apiVersion: apps/v1 kind: StatefulSet metadata: name: mysql namespace: mysql-sts spec: selector: matchLabels: app: mysql app.kubernetes.io/name: mysql serviceName: mysql replicas: 3 template: metadata: labels: app: mysql app.kubernetes.io/name: mysql spec: initContainers: - name: init-mysql image: harbor.ceamg.com/databases/mysql:5.7 command: - bash - \"-c\" - | set -ex # åŸºäº Pod åºå·ç”Ÿæˆ MySQL æœåŠ¡å™¨çš„ IDã€‚ [[ $HOSTNAME =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} echo [mysqld] \u003e /mnt/conf.d/server-id.cnf # æ·»åŠ åç§»é‡ä»¥é¿å…ä½¿ç”¨ server-id=0 è¿™ä¸€ä¿ç•™å€¼ã€‚ echo server-id=$((100 + $ordinal)) \u003e\u003e /mnt/conf.d/server-id.cnf # å°†åˆé€‚çš„ conf.d æ–‡ä»¶ä» config-map å¤åˆ¶åˆ° emptyDirã€‚ if [[ $ordinal -eq 0 ]]; then cp /mnt/config-map/primary.cnf /mnt/conf.d/ else cp /mnt/config-map/replica.cnf /mnt/conf.d/ fi volumeMounts: - name: conf mountPath: /mnt/conf.d - name: config-map mountPath: /mnt/config-map - name: clone-mysql image: harbor.ceamg.com/databases/xtrabackup:1.0 command: - bash - \"-c\" - | set -ex # å¦‚æœå·²æœ‰æ•°æ®ï¼Œåˆ™è·³è¿‡å…‹éš†ã€‚ [[ -d /var/lib/mysql/mysql ]] \u0026\u0026 exit 0 # è·³è¿‡ä¸»å®ä¾‹ï¼ˆåºå·ç´¢å¼• 0ï¼‰çš„å…‹éš†ã€‚ [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} [[ $ordinal -eq 0 ]] \u0026\u0026 exit 0 # ä»åŸæ¥çš„å¯¹ç­‰èŠ‚ç‚¹å…‹éš†æ•°æ®ã€‚ ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql # å‡†å¤‡å¤‡ä»½ã€‚ xtrabackup --prepare --target-dir=/var/lib/mysql volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d containers: - name: mysql image: harbor.ceamg.com/databases/mysql:5.7 env: - name: MYSQL_ALLOW_EMPTY_PASSWORD value: \"1\" ports: - name: mysql containerPort: 3306 volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d resources: requests: cpu: 500m memory: 1Gi livenessProbe: exec: command: [\"mysqladmin\", \"ping\"] initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 readinessProbe: exec: # æ£€æŸ¥æˆ‘ä»¬æ˜¯å¦å¯ä»¥é€šè¿‡ TCP æ‰§è¡ŒæŸ¥è¯¢ï¼ˆskip-networking æ˜¯å…³é—­çš„ï¼‰ã€‚ command: [\"mysql\", \"-h\", \"127.0.0.1\", \"-e\", \"SELECT 1\"] initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 1 - name: xtrabackup image: harbor.ceamg.com/databases/xtrabackup:1.0 ports: - name: xtrabackup containerPort: 3307 command: - bash - \"-c\" - | set -ex cd /var/lib/mysql # ç¡®å®šå…‹éš†æ•°æ®çš„ binlog ä½ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ã€‚ if [[ -f xtrabackup_slave_info \u0026\u0026 \"x$(\u003cxtrabackup_slave_info)\" != \"x\" ]]; then # XtraBackup å·²ç»ç”Ÿæˆäº†éƒ¨åˆ†çš„ â€œCHANGE MASTER TOâ€ æŸ¥è¯¢ # å› ä¸ºæˆ‘ä»¬ä»ä¸€ä¸ªç°æœ‰å‰¯æœ¬è¿›è¡Œå…‹éš†ã€‚(éœ€è¦åˆ é™¤æœ«å°¾çš„åˆ†å·!) cat xtrabackup_slave_info | sed -E 's/;$//g' \u003e change_master_to.sql.in # åœ¨è¿™é‡Œè¦å¿½ç•¥ xtrabackup_binlog_info ï¼ˆå®ƒæ˜¯æ²¡ç”¨çš„ï¼‰ã€‚ rm -f xtrabackup_slave_info xtrabackup_binlog_info elif [[ -f xtrabackup_binlog_info ]]; then # æˆ‘ä»¬ç›´æ¥ä»ä¸»å®ä¾‹è¿›è¡Œå…‹éš†ã€‚è§£æ binlog ä½ç½®ã€‚ [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1 rm -f xtrabackup_binlog_info xtrabackup_slave_info echo \"CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\\ MASTER_LOG_POS=${BASH_REMATCH[2]}\" \u003e change_master_to.sql.in fi # æ£€æŸ¥æˆ‘ä»¬æ˜¯å¦éœ€è¦é€šè¿‡å¯åŠ¨å¤åˆ¶æ¥å®Œæˆå…‹éš†ã€‚ if [[ -f change_master_to.sql.in ]]; then echo \"Waiting for mysqld to be ready (accepting connections)\" until mysql -h 127.0.0.1 -e \"SELECT 1\"; do sleep 1; done echo \"Initializing replication from clone position\" mysql -h 127.0.0.1 \\ -e \"$(\u003cchange_master_to.sql.in), \\ MASTER_HOST='mysql-0.mysql', \\ MASTER_USER='root', \\ MASTER_PASSWORD='', \\ MASTER_CONNECT_RETRY=10; \\ START SLAVE;\" || exit 1 # å¦‚æœå®¹å™¨é‡æ–°å¯åŠ¨ï¼Œæœ€å¤šå°è¯•ä¸€æ¬¡ã€‚ mv change_master_to.sql.in change_master_to.sql.orig fi # å½“å¯¹ç­‰ç‚¹è¯·æ±‚æ—¶ï¼Œå¯åŠ¨æœåŠ¡å™¨å‘é€å¤‡ä»½ã€‚ exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \\ \"xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root\" volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d resources: requests: cpu: 100m memory: 100Mi volumes: - name: conf emptyDir: {} - name: con","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:7:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":"è¿â¾mysqlæœåŠ¡ root@master01[13:33:35]~/mysql-sts-yaml #:kubectl get pod -n mysql-sts NAME READY STATUS RESTARTS AGE mysql-0 2/2 Running 0 102s mysql-1 2/2 Running 0 64s mysql-2 1/2 Running 0 18s ","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:7:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Kubernetes"],"content":"éªŒè¯MySQLä¸»ä»åŒæ­¥æ˜¯å¦æ­£å¸¸ ","date":"2023-01-20","objectID":"/posts/kubernetes/primary/kubernetes-8/:7:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"å®æˆ˜æ¡ˆä¾‹-åŸºäºStatefulSetMySQLä¸»ä»æ¶æ„ (å…«)","uri":"/posts/kubernetes/primary/kubernetes-8/"},{"categories":["Ceph"],"content":"Ceph dashboardæ˜¯é€šè¿‡ä¸€ä¸ª webç•Œé¢ï¼Œå¯¹å·²ç»è¿è¡Œçš„cephé›†ç¾¤è¿›è¡ŒçŠ¶æ€æŸ¥çœ‹åŠåŠŸèƒ½é…ç½®ç­‰åŠŸèƒ½ï¼Œæ—©æœŸcephä½¿ç”¨çš„æ˜¯ç¬¬ä¸‰æ–¹çš„dashboardç»„ä»¶ï¼Œå¦‚: **Calamari: **Calamari å¯¹å¤–æä¾›äº†ååˆ†æ¼‚äº®çš„Webç®¡ç†å’Œç›‘æ§ç•Œé¢ï¼Œä»¥åŠä¸€å¥—æ”¹è¿›çš„REST APIæ¥å£(ä¸åŒäºCephè‡ªèº«çš„REST API)ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šç®€åŒ–äº†Cephçš„ç®¡ç†ï¼Œæœ€åˆCalamariæ˜¯ä½œä¸º Inktankå…¬å¸çš„Cephä¼ä¸šçº§å•†ä¸šäº§å“æ¥é”€å”®ï¼Œçº¢å¸½2015å¹´æ”¶è´­Inktank åä¸ºäº†æ›´å¥½åœ°æ¨åŠ¨Cephçš„å‘å±•ï¼Œå¯¹å¤–å®£å¸ƒCalamari å¼€æºhttps://github.com/ceph/calamariä¼˜ç‚¹: ç®¡ç†åŠŸèƒ½å¥½ ç•Œé¢å‹å¥½ å¯ä»¥åˆ©ç”¨å®ƒæ¥éƒ¨ç½²Cephå’Œç›‘æ§Ceph ç¼ºç‚¹: éå®˜æ–¹ ä¾èµ–OpenStackæŸäº›åŒ… (ceph@ceph-deploy ceph-cluster]$ ceph-deploy -h ....... calamari Install and configure Calamari nodes. Assumes that a repository with Calamari packages is already configured. Refer to the docs for examples (http://ceph.com/ceph-deploy/docs/conf.html)VSM:Virtual Storage Manager (VSM)æ˜¯Intelå…¬å¸ç ”å‘å¹¶ä¸”å¼€æºçš„ä¸€æ¬¾Cephé›†ç¾¤ç®¡ç†å’Œç›‘æ§è½¯ä»¶ï¼Œç®€åŒ–äº†ä¸€äº›Cephé›†ç¾¤éƒ¨ç½²çš„ä¸€äº›æ­¥éª¤ï¼Œ å¯ä»¥ç®€å•çš„é€šè¿‡ WEBé¡µé¢æ¥æ“ä½œ.https://github.com/intel/virtual-storage-manager ä¼˜ç‚¹: æ˜“éƒ¨ç½² è½»é‡çº§ çµæ´»(å¯ä»¥è‡ªå®šä¹‰å¼€å‘åŠŸèƒ½) ç¼ºç‚¹: ç›‘æ§é€‰é¡¹å°‘ ç¼ºä¹Cephç®¡ç†åŠŸèƒ½ Inkscope:Inkscopeæ˜¯ä¸€ä¸ªCephçš„ç®¡ç†å’Œç›‘æ§ç³»ç»Ÿï¼Œä¾èµ–äºCephæä¾›çš„API,ä½¿ç”¨MongoDBæ¥å­˜å‚¨å®æ—¶çš„ç›‘æ§æ•°æ®å’Œå†å²ä¿¡æ¯ã€‚https://github.com/inkscope/inkscopeä¼˜ç‚¹: æ˜“éƒ¨ç½² è½»é‡çº§ çµæ´»(å¯ä»¥è‡ªå®šä¹‰å¼€å‘åŠŸèƒ½) ç¼ºç‚¹: ç›‘æ§é€‰é¡¹å°‘ ç¼ºä¹Cephç®¡ç†åŠŸèƒ½ Ceph-Dash: Ceph-Dashæ˜¯ç”¨ Python å¼€å‘çš„ä¸€ä¸€ä¸ªCephçš„ç›‘æ§é¢æ¿ï¼Œç”¨æ¥ç›‘æ§Cephçš„è¿è¡ŒçŠ¶æ€ã€‚åŒæ—¶æä¾›REST APIæ¥è®¿é—®çŠ¶æ€æ•°æ®ã€‚http://cephdash.crapworks.de/ ä¼˜ç‚¹: æ˜“éƒ¨ç½² è½»é‡çº§ çµæ´»(å¯ä»¥è‡ªå®šä¹‰å¼€å‘åŠŸèƒ½) ç¼ºç‚¹: åŠŸèƒ½ç›¸å¯¹ç®€å• ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:0:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.1 å¯ç”¨dashboardæ’ä»¶ https://docs.ceph.com/en/mimic/mgr/https://docs.ceph.com/en/latest/mgr/dashboard/https://packages.debian.org/unstable/ceph-mgr-dashboard #15 ç‰ˆæœ¬æœ‰ä¾èµ–éœ€è¦å•ç‹¬è§£å†³Ceph mgr æ˜¯ä¸€ä¸ªå¤šæ’ä»¶(æ¨¡å—åŒ–)çš„ç»„ä»¶ï¼Œå…¶ç»„ä»¶å¯ä»¥å•ç‹¬çš„å¯ç”¨æˆ–å…³é—­,ä»¥ä¸‹ä¸ºåœ¨ceph-deployæœåŠ¡å™¨æ“ä½œ:æ–°ç‰ˆæœ¬éœ€è¦å®‰è£… dashboard åŒ…ï¼Œè€Œä¸”å¿…é¡»å®‰è£…åœ¨mgrèŠ‚ç‚¹ï¼Œå¦åˆ™æŠ¥é”™å¦‚ä¸‹: The following packages have unmet dependencies: ceph-mgr-dashboard : Depends: ceph-mgr (= 15.2.13-1-bpo10+1) but it is not going to be installed E: Unable to correct problems, you have held broken packages. root@ceph-mgr1:~# apt-cache madison ceph-mgr-dashboard root@ceph-mgr1:~# apt install ceph-mgr-dashboard[ceph@ceph-deploy ceph-cluster]$ ceph mgr module -h #æŸ¥çœ‹å¸®åŠ© [ceph@ceph-deploy ceph-cluster|$ ceph mgr module ls #åˆ—å‡ºæ‰€æœ‰æ¨¡å—çŠ¶æ€ { \"enabled_modules\": [ #å·²å¼€å¯çš„æ¨¡å— \"balancer\", \"crash\", \"iostat\", \"restful\", \"status\" ], \"disabled_modules\": [ #å·²å…³é—­çš„æ¨¡å— { \"name\": \"dashboard\"ï¼Œ \"can_ run\": true, #æ˜¯å¦å¯ä»¥å¯ç”¨ \"error string\": \"\" }, { \"name\": \"hello\", \"can_run\": true, \"error_string\":\"\" }, ------ [ceph@ceph-deploy ceph-cluster]$ ceph mgr module enable dashboard #å¯ç”¨æ¨¡å—æ³¨:æ¨¡å—å¯ç”¨åè¿˜ä¸èƒ½ç›´æ¥è®¿é—®ï¼Œéœ€è¦é…ç½®å…³é—­SSLæˆ–å¯ç”¨SSLåŠæŒ‡å®šç›‘å¬åœ°å€. ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.1.2 å¯ç”¨dashboardæ¨¡å— Ceph dashboardåœ¨mgrèŠ‚ç‚¹è¿›è¡Œå¼€å¯è®¾ç½®ï¼Œå¹¶ä¸”å¯ä»¥é…ç½®å¼€å¯æˆ–è€…å…³é—­SSLï¼Œå¦‚ä¸‹: [ceph@ceph-deploy ceph-cluster]$ ceph config set mgr mgr/dashboard/ssl false #å…³é—­mgr SSL [ceph@ceph-deploy ceph-clusterl$ ceph config set mgr mgr/dashboard/ceph-mgr1/server_addr 172.31.6.107 #æŒ‡å®šdashboardç›‘å¬åœ°å€ [ceph@ceph-deploy ceph-cluster]$ ceph config set mgr mgr/dashboard/ceph-mgr1/server_port 9009 #æŒ‡å®šdashboardç›‘å¬ç«¯å£ #éªŒè¯cephé›†ç¾¤çŠ¶æ€: (ceph@ceph-deploy ceph-cluster]$ ceph -s cluster: id: 23b0f9f2-8db3-477f-99a7-35a90eaf3dab health: HEALTH_ OK services: mon: 3 daemons, quorum ceph-mon1 ,ceph-mon2,ceph-mon3 mgr: ceph-mgr1(active), standbys: ceph-mgr2 mds: mycephfs-2/2/2 up {0=ceph-mgr1=up:active, 1=ceph-mgr2=upactive}, 1 up:standby osd: 12 osds: 12 up, 12 in å¦‚æœæœ‰ä»¥ä¸‹æŠ¥é”™: Module 'dashboard' has failed: error(\"No socket could be created'ï¼Œ) éœ€è¦æ£€æŸ¥mgræœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Œå¯ä»¥é‡å¯ä¸€émgræœåŠ¡","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:1:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.1.3 åœ¨mgrèŠ‚ç‚¹éªŒè¯ç«¯å£ä¸è¿›ç¨‹ [root@ceph-mgr1 ~]# lsof -i:9009 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME ceph-mgr 2338 ceph 28u IPv4 23986 OtO TCP *:pichat (LISTEN)","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:1:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.1.4 dashboardè®¿é—®éªŒè¯ ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:1:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.1.5 è®¾ç½®dashboardè´¦æˆ·åŠå¯†ç  Ubuntu: ceph@ceph-deploy:/home/ceph/ceph-clustqr$ touch pass.txt ceph@ceph-deploy:/home/ceph/ceph-cluster$ echo \"12345678\" \u003e pass.txt ceph@ceph-deploy:/home/ceph/ceph-cluster$ ceph dashboard set-login-credentials jack -i pass.txt ******************************************************************************** ***WARNING: this command is deprecated. *** Please use the ac-user-* related commands to manage users. *** ******************************************************************************** Username and password updatedæ—©æœŸæ–¹å¼ï¼š [ceph@ceph-deploy ceph-cluster]$ ceph dashboard set-login-credentials -h #å‘½ä»¤æ ¼å¼ Monitor commands: ==================== Dashboard set-login-credentials \u003cusername\u003e \u003cpassword\u003e Set the login credentials [ceph@ceph-deploy ceph-cluster]$ ceph dashboard set-login-credentials jack 123456 Username and password updated #è®¾ç½®jackç”¨æˆ·å¯†ç ä¸º123456 ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:1:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.1.7 dashboard SSL å¦‚æœè¦ä½¿ç”¨SSLè®¿é—®ã€‚åˆ™éœ€è¦é…ç½®ç­¾åè¯ä¹¦.è¯ä¹¦å¯ä»¥ä½¿ç”¨cephå‘½ä»¤ç”Ÿæˆï¼Œæˆ–æ˜¯opesslå‘½ä»¤ç”Ÿæˆ.https://docs.ceph.com/en/latest/mgr/dashboard/ 10.1.7.1 cephè‡ªç­¾åè¯ä¹¦ #ç”Ÿæˆè¯ä¹¦: [ceph@ceph-deploy ceph-cluster]$ ceph dashboard create-self-signed-cert #å¯ç”¨SSL: [ceph@ceph-deploy ceph-cluster]$ ceph config set mgr mgr/dashboard/ssl true #æŸ¥çœ‹å½“å‰dashboardçŠ¶æ€: [ceph@ceph-deploy ceph-cluster]$ ceph mgr services { \"dashboard\": \"http://172.31.6.107:9009/\" } #é‡å¯mgræœåŠ¡: [root@ceph-mgr1 ~]# systemctl restart ceph-mgr@ceph-mgr1 #å†æ¬¡éªŒè¯dashboard: [ceph@ceph-deploy ceph-cluster}$ ceph mgr services { \"dashboard\": \"https://172.31.6.107:9009/\" }10.1.7.2 éªŒè¯è¯ä¹¦ä¿¡æ¯ 10.1.7.4 ç™»é™†æˆåŠŸ ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:1:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.2 é€šè¿‡prometheusç›‘æ§ceph nodeèŠ‚ç‚¹ https://prometheus.io/ ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.2.1 éƒ¨ç½²prometheus [root@ceph-mgr1 ~]# mkdir /apps [root@ceph-mgr1 ~]# cd /apps/ root@ceph-mgr1 apps]# tar xvf prometheus-2.27.1.linux-amd64.tar.gz [root@ceph-mgr1 apps]# ln -sv /apps/prometheus-2.27.1.linux-amd64 /apps/prometheus '/apps/prometheusâ€™-\u003e' /apps/ prometheus-2.27.1.linux-amd64'[root@ceph-node1 prometheus]# cat /etc/systemd/system/prometheus.service [Unit] Description=Prometheus Server Documentation=https://prometheus.io/docs/introduction/overview/ After=network.target [Service] Restart=on-failure WorkingDirectory=/apps/prometheus/ ExecStart=/apps/prometheus/prometheus --config.file=/apps/prometheus/prometheus.yml [Istall] WantedBy=multi-user.target root@ceph-mgr1 apps]# systemctl daemon-reload root@ceph-mgr1 apps]# systemctl restart prometheus root@ceph-mgr1 apps]# systemctl enable prometheus","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:2:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.2.2 è®¿é—®prometheus ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:2:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.2.3 éƒ¨ç½²node_exporter å„nodeèŠ‚ç‚¹å®‰è£…node_exporter [root@ceph-node1 ~]# mkdir /apps [root@ceph-node1 ~]# cd /apps/ [root@ceph-node1 apps]# tar xvf node_exporter-1.0.1.inux. amd64.tar.gz root@ceph-node1 apps]# ln -sv /apps/node_exporter-1.0.1.linux -amd64 /apps/node_exporter rootaceph-node1:/apps# scp node_exporter-1.0.1.linux-amd64.tar.gz 172.31.6.107:/apps/[root@ceph-node2 apps]# cat /etc/systemd/system/node-exporter.service [Unit] Description=Prometheus Node Exporter After-network.target [Service] ExecStart=/apps/node_exporter/node_exporter [Instal] WantedBy=multi-user.target root@ceph-node1 apps]# systemctl daemon-reload [root@ceph-node1 apps]# systemctl restart node-exporter [root@ceph-node1 apps]# svstemctl enable node-exporter ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:2:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.2.4 é…ç½®prometheus serveræ•°æ®å¹¶éªŒè¯ vim /apps/prometheus-2.23.0.linux-amd64/prometheus.yaml scrape configs : # The job name is added as a Label. job=\u003cjob_ name\u003e to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to ' /metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9090'] - job_name: 'ceph-node monitor' static_configs: - targets: ['172.31.6.106:9100','172.31.6.107:9100'] ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:2:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.3 é€šè¿‡prometheusç›‘æ§cephæœåŠ¡ Ceph managerå†…éƒ¨çš„æ¨¡å—ä¸­åŒ…å«äº†prometheus çš„ç›‘æ§æ¨¡å—,å¹¶ç›‘å¬åœ¨æ¯ä¸ª manager èŠ‚ç‚¹çš„9283ç«¯å£ï¼Œè¯¥ç«¯å£ç”¨äºå°†é‡‡é›†åˆ°çš„ä¿¡æ¯é€šè¿‡ httpæ¥å£å‘prometheus æä¾›æ•°æ®.https://docs.ceph.com/en/mimic/mgr/prometheus/?highlight=prometheus ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.3.1 å¯ç”¨ prometheus ç›‘æ§æ¨¡å— [ceph@ceph-deploy ceph-cluster]$ ceph mgr module enable prometheus ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:3:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.3.2 éªŒè¯manager æ•°æ® ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:3:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.3.3 é…ç½®Prometheus é‡‡é›†æ•°æ® vim /apps/prometheus-2.23.0.linux-amd64/prometheus.yaml - job_name: 'ceph-cluster-monitor' static_configs: - targets:['172.31.6.105:9283'] systemctl restart prometheus.service","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:3:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.3.4 éªŒè¯æ•°æ® ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:3:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.4 é€šè¿‡grafanaæ˜¾ç¤ºç›‘æ§æ•°æ® é€šè¿‡granfana æ˜¾ç¤ºå¯¹cephçš„é›†ç¾¤ç›‘æ§æ•°æ®åŠnode æ•°æ®. ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.4.1 å®‰è£…grafana [root@ceph-mgr1 apps]# yum localinstall grafana-7.5.7-1.x86_64.rpm [root@ceph-mgr1 apps]# systemctl enable grafana-server [root@ceph-mgr1 apps]# systemctl restart grafana-server","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:4:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.4.2 ç™»é™† grafana è´¦å·admin å¯†ç  admin ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:4:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.4.3 æ·»åŠ æ•°æ®æº ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:4:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Ceph"],"content":"10.4.4 å¯¼å…¥æ¨¡æ¿ ceph OSDhttps://grafana.com/grafana/dashboards/5336 ceph pool https://grafana.com/grafana/dashboards/5342 ","date":"2023-01-18","objectID":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/:4:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph DashboardåŠç›‘æ§ ï¼ˆåï¼‰","uri":"/posts/ceph/10.-ceph-dashboard%E5%8F%8A%E7%9B%91%E6%8E%A7/"},{"categories":["Kubernetes"],"content":"PodçŠ¶æ€ **ç¬¬ä¸€é˜¶æ®µ ** **Pending **æ­£åœ¨åˆ›å»ºPodä½†æ˜¯Podä¸­çš„å®¹å™¨è¿˜æ²¡æœ‰å…¨éƒ¨è¢«åˆ›å»ºå®Œæˆ=[å¤„äºæ­¤çŠ¶æ€çš„Podåº”è¯¥æ£€æŸ¥Podä¾èµ–çš„å­˜å‚¨æ˜¯å¦æœ‰æƒé™æŒ‚è½½ã€é•œåƒæ˜¯å¦å¯ä»¥ä¸‹è½½ã€è°ƒåº¦æ˜¯å¦æ­£å¸¸ç­‰ã€‚ **Failed **Podä¸­æœ‰å®¹å™¨å¯åŠ¨å¤±è´¥è€Œå¯¼è‡´podå·¥ä½œå¼‚å¸¸ã€‚ **Unknown **ç”±äºæŸç§åŸå› æ— æ³•è·å¾—podçš„å½“å‰çŠ¶æ€ï¼Œé€šå¸¸æ˜¯ç”±äºä¸podæ‰€åœ¨çš„nodeèŠ‚ç‚¹é€šä¿¡é”™è¯¯ã€‚ Succeeded Podä¸­çš„æ‰€æœ‰å®¹å™¨éƒ½è¢«æˆåŠŸç»ˆæ­¢å³podé‡Œæ‰€æœ‰çš„containerså‡å·²terminated. ç¬¬äºŒé˜¶æ®µ **Unschedulable **Podä¸èƒ½è¢«è°ƒåº¦ï¼Œkube-scheduleræ²¡æœ‰åŒ¹é…åˆ°åˆé€‚çš„nodeèŠ‚ç‚¹ã€‚ Podscheduled podæ­£å¤„äºè°ƒåº¦ä¸­ï¼Œåœ¨kube-scheduleråˆšå¼€å§‹è°ƒåº¦çš„æ—¶å€™ï¼Œè¿˜æ²¡æœ‰å°†podåˆ†é…åˆ°æŒ‡å®šçš„nodeï¼Œåœ¨ç­›é€‰å‡ºåˆé€‚çš„èŠ‚ç‚¹åå°±ä¼šæ›´æ–°etcdæ•°æ®ï¼Œå°†podåˆ†é…åˆ°æŒ‡å®šçš„nodeã€‚ Initialized æ‰€æœ‰podä¸­çš„åˆå§‹åŒ–å®¹å™¨å·²ç»å®Œæˆäº†ã€‚ **ImagePullBackoff **Podæ‰€åœ¨çš„nodeèŠ‚ç‚¹ä¸‹è½½é•œåƒå¤±è´¥ **Running **Podå†…éƒ¨çš„å®¹å™¨å·²ç»è¢«åˆ›å»ºå¹¶ä¸”å¯åŠ¨ã€‚ **Ready **è¡¨ç¤ºpodä¸­çš„å®¹å™¨å·²ç»å¯ä»¥æä¾›è®¿é—®æœåŠ¡ Error: #pod å¯åŠ¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ NodeLost: #Pod æ‰€åœ¨èŠ‚ç‚¹å¤±è” Unkown: #Pod æ‰€åœ¨èŠ‚ç‚¹å¤±è”æˆ–å…¶å®ƒæœªçŸ¥å¼‚å¸¸ waiting: #Pod ç­‰å¾…å¯åŠ¨ Pending: #Pod ç­‰å¾…è¢«è°ƒåº¦ Terminating: #Pod æ­£åœ¨è¢«é”€æ¯ CrashLoopBackoff: #podï¼Œä½†æ˜¯kubeletæ­£åœ¨å°†å®ƒé‡å¯ InvalidImageName: #nodeèŠ‚ç‚¹æ— æ³•è§£æé•œåƒåç§°å¯¼è‡´çš„é•œåƒæ— æ³•ä¸‹è½½ ImageInspectError: #æ— æ³•æ ¡éªŒé•œåƒï¼Œé•œåƒä¸å®Œæ•´å¯¼è‡´ ErrImageNeverPull: #ç­–ç•¥ç¦æ­¢æ‹‰å–é•œåƒï¼Œé•œåƒä¸­å¿ƒæƒé™æ˜¯ç§æœ‰ç­‰ ImagePullBackoff: #é•œåƒæ‹‰å–å¤±è´¥ï¼Œä½†æ˜¯æ­£åœ¨é‡æ–°æ‹‰å– RegistryUnavailable: #é•œåƒæœåŠ¡å™¨ä¸å¯ç”¨ï¼Œç½‘ç»œåŸå› æˆ–harborå®•æœº ErrImagePull: #é•œåƒæ‹‰å–å‡ºé”™ï¼Œè¶…æ—¶æˆ–ä¸‹è½½è¢«å¼ºåˆ¶ç»ˆæ­¢ CreateContainerConfigError: #ä¸èƒ½åˆ›å»ºkubeletä½¿ç”¨çš„å®¹å™¨é…ç½® CreateContainerError: #åˆ›å»ºå®¹å™¨å¤±è´¥ PreStartContainer: #æ‰§è¡Œprestart hookæŠ¥é”™ï¼ŒPod hook(é’©å­)æ˜¯ç”± Kubernetes ç®¡ç†çš„ kubelet å‘èµ·çš„ï¼Œå½“å®¹å™¨ä¸­çš„è¿›ç¨‹å¯åŠ¨å‰æˆ–è€…å®¹å™¨ä¸­çš„è¿›ç¨‹ç»ˆæ­¢ä¹‹å‰è¿è¡Œï¼Œæ¯”å¦‚å®¹å™¨åˆ›å»ºå®Œæˆåé‡Œé¢çš„æœåŠ¡å¯åŠ¨ä¹‹å‰å¯ä»¥æ£€æŸ¥ä¸€ä¸‹ä¾èµ–çš„å…¶å®ƒæœåŠ¡æ˜¯å¦å¯åŠ¨ï¼Œæˆ–è€…å®¹å™¨é€€å‡ºä¹‹å‰å¯ä»¥æŠŠå®¹å™¨ä¸­çš„æœåŠ¡å…ˆé€šè¿‡å‘½ä»¤åœæ­¢ã€‚ PoststartHookError: #æ‰§è¡Œ poststart hook æŠ¥é”™ RunContainerError: #podè¿è¡Œå¤±è´¥ï¼Œå®¹å™¨ä¸­æ²¡æœ‰åˆå§‹åŒ–PIDä¸º1çš„å®ˆæŠ¤è¿›ç¨‹ç­‰ ContainersNotInitialized: #podæ²¡æœ‰åˆå§‹åŒ–å®Œæ¯• ContainersNotReady: #podæ²¡æœ‰å‡†å¤‡å®Œæ¯• ContainerCreating: #podæ­£åœ¨åˆ›å»ºä¸­ PodInitializing: #podæ­£åœ¨åˆå§‹åŒ–ä¸­ DockerDaemonNotReady: #nodeèŠ‚ç‚¹deckeræœåŠ¡æ²¡æœ‰å¯åŠ¨ NetworkPluginNotReady: #ç½‘ç»œæ’ä»¶è¿˜æ²¡æœ‰å®Œå…¨å¯åŠ¨","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"Pod æ¢é’ˆ https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/ ","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"æ¢é’ˆç®€ä»‹ æ¢é’ˆ æ˜¯ç”± kubelet å¯¹å®¹å™¨æ‰§è¡Œçš„å®šæœŸè¯Šæ–­ï¼Œä»¥ä¿è¯Podçš„çŠ¶æ€å§‹ç»ˆå¤„äºè¿è¡ŒçŠ¶æ€ï¼Œè¦æ‰§è¡Œè¯Šæ–­ï¼Œkubelet è°ƒç”¨ç”±å®¹å™¨å®ç°çš„Handler(å¤„ç†ç¨‹åº)ï¼Œæœ‰ä¸‰ç§ç±»å‹çš„å¤„ç†ç¨‹åº: ExecAction #åœ¨å®¹å™¨å†…æ‰§è¡ŒæŒ‡å®šå‘½ä»¤ï¼Œå¦‚æœå‘½ä»¤é€€å‡ºæ—¶è¿”å›ç ä¸º0åˆ™è®¤ä¸ºè¯Šæ–­æˆåŠŸã€‚ TcPSocketAction #å¯¹æŒ‡å®šç«¯å£ä¸Šçš„å®¹å™¨çš„IPåœ°å€è¿›è¡ŒTCPæ£€æŸ¥ï¼Œå¦‚æœç«¯å£æ‰“å¼€ï¼Œåˆ™è¯Šæ–­è¢«è®¤ä¸ºæ˜¯æˆåŠŸçš„ã€‚ HTTPGetAction #å¯¹æŒ‡å®šçš„ç«¯å£å’Œè·¯å¾„ä¸Šçš„å®¹å™¨çš„IPåœ°å€æ‰§è¡ŒHTTPGetè¯·æ±‚ï¼Œå¦‚æœå“åº”çš„çŠ¶æ€ç å¤§äºç­‰äº200ä¸”å°äº 400ï¼Œåˆ™è¯Šæ–­è¢«è®¤ä¸ºæ˜¯æˆåŠŸçš„ã€‚æ¯æ¬¡æ¢æµ‹éƒ½å°†è·å¾—ä»¥ä¸‹ä¸‰ç§ç»“æœä¹‹ä¸€ï¼š æˆåŠŸ: å®¹å™¨é€šè¿‡äº†è¯Šæ–­ å¤±è´¥: å®¹å™¨æœªé€šè¿‡è¯Šæ–­ æœªçŸ¥: è¯Šæ–­å¤±è´¥ï¼Œå› æ­¤ä¸ä¼šé‡‡å–ä»»ä½•è¡ŒåŠ¨ ","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:1:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"é…ç½®æ¢é’ˆ å®ç°å¯¹Podçš„çŠ¶æ€æ£€æµ‹ ","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"æ¢é’ˆç±»å‹ livenessProbe #å­˜æ´»æ¢é’ˆï¼Œæ£€æµ‹å®¹å™¨å®¹å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Œå¦‚æœå­˜æ´»æ¢æµ‹å¤±è´¥ï¼Œåˆ™kubeletä¼šæ€æ­»å®¹å™¨ï¼Œå¹¶ä¸”å®¹å™¨å°†å—åˆ°å…¶é‡å¯ç­–ç•¥çš„å½±å“ï¼Œå¦‚æœå®¹å™¨ä¸æä¾›å­˜æ´»æ¢é’ˆï¼Œåˆ™é»˜è®¤çŠ¶æ€ä¸º Successï¼ŒlivenessProbeç”¨äºæ§åˆ¶æ˜¯å¦é‡å¯podã€‚ readinessProbe #å°±ç»ªæ¢é’ˆï¼Œå¦‚æœå°±ç»ªæ¢æµ‹å¤±è´¥ï¼Œç«¯ç‚¹æ§åˆ¶å™¨å°†ä»ä¸PodåŒ¹é…çš„æ‰€æœ‰Serviceçš„ç«¯ç‚¹ä¸­åˆ é™¤è¯¥Podçš„IPåœ°å€ï¼Œåˆå§‹å»¶è¿Ÿä¹‹å‰çš„å°±ç»ªçŠ¶æ€é»˜è®¤ä¸ºFailure(å¤±è´¥)ï¼Œå¦‚æœå®¹å™¨ä¸æä¾›å°±ç»ªæ¢é’ˆï¼Œåˆ™é»˜è®¤çŠ¶æ€ä¸º Successï¼ŒreadinessProbeç”¨äºæ§åˆ¶podæ˜¯å¦æ·»åŠ è‡³serviceã€‚","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"æ¢é’ˆé…ç½® https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/æ¢é’ˆæœ‰å¾ˆå¤šé…ç½®å­—æ®µï¼Œå¯ä»¥ä½¿ç”¨è¿™äº›å­—æ®µç²¾ç¡®çš„æ§åˆ¶å­˜æ´»å’Œå°±ç»ªæ£€æµ‹çš„è¡Œä¸º initialDelaySeconds: 120 #åˆå§‹åŒ–å»¶è¿Ÿæ—¶é—´ï¼Œå‘Šè¯‰kubeletåœ¨æ‰§è¡Œç¬¬ä¸€æ¬¡æ¢æµ‹å‰åº”è¯¥ç­‰å¾…å¤šå°‘ç§’ï¼Œé»˜è®¤æ˜¯0ç§’ï¼Œæœ€å°å€¼æ˜¯0 periodseconds: 60 #æ¢æµ‹å‘¨æœŸé—´éš”æ—¶é—´ï¼ŒæŒ‡å®šäº†kubeletåº”è¯¥æ¯å¤šå°‘ç§’ç§’æ‰§è¡Œä¸€æ¬¡å­˜æ´»æ¢æµ‹ï¼Œé»˜è®¤æ˜¯ 10 ç§’ã€‚æœ€å°å€¼æ˜¯ 1 timeoutseconds: 5 #å•æ¬¡æ¢æµ‹è¶…æ—¶æ—¶é—´ï¼Œæ¢æµ‹çš„è¶…æ—¶åç­‰å¾…å¤šå°‘ç§’ï¼Œé»˜è®¤å€¼æ˜¯1ç§’ï¼Œæœ€å°å€¼æ˜¯1ã€‚ successThreshold: 1 #ä»å¤±è´¥è½¬ä¸ºæˆåŠŸçš„é‡è¯•æ¬¡æ•°ï¼Œæ¢æµ‹å™¨åœ¨å¤±è´¥åï¼Œè¢«è§†ä¸ºæˆåŠŸçš„æœ€å°è¿ç»­æˆåŠŸæ•°ï¼Œé»˜è®¤å€¼æ˜¯1ï¼Œå­˜æ´»æ¢æµ‹çš„è¿™ä¸ªå€¼å¿…é¡»æ˜¯1ï¼Œæœ€å°å€¼æ˜¯ 1ã€‚ failureThreshold: 3 #ä»æˆåŠŸè½¬ä¸ºå¤±è´¥çš„é‡è¯•æ¬¡æ•°ï¼Œå½“Podå¯åŠ¨äº†å¹¶ç›®æ¢æµ‹åˆ°å¤±è´¥ï¼ŒKubernetesçš„é‡è¯•æ¬¡æ•°ï¼Œå­˜æ´»æ¢æµ‹æƒ…å†µä¸‹çš„æ”¾å¼ƒå°±æ„å‘³ç€é‡æ–°å¯åŠ¨å®¹å™¨ï¼Œå°±ç»ªæ¢æµ‹æƒ…å†µä¸‹çš„æ”¾å¼ƒPod ä¼šè¢«æ‰“ä¸Šæœªå°±ç»ªçš„æ ‡ç­¾ï¼Œé»˜è®¤å€¼æ˜¯3ï¼Œæœ€å°å€¼æ˜¯1ã€‚","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:2:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"HTTP æ¢æµ‹å™¨å¯ä»¥åœ¨ httpGet ä¸Šé…ç½®é¢å¤–çš„å­—æ®µ host: #è¿æ¥ä½¿ç”¨çš„ä¸»æœºåï¼Œé»˜è®¤æ˜¯Podçš„ IPï¼Œä¹Ÿå¯ä»¥åœ¨HTTPå¤´ä¸­è®¾ç½® â€œHostâ€ æ¥ä»£æ›¿ scheme: http #ç”¨äºè®¾ç½®è¿æ¥ä¸»æœºçš„æ–¹å¼ (HTTP è¿˜æ˜¯ HTTPS)ï¼Œé»˜è®¤æ˜¯ HTTPã€‚ path: /monitor/index.html #è®¿é—® HTTP æœåŠ¡çš„è·¯å¾„ã€‚ httpHeaders : #è¯·æ±‚ä¸­è‡ªå®šä¹‰çš„ HTTP å¤´ï¼ŒHTTP å¤´å­—æ®µå…è®¸é‡å¤ port: 80 #è®¿é—®å®¹å™¨çš„ç«¯å£å·æˆ–è€…ç«¯å£åï¼Œå¦‚æœæ•°å­—å¿…é¡»åœ¨ 1 ~ 65535 ä¹‹é—´","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:2:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"HTTPæ¢é’ˆç¤ºä¾‹ #apiVersion: extensions/v1beta1 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 1 selector: matchLabels: #rs or deployment app: ng-deploy-80 #matchExpressions: # - {key: app, operator: In, values: [ng-deploy-80,ng-rs-81]} template: metadata: labels: app: ng-deploy-80 spec: containers: - name: ng-deploy-80 image: nginx:1.17.5 ports: - containerPort: 80 #readinessProbe: livenessProbe: httpGet: #path: /monitor/monitor.html path: /index.html port: 80 initialDelaySeconds: 5 periodSeconds: 3 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 3 --- apiVersion: v1 kind: Service metadata: name: ng-deploy-80 spec: ports: - name: http port: 81 targetPort: 80 nodePort: 40012 protocol: TCP type: NodePort selector: app: ng-deploy-80éªŒè¯httpæ¢é’ˆï¼š ","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:2:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"TCP æ¢é’ˆç¤ºä¾‹ apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 1 selector: matchLabels: #rs or deployment app: ng-deploy-80 #matchExpressions: # - {key: app, operator: In, values: [ng-deploy-80,ng-rs-81]} template: metadata: labels: app: ng-deploy-80 spec: containers: - name: ng-deploy-80 image: nginx:1.17.5 ports: - containerPort: 80 livenessProbe: #readinessProbe: tcpSocket: port: 80 #port: 8080 initialDelaySeconds: 5 periodSeconds: 3 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 3 --- apiVersion: v1 kind: Service metadata: name: ng-deploy-80 spec: ports: - name: http port: 81 targetPort: 80 nodePort: 40012 protocol: TCP type: NodePort selector: app: ng-deploy-80","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:2:5","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"ExecActionæ¢é’ˆ å¯ä»¥åŸºäºæŒ‡å®šçš„å‘½ä»¤å¯¹Podè¿›â¾ç‰¹å®šçš„çŠ¶æ€æ£€æŸ¥ã€‚ apiVersion: apps/v1 kind: Deployment metadata: name: redis-deployment spec: replicas: 1 selector: matchLabels: #rs or deployment app: redis-deploy-6379 #matchExpressions: # - {key: app, operator: In, values: [redis-deploy-6379,ng-rs-81]} template: metadata: labels: app: redis-deploy-6379 spec: containers: - name: redis-deploy-6379 image: redis ports: - containerPort: 6379 livenessProbe: #readinessProbe: exec: command: #- /apps/redis/bin/redis-cli - /usr/local/bin/redis-cli - quit initialDelaySeconds: 5 periodSeconds: 3 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 3 --- apiVersion: v1 kind: Service metadata: name: redis-deploy-6379 spec: ports: - name: http port: 6379 targetPort: 6379 nodePort: 40016 protocol: TCP type: NodePort selector: app: redis-deploy-6379å¦‚æœç«¯â¼æ£€æµ‹è¿ç»­è¶…è¿‡æŒ‡å®šçš„ä¸‰æ¬¡éƒ½æ²¡æœ‰é€šè¿‡ï¼Œåˆ™PodçŠ¶æ€å¦‚ä¸‹ï¼š ","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:2:6","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"livenessProbeå’ŒreadinessProbeçš„å¯¹â½ é…ç½®å‚æ•°â¼€æ · livenessProbe è¿ç»­æ¢æµ‹å¤±è´¥ä¼šé‡å¯ã€é‡å»ºpodï¼Œ readinessProbeä¸ä¼šæ‰§â¾é‡å¯æˆ–è€…é‡å»ºPodæ“ä½œlivenessProbe è¿ç»­æ£€æµ‹æŒ‡å®šæ¬¡æ•°å¤±è´¥åä¼šå°†å®¹å™¨ç½®äº(Crash Loop BackOff)ä¸”ä¸å¯â½¤ï¼ŒreadinessProbeä¸ä¼š readinessProbe è¿ç»­æ¢æµ‹å¤±è´¥ä¼šä»serviceçš„endpointdä¸­åˆ é™¤è¯¥Podï¼Œ livenessProbeä¸å…·å¤‡æ­¤åŠŸèƒ½ï¼Œä½†æ˜¯ä¼šå°†å®¹å™¨æŒ‚èµ·livenessProbe livenessProbeâ½¤æˆ·æ§åˆ¶æ˜¯å¦é‡å¯podï¼Œ readinessProbeâ½¤äºæ§åˆ¶podæ˜¯å¦æ·»åŠ â¾„service **å»ºè®®ï¼šä¸¤ä¸ªæ¢é’ˆéƒ½é…ç½® ** ","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:2:7","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"Podé‡å¯ç­–ç•¥ k8såœ¨Podå‡ºç°å¼‚å¸¸çš„æ—¶å€™ä¼šâ¾ƒåŠ¨å°†Podé‡å¯ä»¥æ¢å¤Podä¸­çš„æœåŠ¡ã€‚ :::success restartPolicyAlwaysï¼šå½“å®¹å™¨å¼‚å¸¸æ—¶ï¼Œ k8sâ¾ƒåŠ¨é‡å¯è¯¥å®¹å™¨ï¼Œ ReplicationController/Replicaset/Deploymentã€‚OnFailureï¼šå½“å®¹å™¨å¤±è´¥æ—¶(å®¹å™¨åœâ½Œè¿â¾ä¸”é€€å‡ºç ä¸ä¸º0)ï¼Œ k8sâ¾ƒåŠ¨é‡å¯è¯¥å®¹å™¨ã€‚Neverï¼šä¸è®ºå®¹å™¨è¿â¾çŠ¶æ€å¦‚ä½•éƒ½ä¸ä¼šé‡å¯è¯¥å®¹å™¨,Jobæˆ–CronJobã€‚ ::: ","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Kubernetes"],"content":"é•œåƒæ‹‰å–ç­–ç•¥ IfNotPresent nodeèŠ‚ç‚¹æ²¡æœ‰æ­¤é•œåƒå°±å»æŒ‡å®šçš„é•œåƒä»“åº“æ‹‰å–ï¼Œ nodeæœ‰å°±ä½¿â½¤nodeæœ¬åœ°é•œåƒã€‚Always æ¯æ¬¡é‡å»ºpodéƒ½ä¼šé‡æ–°æ‹‰å–é•œåƒNever **ä»ä¸åˆ°é•œåƒä¸­â¼¼æ‹‰å–é•œåƒï¼Œåªä½¿â½¤æœ¬åœ°é•œåƒ ** ","date":"2023-01-18","objectID":"/posts/kubernetes/primary/kubernetes-7/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Podçš„çŠ¶æ€å’Œæ¢é’ˆ (ä¸ƒ)","uri":"/posts/kubernetes/primary/kubernetes-7/"},{"categories":["Ceph"],"content":"åœºæ™¯ï¼šé›†ç¾¤å†…æœ‰å›ºæ€å’Œæœºæ¢°ç¡¬ç›˜ å¦‚ä½•è®©ä¸é‡è¦çš„ä¸šåŠ¡æ”¾åˆ°æœºæ¢°ç›˜ã€‚ Ceph é›†ç¾¤ä¸­ç”± mon æœåŠ¡å™¨ç»´æŠ¤çš„çš„äº”ç§è¿è¡Œå›¾: Monitor map ç›‘è§†å™¨è¿è¡Œå›¾ OSD map OSDè¿è¡Œå›¾ å„ä¸ªæ¯éš”6sæ±‡æŠ¥çŠ¶æ€åŒæ—¶ç›‘æ§å…¶ä»–OSDçš„çŠ¶æ€ï¼Œè¶…è¿‡20ç§’å°±ä¼šè¢«è¸¢å‡ºå» PG map PGè¿è¡Œå›¾ ï¼ˆä¸€ä¸ªå­˜å‚¨æ± æœ‰å“ªäº›pgï¼‰ Crush map (Controllers replication under scalable hashing) å¯æ§çš„ã€å¯å¤åˆ¶çš„ã€å¯ä¼¸ç¼©çš„ä¸€è‡´æ€§hashç®—æ³•ã€‚crushè¿è¡Œå›¾ï¼Œå½“æ–°å»ºå­˜å‚¨æ± æ—¶ä¼šåŸºäºOSD mapåˆ›å»ºå‡ºæ–°çš„PGç»„åˆåˆ—è¡¨ç”¨äºå­˜å‚¨æ•°æ® MDS map cephfs metadataè¿è¡Œå›¾ æ•°æ®çš„è®¿é—®ï¼š objâ€“\u003epg hash(oid)%pg=pgid å…ˆå°†æ–‡ä»¶è®¡ç®—æˆä¸€ä¸ªhashå€¼ï¼Œè¿™ä¸ªæ•°å–pgæ•°é‡çš„ä½™æ•° æœ€ç»ˆå¾—åˆ°åˆ†é…åˆ°é‚£ä¸ªpgä¸­Objâ€“\u003eOSD crush æ ¹æ®å½“å‰çš„monè¿è¡Œå›¾è¿”å›pgå†…çš„æœ€æ–°çš„OSDç»„åˆ,æ•°æ®å³å¯å¼€å§‹å¾€ä¸»çš„å†™ç„¶åå¾€å‰¯æœ¬OSDåŒæ­¥ crush ç®—æ³•é’ˆå¯¹ç›®çš„èŠ‚ç‚¹çš„é€‰æ‹©:ç›®å‰æœ‰5ç§ç®—æ³•æ¥å®ç°èŠ‚ç‚¹çš„é€‰æ‹©ï¼ŒåŒ…æ‹¬Uniformã€Listã€ Treeã€ Strawã€ Straw2, æ—©æœŸç‰ˆæœ¬ä½¿ç”¨çš„æ˜¯cephé¡¹ç›®çš„å‘èµ·è€…å‘æ˜çš„ç®—æ³•straw,ç›®å‰å·²ç»å‘å±•åˆ°straw2ç‰ˆæœ¬ã€‚æŠ½ç­¾ç®—æ³• ","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:0:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.1 PGä¸OSDæ˜ å°„è°ƒæ•´ é»˜è®¤æƒ…å†µä¸‹,crushç®—æ³•è‡ªè¡Œå¯¹åˆ›å»ºçš„poolä¸­çš„PGåˆ†é…OSD,ä½†æ˜¯å¯ä»¥æ‰‹åŠ¨åŸºäºæƒé‡è®¾ç½® crush ç®—æ³•åˆ†é…æ•°æ®çš„å€¾å‘æ€§ï¼Œ æ¯”å¦‚1T çš„ç£ç›˜æƒé‡æ˜¯1, 2T çš„å°±æ˜¯2, æ¨èä½¿ç”¨ç›¸åŒå¤§å°çš„è®¾å¤‡ã€‚ è°ƒæ•´çš„æ–¹æ³•æœ‰ä¸¤ç§ï¼š 1. è°ƒæ•´weightå€¼ è°ƒæ•´reweightå€¼ ","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.1.1 æŸ¥çœ‹å½“å‰çŠ¶æ€ ceph osd df åŸºäºå­˜å‚¨ç©ºé—´**weight **è¡¨ç¤ºè®¾å¤‡(device)çš„å®¹é‡ç›¸å¯¹å€¼ï¼Œæ¯”å¦‚ 1TB å¯¹åº”1.00 ,é‚£ä¹ˆ500Gçš„ OSD çš„ weight å°±åº”è¯¥æ˜¯0.5, weight æ˜¯åŸºäºç£ç›˜ç©ºé—´åˆ†é…PGçš„æ•°é‡ï¼Œè®©crushç®—æ³•å°½å¯èƒ½å¾€ç£ç›˜ç©ºé—´å¤§çš„OSDå¤šåˆ†é…OSDã€‚å¾€ç£ç›˜ç©ºé—´å°çš„OSDåˆ†é…è¾ƒå°‘çš„OSDã€‚ é‚£ä¸ªç£ç›˜å¿«æ»¡äº†è°ƒæ•´ä¸€ä¸‹é‡Šæ”¾èµ„æº**Reweight **å‚æ•°çš„ç›®çš„æ˜¯é‡æ–°å¹³è¡¡ cephçš„CRUSHç®—æ³•éšæœºåˆ†é…çš„PG,é»˜è®¤çš„åˆ†é…æ˜¯æ¦‚ç‡ä¸Šçš„å‡è¡¡ï¼Œå³ä½¿OSDéƒ½æ˜¯ä¸€ æ ·çš„ç£ç›˜ç©ºé—´ä¹Ÿä¼šäº§ç”Ÿä¸€äº›PGåˆ†å¸ƒä¸å‡åŒ€çš„æƒ…å†µï¼Œ æ­¤æ—¶å¯ä»¥é€šè¿‡è°ƒæ•´reweightå‚æ•°ï¼Œè®©cephé›†ç¾¤ç«‹å³é‡æ–°å¹³è¡¡å½“å‰ç£ç›˜çš„PG,ä»¥è¾¾åˆ°æ•°æ®å‡è¡¡åˆ†å¸ƒçš„ç›®çš„ï¼ŒREWEIGHT æ˜¯PGå·²ç»åˆ†é…å®Œæˆï¼Œè¦åœ¨cepgé›†ç¾¤é‡æ–°å¹³è¡¡PGçš„åˆ†å¸ƒã€‚ ","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:1:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.1.2 ä¿®æ”¹WEIGHTå¹¶éªŒè¯ #ä¿®æ”¹æŸä¸ªæŒ‡å®šIDçš„osdçš„æƒé‡ è°ƒæ•´å®Œç«‹å³ç”Ÿæ•ˆ root@ceph-deploy:~# ceph osd crush reweight osd.10 1.5 #éªŒè¯OSDæƒé‡: root@ceph-deploy:~# ceph osd df","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:1:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.1.3 ä¿®æ”¹ REWEIGHT å¹¶éªŒè¯ OSD çš„ REWEIGHTçš„å€¼é»˜è®¤ä¸º1 ,å€¼å¯ä»¥è°ƒæ•´ï¼ŒèŒƒå›´åœ¨0~1ä¹‹é—´ï¼Œå€¼è¶Šä½PGè¶Šå°ï¼Œå¦‚æœè°ƒæ•´äº†ä»»ä½•ä¸€ä¸ªOSDçš„REWEIGHTå€¼ï¼Œé‚£ä¹ˆOSDçš„PGä¼šç«‹å³å’Œå…¶å®ƒOSDè¿›è¡Œé‡æ–°å¹³è¡¡ï¼Œå³æ•°æ®çš„é‡æ–°åˆ†é…ï¼Œç”¨äºå½“æŸä¸ªOSDçš„PGç›¸å¯¹è¾ƒå¤šéœ€è¦é™ä½å…¶PG æ•°é‡çš„åœºæ™¯ã€‚ root@ceph-deploy:~# ceph osd reweight 9 0.6 ","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:1:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.2 crushè¿è¡Œå›¾ç®¡ç† é€šè¿‡å·¥å…·å°† ceph çš„crush è¿è¡Œå›¾å¯¼å‡ºå¹¶è¿›è¡Œç¼–è¾‘ï¼Œç„¶åå¯¼å…¥ ","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.2.1 å¯¼å‡ºcrushè¿è¡Œå›¾ æ³¨: å¯¼å‡ºçš„ crush è¿è¡Œå›¾ä¸ºäºŒè¿›åˆ¶æ ¼å¼,æ— æ³•é€šè¿‡æ–‡æœ¬ç¼–è¾‘å™¨ç›´æ¥æ‰“å¼€ï¼Œéœ€è¦ä½¿ç”¨crushtoolå·¥å…·è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼åæ‰èƒ½é€šè¿‡vimç­‰æ–‡æœ¬ç¼–è¾‘å®«å·¥å…·æ‰“å¼€å’Œç¼–è¾‘ã€‚ root@ceph-deploy:~# mkdir /data/ceph -p #å¯¼å‡º root@ceph-deploy:~# ceph osd getcrushmap -o /data/ceph/crushmap 67","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:2:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.2.2 å°†è¿è¡Œå›¾è½¬æ¢ä¸ºæ–‡æœ¬: å¯¼å‡ºçš„è¿è¡Œå›¾ä¸èƒ½ç›´æ¥ç¼–è¾‘ï¼Œéœ€è¦è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼å†è¿›è¡ŒæŸ¥çœ‹ä¸ç¼–è¾‘ root@ceph-deploy:~# apt install ceph-base root@ceph-deploy:~# crushtool -d /data/ceph/crushmap \u003e /data/ceph/crushmap.txt root@ceph-deploy:~# file /data/ceph/crushmap.txt /data/ceph/crushmap.txt: ASCII text","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:2:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.2.3 ç¼–è¾‘æ–‡æœ¬ #è‡ªå®šä¹‰ä¿®æ”¹ root@ceph-deploy:~# vim /data/ceph/crushmap.txt # begin crush map #å¯è°ƒæ•´çš„crush mapå‚æ•° tunable choose local tries 0 # devices #å½“å‰çš„è®¾å¤‡åˆ—è¡¨ device 0 osd.0 class hdd device 1 osd.1 class hdd # types #å½“å‰æ”¯æŒçš„bucketç±»å‹ ä»¥ä»€ä¹ˆä¸ºå•ä½ type 0 osd #osdå®ˆæŠ¤è¿›ç¨‹ï¼Œå¯¹åº”åˆ°ä¸€ä¸ªç£ç›˜è®¾å¤‡ type 1 host #ä¸€ä¸ªä¸»æœº (é»˜è®¤æ”¾åœ¨ä¸åŒçš„ä¸»æœº) type 2 chassis #åˆ€ç‰‡æœåŠ¡å™¨çš„æœºç®± type 3 rack #åŒ…å«è‹¥å¹²ä¸ªæœåŠ¡å™¨çš„æœºæŸœ/æœºæ¶ type 4 row #åŒ…å«è‹¥å¹²ä¸ªæœºæŸœçš„ä¸€æ’æœºæŸœ type 5 pdu #æœºæŸœçš„æ¥å…¥ç”µæºæ’åº§ type 7 room #åŒ…å«è‹¥å¹²æœºæŸœçš„æˆ¿é—´ï¼Œä¸€ä¸ªæ•°æ®ä¸­å¿ƒæœ‰å¥½å¤šè¿™æ ·çš„æˆ¿é—´ç»„æˆ type 8 datacenter #ä¸€ä¸ªæ•°æ®ä¸­å¿ƒæˆ–IDS type 9 region #ä¸€ä¸ªåŒºåŸŸï¼Œæ¯”å¦‚AWSå®å¤ä¸­å«æ•°æ®ä¸­å¿ƒ type 10 root #bucketåˆ†å±‚çš„æœ€é¡¶éƒ¨ï¼Œæ ¹ç®—æ³• item osd.0 weight 0.098 #osd0æƒé‡æ¯”ä¾‹ï¼Œcrush ä¼šè‡ªåŠ¨æ ¹æ®ç£ç›˜ç©ºé—´è®¡ç®—ï¼Œä¸åŒçš„ç£ç›˜ç©ºé—´çš„æƒé‡ä¸ä¸€æ · tem osd.1 weight 0.098 tem osd.2 weight 0.098 tem osd.3 weight 0.098 tem osd.4 weight 0.098 } ... root default { #æ ¹çš„é…ç½® id -1 # do not change unnecessarily id -2 class hdd # do not change unnecessarily # weight 3.256 alg straw2 hash 0 # rjenkins1 item ceph-node1 weight 0.488 item ceph-node2 weight 0.488 item ceph-node3 weight 0.488 item ceph-node4 weight 0.488 } # buckets host ceph-node1 { ç±»å‹Host åç§°ä¸ºceph-node1 id -3 # do not change unnecessarily #cephç”Ÿæˆçš„OSD ID,éå¿…è¦ä¸è¦æ”¹ id -4 class hdd # do not change unnecessarily # weight 0.488 alg straw2 #crushç®—æ³•ï¼Œç®¡ç†OSDè§’è‰² hash 0 # rjenkins1 #ä½¿ç”¨æ˜¯å“ªä¸ªhashç®—æ³•ï¼Œ0è¡¨ç¤ºé€‰æ‹©rjenkins1è¿™ç§hashç®—æ³• item osd.0 weight 0.098 #osd 0 æƒé‡æ¯”ä¾‹ï¼Œcrush ä¼šè‡ªåŠ¨æ ¹æ®ç£ç›˜ç©ºé—´è®¡ç®—ï¼Œä¸åŒçš„ç£ç›˜ç©ºé—´çš„æƒé‡ä¸ä¸€æ · item osd.1 weight 0.098 item osd.2 weight 0.098 item osd.3 weight 0.098 item osd.4 weight 0.098 } host ceph-node2 { id -5 # do not change unnecessarily id -6 class hdd # do not change unnecessarily # weight 0.461 alg st raw2 hash 0 # rjenkins1 item osd.5 weight 0.098 item osd.6 weight 0.098 item osd.7 weight 0.070 item osd.8 weight 0.098 item osd.9 weight 0.098 } root default { #æ ¹çš„é…ç½® id -1 # do not change unnecessarily id -2 class hdd # do not change unnecessarily # weight 3.256 alg straw2 hash0 # rjenkins1 item ceph-node1 weight 0.488 item ceph-node2 weight 0.488 item ceph-node3 weight 0.488 item ceph-node4 weight 0.488 } # rules rule replicated _rule { #å‰¯æœ¬æ± çš„é»˜è®¤é…ç½® id 0 type replicated min_size 1 max_size 10 #é»˜è®¤æœ€å¤§å‰¯æœ¬ä¸º10 step take default #åŸºäºdefaultå®šä¹‰çš„ä¸»æœºåˆ†é…OSD step chooseleaf firstn 0 type host #é€‰æ‹©ä¸»æœºï¼Œæ•…éšœåŸŸç±»å‹ä¸ºä¸»æœº step emit #å¼¹å‡ºé…ç½®å³è¿”å›ç»™å®¢æˆ·ç«¯ } rule erasure-code { #çº åˆ ç æ± çš„é»˜è®¤é…ç½® type erasure min_size 3 max_size 4 step set_chooseleaf_tries 5 step set_choose_tries 100 step take default step chooseleaf indep 0 type host step emit }# rules rule replicated rule { id 0 type rep Licated min_size 1 max_size 6 #ä¿®æ”¹æœ€å¤§å‰¯æœ¬æ•° step take default step chooseleaf firstn 0 type host step emit }","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:2:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.2.3 å°†æ–‡æœ¬è½¬æ¢ä¸ºcrushæ ¼å¼ root@ceph-deploy:~# crushtool -c /data/ceph/crushmap.txt -o /data/ceph/newcrushmap","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:2:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.2.4 å¯¼å…¥æ–°çš„crush å¯¼å…¥çš„è¿è¡Œå›¾ä¼šç«‹å³è¦†ç›–åŸæœ‰çš„è¿è¡Œå›¾å¹¶ç«‹å³ç”Ÿæ•ˆ. root@ceph-deploy:~# ceph osd setcrushmap -i /data/ceph/newcrushmap","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:2:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.2.5 éªŒè¯crushè¿è¡Œå›¾æ˜¯å¦ç”Ÿæ•ˆ root@ceph-deploy:~# ceph osd crush rule dump [ { \"rule_id\": 0, \"rule_name\": \"replicated_rule\", \"ruleset\": 0, \"type\": 1, \"min_size\": 1, \"max_size\": 6, ","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:2:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3 crushæ•°æ®åˆ†ç±»ç®¡ç† Cephcrush ç®—æ³•åˆ†é…çš„PGçš„æ—¶å€™å¯ä»¥å°†PGåˆ†é…åˆ°ä¸åŒä¸»æœºçš„OSDä¸Šï¼Œä»¥å®ç°ä»¥ä¸»æœºä¸ºå•ä½çš„é«˜å¯ç”¨ï¼Œè¿™ä¹Ÿæ˜¯é»˜è®¤æœºåˆ¶ï¼Œä½†æ˜¯æ— æ³•ä¿è¯ä¸åŒPGä½äºä¸åŒæœºæŸœæˆ–è€…æœºæˆ¿çš„ä¸»æœºã€‚ å¦‚æœè¦å®ç°åŸºäºæœºæŸœæˆ–è€…æ˜¯æ›´é«˜çº§çš„IDCç­‰æ–¹å¼çš„æ•°æ®é«˜å¯ç”¨ï¼Œè€Œä¸”ä¹Ÿä¸èƒ½å®ç°Aé¡¹ç›®çš„æ•°æ®åœ¨SSD,Bé¡¹ç›®çš„æ•°æ®åœ¨æœºæ¢°ç£ç›˜ï¼Œå¦‚æœæƒ³è¦å®ç°æ­¤åŠŸèƒ½åˆ™éœ€è¦å¯¼å‡ºcrushè¿è¡Œå›¾å¹¶æ‰‹åŠ¨ç¼–è¾‘ï¼Œä¹‹åå†å¯¼å…¥å¹¶è¦†ç›–åŸæœ‰çš„crushè¿è¡Œå›¾ã€‚ ","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3.1 å¯¼å‡ºcurshè¿è¡Œå›¾ root@ceph-deploy:~# mkdir /opt/ceph/ root@ceph-deploy:~# ceph osd getcrushmap -o /opt/ceph/crushmap 68","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3.2 å°†è¿è¡Œå›¾è½¬æ¢ä¸ºæ–‡æœ¬ root@ceph-deploy:~# crushtool -d /opt/ceph/crushmap \u003e /opt/ceph/crushmap.txt root@ceph-deploy:- # file /opt/ceph/crushmap.txt /opt/ceph/crushmap.txt: ASCII text","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3.3 æ·»åŠ è‡ªå®šä¹‰é…ç½® root@ceph-deploy:~# cat topt/ceph/crushmap.txt # begin crush map tunable choose_local_tries 0 tunable choose_local_fallback_tries 0 tunable choose_total_tries 50 tunable chooseleaf_descend_once 1 tunable chooseleaf_vary_r 1 tunable chooseleaf_stable 1 tunable straw_calc_version 1 tunable allowed_bucket_algs 54 # devices device 0 osd.0 class hdd device 1 osd.1 class hdd device 2 osd.2 class hdd device 3 osd.3 class hdd device 4 osd.4 class hdd device 5 osd.5 class hdd device 6 osd.6 class hdd device 7 osd.7 class hdd device 8 osd.8 class hdd device 9 osd.9 class hdd device 10 osd.10 class hdd device 11 osd.11 class hdd device 12 osd.12 class hdd device 13 osd.13 class hdd device 14 osd.14 class hdd device 15 osd.15 class hdd device 16 osd.16 class hdd device 17 osd.17 class hdd device 18 osd.18 class hdd device 19 osd.19 class hdd # types type 0 osd type 1 host type 2 chassis type 3 rack type 4 row type 5 pdu type 6 pod type 7 room type 8 datacenter type 9 zone type 10 region type 11 root # buckets host ceph-node1 { id -3 # do not change unnecessarily id -4 class hdd # do not change unnecessarily # weight 0.490 alg straw2 hash0 # rjenkins1 item osd.0 weight 0.098 item osd.1 weight 0.098 item osd.2 weight 0.098 item osd.3 weight 0.098 } host ceph-node2 { id -5 # do not change unnecessarily id -6 class hdd # do not change unnecessarily # weight 0.490 alg straw2 hash0 # rjenkins1 item osd.5 weight 0.098 item osd.6 weight 0.098 item osd.7 weight 0.098 item osd.8 weight 0.098 item osd.9 weight 0.098 } host ceph-node3 { id -7 # do not change unnecessarily id -8 class hdd # do not change unnecessarily # weight 1.792 alg straw2 hash 0 # rjenkins1 item osd.10 weight 1.400 item osd.11 weight 0.098 item osd.12 weight 0.098 item osd.13 weight 0.098 item osd.14 weight 0.098 } host ceph-node4 { id -9 # do not change unnecessarily id -10 class hdd # do not change unnecessarily # weight 0.490 alg straw2 hash 0 # rjenkins1 item osd.15 weight 0.098 item osd.16 weight 0.098 item osd.17 weight 0.098 item osd.18 weight 0.098 item osd.19 weight 0.098 } root default { id -1 # do not change unnecessarily id -2 class hdd # do not change unnecessarily # weight 3.255 alg straw2 hash 0 # rjenkins1 item ceph-node1 weight 0.488 item ceph-node2 weight 0.488 item ceph-node3 weight 1.791 item ceph-node4 weight 0.488 } #å‰é¢æ˜¯æœºæ¢°èŠ‚ç‚¹ï¼Œåé¢å®šä¹‰ssdèŠ‚ç‚¹ï¼ŒIDä¸èƒ½å†²çª #magedu ssd node host ceph-ssdnode1 { id -103 # do not change unnecessarily id -104 class hdd # do not change unnecessarily # weight 0.098 alg straw2 hash 0 # rjenkins1 item osd.0 weight 0.098 } host ceph-ssdnode2 { id -105 # do not change unnecessarily id -106 class hdd # do not change unnecessarily # weight 0.098 alg straw2 hash0 # rjenkins1 item osd.5 weight 0.098 } host ceph-ssdnode3 { id -107 # do not change unnecessarily id -108 class hdd # do not change unnecessarily # weight 0.098 alg straw2 hash 0 # rjenkins1 item osd.10 weight 0.098 } host ceph-ssdnode4 { id -109 # do not change unnecessarily id -110 class hdd # do not change unnecessarily # weight 0.098 alg straw2 hash 0 # rjenkins1 item osd.15 weight 0.098 } #magedu bucket æŠŠå®šä¹‰nodeåŠ è¿›æ¥ root ssd { id -127 # do not change unnecessarily id -111 class hdd # do not change unnecessarily # weight 1.952 alg straw hash 0 # rjenkins1 item ceph-ssdnode1 weight 0.488 item ceph-ssdnode2 weight 0.488 item ceph-ssdnode3 weight 0.488 item ceph-ssdnode4 weight 0.488 } #magedu ssd-rules rule magedu_ssd_rule { id 20 type replicated #ç±»å‹å‰¯æœ¬æ±  min_size 1 max_size 5 step take ssd #å®šä¹‰ä½¿ç”¨çš„bucket step chooseleaf firstn 0 type host #é€‰æ‹©æ–¹æ³• é€‰æ‹©å½“å‰å‰¯æœ¬æ•°ä¸ªä¸»æœºä¸‹çš„OSDï¼Œ é«˜å¯ç”¨ç±»å‹host step emit } ## chooseleafè¡¨ç¤ºåœ¨ç¡®å®šæ•…éšœåŸŸåï¼Œè¿˜å¿…é¡»é€‰å‡ºè¯¥åŸŸä¸‹é¢çš„OSDèŠ‚ç‚¹ rule replicated rule { id 0 type replicated min_size 1 max_size 10 step take default step chooseleaf firstn 0 type host step emit } rule erasure-code { id 1 type erasure min_size 3 max_size 4 step set_chooseleaf_tries 5 step set_choose_tries 100 step take default step chooseleaf indep 0 type host step emit } rule erasure-code { id 1 type erasure min_size 3 max_size 4","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3.4 è½¬æ¢ä¸ºcrushäºŒè¿›åˆ¶æ ¼å¼ root@ceph-deploy:~# crushtool -C /opt/ceph/crushmap.txt -o /opt/ceph/newcrushmap","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3.5 å¯¼å…¥æ–°çš„crushè¿è¡Œå›¾ root@ceph-deploy:~# ceph osd setcrushmap -i /opt/ceph/crushmap 70","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3.6 éªŒè¯crushè¿è¡Œå›¾æ˜¯å¦ç”Ÿæ•ˆ root@ceph-deploy:~# ceph osd crush rule dump","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3.7 æµ‹è¯•åˆ›å»ºå­˜å‚¨æ±  root@ceph-deploy:~# peph osd pool create magedu-ssdpool 32 32 magedu_ssd_rule pool 'magedu-ssdpool' created #æŒ‡å®šå­˜å‚¨æ±  rule é»˜è®¤æ˜¯defuse","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:7","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Ceph"],"content":"9.3.8 éªŒè¯pgpçŠ¶æ€ ceph pg ls-by-pool magedu-ssdpool awk '{print $1, $2,$15} ' ","date":"2023-01-17","objectID":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/:3:8","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph crushç®—æ³•è¿›é˜¶ ï¼ˆä¹ï¼‰","uri":"/posts/ceph/9.-ceph-crush%E8%BF%9B%E9%98%B6/"},{"categories":["Kubernetes"],"content":"rbdç»“åˆk8sæä¾›å­˜å‚¨å·åŠåŠ¨æ€å­˜å‚¨å·ä½¿ç”¨æ¡ˆä¾‹ ç›®çš„ï¼š è®©k8s ä¸­çš„ pod å¯ä»¥è®¿é—® cephä¸­rbd æä¾›çš„é•œåƒä½œä¸ºå­˜å‚¨è®¾å¤‡ã€‚ éœ€è¦åœ¨ ceph åˆ›å»ºrbdå¹¶ä¸”è®© k8s node èŠ‚ç‚¹èƒ½å¤Ÿé€šè¿‡ ceph çš„è®¤è¯k8såœ¨ä½¿ç”¨ ceph ä½œä¸ºåŠ¨æ€å­˜å‚¨å·çš„æ—¶å€™ï¼Œéœ€è¦ **kube-controller-manager **ç»„ä»¶èƒ½å¤Ÿè®¿é—®cephï¼Œå› æ­¤éœ€è¦åœ¨åŒ…æ‹¬k8s masteråŠ nodeèŠ‚ç‚¹åœ¨å†…çš„æ¯ä¸€ä¸ªnode åŒæ­¥è®¤è¯æ–‡ä»¶ã€‚ ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"1.åˆ›å»ºåˆå§‹åŒ–RBD #åˆ›å»ºæ–°çš„rbd [ceph@ceph-deploy ~]$ ceph osd pool create shijie-rbd-pool1 32 32 pool'xin-rbd-pool1' created #éªŒè¯å­˜å‚¨æ± : [ceph@ceph-deploy ~]$ ceph osd pool ls mypool myrdb1 .rgw.root default.rgw.controldefault.rgw.meta default.rgw.log cephfs-metadata cephfs-datarbd-data1 xin-rbd-pool1 #ç¡®è®¤å­˜å‚¨æ± å·²ç»å­˜åœ¨ #å­˜å‚¨æ± å¯ç”¨rbd ceph@ceph-deploy ~]$ ceph osd pool application enable xin-rbd-pool1 rbd enabled application 'rbd' on pool 'xin-rbd-pool1 #åˆå§‹åŒ– rbdceph@ceph-deploy ~]$ rbd pool init -p xin-rbd-pool1","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"2 åˆ›å»ºimage #åˆ›å»ºé•œåƒ [ceph@ceph-deploy -]$ rbd create xin-img-img1 --size 3G --pool xin-rbd-pool1 --image-format 2 --image-feature layering #éªŒè¯é•œåƒ [ceph@ceph-deploy ~]$ rbd ls --pool xin-rbd-pool1 shijie-img-img1 #éªŒè¯é•œåƒä¿¡æ¯ [ceph@ceph-deploy ~]$ rbd --image xin-img-img1 --pool xin-rbd-pool1 inforbd image 'xin-img-img1': size 3 GiBin 768 objects order 22 (4 MiB objects) id:1e7356b8b4567b lock_name_prefix:rbd_data.1e7356b8b4567 format: 2 features: layering op_features: flags: create timestamp: Wed Jan 611:01:51 2021","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"å®¢æˆ·ç«¯å®‰è£…ceph-common åˆ†åˆ«åœ¨ k8s master ä¸å„ node èŠ‚ç‚¹å®‰è£… ceph-common ç»„ä»¶åŒ… #ä¸‹è½½keyæ–‡ä»¶ root@k8s-master1:$ wget -q -0- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add - root@k8s-master2:$ wget -q -0- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add - root@k8s-worker1:$ wget -q -0- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add - root@k8s-worker2:$ wget -q -0- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add - #å„ masterä¸node èŠ‚ç‚¹é…ç½®aptæº root@k8s-master1:~$ cat /etc/apt/sources.list # é»˜è®¤æ³¨é‡Šäº†æºç é•œåƒä»¥æé«˜ apt update é€Ÿåº¦ï¼Œå¦‚æœ‰éœ€è¦å¯è‡ªè¡Œå–æ¶ˆæ³¨é‡Š deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse #æ›´æ–°è½¯ä»¶æº root@k8s-node3:~$ apt update #éªŒè¯ ceph ç‰ˆæœ¬ root@k8s-master1:~$ apt-cache madison ceph-common #å„èŠ‚ç‚¹å®‰è£…å’Œå½“å‰ ceph é›†ç¾¤ç›¸åŒç‰ˆæœ¬çš„ ceph-common root@k8s-node3:~$ apt install ceph-common=13.2.10-1bionic","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºceph ç”¨æˆ·ä¸æˆæƒ ceph@ceph-deploy ceph-clusterl$ ceph auth get-or-create client.xinceph-zcc mon 'allow r' osd 'allow * pool=xin-rbd-pool1' client.xinceph-zcc] key=AQB4L79g/he7HBAAvJQ7sl3zdSsTUL21Nx6zLQ== #éªŒè¯ç”¨æˆ· [ceph@ceph-deploy ceph-cluster]$ ceph auth get client.xinceph-zcc exported keyring for client.xinceph-zcc [clientmagedu-shijie] key= AQB4L79g/he7HBAAvJQ7sl3zdSsTUL21Nx6zLQ== caps mon =\"allow r\" caps osd =\"allow* pool=xin-rbd-pool1\" #å¯¼å‡ºç”¨æˆ·ä¿¡æ¯è‡³keyringæ–‡ä»¶ ceph@ceph-deploy ceph-cluster]$ceph auth get client.xinceph-zcc -o client.xinceph-zcc.keyring exported keyring for client.xinceph-zcc #åŒæ­¥è®¤è¯æ–‡ä»¶åˆ° k8så„master åŠnodeèŠ‚ç‚¹ ceph@ceph-deploy ceph-cluster]$ scp ceph.conf ceph.client.xinceph-zcc.keyring root@10.1.0.30:/etc/ceph ceph@ceph-deploy ceph-cluster]$ scp ceph.conf ceph.client.xinceph-zcc.keyring root@10.1.0.31:/etc/ceph ceph@ceph-deploy ceph-cluster]$ scp ceph.conf ceph.client.xinceph-zcc.keyring root@10.1.0.32:/etc/ceph ceph@ceph-deploy ceph-cluster]$ scp ceph.conf ceph.client.xinceph-zcc.keyring root@10.1.0.33:/etc/ceph #æ·»åŠ hosts 172.31.6.101 ceph-node1.jie.local ceph-node1 172.31.6.102 ceph-node2.jie.ocal ceph-node2 172.31.6.103 ceph-node3.jie.ocal ceph-node3 172.31.6.104 ceph-mon1.jie.local ceph-mon1 172.31.6.105 ceph-mon2.jie.local ceph-mon2 172.31.6.106 ceph-mon3.jie.local ceph-mon3 172.31.6.107 ceph-mgr1.jie.local ceph-mgr1 172.31.6.108 ceph-mgr2.jie.local ceph-mgr2 172.31.6.109 ceph-deploy.jie.local ceph-deploy #åœ¨k8snodeèŠ‚ç‚¹éªŒè¯ç”¨æˆ·æƒé™ root@k8s-node1:~$ ceph --user xinceph-zcc -s ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:5:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"é€šè¿‡ keyring æ–‡ä»¶æŒ‚è½½ rbd åŸºäº ceph æä¾›çš„rbd å®ç°å­˜å‚¨å·çš„åŠ¨æ€æä¾›ï¼Œç”±ä¸¤ç§å®ç°æ–¹å¼ï¼Œä¸€æ˜¯é€šè¿‡å®¿ä¸»æœºçš„ keyringæ–‡ä»¶æŒ‚è½½rbdï¼Œå¦å¤–ä¸€ä¸ªæ˜¯é€šè¿‡å°† keyring ä¸­key å®šä¹‰ä¸º k8sä¸­çš„ secret,ç„¶å pod é€šè¿‡secret æŒ‚è½½ rbdã€‚ ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:6:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"é€šè¿‡ keyring æ–‡ä»¶ç›´æ¥æŒ‚è½½-busybox #podyamlæ–‡ä»¶ root@k8s-master1:/opt/ceph-case# cat case1-busybox-keyring.yaml apiVersion: v1 kind: Pod metadata: name: busybox namespace: default spec: containers: - image: busybox command: - sleep - \"3600\" imagePullPolicy: Always name: busybox #restartPolicy: Always volumeMounts: - name: rbd-data1 mountPath: /data volumes: - name: rbd-data1 rbd: monitors: - '172.31.6.101:6789' - '172.31.6.102:6789' - '172.31.6.103:6789' pool: xin-rbd-pool1 image: xin-img-img1 fsType: ext4 readOnly: false user: xinceph-zcc keyring: /etc/ceph/ceph.client.xinceph-zcc.keyring #åˆ›å»º pod root@k8s-master1:/opt/ceph-case# kubectl apply -f case1-busybox-keyring.yamlpod/busybox created pod/busybox created #åˆ°podéªŒè¯rbdæ˜¯å¦æŒ‚è½½æˆåŠŸ ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:6:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"é€šè¿‡secret æŒ‚è½½rbd å°†keyå®šä¹‰ä¸ºsecret ï¼Œç„¶ååœ¨æŒ‚è½½è‡³podï¼Œæ¯ä¸ªk8s node å°±ä¸ç”¨ä¿å­˜keyringæ–‡ä»¶äº†ã€‚ ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:7:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºsecret é¦–å…ˆåˆ›å»ºsecret ï¼Œsecretä¸­ä¸»è¦å°±æ˜¯åŒ…å«cephä¸­è¢«æˆæƒç”¨æˆ·çš„keyringæ–‡ä»¶ä¸­çš„key,éœ€è¦å°†keyå†…å®¹é€šè¿‡ base64ç¼–ç åå³å¯åˆ›å»ºsecretã€‚ #å°† key è¿›è¡Œç¼–ç  ceph auth print-key client.xinceph-zcc AQB4L79g/he7HBAAvJQ7sl3zdSsTUL21Nx6zLQ== ceph auth print-key client.xinceph-zcc | base64 QVFDbm1HSmg2L0dCTGhBQWtXQlRUTmg2R1RHWGpreXFtdFo5RHc9PQo=apiVersion: v1 kind: Secret metadata: name: ceph-secret-xinceph-zcc type: \"kubernetes.io/rbd\" data: key: QVFDbm1HSmg2L0dCTGhBQWtXQlRUTmg2R1RHWGpreXFtdFo5RHc9PQo= #æŸ¥çœ‹secret root@k8s-master1:~/ceph-case$ kubectl get secrets NAME TYPE DATA AGE ceph-secret-xinceph-zcc kubernetes.io/service-account-token 1 3sapiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 1 selector: matchLabels: #rs or deployment app: ng-deploy-80 template: metadata: labels: app: ng-deploy-80 spec: containers: - name: ng-deploy-80 image: nginx ports: - containerPort: 80 volumeMounts: - name: rbd-data1 mountPath: /data volumes: - name: rbd-data1 rbd: monitors: - '172.31.6.101:6789' - '172.31.6.102:6789' - '172.31.6.103:6789' pool: xin-rbd-pool1 image: xin-img-img1 fsType: ext4 readOnly: false user: xinceph-zcc secretRef: name: ceph-secret-xinceph-zccæŸ¥çœ‹podæŒ‚è½½æƒ…å†µ ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:7:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"ceph æŒä¹…åŒ–å­˜å‚¨ admin secret ç”¨äºk8s master èŠ‚ç‚¹ è¿æ¥åˆ°ceph è‡ªåŠ¨åˆ›å»ºpv ï¼Œå¹¶å…³è”pvcæä¾›ç»™pod ä½¿ç”¨ã€‚uer secret ç”¨äºpodæŒ‚è½½ã€‚ apiVersion: v1 kind: Secret metadata: name: ceph-secret-admin type: \"kubernetes.io/rbd\" data: key: QVFBM2RoZGhNZC9VQUJBQXIyU05wSitoY0sxZEQ1bDJIajVYTWc9PQo= ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:8:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºå­˜å‚¨ç±» apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: ceph-storage-class-xin annotations: storageclass.kubernetes.io/is-default-class: \"true\" #è®¾ç½®ä¸ºé»˜è®¤å­˜å‚¨ç±» provisioner: kubernetes.io/rbd parameters: monitors: 172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789 adminId: admin adminSecretName: ceph-secret-admin adminSecretNamespace: default pool: xin-rbd-pool1 userId: xinceph-zcc userSecretName: ceph-secret-xinceph-zcc","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:8:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"åˆ›å»º secret root@k8s-master1:~/ceph-cease$ kubectl apply -f case3-secret-client-shijie.yaml root@k8s-master1:~/ceph-cease$ kubectl apply -f case4-secret-client-admin.yaml","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:8:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºpvc å…³è” apiVersion: v1 kind: PersistentVolumeClaim metadata: name: mysql-data-pvc spec: accessModes: - ReadWriteOnce storageClassName: ceph-storage-class-xin resources: requests: storage: '5Gi' #æŸ¥çœ‹pvc root@k8s-master1:~/ceph-cease$ kubectl get pvc apiVersion: apps/v1 kind: Deployment metadata: name: mysql spec: selector: matchLabels: app: mysql strategy: type: Recreate template: metadata: labels: app: mysql spec: containers: - image: mysql:5.6.46 name: mysql env: # Use secret in real usage - name: MYSQL_ROOT_PASSWORD value: 123456 ports: - containerPort: 3306 name: mysql volumeMounts: - name: mysql-persistent-storage mountPath: /var/lib/mysql volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: mysql-data-pvc --- kind: Service apiVersion: v1 metadata: labels: app: mysql-service-label name: mysql-service spec: type: NodePort ports: - name: http port: 3306 protocol: TCP targetPort: 3306 nodePort: 43306 selector: app: mysqlæŸ¥çœ‹cephä½¿ç”¨ç©ºé—´ ceph df ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:8:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"cephFs å®ç°å¤šä¸»æœºçš„æŒ‚è½½å…±äº«æ•°æ® ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:9:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"é…ç½®cephfs æ­¥éª¤å¦‚ä¸‹ï¼šhttps://www.yuque.com/ryanxx/ga3673/bz0645hbae3emovp ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:9:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":"åˆ›å»ºnginx podåŒæ—¶æŒ‚è½½cephfs apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 selector: matchLabels: #rs or deployment app: ng-deploy-80 template: metadata: labels: app: ng-deploy-80 spec: containers: - name: ng-deploy-80 image: nginx ports: - containerPort: 80 volumeMounts: - name: xinceph-staticdata-cephfs mountPath: /usr/share/nginx/html/ volumes: - name: xinceph-staticdata-cephfs cephfs: monitors: - '172.31.6.101:6789' - '172.31.6.102:6789' - '172.31.6.103:6789' path: / user: admin secretRef: name: ceph-secret-admin","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-6/:9:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (å…­)","uri":"/posts/kubernetes/primary/kubernetes-6/"},{"categories":["Kubernetes"],"content":" Author: Ryan title: 5.k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» tag: - k8sè¿›é˜¶è®­ç»ƒè¥ category: k8s date: 2022-6-5 12:12:22 lastUpdated: true #sidebar: false breadcrumb: false #contributors: false ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"è‡ªå®šä¹‰é•œåƒ-è¿è¡Œnginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"1. ç³»ç»ŸåŸºç¡€é•œåƒ harbor.ceamg.com/baseimages/centos:7.8.2003","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"2. æ„å»º nginx åŸºç¡€é•œåƒ root@harbor01:/dockerfile/web/pub-images# pwd /dockerfile/web/pub-images root@harbor01:/dockerfile/web/pub-images# tree . â”œâ”€â”€ build-command.sh â”œâ”€â”€ Dockerfile â””â”€â”€ nginx-1.22.1.tar.gz 0 directories, 3 files#!/bin/bash TAG=$1 docker build -t harbor.ceamg.com/pub-images/nginx-base:${TAG} . sleep 1 docker push harbor.ceamg.com/pub-images/nginx-base:${TAG}#Nginx 1.22.1 FROM harbor.ceamg.com/pub-images/nginx-base:1.22.1 ADD nginx.conf /usr/local/nginx/conf/nginx.conf ADD app1.tar.gz /usr/local/nginx/html/webapp/ ADD index.html /usr/local/nginx/html/index.html #é™æ€èµ„æºæŒ‚è½½è·¯å¾„ RUN mkdir -p /usr/local/nginx/html/webapp/static /usr/local/nginx/html/webapp/images \u0026\u0026 useradd nginx -u 2023 -s /sbin/nologin -M EXPOSE 80 443 CMD [\"nginx\"]","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"3. æ„å»º nginx ä¸šåŠ¡é•œåƒ root@harbor01:/dockerfile/web/xin-01/nginx# pwd /dockerfile/web/xin-01/nginx root@harbor01:/dockerfile/web/xin-01/nginx# tree . â”œâ”€â”€ app1.tar.gz â”œâ”€â”€ bulid-command.sh â”œâ”€â”€ Dockerfile â”œâ”€â”€ index.html â””â”€â”€ nginx.conf#!/bin/bash TAG=$1 docker build -t harbor.ceamg.com/xinweb11/nginx-web1:${TAG} . sleep 1 docker push harbor.ceamg.com/xinweb11/nginx-web1:${TAG}xxx in xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxx /usr/local/nginx/html/index.html xx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxuser nginx nginx; worker_processes auto; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; daemon off; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream tomcat_webserver { server magedu-tomcat-app1-service.magedu.svc.magedu.local:80; } server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } location /webapp { root html; index index.html index.htm; } location /myapp { proxy_pass http://tomcat_webserver; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} }#Nginx 1.22.1 FROM harbor.ceamg.com/pub-images/nginx-base:1.22.1 ADD nginx.conf /usr/local/nginx/conf/nginx.conf ADD app1.tar.gz /usr/local/nginx/html/webapp/ ADD index.html /usr/local/nginx/html/index.html #é™æ€èµ„æºæŒ‚è½½è·¯å¾„ RUN mkdir -p /usr/local/nginx/html/webapp/static /usr/local/nginx/html/webapp/images EXPOSE 80 443 CMD [\"nginx\"]æµ‹è¯•nginxä¸šåŠ¡é•œåƒ root@harbor01:/dockerfile/web/xin-01/nginx# docker run -it --rm -p 8888:80 harbor.ceamg.com/xinweb11/nginx-web1:v1.6 curl http://10.1.0.38:8888 curl http://10.1.0.38:8888/webapp/","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"4. ubuntuåŸºç¡€é•œåƒ docker pull ubuntu:20.04 docker tag docker.io/library/ubuntu:20.04 harbor.ceamg.com/baseimages/ubuntu:20.04 docker push harbor.ceamg.com/baseimages/ubuntu:20.04","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"5. æ„å»ºjdk8 root@harbor01:/dockerfile/web/pub-images/jdk# pwd /dockerfile/web/pub-images/jdk root@harbor01:/dockerfile/web/pub-images/jdk# tree . â”œâ”€â”€ build-command.sh â”œâ”€â”€ Dockerfile â”œâ”€â”€ jdk-8u212-linux-x64.tar.gz â”œâ”€â”€ jdk-8u341-linux-x64.tar.gz â””â”€â”€ profile#JDK Base Image FROM harbor.ceamg.com/baseimages/ubuntu:20.04 MAINTAINER Ryan \"ryanxin.com\" ADD jdk-8u341-linux-x64.tar.gz /usr/local/src/ RUN ln -sv /usr/local/src/jdk1.8.0_341 /usr/local/jdk ADD profile /etc/profile ENV JAVA_HOME /usr/local/jdk ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/:$JRE_HOME/lib/ ENV PATH $PATH:$JAVA_HOME/bin#!/bin/bash TAG=$1 docker build -t harbor.ceamg.com/pub-images/jdk8:${TAG} . sleep 3 docker push harbor.ceamg.com/pub-images/jdk8:${TAG}# /etc/profile: system-wide .profile file for the Bourne shell (sh(1)) # and Bourne compatible shells (bash(1), ksh(1), ash(1), ...). if [ \"${PS1-}\" ]; then if [ \"${BASH-}\" ] \u0026\u0026 [ \"$BASH\" != \"/bin/sh\" ]; then # The file bash.bashrc already sets the default PS1. # PS1='\\h:\\w\\$ ' if [ -f /etc/bash.bashrc ]; then . /etc/bash.bashrc fi else if [ \"$(id -u)\" -eq 0 ]; then PS1='# ' else PS1='$ ' fi fi fi if [ -d /etc/profile.d ]; then for i in /etc/profile.d/*.sh; do if [ -r $i ]; then . $i fi done unset i fi export LANG=en_US.UTF-8 export HISTTIMEFORMAT=\"%F %T `whoami` \" export JAVA_HOME=/usr/local/jdk export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATHæµ‹è¯•é•œåƒ root@harbor01:/dockerfile/web/pub-images/jdk# docker run -it --rm harbor.ceamg.com/pub-images/jdk8:3411 root@494e5aeb25af:/# java -v Unrecognized option: -v Error: Could not create the Java Virtual Machine. Error: A fatal exception has occurred. Program will exit. root@494e5aeb25af:/# java -version java version \"1.8.0_341\" Java(TM) SE Runtime Environment (build 1.8.0_341-b10) Java HotSpot(TM) 64-Bit Server VM (build 25.341-b10, mixed mode)","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:5","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"6. æ„å»º Tomcat é•œåƒ root@harbor01:/dockerfile/web/pub-images/tomcat# pwd /dockerfile/web/pub-images/tomcat root@harbor01:/dockerfile/web/pub-images/tomcat# tree . â”œâ”€â”€ apache-tomcat-8.5.43.tar.gz â”œâ”€â”€ build-command.sh â””â”€â”€ Dockerfile#!/bin/bash docker build -t harbor.ceamg.com/pub-images/tomcat-base:v8.5.43 . sleep 3 docker push harbor.ceamg.com/pub-images/tomcat-base:v8.5.43#Tomcat 8.5.43åŸºç¡€é•œåƒ FROM harbor.ceamg.com/pub-images/jdk8:3411 MAINTAINER Ryanxin ryanxin@outlook.com RUN mkdir /apps /data/tomcat/webapps /data/tomcat/logs -pv ADD apache-tomcat-8.5.43.tar.gz /apps RUN useradd nginx -u 2022 \u0026\u0026 ln -sv /apps/apache-tomcat-8.5.43 /apps/tomcat \u0026\u0026 chown -R nginx.nginx /apps /data -R","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:6","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"7. æ„å»ºTomcat ä¸šåŠ¡é•œåƒ root@harbor01:/dockerfile/web/xin-01/tomcat-app1# tree . â”œâ”€â”€ app1.tar â”œâ”€â”€ app1.tar.gz â”œâ”€â”€ build-command.sh â”œâ”€â”€ catalina.sh â”œâ”€â”€ Dockerfile â”œâ”€â”€ run_tomcat.sh â””â”€â”€ server.xml#tomcat web1 FROM harbor.ceamg.com/pub-images/tomcat-base:v8.5.43.1 ADD catalina.sh /apps/tomcat/bin/catalina.sh ADD server.xml /apps/tomcat/conf/server.xml ADD app1.tar /data/tomcat/webapps/myapp/ ADD run_tomcat.sh /apps/tomcat/bin/run_tomcat.sh RUN mkdir /home/nginx -p \\ \u0026\u0026 chmod 755 /home/nginx \\ \u0026\u0026 cp -a /etc/skel/. /home/nginx \\ \u0026\u0026 chown -R nginx.nginx /data/ /apps/ EXPOSE 8080 8443 CMD [\"/apps/tomcat/bin/run_tomcat.sh\"]#!/bin/bash #echo \"nameserver 223.6.6.6\" \u003e /etc/resolv.conf #echo \"192.168.7.248 k8s-vip.example.com\" \u003e\u003e /etc/hosts #/usr/share/filebeat/bin/filebeat -e -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat \u0026 su -c \"/apps/tomcat/bin/catalina.sh start\" nginx tail -f /etc/hostsserver.xml catalina.sh æµ‹è¯•é•œåƒ docker run -it --rm -p 9900:8080 harbor.ceamg.com/xinweb11/tomcat-app1:1.9 ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:7","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Kubernetes"],"content":"åœ¨k8sä¸­è·‘èµ·æ¥ å¯åŠ¨tomcat pod kind: Deployment #apiVersion: extensions/v1beta1 apiVersion: apps/v1 metadata: labels: app: xin-tomcat-app1-deployment-label name: xin-tomcat-app1-deployment namespace: xin-web spec: replicas: 1 selector: matchLabels: app: xin-tomcat-app1-selector template: metadata: labels: app: xin-tomcat-app1-selector spec: containers: - name: xin-tomcat-app1-container image: harbor.ceamg.com/xinweb11/tomcat-app1:1.9 #command: [\"/apps/tomcat/bin/run_tomcat.sh\"] #imagePullPolicy: IfNotPresent imagePullPolicy: Always ports: - containerPort: 8080 protocol: TCP name: http env: - name: \"password\" value: \"123456\" - name: \"age\" value: \"18\" resources: limits: cpu: 1 memory: \"512Mi\" requests: cpu: 500m memory: \"512Mi\" volumeMounts: - name: xin-images mountPath: /usr/local/nginx/html/webapp/images readOnly: false - name: xin-static mountPath: /usr/local/nginx/html/webapp/static readOnly: false volumes: - name: xin-images nfs: server: 10.1.0.38 path: /data/k8s/web1/images - name: xin-static nfs: server: 10.1.0.38 path: /data/k8s/web1/static # nodeSelector: # project: xin # app: tomcat --- kind: Service apiVersion: v1 metadata: labels: app: xin-tomcat-app1-service-label name: xin-tomcat-app1-service namespace: xin-web spec: type: NodePort ports: - name: http port: 80 protocol: TCP targetPort: 8080 nodePort: 40003 selector: app: xin-tomcat-app1-selectoræ£€æµ‹åç«¯Tomcat SVC è¿é€šæ€§ ping xin-tomcat-app1-service.xin-web.svc.ceamg.local å¯åŠ¨nginx pod kind: Deployment apiVersion: apps/v1 metadata: labels: app: web1-nginx-deployment-label name: web1-nginx-deployment namespace: xin-web spec: replicas: 1 selector: matchLabels: app: web1-nginx-selector template: metadata: labels: app: web1-nginx-selector spec: containers: - name: web1-nginx-container image: harbor.ceamg.com/xinweb11/nginx-web1:v1.0 #command: [\"/apps/tomcat/bin/run_tomcat.sh\"] #imagePullPolicy: IfNotPresent imagePullPolicy: Always ports: - containerPort: 80 protocol: TCP name: http - containerPort: 443 protocol: TCP name: https env: - name: \"password\" value: \"123456\" - name: \"age\" value: \"20\" resources: limits: cpu: 2 memory: 2Gi requests: cpu: 500m memory: 1Gi volumeMounts: - name: xin-images mountPath: /usr/local/nginx/html/webapp/images readOnly: false - name: xin-static mountPath: /usr/local/nginx/html/webapp/static readOnly: false volumes: - name: xin-images nfs: server: 10.1.0.38 path: /data/k8s/web1/images - name: xin-static nfs: server: 10.1.0.38 path: /data/k8s/web1/static #nodeSelector: # group: magedu --- kind: Service apiVersion: v1 metadata: labels: app: web1-nginx-service-label name: web1-nginx-service namespace: xin-web spec: type: NodePort ports: - name: http port: 80 protocol: TCP targetPort: 80 nodePort: 40002 - name: https port: 443 protocol: TCP targetPort: 443 nodePort: 40443 selector: app: web1-nginx-selectornginx é…ç½®æ–‡ä»¶å¯ç”¨location å’Œ upstream åç«¯ä¸»æœº upstream tomcat_webserver { server xin-tomcat-app1-service.xin-web.svc.ceamg.local:80; } server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } location /webapp { root html; index index.html index.htm; } location /myapp { proxy_pass http://tomcat_webserver; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; } ","date":"2023-01-16","objectID":"/posts/kubernetes/primary/kubernetes-5/:1:8","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"k8så®æˆ˜æ¡ˆä¾‹-nginxä¸tomcatå®ç°åŠ¨é™åˆ†ç¦» (äº”)","uri":"/posts/kubernetes/primary/kubernetes-5/"},{"categories":["Ceph"],"content":"Cephä¸­ç‹¬ç«‹çš„æœåŠ¡å¦‚æœä¸ç”¨å¯ä»¥ä¸å¯ç”¨ã€‚ ç±»ä¼¼é˜¿é‡Œäº‘OSSå¯¹è±¡å­˜å‚¨ã€‚éµå¾ªäºšé©¬é€ŠS3æ ‡å‡†æ•°æ®å­˜åœ¨bucketä¸­ å®˜æ–¹æ–‡æ¡£ï¼šhttp:/docs.ceph.org.cn/radosgw/æ•°æ®ä¸éœ€è¦æ”¾ç½®åœ¨ç›®å½•å±‚æ¬¡ç»“æ„ä¸­ï¼Œè€Œæ˜¯å­˜åœ¨äºå¹³é¢åœ°å€ç©ºé—´å†…çš„åŒä¸€çº§åˆ«ï¼Œåº”ç”¨é€šè¿‡å”¯ä¸€åœ°å€æ¥è¯†åˆ«æ¯ä¸ªå•ç‹¬æ•°æ®å¯¹è±¡ã€‚è®¿é—®çš„æ—¶å€™ä¼ é€’çš„URLæ˜¯å›ºå®šçš„ã€‚æ¯ä¸ªå¯¹è±¡å¯åŒ…å«æœ‰åŠ©äºæ£€ç´¢çš„å…ƒæ•°æ®é€šè¿‡RESTful APIåœ¨åº”ç”¨çº§åˆ«(è€Œéç”¨æˆ·çº§åˆ«)è¿›è¡Œè®¿é—® ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:0:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.1 RadosGWå¯¹è±¡å­˜å‚¨ç®€ä»‹ RadosGWæ˜¯å¯¹è±¡å­˜å‚¨(OSS,Object Storage Service)çš„ä¸€ç§å®ç°æ–¹å¼ï¼Œ** RADOSç½‘å…³ä¹Ÿç§°ä¸ºCephå¯¹è±¡ç½‘å…³ã€RadosGWã€RGW,æ˜¯-ç§æœåŠ¡ï¼Œ ä½¿å®¢æˆ·ç«¯èƒ½å¤Ÿåˆ©ç”¨æ ‡å‡†å¯¹è±¡å­˜å‚¨APIæ¥è®¿é—®Cephé›†ç¾¤ï¼Œå®ƒæ”¯æŒAWSS3å’ŒSwiftAPI**ï¼Œåœ¨ceph0.8ç‰ˆæœ¬ä¹‹åä½¿ç”¨Civetweb(https://github.com/civetweb/civetweb))çš„webæœåŠ¡å™¨æ¥å“åº”apiè¯·æ±‚ï¼Œå®¢æˆ·ç«¯ä½¿ç”¨http/httpsåè®®é€šè¿‡RESTful APIä¸RGWé€šä¿¡é»˜è®¤ç«¯å£7480ï¼Œè€ŒRGWåˆ™é€šè¿‡libradosä¸cephé›†ç¾¤é€šä¿¡ï¼ŒRGWå®¢æˆ·ç«¯é€šè¿‡s3æˆ–è€…swift apiä½¿ç”¨RGWç”¨æˆ·è¿›è¡Œèº«ä»½éªŒè¯ï¼Œç„¶åRGWç½‘å…³ä»£è¡¨ç”¨æˆ·åˆ©ç”¨cephxä¸cephå­˜å‚¨è¿›è¡Œèº«ä»½éªŒè¯.S3ç”±Amazonäº2006å¹´æ¨å‡ºï¼Œå…¨ç§°ä¸ºSimple Storage Service,S3å®šä¹‰äº†å¯¹è±¡å­˜å‚¨ï¼Œæ˜¯å¯¹è±¡å­˜å‚¨äº‹å®ä¸Šçš„æ ‡å‡†ï¼Œä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼ŒS3 å°±æ˜¯å¯¹è±¡å­˜å‚¨ï¼Œå¯¹è±¡å­˜å‚¨å°±æ˜¯S3,å®ƒæ˜¯å¯¹è±¡å­˜å‚¨å¸‚åœºçš„éœ¸ä¸»ï¼Œåç»­çš„å¯¹è±¡å­˜å‚¨éƒ½æ˜¯å¯¹S3çš„æ¨¡ä»¿ã€‚ ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:0:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.2 å¯¹è±¡å­˜å‚¨ç‰¹ç‚¹ é€šè¿‡å¯¹è±¡å­˜å‚¨å°†æ•°æ®å­˜å‚¨ä¸ºå¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡é™¤äº†åŒ…å«æ•°æ®ï¼Œè¿˜åŒ…å«æ•°æ®è‡ªèº«çš„å…ƒæ•°æ®ã€‚ å¯¹è±¡é€šè¿‡Object IDæ¥æ£€ç´¢ï¼Œæ— æ³•é€šè¿‡æ™®é€šæ–‡ä»¶ç³»ç»Ÿçš„æ–¹å¼é€šè¿‡æ–‡ä»¶è·¯å¾„åŠæ–‡ä»¶åç§°æ“ä½œæ¥ç›´æ¥è®¿é—®å¯¹è±¡ï¼Œåªèƒ½é€šè¿‡APIæ¥è®¿é—®ï¼Œæˆ–è€…ç¬¬ä¸‰æ–¹å®¢æˆ·ç«¯(å®é™…ä¸Šä¹Ÿæ˜¯å¯¹APIçš„å°è£…)ã€‚ å¯¹è±¡å­˜å‚¨ä¸­çš„å¯¹è±¡ä¸æ•´ç†åˆ°ç›®å½•æ ‘ä¸­ï¼Œè€Œæ˜¯å­˜å‚¨åœ¨æ‰å¹³çš„å‘½åç©ºé—´ä¸­ï¼ŒAmazon S3å°†è¿™ä¸ªæ‰å¹³å‘½åç©ºé—´ç§°ä¸ºbucket,è€Œswiftåˆ™å°†å…¶ç§°ä¸ºå®¹å™¨ã€‚æ— è®ºæ˜¯bucketè¿˜æ˜¯å®¹å™¨ï¼Œéƒ½ä¸èƒ½åµŒå¥—ã€‚ bucketéœ€è¦è¢«æˆæƒæ‰èƒ½è®¿é—®åˆ°ï¼Œä¸€ä¸ªå¸æˆ·å¯ä»¥å¯¹å¤šä¸ªbucketæˆæƒï¼Œè€Œæƒé™å¯ä»¥ä¸åŒã€‚æ–¹ä¾¿æ¨ªå‘æ‰©å±•ã€å¿«é€Ÿæ£€ç´¢æ•°æ®ã€‚ ä¸æ”¯æŒå®¢æˆ·ç«¯æŒ‚è½½ï¼Œä¸”éœ€è¦å®¢æˆ·ç«¯åœ¨è®¿é—®çš„æ—¶å€™æŒ‡å®šæ–‡ä»¶åç§°ã€‚ä¸æ˜¯å¾ˆé€‚ç”¨äºæ–‡ä»¶è¿‡äºé¢‘ç¹ä¿®æ”¹åŠåˆ é™¤çš„åœºæ™¯ã€‚ cephä½¿ç”¨bucketä½œä¸ºå­˜å‚¨æ¡¶(å­˜å‚¨ç©ºé—´)ï¼Œå®ç°å¯¹è±¡æ•°æ®çš„å­˜å‚¨å’Œå¤šç”¨æˆ·éš”ç¦»ï¼Œæ•°æ®å­˜å‚¨åœ¨bucketä¸­ï¼Œç”¨æˆ·çš„æƒé™ä¹Ÿæ˜¯é’ˆå¯¹bucketè¿›è¡Œæˆæƒï¼Œå¯ä»¥è®¾ç½®ç”¨æˆ·å¯¹ä¸åŒçš„bucketæ‹¥æœ‰ä¸åŒçš„æƒé™ï¼Œä»¥å®ç°æƒé™ç®¡ç†ã€‚ åŸºäºbucketå¯¹é¡¹ç›®éš”ç¦» å¯¹è±¡å­˜å‚¨è¿ç»´éœ€è¦åšçš„äº‹æƒ…ï¼šå¯ç”¨RGWåšå¥½RGWçš„é«˜å¯ç”¨åˆ›å»ºbucketåˆ›å»ºç”¨æˆ·å¹¶æˆæƒåšå¥½ç›‘æ§ ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.2.1 bucket ç‰¹æ€§ å­˜å‚¨ç©ºé—´æ˜¯ç”¨äºå­˜å‚¨å¯¹è±¡(Object) çš„å®¹å™¨ï¼Œæ‰€æœ‰çš„å¯¹è±¡éƒ½å¿…é¡»éš¶å±äºæŸä¸ªå­˜å‚¨ç©ºé—´ï¼Œå¯ä»¥è®¾ç½®å’Œä¿®æ”¹å­˜å‚¨ç©ºé—´å±æ€§ç”¨æ¥æ§åˆ¶åœ°åŸŸã€è®¿é—®æƒé™ã€ç”Ÿå‘½å‘¨æœŸç­‰ï¼Œè¿™äº›å±æ€§è®¾ç½®ç›´æ¥ä½œç”¨äºè¯¥å­˜å‚¨ç©ºé—´å†…æ‰€æœ‰å¯¹è±¡ï¼Œå› æ­¤å¯ä»¥é€šè¿‡çµæ´»åˆ›å»ºä¸åŒçš„å­˜å‚¨ç©ºé—´æ¥å®Œæˆä¸åŒçš„ç®¡ç†åŠŸèƒ½ã€‚ åŒä¸€ä¸ªå­˜å‚¨ç©ºé—´çš„å†…éƒ¨æ˜¯æ‰å¹³çš„ï¼Œæ²¡æœ‰æ–‡ä»¶ç³»ç»Ÿçš„ç›®å½•ç­‰æ¦‚å¿µï¼Œæ‰€æœ‰çš„å¯¹è±¡éƒ½ç›´æ¥éš¶å±äºå…¶å¯¹åº”çš„å­˜å‚¨ç©ºé—´ã€‚ æ¯ä¸ªç”¨æˆ·å¯ä»¥æ‹¥æœ‰å¤šä¸ªå­˜å‚¨ç©ºé—´ å­˜å‚¨ç©ºé—´çš„åç§°åœ¨OSSèŒƒå›´å†…å¿…é¡»æ˜¯å…¨å±€å”¯ä¸€çš„ï¼Œä¸€æ—¦åˆ›å»ºä¹‹åæ— æ³•ä¿®æ”¹åç§°ã€‚ å­˜å‚¨ç©ºé—´å†…éƒ¨çš„å¯¹è±¡æ•°ç›®æ²¡æœ‰é™åˆ¶ã€‚ ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:1:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.2.2 bucketå‘½åè§„èŒƒ https://docs.amazonaws.cn/AmazonS3/latest/userguide/bucketnamingrules.html åªèƒ½åŒ…æ‹¬å°å†™å­—æ¯ã€æ•°å­—å’ŒçŸ­æ¨ªçº¿(-) å¿…é¡»ä»¥å°å†™å­—æ¯æˆ–è€…æ•°å­—å¼€å¤´å’Œç»“å°¾. é•¿åº¦å¿…é¡»åœ¨3-63å­—èŠ‚ä¹‹é—´ã€‚ å­˜å‚¨æ¡¶åç§°ä¸èƒ½ä½¿ç”¨ç”¨IPåœ°å€æ ¼å¼. Bucketåç§°å¿…é¡»å…¨å±€å”¯ä¸€ ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:1:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.3 å¯¹è±¡å­˜å‚¨è®¿é—®å¯¹æ¯” ç›®å‰ä¸»æµæœ‰ä¸‰ç§è®¿é—®æ ‡å‡†ï¼š AmEizon S3:æä¾›äº†userã€bucket å’Œobjectåˆ†åˆ«è¡¨ç¤ºç”¨æˆ·ã€å­˜å‚¨æ¡¶å’Œå¯¹è±¡ï¼Œå…¶ä¸­bucketéš¶å±äºuser,å¯ä»¥é’ˆå¯¹userè®¾ç½®ä¸åŒbucketçš„åç§°ç©ºé—´çš„è®¿é—®æƒé™ï¼Œè€Œä¸”ä¸åŒç”¨æˆ·å…è®¸è®¿é—®ç›¸åŒçš„bucketã€‚ï¼ˆä½¿ç”¨æœ€å¤š-æœ€å¹¿æ³›ï¼‰ OpenStack Swift:æä¾›äº†userã€ container å’Œobjectåˆ†åˆ«å¯¹åº”äºç”¨æˆ·ã€å­˜å‚¨æ¡¶å’Œå¯¹è±¡ï¼Œä¸è¿‡å®ƒè¿˜é¢å¤–ä¸ºuseræä¾›äº†çˆ¶çº§ç»„ä»¶account, accountç”¨äºè¡¨ç¤ºä¸€ä¸ªé¡¹ç›®æˆ–ç§Ÿæˆ·(OpenStackç”¨æˆ·)ï¼Œå› æ­¤ä¸€ä¸ªaccountä¸­å¯åŒ…å«ä¸€åˆ°å¤šä¸ªuser,å®ƒä»¬å¯å…±äº«ä½¿ç”¨åŒä¸€ç»„ container, å¹¶ä¸ºcontaineræä¾›åç§°ç©ºé—´ã€‚ RadosGW: æä¾›äº†userã€ subuserã€bucket å’Œobject,å…¶ä¸­çš„userå¯¹åº”äºS3çš„user,è€Œsubuseråˆ™å¯¹åº”äºSwiftçš„user,ä¸è¿‡userå’Œsubuseréƒ½ä¸æ”¯æŒä¸ºbucketæä¾›åç§°ç©ºé—´ï¼Œå› æ­¤ï¼Œä¸åŒç”¨æˆ·çš„å­˜å‚¨æ¡¶ä¹Ÿä¸å…è®¸åŒå;ä¸è¿‡ï¼Œè‡ªJewelç‰ˆæœ¬èµ·ï¼ŒRadosGWå¼•å…¥äº†tenant(ç§Ÿæˆ·)ç”¨äºä¸ºuserå’Œbucketæä¾›åç§°ç©ºé—´ï¼Œä½†å®ƒæ˜¯ä¸ªå¯é€‰ç»„ä»¶ï¼ŒRadosGW åŸºäºACLä¸ºä¸åŒçš„ç”¨æˆ·è®¾ç½®ä¸åŒçš„æƒé™æ§åˆ¶ï¼Œå¦‚:Readè¯»æƒé™Writeå†™æƒé™Readwriteè¯»å†™æƒé™full-controlå…¨éƒ¨æ§åˆ¶æƒé™ ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:1:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.4 éƒ¨ç½²RadosGWæœåŠ¡ å°†ceph-mgr1ã€ceph-mgr2 æœåŠ¡å™¨éƒ¨ç½²ä¸ºé«˜å¯ç”¨çš„radosGWæœåŠ¡ ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.4.1 å®‰è£…radosgwæœåŠ¡å¹¶åˆå§‹åŒ– Ubuntu #apt install radosgwCentOS [root@ceph-mgr1 ~]# yum install ceph-radosgw [root@ceph-mgr2 ~]# yum install ceph-radosgw #åœ¨ceph deployæœåŠ¡å™¨å°†ceph-mgr1åˆå§‹åŒ–ä¸ºradosGWæœåŠ¡: [ceph@ceph-deploy ~]$ cd ceph-cluster/ [ceph@ceph-deploy ceph-cluster]$ ceph-deploy rgw create ceph-mgr2 [ceph@ceph-deploy ceph-cluster]$ ceph-deploy rgw create ceph-mgr1","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:2:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.4.2 éªŒè¯radosgwæœåŠ¡çŠ¶æ€ ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:2:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.4.3 éªŒè¯radosgwæœåŠ¡è¿›ç¨‹ ps -ef | grep radosgw","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:2:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.4.4 radosgwçš„å­˜å‚¨æ± ç±»å‹ å¯åŠ¨radosgw æœåŠ¡è‡ªåŠ¨åˆ›å»ºdefault zoneåŒºåŸŸå­˜å‚¨æ± ï¼Œè¿™äº›å­˜å‚¨æ± çš„åŠŸèƒ½æ˜¯ä¸ä¸€æ ·çš„ root@ceph-deploy:~# ceph osd pool ls device_health_metrics cephfs-metadata cephfs-data .rgw.root default.rgw.log default.rgw.control default.rgw.meta default.rgw.buckets.index default.rgw.buckets.data root@ceph-deploy:~# ceph osd pool get default.rgw.buckets.data crush_rule crush_rule: replicated_rule #é»˜è®¤æ˜¯å‰¯æœ¬æ±  root@ceph-deploy:~# ceph osd pool get default.rgw.buckets.data size size: 3 #é»˜è®¤çš„å‰¯æœ¬æ•° root@ceph-deploy:~# ceph osd pool get default.rgw.buckets.data pgp_num pgp_num: 32 #é»˜è®¤çš„pgpæ•°é‡ root@ceph-deploy:~# ceph osd pool get default.rgw.buckets.data pg_num pg_num: 32 #é»˜è®¤çš„pgæ•°é‡","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:2:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.4.5 RGWå­˜å‚¨æ± åŠŸèƒ½ root@ceph-deploy:~ # ceph osd lspools 1 device_health_metrics 3 cephfs-metadata 4 cephfs-data 9.rgw.root 10 default.rgw.log 11 default.rgw.control 12 default.rgw.meta 13 default.rgw.buckets.index 14 default.rgw.buckets.data 15 default.rgw.buckets.non-ec.rgw.root: åŒ…å« realm(é¢†åŸŸä¿¡æ¯)ï¼Œæ¯”å¦‚zoneå’Œzonegroupã€‚ï¼ˆç”¨äºä¸åŒåŒºåŸŸå¤šæœºæˆ¿ä¹‹é—´ï¼‰default.rgw.log: å­˜å‚¨æ—¥å¿—ä¿¡æ¯ï¼Œç”¨äºè®°å½•å„ç§logä¿¡æ¯ã€‚default.rgw.control: ç³»ç»Ÿæ§åˆ¶æ± ï¼Œåœ¨æœ‰æ•°æ®æ›´æ–°æ—¶ï¼Œé€šçŸ¥å…¶å®ƒRGWæ›´æ–°ç¼“å­˜ã€‚default.rgw.meta: å…ƒæ•°æ®å­˜å‚¨æ± ï¼Œé€šè¿‡ä¸åŒçš„åç§°ç©ºé—´åˆ†åˆ«å­˜å‚¨ä¸åŒçš„radoså¯¹è±¡ï¼Œè¿™äº›åç§°ç©ºé—´åŒ…æ‹¬ç”¨æˆ·UIDåŠå…¶bucketæ˜ å°„ä¿¡æ¯çš„åç§°ç©ºé—´users.uidã€ç”¨æˆ·çš„å¯†é’¥åç§°ç©ºé—´users.keysã€ç”¨æˆ¶çš„emailåç§°ç©ºé—´users.emailã€ç”¨æˆ·çš„subuserçš„åç§°ç©ºé—´users. swiftã€ä»¥åŠbucketçš„åç§°ç©ºé—´rootç­‰ã€‚default.rgw.buckets.index: å­˜æ”¾ bucketåˆ°objectçš„ç´¢å¼•ä¿¡æ¯ã€‚default.rgw.buckets.data: å­˜æ”¾å¯¹è±¡çš„æ•°æ® ã€‚default.rgw. buckets.non-ec ï¼šæ•°æ®çš„é¢å¤–ä¿¡æ¯å­˜å‚¨æ± ã€‚ ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:2:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.4.6 éªŒè¯RGW zoneä¿¡æ¯ root@ceph-deploy:~# radosgw-admin zone get --rgw-zone=default","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:2:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.5 radosgwæœåŠ¡é«˜å¯ç”¨é…ç½® ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.5.1 radosgw httpé«˜å¯ç”¨ 8.5.1.1 è‡ªå®šä¹‰httpç«¯å£ é…ç½®æ–‡ä»¶å¯ä»¥åœ¨ceph deployæœåŠ¡å™¨ä¿®æ”¹ç„¶åç»Ÿä¸€æ¨é€ï¼Œæˆ–è€…å•ç‹¬ä¿®æ”¹æ¯ä¸ªradosgwæœåŠ¡å™¨çš„é…ç½®ä¸ºç»Ÿä¸€é…ç½®ï¼Œç„¶åé‡å¯RGWæœåŠ¡ã€‚ https://docs. ceph.com/en/latest/radosaw/frontends/[é“¾æ¥](https://docs. ceph.com/en/latest/radosaw/frontends/) [root@ceph-mgr2 ~]# vim /etc/ceph/ceph.conf [client.rgw.ceph-mgr2] #åœ¨æœ€åé¢æ·»åŠ é’ˆå¯¹å½“å‰èŠ‚ç‚¹çš„è‡ªå®šä¹‰é…ç½®å¦‚ä¸‹: rgw_host=ceph-mgr2 rrgw_frontends=civetweb port=9900 #é‡å¯æœåŠ¡ [root@ceph-mgr2 ~]# systemctl restart ceph-radosgw@rgw.ceph-mgr2.service 8.5.1.3 æµ‹è¯•httpåå‘ä»£ç† ä½¿ç”¨haproxyä»£ç† rgwä¸¤ä¸ªèŠ‚ç‚¹ yum install haproxy vim /etc/haproxy/haproxy.cfg listen ceph-rgw bind 172.31.6.201:80 mode tcp server rgw1 172.31.6.104:7480 check inter 3s fall 3 rise 5 server rgw2 172.31.6.105:7480 check inter 3s fall 3 rise 5 systemctl restart haproxy.service ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:3:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.5.2 radosgw https åœ¨rgwèŠ‚ç‚¹ç”Ÿæˆç­¾åè¯ä¹¦å¹¶é…ç½®radosgwå¯ç”¨SSLæ–¹å¼ä¸€ï¼š åœ¨åå‘ä»£ç†é…ç½®SSLè¯ä¹¦æ–¹å¼äºŒï¼š å†…ç½®è‡ªç­¾è¯ä¹¦ï¼ˆæµè§ˆå™¨æå‡ä¸å®‰å…¨è¯ä¹¦ï¼‰ 8.5.2.1 è‡ªç­¾åè¯ä¹¦ [root@ceph-mgr2 ~]# cd /etc/ceph/ [root@ceph-mgr2 ceph]# mkdir certs [root@ceph-mgr2 ceph]# cd certs/ #ç”Ÿæˆkey root@ceph-mgr2 certs]# openssl genrsa -out civetweb.key 2048 #è‡ªç­¾å‘ [root@ceph-mgr2 certs]# openssl req -new -x509 -key civetweb.key -out civetweb.crt -subj \"/CN=rgw.magedu.net\" #å°†keyå’Œç§é’¥æ”¾ä¸€å— [root@ceph-mgr2 certs]# cat civetweb.key civetweb.crt \u003e civetweb.pem [root@ceph-mgr2 certs]# tree8.5.2.2 SSLé…ç½® [root@ceph-mgr2 certs]# vim /etc/ceph/ceph.conf [client.rgw.ceph-mgr2] rgw_host = ceph-mgr2 rgw_frontends = \"civetweb port-9900+9443s ssl_certificate=/etc/ceph/certs/civetweb.pem\" root@ceph-mgr2 certs]# systemctl restart ceph-radosgw@rgw.ceph-mgr2.service8.5.2.3 éªŒè¯httpsç«¯å£ ss -tnl","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:3:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.5.3 radosgw httpsé«˜å¯ç”¨ é€šè¿‡è´Ÿè½½å‡è¡¡å¯¹radosgwè¿›è¡Œåå‘ä»£ç†ï¼Œå®ç°é«˜å¯ç”¨ 8.5.3.1 åŸŸåè§£æè‡³VIP å…ˆå°†åŸŸåè§£æè‡³è´Ÿè£å‡è¡¡çš„IP172.31.6.201 rgw.magedu.net 8.5.3.2 è´Ÿè½½å‡è¡¡é…ç½® è´Ÿè½½å‡è¡¡é…ç½®ç›‘å¬åŠrealserver ,æŠŠSSLè¯ä¹¦æ”¾åœ¨äº†rgwèŠ‚ç‚¹ä¸Šé¢ï¼ˆä¹Ÿæ”¾åœ¨è´Ÿè½½å‡è¡¡ä¸Šé¢ï¼‰ #ceph http access listen ceph-rgw bind 172.31.6.201:80 mode tcp server 172.31.6.104 172.31.6.104:9900 check inter 3s fall 3 rise 5 server 172.31.6.105 172.31.6.105:9900 check inter 3s fall 3 rise 5 #ceph https access listen ceph-rgw bind 172.31.6.201:443 mode tcp server 172.31.6.104 172.31 .6.104:9443 check inter 3s fall 3 rise 5 server 172.31.6.105 172.31 .6.105:9443 check inter 3s fall 3 rise 58.5.3.3 é‡å¯è´Ÿè½½å‡è¡¡ [root@ceph-client1-centos7 ~]# systemctl restart haproxy8.5.3.4 æµ‹è¯•è®¿é—® ","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:3:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.5.4 æ—¥å¿—åŠå…¶å®ƒä¼˜åŒ–é…ç½® #åˆ›å»ºæ—¥å¿—ç›®å½•: [root@ceph-mgr2 certs]# mkdir /var/log/radosgw [root@ceph-mgr2 certs]# chown ceph.ceph /var/log/radosgw #å½“å‰é…ç½® [root@ceph-mgr2 ceph]# vim ceph.conf [client.rgw.ceph-mgr2] rgw_host = ceph-mgr2 rgw_frontends = \"civetweb port=9900+8443s ssl_certificate=/etc/ceph/certs/civetweb.pem error_log_file=/var/log/radosgw/civetweb.error.log access_log_file=/var/log/radosgw/civetweb.access.log request_timeout_ms=30000 num_threads=200\" #è¯·æ±‚è¶…è¿‡30s æŠ¥è¶…æ—¶ #100çº¿ç¨‹ æ¯ä¸ªæ˜¾ç¤ºå¤„ç†ä¸€ä¸ªè¯·æ±‚ï¼ˆ2000ï¼‰ #https://docs.ceph.com/en/mimic/radosgw/config-ref/ num_threadsé»˜è®¤å€¼ç­‰äº rgw_thread_pool_size=100 #é‡å¯æœåŠ¡ [root@ceph-mgr2 certs]# systemctl restart ceph-radosgw@rgw.ceph-mgr2.service #è®¿é—®æµ‹è¯•: [root@ceph-mgr2 certs]# curl -k https://172.31.6.108:8443 #éªŒè¯æ—¥å¿— tail /var/log/radosgw/civetweb/access.log","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:3:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.6 æµ‹è¯•æ•°æ®è¯»å†™ 8.6.1 RGW Serveré…ç½®: åœ¨å®é™…çš„ç”Ÿäº§ç¯å¢ƒï¼ŒRGW1å’ŒRGWçš„é…ç½®å‚æ•°æ˜¯å®Œå…¨ä¸€æ ·çš„. jack@ceph-mgr2:-$ sudo cat /etc/ceph/ceph.conf [global] fsid = 1883278f-95fe-4f85-b027-3a6eba444861 public_network = 172.31.0.0/21 cluster_network = 192.168.0.0/21 mon_initial members = ceph-mon1 mon_host= 172.31.6.101 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx [client.rgw.ceph-mgr1] rgw_host = ceph-mgr1 rgw_frontends = civetweb port:=9900 rgw_dns_name = rgw.magedu.net [client.rgw.ceph-mgr2] rgw_host = ceph-mgr2 rgw_frontends = civetweb port:=9900 rgw_dns_name = rgw.magedu.net","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.6.2 åˆ›å»ºRGW è´¦å· ceph@ceph-deploy:/home/ceph/ceph cluster$ rdosgw admin user create --uid=\"user1\" --display-name=\"user1\" #åˆ›å»ºç”¨æˆ·ä¼šç”Ÿæˆkey æ˜¯è®¿é—®SGWå­˜å‚¨çš„å‡­è¯ \"keys\": [ { \"user\" : \"\"use1\"\", \"access_key\": \"T119RIWTRMMI9BBJEC66\"ï¼Œ \"secret_key\": \"r8kwaYi9hdZJyCKW23hucEUABli 5xOAXSGs8worB\" } ],","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:4:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.6.3 å®‰è£…s3cmdå®¢æˆ·ç«¯ s3cmd æ˜¯ä¸€ä¸ªé€šè¿‡å‘½ä»¤è¡Œè®¿é—®ceph RGWå®ç°åˆ›å»ºå­˜å‚¨åŒæ¡¶ã€ä¸Šä¼ ã€ä¸‹è½½ä»¥åŠç®¡ç†æ•°æ®åˆ°å¯¹è±¡å­˜å‚¨çš„å‘½ä»¤è¡Œå®¢æˆ·ç«¯å·¥å…·ã€‚ ceph@ceph-deploy:/home/ceph/ceph-cluster$ sudo apt-cache madison s3cmd ceph@ceph-deploy:/home/ceph/ceph-cluster$ sudo apt install s3cmd","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:4:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.6.4 é…ç½®å®¢æˆ·ç«¯æ‰§è¡Œç¯å¢ƒ 8.6.4.1 s3cmdå®¢æˆ·ç«¯æ·»åŠ åŸŸåè§£æ vim /etc/hosts 127.0.0.1 localhost 127.0.1.1 ubuntu.example.local ubuntu 172.31.6.108 ceph-node3.example.local ceph-node3 172.31.6.109 ceph-node4.example.local ceph-node4 172.31.6.201 rgw.magedu.net8.6.4.2 é…ç½®å‘½ä»¤æ‰§è¡Œç¯å¢ƒ jack@ceph-deploy:~$ sudo su - root root@ceph-deploy:~# s3cmd --help root@ceph-deploy:~# s3cmd --configure Enter new values or accept defaults in brackets with Enter. Refer to user manual for detailed description of all options. Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables. Access Key: JIJX25OFEJ40JEBECDZV #è¾“å…¥ç”¨æˆ· access key Secret Key: vBa23pj4AhGk9GPeSrhL9NLaldShudVfjQ4AC90E #è¾“å…¥ç”¨æˆ·secret key Default Region [US]: #region é€‰é¡¹ Use \"s3.amazonaws.com\" for S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: rgw.magedu.net:9900 #RGW åŸŸå Use \"%(bucket)s.s3.amazonaws.com\" to the target Amazon S3. \"%(bucket)s\" and \"%(location)s\" vars can be used if the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.s3.amazonaws.com]: rgw.magedu.net:9900/%(bucket) #bucketåŸåæ ¼å¼ Encryption password is used to protect your files from reading by unauthorized persons while in transfer to S3 Encryption password : #ç§˜é’¥æ˜¯å¦ä½¿ç”¨å¯†ç åŠ å¯† Path to GPG program [/usr/bin/gpg]: #ä½¿ç”¨gpgè¿›è¡ŒåŠ å¯†ï¼ˆç³»ç»Ÿè‡ªå¸¦ä¸éœ€è¦å®‰è£…ï¼‰ #æ˜¯å¦ä½¿ç”¨HTTPS When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newe r Use HTTPS protocol [Yes]: No ##æ˜¯å¦ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ On some networks all internet access must go through a HTTP proxy. Try setting it here if you can't connect to S3 directly HTTP Proxy server name : #ç”Ÿæˆçš„ä¿¡æ¯ New settings: Access Key: T119RIWTRMMI9BBJEC66 Secret Key: r8kWaY i9hdZJyCKW23hucEUABli5x0AXSGs8worB Default Region: US S3 Endpoint: rgw.magedu.net:9900 DNS-style bucket+hostname:port template for accessing a bucket: rgw.magedu.net:9900/%(bucket) Enc ryption password: Path to GPG prog ram:/usr/bin/gpg Use HTTPS protocol: False HTTP Proxy server name: HTTP Proxy server port: 0 Test access with supplied credentials? [Y/n]] Y #æµ‹è¯•è¿æ¥ PLease wait, attempting to list all buckets.. . Success. Your access key and secret key worked fine :-) #å¦‚æœè¿æ¥æˆåŠŸå°±å¼¹å‡ºä¿å­˜é…ç½® Now verifying that encryption works. . . Not conf igured. Never mind. Save settings? [y/N] y Configuration saved to '/root/.s3cfg' #æµ‹è¯•å‘½ä»¤ s3cmd la","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:4:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"8.6.5 å‘½ä»¤è¡Œå®¢æˆ·ç«¯s3cmd éªŒè¯æ•°æ®ä¸Šä¼  8.6.5.1 æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯ s3cmd --help8.6.5.2 åˆ›å»ºbucket ä»¥éªŒè¯æƒé™ å­˜å‚¨ç©ºé—´(Bucket) æ˜¯ç”¨äºå­˜å‚¨å¯¹è±¡(Object) çš„å®¹å™¨ï¼Œ åœ¨ä¸Šä¼ ä»»æ„ç±»å‹çš„Objectå‰ï¼Œæ‚¨éœ€è¦å…ˆåˆ›å»ºBucket. Make bucket s3cmd mb s3://BUCKET ------------------------------------------------- root@ceph-deploy:~# s3cmd mb s3://mybucket Bucket 's3://mybucket/' created root@ceph-deploy:~# s3cmd mb s3://css Bucket 's3://css/' created root@ceph-deploy:~# s3cmd mb s3://images Bucket 's3://images/' created8.6.5.3 éªŒè¯ä¸Šä¼ æ•°æ® Put file into bucket s3cmd put FILE [FILE..] s3://BUCKET[/PREFIX] root@ceph-deploy:~# wget http://www.magedu.com/wp-content/uploads/2019/07/2019070508503489.png #ä¸Šä¼ æ•°æ® root@ceph-deploy:~# s3cmd put 2019070508503489.png s3://mages/ upload: '2019070508503489.png -\u003e 's3://images/2019070508503489.png' [1 of 1] 40703 of 40703 100% in 0s 1911.84 kB/s done root@ceph-deploy:~# s3cmd put 2019070508503489.png s3://images/png/ upload: '2019070508503489.png' -\u003e 's3://images/png/2019070508503489.png' [1 of 1] 40703 of 40703 100% in 2s 16.24 kB/s done #éªŒè¯æ•°æ® root@ceph-deploy:~# s3cmd ls s3://images/ DIR s3://images/png/ 2021-08-26 13:35 40703 s3://images/2019070508503489.png root@ceph-deploy:~# s3cmd ls s3://images/png/ 2021-08-26 13:35 40703 s3://images/png/2019070508503489.png8.6.5.4 éªŒè¯ä¸‹è½½æ–‡ä»¶ Get file from bucket s3cmd get s3://BUCKET/OBJECT LOCAL_FILE ------------------------------------------------------------------------ root@ceph-deploy:~# s3cmd get s3://images/2019070508503489.png /opt/ download: 's3://images/2019070508503489.png' -\u003e /opt/2019070508503489.png' [1of 1] 40703 of 40703 100% in 0s 5.80 MB/s done root@ceph-deploy:~# ls /opt/2019070508503489.png8.6.5.5 åˆ é™¤æ–‡ä»¶ Delete file from bucket (alias for del) s3cmd rm s3://BUCKET/OBJECT --------------------------------------------------- root@ceph-deploy: ~# s3cmd ls s3://images/ #éªŒè¯å½“å‰æ–‡ä»¶ DIR s3://images/png/ 2021-08-26 13:35 40703 s3://images/2019070508503489.png root@ceph-deploy: ~# s3cmd rm s3://images/2019070508503489.png #åˆ é™¤æ–‡ä»¶ delete: 's3://images/2019070508503489.png' root@ceph-deploy:~# s3cmd ls s3://images/ #éªŒè¯æ˜¯å¦è¢«åˆ é™¤ DIR s3://images/png/ #æŸ¥çœ‹å­˜å‚¨æ± pg ceph pg ls-by-pool default.rgw.buckets.data awk '{print $1, $2, $15}'","date":"2023-01-16","objectID":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/:4:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"RGWå¯¹è±¡å­˜å‚¨ç½‘å…³ ï¼ˆå…«ï¼‰","uri":"/posts/ceph/8.-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%BD%91%E5%85%B3rgw/"},{"categories":["Ceph"],"content":"ceph FSå³ceph filesystemï¼Œå¯ä»¥å®ç°æ–‡ä»¶ç³»ç»Ÿå…±äº«åŠŸèƒ½ï¼Œå®¢æˆ·ç«¯é€šè¿‡cephåè®®æŒ‚è½½å¹¶ä½¿ç”¨cephé›†ç¾¤ä½œä¸ºæ•°æ®å­˜å‚¨æœåŠ¡å™¨ã€‚ ï¼ˆç±»ä¼¼NFSï¼‰ Ceph FSéœ€è¦è¿è¡ŒMeta Data Services(MDS)æœåŠ¡ï¼Œå…¶å®ˆæŠ¤è¿›ç¨‹ä¸ºceph-mds, ceph-mdsè¿›ç¨‹ç®¡ç†ä¸Ceph FSä¸Šå­˜å‚¨çš„æ–‡ä»¶ç›¸å…³çš„å…ƒæ•°æ®ï¼Œå¹¶åè°ƒå¯¹cephå­˜å‚¨é›†ç¾¤çš„è®¿é—®ã€‚http://docs.ceph.org.cn/cephfs/Ceph FSçš„å…ƒæ•°æ®ä½¿ç”¨çš„åŠ¨æ€å­æ ‘åˆ†åŒº,æŠŠå…ƒæ•°æ®åˆ’åˆ†åç§°ç©ºé—´å¯¹åº”åˆ°ä¸åŒçš„mds,å†™å…¥å…ƒæ•°æ®çš„æ—¶å€™å°†å…ƒæ•°æ®æŒ‰ç…§åç§°ä¿å­˜åˆ°ä¸åŒä¸»mdsä¸Šï¼Œæœ‰ç‚¹ç±»ä¼¼äºnginxä¸­çš„ç¼“å­˜ç›®å½•åˆ†å±‚ä¸€æ ·ã€‚ä½†æ˜¯æœ€ç»ˆå…ƒæ•°æ®éƒ½ä¼šä¿å­˜åœ¨ceph å…ƒæ•°æ®æ± ä¸­ã€‚ ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:0:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.1 éƒ¨ç½²MDS æœåŠ¡ å¦‚æœè¦ä½¿ç”¨cephFS,éœ€è¦éƒ¨ç½²cephfsæœåŠ¡ã€‚ Ubuntu: root@ceph-mgr1:~# apt-cache madison ceph-mds root@ceph-mgr1:~# apt install ceph-mds Centos: root@ceph-mgr1 ~]# yum install ceph-mds $ ceph-deploy mds create ceph-mgr1","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.2 åˆ›å»ºCephFS metadataå’Œdataå­˜å‚¨æ±  ä½¿ç”¨CephFSä¹‹å‰éœ€è¦äº‹å…ˆäºé›†ç¾¤ä¸­åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿï¼Œå¹¶ä¸ºå…¶åˆ†åˆ«æŒ‡å®šå…ƒæ•°æ®å’Œæ•°æ®ç›¸å…³çš„å­˜å‚¨æ± ã€‚ä¸‹é¢åˆ›å»ºä¸€ä¸€ä¸ªåä¸ºcephfsçš„æ–‡ä»¶ç³»ç»Ÿç”¨äºæµ‹è¯•ï¼Œå®ƒä½¿ç”¨cephfs-metadataä¸ºå…ƒæ•°æ®å­˜å‚¨æ± ï¼Œä½¿ç”¨cephfs-data ä¸ºæ•°æ®å­˜å‚¨æ± ã€‚ #ä¿å­˜metadataçš„pool [ceph@ceph-deploy ceph-cluster]$ ceph osd pool create cephfs-metadata 32 32 pool 'cephfs-metadata' created #ä¿å­˜æ•°æ®çš„pool [ceph@ceph-deploy ceph-cluster]$ ceph osd pool create cephfs data 64 64 pool 'cephfs-data' created (ceph@ceph-deploy ceph-cluster]$ ceph -s #å½“å‰cephçŠ¶æ€ cluster: id:80a34e06-4458-4 1a8- 8d19-1 c0501152d69 health: HEALTH_ OK services: mon: 3 daemons, quorum ceph-mon1 ,ceph-mon2,ceph-mon3 mgr: ceph-mgr1(active), standbys: ceph-mgr2 osd: 12 osds: 12 up, 12 in rgw: 1 daemon active data: pools: 8 pools, 224 pgs objects: 278 objects, 302 MiB usage: 13 GiB used, 1.2 TiB / 1.2 TiB avail pgs: 224 active+clean","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.3 åˆ›å»ºcephFSå¹¶éªŒè¯ [ceph@ceph-deploy ceph-cluster]$ ceph fs new mycephfs cephfs-metadata cephfs-data new fs with metadata pool 7 and data pool 8 [ceph@ceph-deploy ceph-cluster]$ ceph fs ls name: mycephfs, metadata pool: cephfs-metadata, data pools: [cephfs-data ]ã€ #æŸ¥çœ‹æŒ‡å®šcephFSçŠ¶æ€ [ceph@ceph-deploy ceph-cluster$ ceph fs status mycephfs ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.4 éªŒè¯cepfFSæœåŠ¡çŠ¶æ€ #ç°åœ¨å·²ç»è½¬å˜ä¸ºæ´»åŠ¨çŠ¶æ€ $ ceph mds stat mycephfs-1/1/1 up {0=ceph-mgr1=up:active} ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.5 åˆ›å»ºå®¢æˆ·ç«¯è´¦æˆ· #åˆ›å»ºè´¦æˆ· [ceph@ceph-deploy ceph-cluster]$ ceph auth add client.yanyan mon 'allow r' mds 'allow rw' osd 'allow rwx pool=cephfs-data' added key for client.yanyan #éªŒè¯è´¦æˆ· [ceph@ceph-deploy ceph-cluster]$ ceph auth get client.yanyan exported keyring for client.yanyan [client.yanyan] key = AQCxpdhfjQt1OxAAGe0mqTMveNu2ZMEem3tb0g== caps mds = \"allow rw\" caps mon = \"allow r\" caps osd = \"allow rwx pool=cephfs-data\" #åˆ›å»ºç”¨keyringæ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ceph auth get client.yanyan -o ceph.client.yanyan.keyring #åˆ›å»ºkeyæ–‡ä»¶: [ceph@ceph-deploy ceph-cluster]$ ceph auth print-key client.yanyan \u003e yanyan.key #éªŒè¯ç”¨æˆ·çš„keyringæ–‡ä»¶ [ceph@ceph-deploy ceph-clusterl$ cat ceph.client.yanyan.keyring [client.yanyan] key = AQCxpdhfjQt1OxAAGe0mqTMveNu2ZMEem3tb0g== caps mds = \"allow rw\" caps mon = \"allow r\" caps osd = \"allow rwx pool=cephfs-data\"","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:5:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.6 å®‰è£…cephå®¢æˆ·ç«¯ [root@ceph-client3 ~]# yum install epel-release -y [root@ceph-client3~]# yum install htts://mirs.aliyun.com/ceph/rpm-octopus/el7/noarch/ceph-release- 1-1.el7.noarch.rpm","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:6:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.7 åŒæ­¥å®¢æˆ·ç«¯è®¤è¯æ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ scp ceph.conf ceph.client.yanyan.keyring yanyan.key root@172.31.6.203:/etc/ceph/","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:7:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.8 å®¢æˆ·ç«¯éªŒè¯æƒé™ [root@ceph-client3 ~]# ceph --user yanyan -s","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:8:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.9 å†…æ ¸ç©ºé—´æŒ‚è½½ceph-fs å®¢æˆ·ç«¯æŒ‚è½½æœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€æ˜¯å†…æ ¸ç©ºé—´ï¼ŒäºŒæ˜¯ç”¨æˆ·ç©ºé—´,å†…æ ¸ç©ºé—´æŒ‚è½½éœ€è¦å†…æ ¸æ”¯æŒcephæ¨¡å—ï¼Œç”¨æˆ·ç©ºé—´æŒ‚è½½éœ€è¦å®‰è£…ceph-fuseã€‚ å†…æ ¸\u003e 2.6.34é»˜è®¤æ”¯æŒceph ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:9:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.9.1 å®¢æˆ·ç«¯é€šè¿‡keyæ–‡ä»¶æŒ‚è½½ root@ceph-client3 ~]# mkdir /data [root@ceph-client3~]# mount -t ceph 172.31.6.104:6789,172.31.6.105:6789,172.31.6.106:6789:/ /data -o name-yanyan,secretfile=/etc/ceph/yanyan.key ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:9:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.9.2 å®¢æˆ·ç«¯é€šè¿‡keyæŒ‚è½½ [root@ceph-client3 ~]# tail /etc/ceph/yanyan.key AQCxpdhfjQt1OxAAGe0mqTMveNu2ZMEem3tb0g== root@ceph-client3 ~]# umount /data/ [root@ceph-client3 ~]# mount -t ceph 172.31.6.104:6789,172.31.6.105:6789,172.31.6.106:6789:/ /data -o name=yanyan,secret=AQCxpdhfjQt1OxAAGe0mqTMveiJu2ZMEem3tb0g==","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:9:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.9.3 å¼€æœºæŒ‚è½½ root@ceph-client3 ~]# cat /etc/fstab 172.31.6.104:6789,172.31.6.105:6789,172.31.6.106:6789:/ /data ceph defaults,name=yanyan,secretfile=/etc/ceph/yanyan.key,_netdev 0 0 [root@ceph-client3 ~]# mount -a #secretæŒ‚è½½ 172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:/ /data/cephfs ceph defaults ,name=yanyan,secret=AQBpxyBhUXlrIBAA9bW3UG2rdv6hQm0Is9MC7Q==,_netdev 0 0","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:9:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.9.4 å®¢æˆ·ç«¯æ¨¡å— å®¢æˆ·ç«¯å†…æ ¸åŠ è½½ceph.koæ¨¡å—æŒ‚è½½cephfsæ–‡ä»¶ç³»ç»Ÿ ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:9:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.10 ç”¨æˆ·ç©ºé—´æŒ‚è½½ceph-fs å¦‚æœå†…æ ¸æœ¬è¾ƒä½è€Œæ²¡æœ‰cephæ¨¡å—,é‚£ä¹ˆå¯ä»¥å®‰è£…ceph-fuse æŒ‚è½½ï¼Œä½†æ˜¯æ¨èä½¿ç”¨å†…æ ¸æ¨¡å—æŒ‚è½½ã€‚ ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:10:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.10.1 å®‰è£…ceph-fuse http://docs.ceph.org.cn/man/8/ceph-fuse/åœ¨ä¸€å°æ–°çš„å®¢æˆ·ç«¯æˆ–è¿˜åŸå¿«ç…§ï¼Œç„¶åå®‰è£…ceph-fuse [root@ceph- client2 ~]# yum install epel-release -y [root@ceph-client2 ~]# yum install https://mirrors.aliyun.com/ceph/rpm-octopus/el7/noarch/ceph-release-1-1.el7.noarch.rpm -y [ceph@ceph-deploy ceph-cluster]$ scp /etc/yum.repos.d/ceph.repo /etc/yum.repos.d/epel* root@172.31.6.111:/etc/yum.repos.d/ root@ceph-client2 ~]# yum install ceph-fuse ceph-common -y","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:10:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.10.2 ceph-fuse æŒ‚è½½ #åŒæ­¥è®¤è¯åŠé…ç½®æ–‡ä»¶: [ceph@ceph-deploy ceph-cluster]$ scp ceph.conf ceph.client.yanyan.keyring root@172.31 .6.111:/etc/ceph/ root@172.31.6.111's password: #é€šè¿‡ceph-fuseæŒ‚è½½ceph [root@ceph-client2 ~]# mkdir /data [root@ceph-client2 ~]# ceph-fuse --name client.yanyan -m 172.31.6.104:6789,172.31.6.105:6789,172.31.6.106:6789 /data ceph-fuse[1628]: starting ceph client 2021-06-08 10:51:24.332 7f5a3898ec00 -1 init, newargv = 0x556a48c77da0 newargc=7 ceph-fuse[1628]: starting fuse #å¼€æœºæŒ‚è½½,æŒ‡å®šç”¨æˆ·ä¼šè‡ªåŠ¨æ ¹æ®ç”¨æˆ·åç§°åŠ è½½æˆæƒæ–‡ä»¶åŠé…ç½®æ–‡ä»¶ceph.conf root@ceph-cient2 ~]# vim /etc/fstab none /data fuse.ceph ceph.id=yanyan,ceph.conf=/etc/ceph/ceph.conf,_netdev,defaults 0 0 [root@ceph-client2 ~]# umount /data [root@ceph-client2 ~]# mount -a ceph-fuse[1760]: starting ceph client 2021-06-08 10:56:57.602 7f24d91b9c00 -1 init, newargv = 0x55999f6cda40 newargc=9 ceph-fuse[1 7601. startina fuse","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:10:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11 ceph mdsé«˜å¯ç”¨ åŸºäºå¤šmdsæœåŠ¡å™¨ï¼Œåœ¨ä¸šåŠ¡é«˜å¹¶å‘æ—¶é¢‘ç¹è¯»å†™å…ƒæ•°æ®çš„åœºæ™¯ã€‚ Ceph mds(etadata service)ä½œä¸ºcephçš„è®¿é—®å…¥å£ï¼Œéœ€è¦å®ç°é«˜æ€§èƒ½åŠæ•°æ®å¤‡ä»½ï¼Œå‡è®¾å¯åŠ¨4ä¸ªMDSè¿›ç¨‹ï¼Œè®¾ç½®2ä¸ªRank.è¿™æ—¶å€™æœ‰2ä¸ªMDSè¿›ç¨‹ä¼šåˆ†é…ç»™ä¸¤ä¸ªRankï¼Œè¿˜å‰©ä¸‹2ä¸ªMDSè¿›ç¨‹åˆ†åˆ«ä½œä¸ºå¦å¤–ä¸ªçš„å¤‡ä»½ã€‚ é€šè¿‡å‚æ•°æŒ‡å®šé‚£ä¸»çš„å¤‡æ˜¯è°è®¾ç½®æ¯ä¸ªRankçš„å¤‡ä»½MDS,ä¹Ÿå°±æ˜¯å¦‚æœæ­¤Rankå½“å‰çš„MDSå‡ºç°é—®é¢˜é©¬ä¸Šåˆ‡æ¢åˆ°å¦ä¸ªMDSï¼Œè®¾ç½®å¤‡ä»½çš„æ–¹æ³•æœ‰å¾ˆå¤šï¼Œå¸¸ç”¨é€‰é¡¹å¦‚ä¸‹ã€‚mds_standby_replay: å€¼ä¸ºtrueæˆ–false, true è¡¨ç¤ºå¼€å¯replay æ¨¡å¼ï¼Œè¿™ç§æ¨¡å¼ä¸‹ä¸»MDSå†…çš„æ•°é‡å°†å®æ—¶ä¸ä»MDSåŒæ­¥ï¼Œå¦‚æœä¸»å®•æœºï¼Œä»å¯ä»¥å¿«é€Ÿçš„åˆ‡æ¢ï¼Œå¦‚æœä¸ºfalseåªæœ‰å®•æœºçš„æ—¶å€™æ‰å»åŒæ­¥æ•°æ®ï¼Œè¿™æ ·ä¼šæœ‰ä¸€æ®µæ—¶é—´çš„ä¸­æ–­.mds_standby_for_name:è®¾ç½®å½“å‰MDSè¿›ç¨‹åªç”¨äºå¤‡ä»½äºæŒ‡å®šåç§°çš„MDS.mds_standby_for_rank: è®¾ç½®å½“å‰MDSè¿›ç¨‹åªç”¨äºå¤‡ä»½äºå“ªä¸ªRank,é€šå¸¸ä¸ºRankç¼–å·å¦å¤–åœ¨å­˜åœ¨ä¹‹ä¸ªCephFSæ–‡ä»¶ç³»ç»Ÿä¸­ï¼Œè¿˜å¯ä»¥ä½¿ç”¨mds_standby_for fscid å‚æ•°æ¥ä¸ºæŒ‡å®šä¸åŒçš„æ–‡ä»¶ç³»ç»Ÿã€‚mds_standby_for fscid: æŒ‡å®šCephFSæ–‡ä»¶ç³»ç»ŸID,éœ€è¦è”åˆmds_standby_for_rankç”Ÿæ•ˆï¼Œå¦‚æœè®¾ç½®mds_standby_for_rank, é‚£ä¹ˆå°±æ˜¯ç”¨äºæŒ‡å®šæ–‡ä»¶ç³»ç»Ÿçš„æŒ‡å®šRank,å¦‚æœæ²¡æœ‰è®¾ç½®ï¼Œå°±æ˜¯æŒ‡å®šæ–‡ä»¶ç³»ç»Ÿçš„æ‰€æœ‰Rankã€‚ ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11.1 å½“å‰mdsæœåŠ¡å™¨çŠ¶æ€ [ceph@ceph-deploy ceph-cluster]$ ceph mds stat mycephfs-1/1/1 up {0=ceph-mgr1=up:active}","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11.2 æ·»åŠ MDSæœåŠ¡å™¨ å°†ceph-mgr2å’Œceph-mon2å’Œceph-mon3ä½œä¸ºmdsæœåŠ¡è§’è‰²æ·»åŠ è‡³cephé›†ç¾¤.æœ€åå®ç°ä¸¤ä¸»ä¸¤å¤‡çš„mdsé«˜å¯ç”¨å’Œé«˜æ€§èƒ½ç»“æ„ã€‚ #mdsæœåŠ¡å™¨å®‰è£…ceph-mdsæœåŠ¡ [root@ceph-mgr2 ~]# yum install ceph-mds -y [root@ceph-mon2 ~]# yum install ceph-mds -y [root@ceph-mon3 ~]# yum install ceph-mds -y #æ·»åŠ mdsæœåŠ¡å™¨ [ceph@ceph-deploy ceph-cluster]$ ceph-deploy mds create ceph-mgr2 [ceph@ceph-deploy ceph-cluster]$ ceph-deploy mds create ceph-mon2 [ceph@ceph-deploy ceph-cluster]$ ceph-deploy mds create ceph-mon3 #éªŒè¯mdsæœåŠ¡å™¨å½“å‰çŠ¶æ€: [ceph@ceph-deploy ceph-cluster]$ ceph mds stat mycephfs-1/1/1 up {0=ceph-mgr1 =up:active}, 3 up:standby","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11.3 éªŒè¯cephé›†ç¾¤å½“å‰çŠ¶æ€ å½“å‰å¤„äºæ¿€æ´»çŠ¶æ€çš„mdsæœåŠ¡å™¨æœ‰ä¸€å°ï¼Œå¤„äºå¤‡ä»½çŠ¶æ€çš„mdsæœåŠ¡å™¨æœ‰ä¸‰å°. [ceph@ceph-deploy ceph-cluster]$ ceph fs status ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11.4 å½“å‰çš„æ–‡ä»¶ç³»ç»ŸçŠ¶æ€ [ceph@ceph-deploy ceph-cluster]$ ceph fs get mycephfs Filesystem 'mycephfs' (1) fs_name mycephfs epoch 4 flags 12 created 2021-06-01 17:09:25.850256 modified 2021-06-0117:09:26.854640 tableserver 0 root 0 session_timeout 60","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11.5 è®¾ç½®å¤„äºæ¿€æ´»çŠ¶æ€çš„mdsçš„æ•°é‡ ç›®å‰æœ‰å››ä¸ªmdsæœåŠ¡å™¨ï¼Œä½†æ˜¯æœ‰ä¸€ä¸ªä¸»ä¸‰ä¸ªå¤‡ï¼Œå¯ä»¥ä¼˜åŒ–ä¸€ ä¸‹éƒ¨ç½²æ¶æ„ï¼Œè®¾ç½®ä¸ºä¸ºä¸¤ä¸»ä¸¤å¤‡ [ceph@ceph-deploy ceph-cluster]$ cepn fs set mycephfs max_mds 2 #è®¾ç½®åŒæ—¶æ´»è·ƒçš„ä¸»mdsæœ€å¤§å€¼ä¸º2 cephaceph-dep loy :~/ ceph-c luster$ ceph fs status mycephfs - 1 clients ======== RANK STATE MDS ACTIVITY DNS INOS DIRS CAPS 0 active ceph-mgr1 Reqs: 0 /s 32 19 12 7 1 active ceph-mon2 Reqs: 0 /s 10 13 11 0 POOL TYPE USED AVAIL cephfs-metadata metadata 1347k 630G cephfs-data data 849M 630G STANDBY MDS ceph-mon1 ceph-mon3 MDS version: ceph version 16.2.5 ( 0883bdea7337b95e4b611c768c0279868462204a) pacific (stable)","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11.6 MDSé«˜å¯ç”¨ä¼˜åŒ– ç›®å‰çš„çŠ¶æ€æ˜¯ceph-mgr1å’Œceph-mon2åˆ†åˆ«æ˜¯active çŠ¶æ€ï¼Œceph-mon3 å’Œceph-mgr2åˆ†åˆ«å¤„äºstandbyçŠ¶æ€ã€‚ç°åœ¨å¯ä»¥å°†ceph-mgr2è®¾ç½®ä¸ºceph-mgr1çš„standby,å°†ceph-mon3è®¾ç½®ä¸ºceph-mon2çš„standby,ä»¥å®ç°æ¯ä¸ªä¸»éƒ½æœ‰ä¸€ä¸ªå›ºå®šå¤‡ä»½è§’è‰²çš„ç»“æ„ï¼Œåˆ™ä¿®æ”¹é…ç½®æ–‡ä»¶å¦‚ä¸‹: [ceph@ceph-deploy ceph-cluster]$ vim ceph.conf [global] fsid = 23b0f9f2-8db3-477f-99a7-35a90eaf3dab public_ network = 172.31.0.0/21 cluster_ network = 192.168.0.0/21 mon_ initial members = ceph-mon1 monhost= 172.31.6.104 auth_ cluster_ required = cephx auth service_ required = cephx auth_ client required = cephx mon clock drift allowed = 2 mon clock drift warn backoff = 30 [mds.ceph-mgr2] #æŒ‡å®šmgrçš„é…ç½® #mds_standby_for_fscid = mycephfs mds_standby_for_name = ceph-mgr1 #æŒ‡å®šä¸»æ˜¯è° mds_standby_replay = true [mds_ceph-mon3] #æŒ‡å®šmon3çš„é…ç½® mds_standby_for name = ceph-mon2 #æŒ‡å®šä¸»æ˜¯è° mds_standby_replay = true","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11.7 åˆ†å‘é…ç½®æ–‡ä»¶å¹¶é‡å¯mdsæœåŠ¡ #åˆ†å‘é…ç½®æ–‡ä»¶ä¿è¯å„mdsæœåŠ¡é‡å¯æœ‰æ•ˆ $ ceph-deploy --overwrite-conf config push ceph-mon3 $ ceph-deploy --overwrite-conf config push ceph-mon2 $ ceph-deploy --overwrite-conf config push ceph-mgr1 $ ceph-deploy --overwrite-conf config push ceph-mgr2 root@ceph-mon2 ~]# systemctl restart ceph-mds@ceph-mon2 .service root@ceph-mon3 ~]# systemctl restart ceph-mds@ceph-mon3.service root@ceph-mgr2 ~]# systemctl restart ceph-mds@ceph-mgr2.service root@ceph-mgr1 ~]# systemctl restart ceph-mds@ceph-mgr1.service","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:7","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.11.8 cephé›†ç¾¤mdsé«˜å¯ç”¨çŠ¶æ€ ceph fs status","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:11:8","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.12 é€šè¿‡ganeshaå°†cephfså¯¼å‡ºä¸ºNFS é€šè¿‡ganeshaå°†cephfsé€šè¿‡NFSåè®®å…±äº«ä½¿ç”¨ã€‚ https://www.server-world.info/en/note?os=Ubuntu_20.04\u0026p=ceph15\u0026f=8 æŠŠCeph Fs ä¸­è½¬æˆNFSåè®® ","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:12:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.12.1 æœåŠ¡ç«¯é…ç½® root@ceph-mgr1:~# apt install nfs-ganesha-ceph root@ceph-mgr1:~# cd /etc/ganesha/ root@ceph-mgr1:/etc/ganesha# cat ganesha.conf # create new NFS_CORE_PARAM { # disable NLM Enable_ NLM = false; # disable RQUOTA (not suported on CephFS) Enable_ RQUOTA = false; # NFS protocol Protocols = 4; } EXPORT_DEFAULTS { # default access mode Access_Type = RW; } EXPORT { # uniq ID Export_ld = 1; # mount path of CephFS Path = \"/\"; FSAL { name = CEPH; # hostname or IP address of this Node hostname=\"172.31.6.104\"; } # setting for root Squash Squash=\"No_root_squash\"; # NFSv4 Pseudo path Pseudo= */magedu\"; # allowed security options SecType = \"sys\"; } LOG { # default log level Default_ _Log_ Level = WARN; } root@ceph-mgr1:/etc/ganesha# systemctl restart nfs-ganesha","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:12:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"7.12.2 å®¢æˆ·ç«¯æŒ‚è½½æµ‹è¯• root@ceph- client3-ubuntu1804:~# mount -t nfs 172.31.6.104:/magedu /data éªŒè¯æŒ‚è½½: df -TH #å®¢æˆ·ç«¯æµ‹è¯•å†™äººæ•°æ®: root@ceph-client3-ubuntu1804:~# echo \"ganesha v11111111\" \u003e\u003e /data/magedu/data/magedu.txt","date":"2023-01-15","objectID":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/:12:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph FS ï¼ˆä¸ƒï¼‰","uri":"/posts/ceph/7.-ceph-fs%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.1 RBDæ¶æ„å›¾ Cephå¯ä»¥åŒæ—¶æä¾›å¯¹è±¡å­˜å‚¨RADOSGW ã€å—å­˜å‚¨RBDã€æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨Ceph FSRBDå³RADOS Block Deviceçš„ç®€ç§°ï¼ŒRIBD å—å­˜å‚¨æ˜¯å¸¸ç”¨çš„å­˜å‚¨ç±»å‹ä¹‹ä¸€ï¼ŒRBDå—è®¾å¤‡ç±»ä¼¼ç£ç›˜å¯ä»¥è¢«æŒ‚è½½ï¼ŒRBD å—è®¾å¤‡å…·æœ‰å¿«ç…§ã€å¤šå‰¯æœ¬ã€å…‹éš†å’Œä¸€è‡´æ€§ç­‰ç‰¹æ€§ï¼Œæ•°æ®ä»¥æ¡å¸¦åŒ–çš„æ–¹å¼å­˜å‚¨åœ¨Cephé›†ç¾¤çš„å¤šä¸ªOSDä¸­ï¼Œæ¡å¸¦åŒ–æŠ€æœ¯å°±æ˜¯ä¸€ç§è‡ªåŠ¨çš„å°†1/0 çš„è´Ÿè½½å‡è¡¡åˆ°å¤šä¸ªç‰©ç†ç£ç›˜ä¸Šçš„æŠ€æœ¯ï¼Œæ¡å¸¦åŒ–æŠ€æœ¯å°±æ˜¯å°†ä¸€å—è¿ç»­çš„æ•°æ®åˆ†æˆå¾ˆå¤šå°éƒ¨åˆ†å¹¶æŠŠä»–ä»¬åˆ†åˆ«å­˜å‚¨åˆ°ä¸åŒç£ç›˜ä¸Šå».è¿™å°±èƒ½ä½¿å¤šä¸ªè¿›ç¨‹åŒæ—¶è®¿é—®æ•°æ®çš„å¤šä¸ªä¸åŒéƒ¨åˆ†è€Œä¸ä¼šé€ æˆç£ç›˜å†²çªï¼Œè€Œä¸”åœ¨éœ€è¦å¯¹è¿™ç§æ•°æ®è¿›è¡Œé¡ºåºè®¿é—®çš„æ—¶å€™å¯ä»¥è·å¾—æœ€å¤§ç¨‹åº¦ä¸Šçš„/Oå¹¶è¡Œèƒ½åŠ›ï¼Œä»è€Œè·å¾—éå¸¸å¥½çš„æ€§èƒ½ã€‚ ","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.2 åˆ›å»ºå­˜å‚¨æ±  [ceph@ceph-deploy ceph-cluster]$ ceph osd pool create rbd-data1 32 32 pool 'rbd-data1' created #åœ¨å­˜å‚¨æ± å¯ç”¨rbd [ceph@ceph-deploy ceph-cluster]$ ceph osd pool appliclition enable rbd-data1 rbd enabled application 'rbd' on pool 'rbd-data1' #åˆå§‹åŒ–rbd: [ceph@ceph-deploy ceph-cluster]$ rbd pool init -P rbd-data1","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.3 åˆ›å»ºimgé•œåƒ rbdå­˜å‚¨æ± å¹¶ä¸èƒ½ç›´æ¥ç”¨äºå—è®¾å¤‡ï¼Œè€Œæ˜¯éœ€è¦äº‹å…ˆåœ¨å…¶ä¸­æŒ‰éœ€åˆ›å»ºæ˜ åƒ(image) ï¼Œå¹¶æŠŠæ˜ åƒæ–‡ä»¶ä½œä¸ºå—è®¾å¤‡ä½¿ç”¨ã€‚rbd å‘½ä»¤å¯ç”¨äºåˆ›å»ºã€æŸ¥çœ‹åŠåˆ é™¤å—è®¾å¤‡ç›¸åœ¨çš„æ˜ åƒ(image) ï¼Œä»¥åŠå…‹éš†æ˜ åƒã€åˆ›å»ºå¿«ç…§.å°†æ˜ åƒå›æ»šåˆ°å¿«ç…§å’ŒæŸ¥çœ‹å¿«ç…§ç­‰ç®¡ç†æ“ä½œã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„å‘½ä»¤èƒ½å¤Ÿåœ¨æŒ‡å®šçš„RBDå³rbd-data1åˆ›å»ºä¸€ä¸ªåä¸ºmyimg1çš„æ˜ åƒ: ","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.3.1 åˆ›å»ºé•œåƒ åˆ›å»ºé•œåƒå‘½ä»¤æ ¼å¼: #åˆ›å»ºä¸¤ä¸ªé•œåƒ: $ rbd create data-img1 --size 3G --pool rbd-data1 --image-format 2 --image-feature layering $ rbd create data-img2 --size 5G --pool rbd-data1 --image-format 2 --image-feature layering #éªŒè¯é•œåƒ: $ rbd ls --pool rbd-data1 data-img1 data-img2 #åˆ—å‡ºé•œåƒä¸ªå¤šä¿¡æ¯: $ rbd Is --pool rbd-data1 -| 1 NAME SIZE PARENT FMT PROT LOCK data-img1 3 GiB 2 data-img2 5 GiB 2","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:3:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.3.2 æŸ¥çœ‹é•œåƒè¯¦ç»†ä¿¡æ¯ $ rbd --image data-img2 --pool rbd-data1 info rbd image 'data-img2': size 5 GiB in 1280 objects order 22 (4 MiB objects) #å¯¹è±¡å¤§å°ï¼Œæ¯ä¸ªå¯¹è±¡æ˜¯2^22/1024/1024=4MiB id: d42b6b8b4567 #é•œåƒid block_name_prefix: rbd_data.d42b6b8b4567 #sizeé‡Œé¢çš„1280ä¸ªå¯¹è±¡åç§°å‰ç¼€ format:2 #é•œåƒæ–‡ä»¶æ ¼å¼ç‰ˆæœ¬ features:layering #ç‰¹æ€§ï¼Œlayering æ”¯æŒåˆ†å±‚å¿«ç…§ä»¥å†™æ—¶å¤åˆ¶ op_features: flags: create timestamp: Mon Dec 14 12:22:27 2020","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:3:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.3.3 ä»¥jsonæ ¼å¼æ˜¾ç¤ºé•œåƒä¿¡æ¯: $ rbd ls --pool rbd-data1 -| --format json --pretty-format [ { \"image\": \"data-img1\", \"size\": 3221225472, \"format\": 2 }, { \"image\": \"data-img2\", \"size\": 5368709120, \"format\": 2 } ]","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:3:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.3.4 é•œåƒçš„å…¶ä»–ç‰¹æ€§ ç‰¹æ€§ç®€ä»‹layering:æ”¯æŒé•œåƒåˆ†å±‚å¿«ç…§ç‰¹æ€§ï¼Œç”¨äºå¿«ç…§åŠå†™æ—¶å¤åˆ¶ï¼Œå¯ä»¥å¯¹imageåˆ›å»ºå¿«ç…§å¹¶ä¿æŠ¤ï¼Œç„¶åä»å¿«ç…§å…‹éš†å‡ºæ–°çš„imageå‡ºæ¥ï¼Œçˆ¶å­imageä¹‹é—´é‡‡ç”¨COWæŠ€æœ¯ï¼Œå…±äº«å¯¹è±¡æ•°æ®ã€‚striping:æ”¯æŒæ¡å¸¦åŒ–v2ï¼Œç±»ä¼¼raid 0 ï¼Œåªä¸è¿‡åœ¨cephç¯å¢ƒä¸­çš„æ•°æ®è¢«åˆ†æ•£åˆ°ä¸åŒçš„å¯¹è±¡ä¸­ï¼Œå¯æ”¹å–„é¡ºåºè¯»å†™åœºæ™¯è¾ƒå¤šæƒ…å†µä¸‹çš„æ€§èƒ½ã€‚ exclusive-lock: æ”¯æŒç‹¬å é”ï¼Œé™åˆ¶-ä¸€ä¸ªé•œåƒåªèƒ½è¢«ä¸€ä¸ªå®¢æˆ·ç«¯ ä½¿ç”¨.object-map: æ”¯æŒå¯¹è±¡æ˜ å°„(ä¾èµ–exclusive-lock),åŠ é€Ÿæ•°æ®å¯¼äººå¯¼å‡ºåŠå·²ç”¨ç©ºé—´ç»Ÿè®¡ç­‰ï¼Œæ­¤ç‰¹æ€§å¼€å¯çš„æ—¶å€™ï¼Œä¼šè®°å½•imageæ‰€æœ‰å¯¹è±¡çš„ä¸€ä¸ªä½å›¾ï¼Œç”¨ä»¥æ ‡è®°å¯¹è±¡æ˜¯å¦çœŸçš„å­˜åœ¨ï¼Œåœ¨ä¸€äº›åœºæ™¯ä¸‹å¯ä»¥åŠ é€Ÿioã€‚ fast-diff: å¿«é€Ÿè®¡ç®—é•œåƒä¸å¿«ç…§æ•°æ®å·®å¼‚å¯¹æ¯”(ä¾èµ–object-map).deep-flatten: æ”¯æŒå¿«ç…§æ‰å¹³åŒ–æ“ä½œï¼Œç”¨äºå¿«ç…§ç®¡ç†æ—¶è§£å†³å¿«ç…§ä¾èµ–å…³ç³»ç­‰ã€‚journaling: ä¿®æ”¹æ•°æ®æ˜¯å¦è®°å½•æ—¥å¿—ï¼Œè¯¥ç‰¹æ€§å¯ä»¥é€šè¿‡è®°å½•æ—¥å¿—å¹¶é€šè¿‡æ—¥å¿—æ¢å¤æ•°æ®(ä¾èµ–ç‹¬å é”)ï¼Œå¼€å¯æ­¤ç‰¹æ€§ä¼šå¢åŠ ç³»ç»Ÿç£ç›˜I0ä½¿ç”¨. jewelé»˜è®¤å¼€å¯çš„ç‰¹æ€§åŒ…æ‹¬: layering/exlcusive lock/object map/fast diff/deep flatten [ceph@ceph-deploy ceph-cluster]$ rbd help feature enable usage: rbd feature enable [--pool \u003cpool\u003e] [-image \u003cimage\u003e] [--journal-splay-width \u003cjourmal-splay-width\u003e] [--jourmal-object- size \u003cjournal-object- size\u003e] [--journal-pool \u003cjournal-pool\u003e] \u003cimage-spec\u003e \u003cfeatures\u003e [\u003cfeatures\u003e ... ] Enable the specified image feature. Positional arguments \u003cimage-spec\u003e image specification (example: [\u003cpool-name\u003e/\u003cimage-name\u003e) \u003cfeatures\u003e image features [exclusive-lock, object-map, fast-diff, journaling] Optional arguments -P [--pool] arg pool name --image arg image name --journal-splay-width arg number of active journal objects --joumal-object-size arg size of journal objects [4K \u003c= size \u003c= 64M] --joumnal-pool arg pool for journal objects","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:3:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.3.6 é•œåƒç‰¹æ€§çš„å¯ç”¨ å¯ç”¨æŒ‡å®šå­˜å‚¨æ± ä¸­çš„æŒ‡å®šé•œåƒçš„ç‰¹æ€§: $ rbd feature enable exclusive-lock --pool rbd-data1 --image data-img1 $ rbd feature enable object-map --pool rbd-data1 --image data-img1 $ rbd feature enable fast-diff --pool rbd-data1 --image data-img1 #éªŒè¯é•œåƒç‰¹æ€§: $ rbd -imnage data-img1 --pool rbd-data1 info rbd image 'data-img1': size 3 GiB in 768 objects order 22 (4 MiB objects) id: d45b6b8b4567 block_name_prefix: rbd_data.d45b6b8b4567 format: 2 features: layering, exclusive-lock, object-map, fast-diff op_features: flags: object map invalid, fast diff invalid create_ timestamp: Mon Dec 14 12:35:44 2020","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:3:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.3.7 é•œåƒç‰¹æ€§çš„ç¦ç”¨ ç¦ç”¨æŒ‡å®šå­˜å‚¨æ± ä¸­æŒ‡å®šé•œåƒçš„ç‰¹æ€§ $ rbd feature disable fast-diff --pool rbd-data1 --image data-img1 #éªŒè¯é•œåƒç‰¹æ€§: $ rbd --image data-img1 --pool rbd-data1 info rbd image 'data-img1': size 3 GiB in 768 objects order 22 (4 MiB objects) id: d45b6b8b4567 block_name_prefix: rbd_data.d45b6b8b4567 format: 2 features: layering, exclusive-lock, object-map #å°‘äº†ä¸€ä¸ªfast-diff ç‰¹æ€§ op_features: flags: object map invalid create_timestamp: Mon Dec 14 12:35:44 2020","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:3:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4 é…ç½®å®¢æˆ·ç«¯ä½¿ç”¨RBD åœ¨centoså®¢æˆ·ç«¯æŒ‚è½½RBDï¼Œå¹¶åˆ†åˆ«ä½¿ç”¨adminåŠæ™®é€šç”¨æˆ·æŒ‚è½½RBDå¹¶éªŒè¯ä½¿ç”¨. ","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.1 å®¢æˆ·ç«¯é…ç½®yumæº å®¢æˆ·ç«¯è¦æƒ³æŒ‚è½½ä½¿ç”¨ceph RBDï¼Œéœ€è¦å®‰è£…cephå®¢æˆ·ç«¯ç»„ä»¶ceph-commonï¼Œä½†æ˜¯ceph-commonä¸åœ¨cenosçš„yumä»“åº“ï¼Œå› æ­¤éœ€è¦å•ç‹¬é…ç½®yumæºã€‚ #é…ç½®yumæº: yum install epel-release yum install htps://mirrors.aliyun.com/ceph/rpm-octopus/el7/noarch/ceph-release-1-1.el7.noarch.rpm -y","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.2 å®¢æˆ·ç«¯å®‰è£…ceph-common: yum install ceph-common","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.3 å®¢æˆ·ç«¯ä½¿ç”¨æ™®é€šç”¨æˆ·æŒ‚è½½å¹¶ä½¿ç”¨RBD åˆ›å»ºæ™®é€šè´¦æˆ·å¹¶æˆæƒ: #åˆ›å»ºæ™®é€šè´¦æˆ· [ceph@ceph-deploy ceph-cluster]$ ceph auth add clientshjie mon 'allow r' osd 'allow rwx pool=rbd-data1' added key for client.lije #éªŒè¯ç”¨æˆ·ä¿¡æ¯ [ceph@ceph-deploy ceph-cluster$ ceph auth get client.shijie exported keyring for client.shijie [client.shijie] key = AQDHE9hfhzPVCRAAIlRuUIkWQW8YXv/JiLizFuA== caps mon = \"allow r\" caps osd = \"allow rwx pool=rbd-data1\" #åˆ›å»ºç©ºçš„keyringæ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ ceph-authtool --riate-keyring ceph.client.shijie.keyring creating ceph.clent.shije.keyring #å¯¼å‡ºç”¨æˆ·keyring [ceph@ceph-deploy ceph-cluster]$ ceph auth get client.shijie -o ceph.client.shiie.keyring exported keyring for client.shjjie #éªŒè¯æŒ‡å®šç”¨æˆ·çš„keyringæ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ cat ceph.client.shiie.keyringæ‹·è´é…ç½®æ–‡ä»¶ä¸æ™®é€šè´¦æˆ·keyringæ–‡ä»¶åˆ°å®¢æˆ·ç«¯ scp ceph.cpnf ceph.client.shiie.keyring root@172.31.6.201:/etc/ceph","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.4 åœ¨å®¢æˆ·ç«¯éªŒè¯æƒé™ [root@ceph-client2 ~]# cd /etc/ceph/ root@ceph-client2 ceph]# ls ceph.client.shije.keyring ceph.conf rbdmap root@ceph-client2 ceph]# ceph --user shijie -s #é»˜è®¤ä½¿ç”¨adminè´¦æˆ· cluster: id: 23b0f9f2 -8db3-477f-99a7 -35a90eaf3dab health: HEALTH_ OK mgr: ceph-mgr1(active), standbys: ceph-mgr2 mds: mycephfs-1/1/1 up {0=ceph-mgr1=up:active} osd: 12 osds: 12 up, 12 in rgw.1 daemon active data: pools: 9 pools, 256 pgs objects: 400 objects, 455 MiB usage: 14 GiB used, 1.2 TiB / 1.2 TiB avail pgs: 256 active+clean","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.5 æ˜ å°„rbd ä½¿ç”¨æ™®é€šç”¨æˆ·æƒé™æ˜ å°„rbd #æ˜ å°„rbd root@ceph-client2 ceph]# rbd --user shijie -p rbd-data1 map data-img2 /dev/rbd0 #éªŒè¯rbd root@ceph- client2 ceph]# fdisk - /dev/rbd0 Disk /dev/rbd0: 5368 MB, 5368709120 bytes, 10485760 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 4194304 bytes / 4194304 bytes ","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.6 æ ¼å¼åŒ–å¹¶ä½¿ç”¨rbdé•œåƒ [root@ceph-client2 ceph]# mkfs.ext4 /dev/rbd0 [root@ceph-client2 ceph]# mkdir /data [root@ceph-client2 ceph]# mount /dev/rbd0 /data/ [root@ceph-client2 ceph]# cp /var/log/messages /data/ root@ceph-client2 ceph]# df -TH #ç®¡ç†ç«¯éªŒè¯é•œåƒçŠ¶æ€ [ceph@ceph-deploy ceph-cluster]$ rbd ls -p rbd-data1 -l NAME SIZE PARENT FMT PROT LOCK data-img1 3 GiB 2 excl #æ–½åŠ é”æ–‡ä»¶ï¼Œå·²ç»è¢«å®¢æˆ·ç«¯æ˜ å°„ data-img2 5 GiB 2","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.7 éªŒè¯cephå†…æ ¸æ¨¡å— æŒ‚è½½rbdä¹‹åç³»ç»Ÿå†…æ ¸ä¼šè‡ªåŠ¨åŠ è½½ libceph.ko æ¨¡å— #centos lsmod | grep ceph modinfo libceph #ubuntu ","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:7","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.8 rbdé•œåƒç©ºé—´æ‹‰ä¼¸ å¯ä»¥æ‰©å±•ç©ºé—´ï¼Œä¸å»ºè®®ç¼©å°ç©ºé—´ #å½“å‰rbdé•œåƒç©ºé—´å¤§å° [ceph@ceph-deploy ceph-cluster$ rbd ls -p rbd-data1 -l NAME SIZE PARENT FMT PROT LOCK data-img1 3 GiB 2 excl data-ima2 5 GiB 2 #rbdé•œåƒç©ºé—´æ‹‰ä¼¸å‘½ä»¤ [ceph@ceph-deploy ceph-cluster]$ rbd help resize usage: rbd resize [--pool \u003cpool\u003e] [--image \u003cimage\u003e] --size \u003csize\u003e [--allow-shrink] [--no-progress] \u003cimage-spec\u003e #æ‹‰ä¼¸rbdé•œåƒç©ºé—´ [ceph@ceph-deploy ceph-cluster]$ rbd resize --pool rbd-data1 --image data-img2 -size 8G Resizing image: 100% complete..done. [ceph@ceph-deploy ceph-cluster]$ rbd ls -p rbd-data1 -l NAME SIZE PARENT FMT PROT LOCK data-img1 3 GiB 2 excl data-img2 8 GiB 2 å®¢æˆ·ç«¯éªŒè¯é•œåƒç©ºé—´: [root@ceph-client2 ~]# fdisk -l /dev/rbd0 Disk /dev/rbd0: 8589 MB, 8589934592 bytes, 16777216 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes/ 512 bytes I/O size (minimum/optimal): 4194304 bytes / 4194304 bytes","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:8","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.9 å¼€æœºè‡ªåŠ¨æŒ‚è½½ [root@ceph-client2 ~]# cat /etc/rc.d/rc.local ripod --user shijie -p rbd-data1 map data-img1 mount /dev/rbd0 /data/ [root@ceph-client2 ~]# chmod a+x /etc/rc.d/rc.local [root@ceph-client2 ~]# reboot #æŸ¥çœ‹æ˜ å°„ [root@ceph-client2 ~]# rbd showmapped id pool image snap device 0 rbd-data1 data-img2 - /dev/rbd0 #éªŒè¯æŒ‚è½½ [root@ceph-client2 ~]# df -TH Filesystem Type Size Used Avail Use% Mounted on devtmpfs devtmpfs 942M 0 942M 0% /dev","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:9","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.10 å¸è½½rbdé•œåƒ [root@ceph-client2 ceph]# umount /data root@ceph-client2 ceph]# rbd --user shijie -p rbd-data1 unmap data-img2","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:10","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.11 åˆ é™¤rbdé•œåƒ é•œåƒåˆ é™¤åæ•°æ®ä¹Ÿä¼šè¢«åˆ é™¤è€Œä¸”æ˜¯æ— æ³•æ¢å¤ï¼Œå› æ­¤åœ¨æ‰§è¡Œåˆ é™¤æ“ä½œçš„æ—¶å€™è¦æ…é‡ã€‚ [ceph@ceph-deploy ceph-cluster]$ rbd help rm usage: rbd rm [--pool \u003cpool\u003e] [--image \u003cimage\u003e] [--no-progress] \u003cimage-spec\u003e","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:11","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.4.12 rbdé•œåƒå›æ”¶ç«™æœºåˆ¶ åˆ é™¤çš„é•œåƒæ•°æ®æ— æ³•æ¢å¤,ä½†æ˜¯è¿˜æœ‰å¦å¤–ä¸€ç§æ–¹æ³•å¯ä»¥å…ˆæŠŠé•œåƒç§»åŠ¨åˆ°å›æ”¶ç«™ï¼ŒåæœŸç¡®è®¤åˆ é™¤çš„æ—¶å€™å†ä»å›æ”¶ç«™åˆ é™¤å³å¯ã€‚ [ceph@ceph-deploy ceph-cluster$ rbd help trash status Show the status of this image. trash list (trash ls) List trash images. trash move (trash mv) Move an image to the trash. trash purge Remove all expired images from trash. trash remove (trash rm) Remove an image from trash. trash restore Restore an image from trash. #æŸ¥çœ‹é•œåƒçŠ¶æ€: [ceph@ceph-deploy ceph-cluster]$ rbd status --pool rbd-data1 --image data-img2 Watchers: watcher=172.31.6.1 10:0/2342274731 client.54552 cookie=18446462598732840961 watcher=1 72.31.6.111:0/2165319040 client.54558 cookie=18446462598732840961 #å°†é•œåƒç§»åŠ¨åˆ°å›æ”¶ç«™: [ceph@ceph-deploy ceph-cluster]$ rbd trash move --pool rbd-data1 --image data-img2 #æŸ¥çœ‹å›æ”¶ç«™çš„é•œåƒ: [ceph@ceph-deploy ceph-cluster$ rbd trash list --pool rbd-data1 d42b6b8b4567 data-img2 #ä»å›æ”¶ç«™åˆ é™¤é•œåƒ å¦‚æœé•œåƒä¸å†ä½¿ç”¨ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨trash removeå°†å…¶ä»å›æ”¶ç«™åˆ é™¤ #è¿˜åŸé•œåƒ [ceph@ceph-deploy ceph-cluster]$lybd trash restore --pool rbd-data1 --image data-img2 --image-id d42b6b8b4567 #éªŒè¯é•œåƒ: [ceph@ceph-deploy ceph-cluster]$ rbd Is --pool rbd-data1 -1 NAME SIZE PARENT FMT PROT LOCK data-img2 8 GiB 2","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:4:12","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.5 é•œåƒå¿«ç…§ [ceph@ceph-deploy ceph-cluster]$ rbd help snap snap create (snap add) #åˆ›å»ºå¿«ç…§ snap limit clear #æ¸…é™¤é•œåƒçš„å¿«ç…§æ•°é‡é™åˆ¶ snap limit set #è®¾ç½®ä¸€ä¸ªé•œåƒçš„å¿«ç…§ä¸Šé™ snap list (snap ls) #åˆ—å‡ºå¿«ç…§ snap protect #ä¿æŠ¤å¿« ç…§è¢«åˆ é™¤ snap purge #åˆ é™¤æ‰€æœ‰æœªä¿æŠ¤çš„å¿«ç…§ snap remove (snap rm) #åˆ é™¤ä¸€ä¸ªå¿«ç…§ snap rename #é‡å‘½åå¿«ç…§ snap rollback (snap revert) #è¿˜åŸå¿«ç…§ snap unprotect #å…è®¸ä¸€ä¸ªå¿«ç…§è¢«åˆ é™¤(å–æ¶ˆå¿«ç…§ä¿æŠ¤)","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:5:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.5.1 åˆ›å»ºå¿«ç…§ (ceph@ceph-deploy ceph-cluster]$ rbd help snap create usage: rbd snap create [--pool \u003cpoob\u003e] [--image \u003cimage\u003e] [--snap \u003csnap\u003e] \u003csnap-spec\u003e #åˆ›å»ºå¿«ç…§ $ rbd snap create --pool rbd-data1 --image data-img2 - snap img2-snap-20201215 #éªŒè¯å¿«ç…§ $ rbd snap list --pool rbd-data1 --image data-img2 SNAPID NAME SIZE TIMESTAMP 4 img2-snap-20201215 8 GiB Tue Dec 15 15:26:20 2020","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:5:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.5.2 åˆ é™¤æ•°æ®å¹¶è¿˜åŸå¿«ç…§ å…³é—­æœåŠ¡\u003eå–æ¶ˆæŒ‚è½½ \u003e å–æ¶ˆæ˜ å°„ #å¸è½½rbd root@ceph-client2 ~]# umount /data root@ceph-client2 ~]# rbd unmap /dev/rbd0 #å›æ»šå‘½ä»¤: [ceph@ceph-deploy ceph-cluster]$ rbd help snap rollback usage: rbd snap rollback [--pool \u003cpool\u003e] [-image \u003cimage\u003e] [--snap \u003csnap\u003e] [--no-progress] \u003csnap-spec\u003e #å›æ»šå¿«ç…§ [ceph@ceph-deploy ceph-clusterI$ rbd snap rollbaci --pool rbd-data1 --image data-img2 --snap img2-snap-20201215 Rolling back to snapshot: 100% complete..done.","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:5:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.5.3 åˆ é™¤å¿«ç…§ #åˆ é™¤æŒ‡å®šå¿«ç…§ [ceph@ceph-deploy ceph-cluster]$I rbd snap remove --pool rbd-data1 --image data-img2 --snap img2-snap-20201215 Removing snap: 100% complet...done. #éªŒè¯å¿«ç…§æ˜¯å¦åˆ é™¤ [ceph@ceph-deploy ceph-cluster]$ rbd snap list --pool rbd-data1 --image data-img2","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:5:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"6.5.4 å¿«ç…§æ•°é‡é™åˆ¶ #è®¾ç½®ä¸ä¿®æ”¹å¿«ç…§æ•°é‡é™åˆ¶ [ceph@ceph-deploy ceph-cluster]$ rbd snap limit set --pool rbd-data1 --image data-img2 --limit 30 [ceph@ceph-deploy ceph-cluster]$ rbd snap limit set --pool rbd-data1 --image data-img2 --limit 20 [ceph@ceph-deploy ceph-cluster]$ rbd snap limit set --pool rbd-data1 --image data-img2 --limit 15","date":"2023-01-14","objectID":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/:5:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph RBD ï¼ˆå…­ï¼‰","uri":"/posts/ceph/6.-ceph-rbd%E4%BD%BF%E7%94%A8/"},{"categories":["Ceph"],"content":"Cephä½¿ç”¨cephxåè®®å¯¹å®¢æˆ·ç«¯è¿›è¡Œèº«ä»½è®¤è¯cephxç”¨äºå¯¹cephä¿å­˜çš„æ•°æ®è¿›è¡Œè®¤è¯è®¿é—®å’Œæˆæƒï¼Œç”¨äºå¯¹è®¿é—®cephçš„è¯·æ±‚è¿›è¡Œè®¤è¯å’Œæˆæƒæ£€æµ‹ï¼Œä¸moné€šä¿¡çš„è¯·æ±‚éƒ½è¦ç»è¿‡cephè®¤è¯é€šè¿‡ï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥åœ¨monèŠ‚ç‚¹å…³é—­cephxè®¤è¯ï¼Œä½†æ˜¯å…³é—­è®¤è¯ä¹‹åä»»ä½•è®¿é—®éƒ½å°†è¢«å…è®¸ï¼Œå› æ­¤æ— æ³•ä¿è¯æ•°æ®çš„å®‰å…¨æ€§, ","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:0:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.1 æˆæƒæµç¨‹ æ¯ä¸ªmonèŠ‚ç‚¹éƒ½å¯ä»¥å¯¹å®¢æˆ·ç«¯è¿›è¡Œèº«ä»½è®¤è¯å¹¶åˆ†å‘ç§˜é’¥ï¼Œå› æ­¤å¤šä¸ªmonèŠ‚ç‚¹å°±ä¸å­˜åœ¨å•ç‚¹æ•…éšœå’Œè®¤è¯æ€§èƒ½ç“¶é¢ˆã€‚monèŠ‚ç‚¹ä¼šè¿”å›ç”¨äºèº«ä»½è®¤è¯çš„æ•°æ®ç»“æ„ï¼Œå…¶ä¸­åŒ…å«è·å–cephæœåŠ¡æ—¶ç”¨åˆ°çš„session key,session keyé€šè¿‡å®¢æˆ·ç«¯ç§˜é’¥è¿›è¡ŒåŠ å¯†ï¼Œç§˜é’¥æ˜¯åœ¨å®¢æˆ·ç«¯æå‰é…ç½®å¥½çš„ï¼Œ/etc/ceph/ceph.client.admin.keyring å®¢æˆ·ç«¯ä½¿ç”¨session keyå‘monè¯·æ±‚æ‰€éœ€è¦çš„æœåŠ¡ï¼Œmon å‘å®¢æˆ·ç«¯æä¾›ä¸€ä¸ªtiket, ç”¨äºå‘å®é™…å¤„ç†æ•°æ®çš„OSDç­‰æœåŠ¡éªŒè¯å®¢æˆ·ç«¯èº«ä»½ï¼ŒMONå’ŒOSDå…±äº«åŒä¸€ä¸ªsecret,å› æ­¤OSDä¼šä¿¡ä»»æ‰€æœ‰MONå‘æ”¾çš„tikettiketå­˜åœ¨æœ‰æ•ˆæœŸ :::info æ³¨æ„:CephXèº«ä»½éªŒè¯åŠŸèƒ½ä»…é™åˆ¶åœ¨Cephçš„å„ç»„ä»¶ä¹‹é—´ï¼Œä¸èƒ½æ‰©å±•åˆ°å…¶ä»–écephç»„ä»¶Ceph åªè´Ÿè´£è®¤è¯æˆæƒï¼Œä¸èƒ½è§£å†³æ•°æ®ä¼ è¾“çš„åŠ å¯†é—®é¢˜ ::: ","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:0:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.2 è®¿é—®æµç¨‹ æ— è®ºcephå®¢æˆ·ç«¯æ˜¯å“ªç§ç±»å‹ï¼Œä¾‹å¦‚å—è®¾å¤‡ã€å¯¹è±¡å­˜å‚¨ã€æ–‡ä»¶ç³»ç»Ÿï¼Œceph éƒ½ä¼šåœ¨å­˜å‚¨æ± ä¸­å°†æ‰€æœ‰æ•°æ®å­˜å‚¨ä¸ºå¯¹è±¡: cephç”¨æˆ·éœ€è¦æ‹¥æœ‰å­˜å‚¨æ± è®¿é—®æƒé™ï¼Œæ‰èƒ½è¯»å–å’Œå†™å…¥æ•°æ®cephç”¨æˆ·å¿…é¡»æ‹¥æœ‰æ‰§è¡Œæƒé™æ‰èƒ½ä½¿ç”¨cephçš„ç®¡ç†å‘½ä»¤ æŸ¥çœ‹key cephaceph-dep Loy:~/ ceph-cluster$ cat ceph. C lient . admin. key ring [client. admin] key = AQA3dhdhMd/UABAAr 2SNpJ+hcK1dD5 L2Hj 5XMg== caps mds = \"allow *\" caps mgr = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\"","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.3 cephç”¨æˆ· ç”¨æˆ·æ˜¯æŒ‡ä¸ªäºº(cephç®¡ç†è€…)æˆ–ç³»ç»Ÿå‚ä¸è€…**(MON/OSD/MDS)**.é€šè¿‡åˆ›å»ºç”¨æˆ·ï¼Œå¯ä»¥æ§åˆ¶ç”¨æˆ·æˆ–å“ªä¸ªå‚ä¸è€…èƒ½å¤Ÿè®¿é—®cephå­˜å‚¨é›†ç¾¤ã€ä»¥åŠå¯è®¿é—®çš„å­˜å‚¨æ± åŠå­˜å‚¨æ± ä¸­çš„æ•°æ®ã€‚cephæ”¯æŒå¤šç§ç±»å‹çš„ç”¨æˆ·ï¼Œä½†å¯ç®¡ç†çš„ç”¨æˆ·éƒ½å±äºclientç±»å‹åŒºåˆ†ç”¨æˆ·ç±»å‹çš„åŸå› åœ¨äº, MON/OSD/MDS ç­‰ç³»ç»Ÿç»„ä»¶ç‰¹ä½¿ç”¨cephxåè®®,ä½†æ˜¯å®ƒä»¬ä¸ºéå®¢æˆ·ç«¯ã€‚ é€šè¿‡ç‚¹å·æ¥åˆ†å‰²ç”¨æˆ·ç±»å‹å’Œç”¨æˆ·åï¼Œæ ¼å¼ä¸ºTYPE.ID,ä¾‹å¦‚client. admin é€šå¸¸å®¹å™¨å’ŒæœåŠ¡å™¨ä½¿ç”¨clientç±»å‹ cephaceph-dep Loy:~/ ceph-cluster$ cat ceph.Client.admin.key ring [client.admin] key = AQA3dhdhMd/UABAAr 2SNpJ+hcK1dD5 L2Hj 5XMg== caps mds = \"allow *\" caps mgr = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\"","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.3.1 åˆ—å‡ºæŒ‡å®šç”¨æˆ·ä¿¡æ¯: (ceph@ceph-deploy ceph-cluster]$ ceph auth get osd.10 exported keyring for osd.10 [osd.10] key = AQCKF6JfL aEpBRAAbY/P +cHPFPUtnkzljruyXw== caps mgr = \"allow profile osd\" caps mon = \"allow profile osd\" caps osd = \"allow [ceph@ceph-deploy ceph-cluter$ ceph auth get client.admin exported keyring for client.admin [client.admin] key = AQAGDKJfQk/dAxAA3Y +9xoE/p8in6QjoHeXmeg== caps mds = \"allow *\" caps mgr = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\"","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:2:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.4 cephæˆæƒå’Œä½¿èƒ½ cephåŸºäºä½¿èƒ½/èƒ½åŠ›(Capabilities,ç®€ç§°caps )æ¥æè¿°ç”¨æˆ·å¯é’ˆå¯¹MON/OSDæˆ–MDSä½¿ç”¨çš„æˆæƒèŒƒå›´æˆ–çº§åˆ«ï¼Œé€šç”¨çš„è¯­æ³•æ ¼å¼: daemon-type 'allow caps' [...] èƒ½åŠ›ä¸€è§ˆè¡¨: r: å‘ç”¨æˆ·æˆå­è¯»å–æƒé™ï¼Œè®¿é—®ç›‘è§†å™¨(mon)ä»¥æ£€ç´¢CRUSHè¿è¡Œå›¾æ—¶éœ€å…·æœ‰æ­¤èƒ½åŠ›ã€‚W: å‘ç”¨æˆ·æˆå­é’ˆå¯¹å¯¹è±¡çš„å†™äººæƒé™ã€‚x: æˆäºˆç”¨æˆ·è°ƒç”¨ç±»æ–¹æ³•(åŒ…æ‹¬è¯»å–å’Œå†™äºº)çš„èƒ½åŠ›ï¼Œä»¥åŠåœ¨ç›‘è§†å™¨ä¸­æ‰§è¡Œauthæ“ä½œçš„èƒ½åŠ›ã€‚*: æˆäºˆç”¨æˆ·å¯¹ç‰¹å®šå®ˆæŠ¤è¿›ç¨‹/å­˜å‚¨æ± çš„è¯»å–ã€å†™å…¥å’Œæ‰§è¡Œæƒé™ï¼Œä»¥åŠæ‰§è¡Œç®¡ç†å‘½ä»¤çš„èƒ½åŠ› class-read:æˆå­ç”¨æˆ·è°ƒç”¨ç±»è¯»å–æ–¹æ³•çš„èƒ½åŠ›ï¼Œå±äºæ˜¯x èƒ½åŠ›çš„å­é›†.class-write:æˆå­ç”¨æˆ·è°ƒç”¨ç±»å†™äººæ–¹æ³•çš„èƒ½åŠ›ï¼Œå±äºæ˜¯x èƒ½åŠ›çš„å­é›†ã€‚ é›†ç¾¤ç»„ä»¶æƒé™profile osd: æˆäºˆç”¨æˆ·ä»¥æŸä¸ªOSDèº«ä»½è¿æ¥åˆ°å…¶ä»–OSDæˆ–ç›‘è§†å™¨çš„æƒé™.æˆäºˆOSDæƒé™ï¼Œä½¿OSD èƒ½å¤Ÿå¤„ç†å¤åˆ¶æ£€æµ‹ä¿¡å·æµé‡å’ŒçŠ¶æ€æŠ¥å‘Š(è·å–OSDçš„çŠ¶æ€ä¿¡æ¯).profile mds: æˆäºˆç”¨æˆ·ä»¥æŸä¸ªMDSèº«ä»½è¿æ¥åˆ°å…¶ä»–MDSæˆ–ç›‘è§†å™¨çš„æƒé™ã€‚profile bootstrap-osd: æˆäºˆç”¨æˆ·å¼•å¯¼OSDçš„æƒé™(åˆå§‹åŒ–OSDå¹¶å°†OSDåŠ äººcephé›†ç¾¤)ï¼Œæˆæƒç»™éƒ¨ç½²å·¥å…·ï¼Œä½¿å…¶åœ¨å¼•å¯¼OSDæ—¶æœ‰æƒæ·»åŠ å¯†é’¥ã€‚profile bootstrap-mds: æˆå­ç”¨æˆ·å¼•å¯¼å…ƒæ•°æ®æœåŠ¡å™¨çš„æƒé™ï¼Œæˆæƒéƒ¨ç½²å·¥å…·æƒé™ï¼Œä½¿å…¶åœ¨å¼•å¯¼å…ƒæ•°æ®æœåŠ¡å™¨æ—¶æœ‰æƒæ·»åŠ å¯†é’¥. MONèƒ½åŠ›:åŒ…æ‹¬r/w/xå’Œallow profile cap(cephçš„è¿è¡Œå›¾)ä¾‹å¦‚: mon 'allow rwx' mon 'allow profile osd'OSDèƒ½åŠ›:åŒ…æ‹¬rã€wã€ xã€class-readã€ class-write(ç±»è¯»å–) å’Œprofile osd(ç±»å†™å…¥)ï¼Œå¦å¤–OSDèƒ½åŠ›è¿˜å…è®¸è¿›è¡Œå­˜å‚¨æ± å’Œåç§°ç©ºé—´è®¾ç½®ã€‚ osd 'llow capability' [pool=poolname] [namespace =namespace-name]MDSèƒ½åŠ›:åªéœ€è¦allow æˆ–ç©ºéƒ½è¡¨ç¤ºå…è®¸. mds 'allow'","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.5 cephç”¨æˆ·ç®¡ç† ç”¨æˆ·ç®¡ç†åŠŸèƒ½å¯è®© Cephé›†ç¾¤ç®¡ç†å‘˜èƒ½å¤Ÿç›´æ¥åœ¨ Cephé›†ç¾¤ä¸­åˆ›å»ºæ›´æ–°å’Œåˆ é™¤ç”¨æˆ·ã€‚åœ¨Cephé›†ç¾¤ä¸­åˆ›å»ºæˆ–åˆ é™¤ç”¨æˆ·æ—¶ï¼Œå¯èƒ½éœ€è¦å°†å¯†é’¥åˆ†å‘åˆ°å®¢æˆ·ç«¯ï¼Œä»¥ä¾¿å°†å¯†é’¥æ·»åŠ åˆ°å¯†é’¥ç¯æ–‡ä»¶ä¸­/etc/ceph/ceph.client.admin.keyringï¼Œæ­¤æ–‡ä»¶ä¸­å¯ä»¥åŒ…å«ä¸€ä¸ªæˆ– è€…å¤šä¸ªç”¨æˆ·è®¤è¯ä¿¡æ¯ï¼Œå‡¡æ˜¯æ‹¥æœ‰æ­¤æ–‡ä»¶çš„èŠ‚ç‚¹ï¼Œå°†å…·å¤‡è®¿é—®cephçš„æƒé™ï¼Œè€Œä¸”å¯ä»¥ä½¿ç”¨å…¶ä¸­ä»»ä½•ä¸€ä¸ªè´¦æˆ·çš„æƒé™ï¼Œæ­¤æ–‡ä»¶ç±»ä¼¼äºlinuxç³»ç»Ÿçš„ä¸­çš„**/etc/passwd**æ–‡ä»¶. æ³¨æ„: TYPEID è¡¨ç¤ºæ³•é’ˆå¯¹ç”¨æˆ·é‡‡ç”¨TYPE.IDè¡¨ç¤ºæ³• ä¾‹å¦‚osd.0æŒ‡å®šæ˜¯osdç±»å¹¶ä¸”IDä¸º0çš„ç”¨æˆ·(èŠ‚ç‚¹), client.adminæ˜¯clientç±»å‹çš„ç”¨æˆ·ï¼Œå…¶IDä¸ºadmin, å¦è¯·æ³¨æ„ï¼Œæ¯ä¸ªé¡¹åŒ…å«ä¸€ä¸ª key=xxxé¡¹ï¼Œä»¥åŠä¸€ä¸ªæˆ–å¤šä¸ªcapsé¡¹ã€‚ å¯ä»¥ç»“åˆä½¿ç”¨-0æ–‡ä»¶åé€‰é¡¹å’Œceph auth list å°†è¾“å‡ºä¿å­˜åˆ°æŸä¸ªæ–‡ä»¶, [ceph@ceph-deploy ceph-cluster]$ ceph auth list -o 123.key æ·»åŠ ä¸€ä¸ªç”¨æˆ·ä¼šåˆ›å»ºç”¨æˆ·å(TYPE.ID). æœºå¯†å¯†é’¥ï¼Œä»¥åŠåŒ…å«åœ¨å‘½ä»¤ä¸­ç”¨äºåˆ›å»ºè¯¥ç”¨æˆ·çš„æ‰€æœ‰èƒ½åŠ›,ç”¨æˆ·å¯ä½¿ç”¨å…¶å¯†é’¥å‘Ceph å­˜å‚¨é›†ç¾¤è¿›è¡Œèº«ä»½éªŒè¯ã€‚ç”¨æˆ·çš„èƒ½åŠ›æˆäºˆè¯¥ç”¨æˆ·åœ¨Ceph monitor (mon)ã€Ceph OSD (osd)æˆ–Cephå…ƒæ•°æ®æœåŠ¡å™¨(mds) ä¸Šè¿›è¡Œè¯»å–ã€å†™å…¥æˆ–æ‰§è¡Œçš„èƒ½åŠ›,å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‡ ä¸ªå‘½ä»¤æ¥æ·»åŠ ç”¨æˆ·: ","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.5.1 ceph auth add æ­¤å‘½ä»¤æ˜¯æ·»åŠ ç”¨æˆ·çš„è§„èŒƒæ–¹æ³•ã€‚å®ƒä¼šåˆ›å»ºç”¨æˆ·ã€ç”Ÿæˆå¯†é’¥ï¼Œå¹¶æ·»åŠ æ‰€æœ‰æŒ‡å®šçš„èƒ½åŠ›ã€‚ [ceph@ceph-deploy ceph-cluster]$ ceph auth -h auth add \u003centity\u003e {\u003ccaps\u003e[\u003ccaps\u003e...]} #æ·»åŠ è®¤è¯key: [ceph@ceph-deploy ceph-cluster]$ ceph auth add client.tom mon 'allow r' osd 'allow rwx pool=mypool' added key for client.tom #tomç”¨æˆ·åªèƒ½åœ¨mypoolå­˜å‚¨æ± å¯¹monæœ‰è¯»æƒé™ã€å¯¹osdæœ‰è¯»å†™æ‰§è¡Œæƒé™ #éªŒè¯key [ceph@ceph-deploy ceph-cluster]$ ceph auth get client.tom exported keyring for client.tom [client.tom] key = AQCErsdftuumL BAADUiAfQUI42ZIX1e/4PjpdA== caps mon = \"allow r\" caps osd = \"allow rwx pool=mypool\" exported keyring for client.tom","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:4:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.5.2 ceph auth get-or-create ceph auth get-or-createæ­¤å‘½ä»¤æ˜¯åˆ›å»ºç”¨æˆ·è¾ƒä¸ºå¸¸è§çš„æ–¹å¼ä¹‹ä¸€, å®ƒä¼šè¿”å›åŒ…å«ç”¨æˆ·å(åœ¨æ–¹æ‹¬å·ä¸­)å’Œå¯†é’¥çš„å¯†é’¥æ–‡ï¼Œå¦‚æœè¯¥ç”¨æˆ·å·²å­˜åœ¨ï¼Œæ­¤å‘½ä»¤åªä»¥å¯†é’¥æ–‡ä»¶æ ¼å¼è¿”å›ç”¨æˆ·åå’Œå¯†é’¥ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ -o æŒ‡å®šæ–‡ä»¶åé€‰é¡¹å°†è¾“å‡ºä¿å­˜åˆ°æŸä¸ªæ–‡ä»¶ã€‚ #åˆ›å»ºç”¨æˆ· [ceph@ceph-deploy ceph-cluster]$ ceph auth get-or-create client,jack mon 'allow r osd 'allow rwx pool=mypool' [client.jack] key = AQAtr8dfi37XMhAADbHWEZOshY1QZ5A8eBpeoQ== #éªŒè¯ç”¨æˆ· [ceph@ceph-deploy ceph-clusterI$ ceph auth get client.jack exported keyring for cliet,jack [client.jack] key = AQAtr8dfi37XMhAADbHWEZOshY1QZ5A8eBpeoQ== caps mon=\"allow r\" caps osd =\"allow rwx pool=mypool\" #å†æ¬¡åˆ›å»ºå°±ä¸ä¼šåˆ›å»ºäº†ä¼šæ‰“å°keyä¿¡æ¯ [ceph@ceph-deploy ceph-cluster]$ ceph auth get-or-create client.jack mon 'allow r osd 'allow rwx pool=mypool [client.jack] key = AQAtr8dfiI37XMhAADbHWEZ0shY1QZ5A8eBpeoQ==","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:4:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.5.3 ceph auth get-or-create-key æ­¤å‘½ä»¤æ˜¯åˆ›å»ºç”¨æˆ·å¹¶ä»…è¿”å›ç”¨æˆ·å¯†é’¥ï¼Œå¯¹äºåªéœ€è¦å¯†é’¥çš„å®¢æˆ·ç«¯(ä¾‹å¦‚libvirt) ï¼Œæ­¤å‘½ä»¤éå¸¸æœ‰ç”¨ã€‚å¦‚æœè¯¥ç”¨æˆ·å·²å­˜åœ¨ï¼Œæ­¤å‘½ä»¤åªè¿”å›å¯†é’¥ã€‚æ‚¨å¯ä»¥ä½¿ç”¨-oæ–‡ä»¶åé€‰é¡¹å°†è¾“å‡ºä¿å­˜åˆ°æŸä¸ªæ–‡ä»¶ã€‚ åˆ›å»ºå®¢æˆ·ç«¯ç”¨æˆ·æ—¶ï¼Œå¯ä»¥åˆ›å»ºä¸å…·æœ‰èƒ½åŠ›çš„ç”¨æˆ·.ä¸å…·æœ‰èƒ½åŠ›çš„ç”¨æˆ·å¯ä»¥è¿›è¡Œèº«ä»½éªŒè¯ï¼Œä½†ä¸èƒ½æ‰§è¡Œå…¶ä»–æ“ä½œï¼Œæ­¤ç±»å®¢æˆ·ç«¯æ— æ³•ä»ç›‘è§†å™¨æ£€ç´¢é›†ç¾¤åœ°å›¾,ä½†æ˜¯,å¦‚æœå¸Œæœ›ç¨åå†æ·»åŠ èƒ½åŠ›ï¼Œå¯ä»¥ä½¿ç”¨ceph auth capså‘½ä»¤åˆ›å»ºä¸€ä¸ªä¸å…·æœ‰èƒ½åŠ›çš„ç”¨æˆ·ã€‚å…¸å‹çš„ç”¨æˆ·è‡³å°‘å¯¹Ceph monitorå…·æœ‰è¯»å–åŠŸèƒ½ï¼Œå¹¶å¯¹Ceph OSDå…·æœ‰è¯»å–å’Œå†™äººåŠŸèƒ½.æ­¤å¤–ï¼Œç”¨æˆ·çš„OSD æƒé™é€šå¸¸é™åˆ¶ä¸ºåªèƒ½è®¿é—®ç‰¹å®šçš„å­˜å‚¨æ± ã€‚ [ceph@ceph-deploy ceph-cluster]$ ceph auth get-or-create-key client.jack mon 'allow r' osd 'allow rwx pool=mypool' AQAtr8dfi37XMhAADbHWEZ0shY1QZ5A8eBpeoQ== #ç”¨æˆ·æœ‰keyå°±æ˜¾ç¤ºæ²¡æœ‰å°±åˆ›å»º","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:4:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.5.4 ceph auth print-key åªè·å–å•ä¸ªæŒ‡å®šç”¨æˆ·çš„keyä¿¡æ¯ [ceph@ceph-deploy ceph-cluster$ ceph auth print-key client.jack AQAtr8dfi37XMhAADbHWEZ0shY 1QZ5A8eBpeoQ==","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:4:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.5.5 ä¿®æ”¹ç”¨æˆ·èƒ½åŠ› ä½¿ç”¨ceph auth capså‘½ä»¤å¯ä»¥æŒ‡å®šç”¨æˆ·ä»¥åŠæ›´æ”¹è¯¥ç”¨æˆ·çš„èƒ½åŠ›ï¼Œè®¾ç½®æ–°èƒ½åŠ›ä¼šå®Œå…¨è¦†ç›–å½“å‰çš„èƒ½åŠ›ï¼Œå› æ­¤è¦åŠ ä¸Šä¹‹å‰çš„ç”¨æˆ·å·²ç»æ‹¥æœ‰çš„èƒ½å’Œæ–°çš„èƒ½åŠ›ï¼Œå¦‚æœçœ‹å½“å‰èƒ½åŠ›ï¼Œå¯ä»¥è¿è¡Œceph auth get USERTYPE.USERID,å¦‚æœè¦æ·»åŠ èƒ½åŠ›ï¼Œä½¿ç”¨ä»¥ä¸‹æ ¼å¼æ—¶è¿˜éœ€è¦æŒ‡å®šç°æœ‰èƒ½åŠ›: æƒé™ä¿®æ”¹åç«‹å³ç”Ÿæ•ˆ #æŸ¥çœ‹ç”¨æˆ·å½“å‰æƒé™ [ceph@ceph-deploy ceph-cluster]$ ceph auth get client.jack exported keyring for client.jack [client.jack] key = AQAtr8dfi37XMhAADbHWEZ0shY1QZ5A8eBpeoQ== caps mon = \"allow r\" caps osd = \"allw rwx pool=mypool\" #ä¿®æ”¹ç”¨æˆ·æƒé™ [ceph@ceph-deploy ceph-cluster]$ ceph auth caps client.jack mon 'allow r' osd 'allow rw pool=mypool' updated caps for client.jack #å†æ¬¡éªŒè¯æƒé™ [ceph@ceph-deploy ceph-cluster]$ ceph auth get client.jack exported keyring for client.jack","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:4:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.5.6 åˆ é™¤ç”¨æˆ· è¦åˆ é™¤ç”¨æˆ·ä½¿ç”¨ceph auth del TYPE.ID,å…¶ä¸­TYPEæ˜¯client. osd. mon æˆ–mdsä¹‹ä¸€,IDæ˜¯ç”¨æˆ·åæˆ–å®ˆæŠ¤è¿›ç¨‹çš„ID. [ceph@ceph-deploy ceph-cluster]$ ceph auth del client.tom updated","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:4:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.6 ç§˜é’¥ç¯ç®¡ç† cephçš„ç§˜é’¥ç¯æ˜¯ä¸€ä¸ªä¿å­˜äº†secretsã€keys ã€certificateså¹¶ä¸”èƒ½å¤Ÿè®©å®¢æˆ·ç«¯é€šè®¤è¯è®¿é—®cephçš„keyring file(é›†åˆæ–‡ä»¶ï¼‰ï¼Œä¸€ä¸ªkeyring fileå¯ä»¥ä¿å­˜ä¸€ä¸ªæˆ–è€…å¤šä¸ªè®¤è¯ä¿¡æ¯ï¼Œæ¯ä¸€ä¸ª keyéƒ½æœ‰ä¸€ä¸ªå®ä½“åç§°åŠ æƒé™ï¼Œç±»å‹ä¸º:{clientã€monã€mdsã€osd)}.name å½“å®¢æˆ·ç«¯è®¿é—®cephé›†ç¾¤æ—¶ï¼Œceph ä¼šæŒ‰é¡ºåºä¾æ¬¡ä½¿ç”¨ä»¥ä¸‹å››ä¸ªå¯†é’¥ç¯æ–‡ä»¶é¢„è®¾ç½®å¯†é’¥ç¯è®¾ç½®:é›†ç¾¤åè¯ + ç”¨æˆ·ç±»å‹ +ç”¨æˆ·ID+å›ºå®šåç¼€/etc/ceph/\u003c$cluster name\u003e.\u003cuser $type\u003e.\u003cuser $id\u003e.keyring ä¿å­˜å•ä¸ªç”¨æˆ·çš„keyring/etc/ceph/cluster.keyring ä¿å­˜å¤šä¸ªç”¨æˆ·çš„keyring/etc/ceph/keyring æœªå®šä¹‰é›†ç¾¤åç§°çš„å¤šä¸ªç”¨æˆ·çš„keyring/etc/ceph/keyring.bin ç¼–è¯‘åçš„äºŒè¿›åˆ¶æ–‡ä»¶ ","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:5:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.6.1 é€šè¿‡ç§˜é’¥ç¯æ–‡ä»¶å¤‡ä»½ä¸æ¢å¤ç”¨æˆ· å¦‚æœè¯¯åˆ é™¤è´¦å·å¯ä»¥é€šè¿‡ç§˜é’¥ç¯æ¢å¤ç”¨æˆ·ï¼Œä¸»è¦æ˜¯keyä¸ä¼šå˜ï¼ˆk8s å‡ åå‡ ç™¾ä¸ªpodï¼‰ä½¿ç”¨ceph auth addç­‰å‘½ä»¤æ·»åŠ çš„ç”¨æˆ·è¿˜éœ€è¦é¢å¤–ä½¿ç”¨ceph-authtoolå‘½ä»¤ä¸ºå…¶åˆ›å»ºç”¨æˆ·ç§˜é’¥ç¯æ–‡ä»¶.å…ˆåˆ›å»ºç©º keyringæ–‡ä»¶å‘½ä»¤æ ¼å¼: ceph-authtool --create-keyring FILEå¯¼å‡ºç”¨æˆ·è®¤è¯ä¿¡æ¯è‡³keyringæ–‡ä»¶:å°†ç”¨æˆ·ä¿¡æ¯å¯¼å‡ºè‡³keyringæ–‡ä»¶ï¼Œå¯¹ç”¨æˆ·ä¿¡æ¯è¿›è¡Œå¤‡ä»½ã€‚ #åˆ›å»ºç”¨æˆ·: (ceph@ceph-deploy ceph cluster]$ ceph auth get-or-create client.user1 mon 'allow r' osd 'allow *pool=mypool' [client.user1] key =AQAUUchfjpMqGRAARV6h0ofdDEneuaRnxuHjoQ== #éªŒè¯ç”¨æˆ· [ceph@ceph-deploy ceph-clusterl$ ceph auth get client.user1 exported keyring for client.user1 [client.user1] key = AQAUUchfjpMqGRAARV6hOofdDEneuaRnxuHjoQ== caps mon = \"allow r\" caps osd = \"allow *pool=mypool\" #åˆ›å»ºkeyringæ–‡ä»¶: (ceph@ceph-deploy ceph-cluster]$ ceph-authtool --create-keyring ceph.client.user1.keyring #éªŒè¯keyringæ–‡ä»¶: [ceph@ceph-deploy ceph-cluster]$ cat ceph.client.user1.keyring #æ˜¯ä¸ªç©ºæ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ file ceph.client.user1.keyring ceph.client.user1.keyring: empty #å¯¼å‡ºkeyringè‡³æŒ‡å®šæ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ceph auth get client.user1 -o ceph.client.user1.keyring exported keyring for client.user1 #éªŒè¯æŒ‡å®šç”¨æˆ·çš„keyringæ–‡ä»¶: [ceph@ceph-deploy ceph-cluster]$ cat ceph.client.user1.keyring [client.user1] key = AQAUUchfjpMqGRAARV6hOofdDEneuaRnxuHjoQ== caps mon = \"allow r\" caps osd = \"allow * pool=mypool\"åœ¨åˆ›å»ºåŒ…å«å•ä¸ªç”¨æˆ·çš„å¯†é’¥ç¯æ—¶ï¼Œé€šå¸¸å»ºè®®ä½¿ç”¨cephé›†ç¾¤åç§°ã€ç”¨æˆ·ç±»å‹å’Œç”¨æˆ·ååŠkeyringæ¥å‘½åï¼Œå¹¶å°†å…¶ä¿å­˜åœ¨**/etc/ceph** ç›®å½•ä¸­ï¼Œä¾‹å¦‚ä¸ºclient.user1ç”¨æˆ·åˆ›å»ºceph.client.user1.keyring ","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:5:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.6.2 ä»keyringæ–‡ä»¶æ¢å¤ç”¨æˆ·è®¤è¯ä¿¡æ¯ å¯ä»¥ä½¿ç”¨ceph auth import +æŒ‡å®škeyringæ–‡ä»¶å¹¶å¯¼äººåˆ°ceph,å…¶å®å°±æ˜¯èµ·åˆ°ç”¨æˆ·å¤‡ä»½å’Œæ¢å¤çš„ç›®çš„: [ceph@ceph-deploy ceph-cluster]$ ceph auth import -i ceph.client.user1.keyring #å¯¼å…¥ç”¨æˆ·","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:5:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"5.6.3 ç§˜é’¥ç¯æ–‡ä»¶æ·»åŠ å¤šç”¨æˆ· ä¸€ä¸ªkeyringæ–‡ä»¶ä¸­å¯ä»¥åŒ…å«å¤šä¸ªä¸åŒç”¨æˆ·çš„è®¤è¯æ–‡ä»¶ã€‚å°†å¤šç”¨æˆ·å¯¼å‡ºè‡³ç§˜é’¥ç¯: #åˆ›å»ºkeyringæ–‡ä»¶: $ ceph-authtool --create-keyring ceph.client.user.keyring #åˆ›å»ºç©ºçš„keyringæ–‡ä»¶ creating ceph.client.user.keyring #æŠŠæŒ‡å®šçš„adminç”¨æˆ·çš„keyringæ–‡ä»¶å†…å®¹å¯¼äººåˆ°userç”¨æˆ·çš„keyringæ–‡ä»¶: $ceph-authtool ./ceph.client.user.keyring --import-keyring ./ceph.client.admin.keyring importing contents of ./ceph.client.admin.keyring into ./ceph.client.user.keyring #éªŒè¯keyringæ–‡ä»¶: [ceph@ceph-deploy ceph-cluster]$ ceph-authtool -I ./ceph.client.user.keyring [client.admin] key = AQAGDKJfQk/dAxAA3Y +9xoE/p8in6QjoHeXmeg== caps mds = \"allow *\" caps mgr = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" #å†å¯¼å…¥ä¸€ä¸ªå…¶ä»–ç”¨æˆ·çš„keyring: (ceph@ceph-deploy ceph-cluster]$ceph-authtool ./ceph.client.user.keyring --import-kevring ./ceph.client.user1.kevring #å†æ¬¡éªŒè¯keyringæ–‡ä»¶æ˜¯å¦åŒ…å«å¤šä¸ªç”¨æˆ·çš„è®¤è¯ä¿¡æ¯: [ceph@ceph-deploy ceph-cluster]$ ceph- authtool -I ./ceph.client.user.keyring [client.admin] key = AQAGDKJfQk/dAxAA3Y +9xoE/p8in6QjoHeXmeg== caps mds = \"allow *\" caps mgr = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" [client.user1] key = AQAUUchfjpMqGRAARV6h0ofdDEneuaRnxuHjoQ== caps mon = \"allow r\" caps osd = \"allow * pool=mypool\"","date":"2023-01-13","objectID":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/:5:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"CephX è®¤è¯æœºåˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/ceph/5.-cephx%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/"},{"categories":["Ceph"],"content":"cephé›†ç¾¤é…ç½®ã€éƒ¨ç½²ä¸è¿ç»´ http://docs.ceph.org.cn/rados/ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:0:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.1:é€šè¿‡å¥—æ¥å­—è¿›è¡Œå•æœºç®¡ç† æ¯ä¸ªnodeèŠ‚ç‚¹ä¸Šéƒ½æœ‰ä¸åŒæ•°é‡çš„OSDæ•°é‡ å¯åŠ¨osdè¿›ç¨‹ä¼šåœ¨ /var/run/cephä¸‹ç”Ÿæˆsokeæ–‡ä»¶ ls /var/run/ceph ceph-osd.0.asok= ceph-osd.1.asok= ceph-osd.2.asok= ceph-osd.3.asok= ceph-osd.4.asok=","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"å¯åœ¨nodeèŠ‚ç‚¹æˆ–è€…monèŠ‚ç‚¹é€šè¿‡cephå‘½ä»¤è¿›è¡Œå•æœºç®¡ç†æœ¬æœºçš„monæˆ–è€…osdæœåŠ¡ å…ˆå°†adminè®¤è¯æ–‡ä»¶åŒæ­¥åˆ°monæˆ–è€…nodeèŠ‚ç‚¹ ceph@ceph-deploy:/home/ceph/ceph-cluster$scp ceph.client.admin.keyring root@172.31.6.101:/etc/ceph #æŒ‡å®šè¦ç®¡ç†çš„asokæ–‡ä»¶ [root@ceph-node1 ~]# ceph -- admin-socket /var/run/ceph/ceph-osd.0.asok --help -- admin-daemon åœ¨ monèŠ‚ç‚¹è·å–daemonæœåŠ¡å¸®åŠ©: #å¸®åŠ©ä¿¡æ¯: ceph-mon1~]#ceph --admin-daemon /var/run/ceph/ceph-mon.cephjmon1.asok help #monçŠ¶æ€: ceph-mon1~]# ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-mon1.asok mon_ status #æŸ¥çœ‹é…ç½®ä¿¡æ¯: ceph-mon1~]# ceph - admin-daemon /var/run/ceph/ceph-mon.ceph-mon1.asok config show","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:1:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.2 cephé›†ç¾¤çš„åœæ­¢æˆ–é‡å¯ é‡å¯ä¹‹å‰æŒ‰ç…§æ­£ç¡®çš„æµç¨‹ï¼Œè¦æå‰è®¾ç½®cephé›†ç¾¤ä¸è¦å°†OSDæ ‡è®°ä¸ºout,é¿å…nodeèŠ‚ç‚¹å…³é—­æœåŠ¡åè¢«è¸¢å‡ºcephé›†ç¾¤å¤– nodeèŠ‚ç‚¹æ¯éš”6så‘monèŠ‚ç‚¹æ±‡æŠ¥ä¸€æ¬¡OSDçŠ¶æ€ï¼Œè¿ç»­20ç§’åæ²¡æœ‰é€šå‘Šæ­£å¸¸monå°±ä¼šæŠŠOSDæ ‡è®°ä¸ºOUT ï¼Œå°±ä¼šè§¦å‘ç£ç›˜çš„é«˜å¯ç”¨å¼€å§‹ç£ç›˜çš„é€‰ä¸¾å’Œæ•°æ®åŒæ­¥ã€‚ #å…³é—­æœåŠ¡å‰è®¾ç½®noout [ceph@ceph-deploy ceph-cluster]$ ceph osd set noout noout is set #å¯åŠ¨æœåŠ¡åå–æ¶ˆnoout [ceph@ceph-deploy ceph-cluster]$ ceph osd unset noout noout is unset","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.2.1 å…³é—­é¡ºåº å…³é—­æœåŠ¡å‰è®¾ç½®noout å…³é—­å­˜å‚¨å®¢æˆ·ç«¯åœæ­¢è¯»å†™æ•°æ® å¦‚æœä½¿ç”¨RGWï¼Œå…³é—­RGW å…³é—­cephfs å…ƒæ•°æ®æœåŠ¡ å…³é—­ceph OSD å…³é—­ceph manager å…³é—­ ceph monitor ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:2:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.2.2 å¯åŠ¨é¡ºåº å¯åŠ¨ ceph monitor å¯åŠ¨ ceph manager å¯åŠ¨ ceph OSD å¯åŠ¨ ceph FS å…ƒæ•°æ®æœåŠ¡ å¯åŠ¨RGW å¯åŠ¨å­˜å‚¨å®¢æˆ·ç«¯ å¯åŠ¨æœåŠ¡åå–æ¶ˆ noout ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:2:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.2.3 æœåŠ¡æ—¶é—´åå·® http://docs.ceph.org.cn/rados/configuration/mon-config-ref/ é‡å¯å‘ç°ï¼š cluster: id:5ac860ab- 9a4e- 4edd- 9da2 e3de293a8d44 health: HEALTH WARN clock skew detected on mon. ceph-mon2, mon. ceph-mon3 noout flag(s) set é€šå¸¸ç”±äºæœåŠ¡å™¨é‡å¯åå¯¼è‡´æ—¶é—´ä¸å¤ªä¸€è‡´ï¼Œå› ä¸ºæœåŠ¡å™¨æœ‰æ—¶é—´åŒæ­¥è®¡åˆ’ä»»åŠ¡åŒæ­¥å‘¨æœŸè¿˜æ²¡åˆ° å¯ä»¥è®¾ç½®ç›‘è§†å™¨è¿è¡Œçš„æ—¶é’Ÿæ¼‚ç§»é‡ï¼Œé»˜è®¤ä¸º0.050ç§’å³50æ¯«ç§’ cat /ceph.conf #è®¾ç½®ç›‘è§†å™¨è¿è¡Œçš„æ—¶é’Ÿæ¼‚ç§»é‡ mon clock drift allowed =3 #æ—¶é’Ÿåç§»è­¦å‘Šçš„é€€é¿æŒ‡æ•¸å³è¿ç»­å¤šå°‘æ¬¡æ—¶é—´åå·®åå°±å‡ºå‘è­¦å‘Š mon clock drift warn backoff= 10 #åŒæ­¥é…ç½®æ–‡ä»¶monæœåŠ¡å™¨ [ceph@ceph-deploy ceph-cluster]$ ceph-deploy --overwrite-conf config push stor01..3) #é‡å¯mon #æ‹·è´æ–¹å¼ #ceph@ceph-deploy:~/ceph-cluster$ scp ceph.conf root@172.31.6.101: /etc/ceph/ #ceph@ceph-deploy:~/ceph-cluster$ scp ceph.conf root@172.31.6.102: /etc/ceph/ #ceph@ceph-deploy:~/ceph-cluster$ scp ceph.conf root@172.31.6.103: /etc/ceph/ [root@ceph-mon1 ~]# ntpdate timel.aliyun.com \u0026\u0026 hwclock -W root@ceph-mon1:~# systemctl restart ceph-mon@ceph-mon1.service","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:2:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.3 ceph é…ç½®æ–‡ä»¶ Cephçš„ä¸»é…ç½®æ–‡ä»¶æ˜¯/etc/ceph/ceph.conf ï¼Œceph æœåŠ¡åœ¨å¯åŠ¨æ—¶ä¼šæ£€æŸ¥ceph.confåˆ†å·;å’Œ#åœ¨é…ç½®æ–‡ä»¶ä¸­éƒ½æ˜¯æ³¨é‡Šï¼Œceph.conf ä¸»è¦ç”±ä»¥ä¸‹é…ç½®æ®µç»„æˆ: :::info [global] #å…¨å±€é…ç½®[osd] #osdä¸“ç”¨é…ç½®ï¼Œå¯ä»¥ä½¿ç”¨osd.N, æ¥è¡¨ç¤ºæŸä¸€ä¸ªOSDä¸“ç”¨é…ç½®ï¼ŒNä¸ºosdçš„ç¼–å·ï¼Œå¦‚0ã€2ã€1ç­‰ï¼Œ [mon] #monä¸“ç”¨é…ç½®ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨mon.Aæ¥ä¸ºæŸä¸€ä¸ªmonitorèŠ‚ç‚¹åšä¸“ç”¨é…ç½®ï¼Œå…¶ä¸­Aä¸ºè¯¥èŠ‚ç‚¹çš„åç§°ï¼Œceph-monitor-2ã€ ceph-monitor-1 ç­‰ï¼Œä½¿ç”¨å‘½ä»¤ceph mon dumpå¯ä»¥è·å–èŠ‚ç‚¹çš„åç§°ã€ [client] #å®¢æˆ·ç«¯ä¸“ç”¨é…ç½®. ::: ceph æ–‡ä»¶çš„åŠ è¼‰é †åº $CEPH_CONF ç¯å¢ƒå˜é‡ -c æŒ‡å®šé…ç½®æ–‡ä»¶ä½ç½® /etc/ceph/ceph.conf ~/.ceph/ceph.conf ./ceph.conf","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.4 å­˜å‚¨æ± ã€PGä¸CRUSH :::info å‰¯æœ¬æ± :repicated,å®šä¹‰æ¯ä¸ªå¯¹è±¡åœ¨é›†ç¾¤ä¸­ä¿å­˜ä¸ºå¤šå°‘ä¸ªå‰¯æœ¬ï¼Œé»˜è®¤ä¸ºä¸‰ä¸ªå‰¯æœ¬, ä¸€ä¸»ä¸¤å¤‡,å®ç°é«˜å¯ç”¨ï¼Œå‰¯æœ¬æ± æ˜¯cephé»˜è®¤çš„å­˜å‚¨æ± ç±»å‹. ::: åœ¨åˆ›å»ºå­˜å‚¨æ± çš„æ—¶å€™å¯ä»¥æŒ‡å®šé»˜è®¤æ˜¯ä¸‰å‰¯æœ¬osd pool create pool --help [replicated] :::info çº åˆ ç æ± (erasure code): cephå¦ä¸€ç§æ•°æ®å¯ç”¨æ€§æœºåˆ¶ä¸€å®šç¨‹åº¦ä¸Šå®ç°æ•°æ®é«˜å¯ç”¨ï¼ˆä½¿ç”¨çš„ä¸å¤šï¼‰ï¼Œå­˜å‚¨æœºåˆ¶ç±»ä¼¼äºraid5 æŠŠä¸€éƒ¨åˆ†å­˜å‚¨ç©ºé—´ç”¨äºå­˜æ”¾æ ¡éªŒç å®ç°æ•°æ®æ¢å¤çš„ç›®çš„ï¼Œæ—¢å¯ä»¥æé«˜ç£ç›˜ç©ºé—´åˆ©ç”¨ç‡ï¼Œåˆèƒ½å®ç°ä¸€å®šç¨‹åº¦ä¸Šçš„æ•°æ®é«˜å¯ç”¨ã€‚å’Œraidæœºåˆ¶ä¸€æ ·ä¸èƒ½åä¸€å®šæ•°é‡çš„ç£ç›˜æ‰€ä»¥é«˜å¯ç”¨æœºåˆ¶æœ‰é™ã€‚ ::: ä½†æ˜¯ä¸æ˜¯æ‰€æœ‰åº”ç”¨éƒ½æ”¯æŒçº åˆ ç æ± ï¼ŒRDBå—å­˜å‚¨åªæ”¯æŒå‰¯æœ¬æ± è€Œradosgw å¯ä»¥æ”¯æŒçº åˆ ç æ±  ä¸€éƒ¨åˆ†å­˜æ•°æ®ã€ä¸€éƒ¨åˆ†å­˜æ ¡éªŒç  æŠŠå„å¯¹è±¡å­˜å‚¨ä¸ºN=K+Mä¸ªå—ï¼Œå…¶ä¸­Kä¸ºæ•°æ®å—æ•°é‡ï¼ŒMä¸ºç¼–ç å¿«æ•°é‡ï¼Œå› æ­¤å­˜å‚¨æ± çš„å°ºå¯¸ä¸ºK+M. å³æ•°æ®ä¿å­˜åœ¨Kä¸ªæ•°æ®å—,å¹¶æä¾›Mä¸ªå†—ä½™å—æä¾›æ•°æ®é«˜å¯ç”¨ï¼Œé‚£ä¹ˆæœ€å¤šèƒ½æ•…éšœçš„å—å°±æ˜¯Mä¸ª,å®é™…çš„ç£ç›˜å ç”¨å°±æ˜¯K+Må—ï¼Œå› æ­¤ç›¸æ¯”å‰¯æœ¬æ± æœºåˆ¶æ¯”è¾ƒèŠ‚çœå­˜å‚¨èµ„æºã€‚ ä¸€èˆ¬é‡‡ç”¨8+4æœºåˆ¶ï¼Œå³8ä¸ªæ•°æ®å—+4ä¸ªå†—ä½™å—ï¼Œé‚£ä¹ˆä¹Ÿå°±æ˜¯12ä¸ªæ•°æ®å—æœ‰8ä¸ªæ•°æ®å—ä¿å­˜æ•°æ®,æœ‰4ä¸ªå®ç°æ•°æ®å†—ä½™ï¼Œå³1/3çš„ç£ç›˜ç©ºé—´ç”¨äºæ•°æ®å†—ä½™ï¼Œæ¯”é»˜è®¤å‰¯æœ¬æ± çš„ä¸‰å€å†—ä½™èŠ‚çœç©ºé—´,ä½†æ˜¯ä¸èƒ½å‡ºç°å¤§äºä¸€å®šæ•°æ®å—æ•…éšœã€‚ ä½†æ˜¯ä¸æ˜¯æ‰€æœ‰çš„åº”ç”¨éƒ½æ”¯æŒçº åˆ ç æ± ï¼ŒRBDåªæ”¯æŒå‰¯æœ¬æ± è€ŒTjadosgwåˆ™å¯ä»¥æ”¯æŒçº åˆ ç æ± ã€‚ åˆ›å»ºçº åˆ ç æ±  ceph osd pool create erasure-testpool 32 32 erasureå†™å…¥æ•°æ® sudo rados put -p erasure-testpool testfile1 /var/log/syslogéªŒè¯æ•°æ® ceph osd map erasure-testpool testfile1éªŒè¯å½“å‰pgçŠ¶æ€ ceph pg ls-by-pool erasure-testpool | awk '{print $1,$2,$15}'","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.4.1 å‰¯æœ¬æ±  å°†ä¸€ä¸ªæ•°æ®å¯¹è±¡å­˜å‚¨ä¸ºå¤šä¸ªå‰¯æœ¬ åœ¨å®¢æˆ·ç«¯å†™å…¥æ“ä½œæ—¶ï¼Œcephä½¿ç”¨CRUSHç®—æ³•è®¡ç®—å‡ºä¸å¯¹è±¡ç›¸å¯¹åº”çš„PG IDå’Œprimary OSD ä¸»OSDæ ¹æ®è®¾ç½®çš„å‰¯æœ¬æ•°ã€å¯¹è±¡åç§°ã€å­˜å‚¨æ± åç§°å’Œ**é›†ç¾¤è¿è¡Œå›¾(cluster map)**è®¡ç®—å‡ºPG çš„å„è¾…åŠ©OSDï¼Œç„¶åç”±OSDå°†æ•°æ®å†åŒæ­¥ç»™è¾…åŠ©OSD. è¯»å–æ•°æ®: 1.å®¢æˆ·ç«¯å‘é€è¯»è¯·æ±‚ï¼ŒRADOS å°†è¯·æ±‚å‘é€åˆ°ä¸»OSD. 2.ä¸»OSDä»æœ¬åœ°ç£ç›˜è¯»å–æ•°æ®å¹¶è¿”å›æ•°æ®ï¼Œæœ€ç»ˆå®Œæˆè¯»è¯·æ±‚ã€‚ å†™å…¥æ•°æ®: å®¢æˆ·ç«¯APPè¯·æ±‚å†™å…¥æ•°æ®ï¼ŒRADOSå‘é€æ•°æ®åˆ°ä¸»OSD. ä¸»OSDè¯†åˆ«å‰¯æœ¬OSDs,å¹¶å‘é€æ•°æ®åˆ°å„å‰¯æœ¬OSD. å‰¯æœ¬OSDså†™å…¥æ•°æ®ï¼Œå¹¶å‘é€å†™å…¥å®Œæˆä¿¡å·ç»™ä¸»OSD. ä¸»OSDå‘é€å†™äººå®Œæˆä¿¡å·ç»™å®¢æˆ·ç«¯APP. ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:4:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.4.2 çº åˆ ç æ±  çº åˆ ç æ± é™ä½äº†æ•°æ®ä¿å­˜æ‰€éœ€è¦çš„ç£ç›˜æ€»ç©ºé—´æ•°é‡ï¼Œä½†æ˜¯è¯»å†™æ•°æ®çš„è®¡ç®—æˆæœ¬è¦æ¯”å‰¯æœ¬æ± é«˜RGWå¯ä»¥æ”¯æŒçº åˆ ç æ± ï¼ŒRBD ä¸æ”¯æŒçº åˆ ç æ± å¯ä»¥é™ä½ä¼ä¸šçš„å‰æœŸTCOæ€»æ‹¥æœ‰æˆæœ¬ã€‚ çº åˆ ç å†™:æ•°æ®å°†åœ¨ä¸»OSDè¿›è¡Œç¼–ç ç„¶ååˆ†å‘åˆ°ç›¸åº”çš„OSDs.ä¸Šå»ã€‚1.è®¡ç®—åˆé€‚çš„æ•°æ®å—å¹¶è¿›è¡Œç¼–ç 2.å¯¹æ¯ä¸ªæ•°æ®å—è¿›è¡Œç¼–ç å¹¶å†™å…¥OSD çº åˆ ç è¯»:ä»ç›¸åº”çš„OSDsä¸­è·å–æ•°æ®åè¿›è¡Œè§£ç ï¼Œå¦‚æœæ­¤æ—¶æœ‰æ•°æ®ä¸¢å¤±ï¼ŒCeph ä¼šè‡ªåŠ¨ä»å­˜æ”¾æ ¡éªŒç çš„OSDä¸­è¯»å–æ•°æ®è¿›è¡Œè§£ç ã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:4:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.5 PGä¸PGP :::info PG = Placement Group å½’ç½®ç»„PGP = Placement Group for Placement purpose å½’ç½®ç»„çš„ç»„åˆï¼Œ pgp ç›¸å½“äºæ˜¯pgå¯¹åº”osdçš„ä¸€ç§æ’åˆ—ç»„åˆå…³ç³»ã€‚ ::: **å½’ç½®ç»„(placement group)**æ˜¯ç”¨äºè·¨è¶Šå¤šOSDå°†æ•°æ®å­˜å‚¨åœ¨æ¯ä¸ªå­˜å‚¨æ± ä¸­çš„å†…éƒ¨æ•°æ®ç»“æ„.å½’ç½®ç»„åœ¨OSDå®ˆæŠ¤è¿›ç¨‹å’Œcephå®¢æˆ·ç«¯ä¹‹é—´ç”Ÿæˆäº†ä¸€ä¸ªä¸­é—´å±‚ï¼ŒCRUSH ç®—æ³•è´Ÿè´£å°†æ¯ä¸ªå¯¹è±¡åŠ¨æ€æ˜ å°„åˆ°ä¸€ä¸ªå½’ç½®ç»„ï¼Œç„¶åå†å°†æ¯ä¸ªå½’ç½®ç»„åŠ¨æ€æ˜ å°„åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªOSDå®ˆæŠ¤è¿›ç¨‹,ä»è€Œèƒ½å¤Ÿæ”¯æŒåœ¨æ–°çš„OSDè®¾å¤‡ä¸Šçº¿æ—¶è¿›è¡Œæ•°æ®é‡æ–°å¹³è¡¡ã€‚ ç›¸å¯¹äºå­˜å‚¨æ± æ¥è¯´ï¼ŒPGæ˜¯ä¸€ä¸ªè™šæ‹Ÿç»„ä»¶ï¼Œå®ƒæ˜¯å¯¹è±¡æ˜ å°„åˆ°å­˜å‚¨æ± æ—¶ä½¿ç”¨çš„è™šæ‹Ÿå±‚ã€‚æ ¹æ®ä¸šåŠ¡çš„æ•°æ®é‡åˆ†é…PG ä¸€èˆ¬ å‡ ç™¾ä¸ªG16å’Œ32å°±å¯ä»¥ï¼ŒTBçº§ 64 åˆ°128ã€‚2çš„æ¬¡æ–¹ æƒ³å¯¹äºå­˜å‚¨æ± æ¥è¯´ï¼ŒPG æ˜¯ä¸€ä¸ªè™šæ‹Ÿç»„ä»¶ï¼Œå®ƒæ˜¯å¯¹è±¡æ˜ å°„åˆ°å­˜å‚¨æ± æ—¶ä½¿ç”¨çš„è™šæ‹Ÿå±‚ã€‚å¯ä»¥è‡ªå®šä¹‰å­˜å‚¨æ± ä¸­çš„å½’ç½®ç»„æ•°é‡ã€‚ cephå‡ºäºè§„æ¨¡ä¼¸ç¼©åŠæ€§èƒ½æ–¹é¢çš„è€ƒè™‘ï¼Œceph å°†å­˜å‚¨æ± ç»†åˆ†ä¸ºå¤šä¸ªå½’ç½®ç»„ï¼ŒæŠŠæ¯ä¸ªå•ç‹¬çš„å¯¹è±¡æ˜ å°„åˆ°å½’ç½®ç»„ï¼Œå¹¶ä¸ºå½’ç½®ç»„åˆ†é…ä¸€ä¸ªä¸»OSD. å­˜å‚¨æ± ç”±ä¸€ç³»åˆ—çš„å½’ç½®ç»„ç»„æˆï¼Œè€ŒCRUSHç®—æ³•åˆ™æ ¹æ®é›†ç¾¤è¿è¡Œå›¾å’Œé›†ç¾¤çŠ¶æ€ï¼Œå°†ä¸ªPGå‡åŒ€ã€ä¼ªéšæœº(åŸºäºhashæ˜ å°„ï¼Œæ¯æ¬¡çš„è®¡ç®—ç»“æœå¤Ÿ æ ·)çš„åˆ†å¸ƒåˆ°é›†ç¾¤ä¸­çš„OSDä¹‹ä¸Šã€‚å¦‚æœæŸä¸ªOSDå¤±è´¥æˆ–éœ€è¦å¯¹é›†ç¾¤è¿›è¡Œé‡æ–°å¹³è¡¡ï¼Œceph åˆ™ç§»åŠ¨æˆ–å¤åˆ¶æ•´ä¸ªå½’ç½®ç»„è€Œä¸éœ€è¦å•ç‹¬å¯¹æ¯ä¸ªé•œåƒè¿›è¡Œå¯»å€ã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:5:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.6 PGä¸ OSDçš„å…³ç³» cephåŸºäºcrushç®—æ³•å°†å½’ç½®ç»„PGåˆ†é…è‡³OSDå½“ä¸€ä¸ªå®¢æˆ·ç«¯å­˜å‚¨å¯¹è±¡çš„æ—¶å€™ï¼ŒCRUSH ç®—æ³•æ˜ å°„æ¯ä¸€ä¸ªå¯¹è±¡è‡³å½’ç½®ç»„(PG) ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:6:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.7 PGåˆ†é…è®¡ç®— å½’ç½®ç»„(PG)çš„æ•°é‡æ˜¯ç”±ç®¡ç†å‘˜åœ¨åˆ›å»ºå­˜å‚¨æ± çš„æ—¶å€™æŒ‡å®šçš„ï¼Œç„¶åç”±CRUSHè´Ÿè´£åˆ›å»ºå’Œä½¿ç”¨ï¼ŒPGçš„æ•°é‡æ˜¯2çš„Næ¬¡æ–¹çš„å€æ•°,æ¯ä¸ªOSDçš„PGä¸è¦è¶…å‡º250ä¸ªPGï¼Œå®˜æ–¹æ˜¯æ¯ä¸ªOSD100ä¸ªå·¦å³ ä¸€ä¸ªç£ç›˜å¯èƒ½å±äºå¤šä¸ªPGåˆ†åˆ«æ‹…ä»»ä¸åŒçš„è§’è‰²ï¼Œhttps://docs.ceph.com/en/mimic/rados/configuration/pool-pg-config-ref/ recommend approximatelyç¡®ä¿è®¾ç½®äº†åˆé€‚çš„å½’ç½®ç»„å¤§å°ï¼Œæˆ‘ä»¬å»ºè®®æ¯ä¸ªOSDå¤§çº¦100ä¸ªï¼Œä¾‹å¦‚ï¼Œosd æ€»æ•°ä¹˜ä»¥100é™¤ä»¥å‰¯æœ¬æ•°é‡(å³ osdæ± é»˜è®¤å¤§å°)ï¼Œå› æ­¤ï¼Œå¯¹äº10ä¸ªosdã€å­˜å‚¨æ± ä¸º4ä¸ªï¼Œæˆ‘ä»¬å»ºè®®æ¯ä¸ªå­˜å‚¨æ± å¤§çº¦(100 * 10) /4= 250 å…ˆç®—ç£ç›˜æ•°é‡æ˜¯å¤šå°‘å—ï¼Œå®˜æ–¹æ¨èæ¯ä¸ªOSDæ˜¯100ä¸ªPGå·¦å³ï¼Œ10å—å°±æ˜¯1000ä¸ªPG PGçš„æ•°é‡åœ¨é›†ç¾¤åˆ†å‘æ•°æ®å’Œé‡æ–°å¹³è¡¡æ—¶æ‰®æ¼”è€…é‡è¦çš„è§’è‰² PGçš„æ•°é‡è¿‡å°‘ï¼ŒPGçš„æ•°é‡åœ¨cephåŒæ­¥æ•°æ®æ—¶æœ‰çŸ­æš‚å½±å“ï¼Œä¸€ä¸ªOSDä¸Šä¿å­˜çš„æ•°æ®æ•°æ®ä¼šç›¸å¯¹åŠ å¤šï¼Œé‚£ä¹ˆcephåŒæ­¥æ•°æ®çš„æ—¶å€™äº§ç”Ÿçš„ç½‘ç»œè´Ÿè½½å°†å¯¹é›†ç¾¤çš„æ€§èƒ½è¾“å‡ºäº§ç”Ÿä¸€å®šå½±å“ã€‚ PGæ•°é‡å¤ªå°‘ æ•°æ®é‡åˆå¤§ï¼Œé‚£ä¹ˆå¿…ç„¶åŒæ­¥æ˜¯æ—¶é—´å°±é•¿ PGè¿‡å¤šçš„æ—¶å€™ï¼Œcephå°†ä¼šå ç”¨è¿‡å¤šçš„CPUå’Œå†…å­˜èµ„æºç”¨äºè®°å½•PGçš„çŠ¶æ€ä¿¡æ¯ è‡³äºä¸€ä¸ªpoolåº”è¯¥ä½¿ç”¨å¤šå°‘ä¸ªPGï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢çš„å…¬å¼è®¡ç®—åï¼Œå°†poolçš„PGå€¼å››èˆäº”äººåˆ°æœ€è¿‘çš„2çš„Næ¬¡å¹‚ï¼Œå¦‚ä¸‹å…ˆè®¡ç®—å‡ºcephé›†ç¾¤çš„æ€»PGæ•°: ç£ç›˜æ€»æ•°xæ¯ä¸ªç£ç›˜PGæ•°/å‰¯æœ¬æ•°=\u003e cephé›†ç¾¤æ€»PGæ•°(ç•¥å¤§äº2^næ¬¡æ–¹)å•ä¸ªpoolçš„PGè®¡ç®—å¦‚ä¸‹: :::info æœ‰100ä¸ªosd,3å‰¯æœ¬ï¼Œ5ä¸ªpoolTotal PGS =100*100/3-3333æ¯ä¸ªpoolçš„PG=3333/5=512.é‚£ä¹ˆåˆ›å»ºpoolçš„æ—¶å€™å°±æŒ‡å®špgä¸º512 ::: éœ€è¦ç»“åˆæ•°æ®æ•°é‡ã€ç£ç›˜æ•°é‡åŠç£ç›˜ç©ºé—´è®¡ç®—å‡ºPGæ•°é‡ï¼Œ8ã€16ã€ 32ã€64ã€128ã€ 256ç­‰2çš„Næ¬¡æ–¹ã€‚ä¸€ä¸ªRADOSé›†ç¾¤ä¸Šä¼šå­˜åœ¨å¤šä¸ªå­˜å‚¨æ± ï¼Œå› æ­¤ç®¡ç†å‘˜è¿˜éœ€è¦è€ƒè™‘æ‰€æœ‰å­˜å‚¨æ± ä¸Šçš„PGåˆ†å¸ƒåæ¯ä¸ªOSDéœ€è¦æ˜ å°„çš„PGæ•°é‡. ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:7:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8 PGçš„çŠ¶æ€ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.1:Peering æ­£åœ¨åŒæ­¥çŠ¶æ€ï¼ŒåŒä¸€ä¸ªPGä¸­çš„OSDéœ€è¦å°†å‡†å¤‡æ•°æ®åŒæ­¥ä¸€è‡´, è€ŒPeering(å¯¹ç­‰)å°±æ˜¯OSDåŒæ­¥è¿‡ç¨‹ä¸­çš„çŠ¶æ€ã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.2:Activating Peeringå·²ç»å®Œæˆï¼ŒPG æ­£åœ¨ç­‰å¾…æ‰€æœ‰PGå®ä¾‹åŒæ­¥Peeringçš„ç»“æœ(infoã€Logç­‰) ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.3 Clean ç£ç›˜æ²¡æœ‰å®•æœº å¹²å‡€æ€,PGå½“å‰ä¸å­˜åœ¨å¾…ä¿®å¤çš„å¯¹è±¡ï¼Œå¹¶ä¸”å¤§å°ç­‰äºå­˜å‚¨æ± çš„å‰¯æœ¬æ•°ï¼Œå³PGçš„æ´»åŠ¨é›†(Acting Set)å’Œä¸Šè¡Œé›†(Up Set)ä¸ºåŒä¸€ç»„OSDä¸”å†…å®¹ä¸€è‡´ã€‚ æ´»åŠ¨é›†(Acting Set):ç”±PGå½“å‰ä¸»çš„OSDå’Œå…¶ä½™å¤„äºæ´»åŠ¨çŠ¶æ€çš„å¤‡ç”¨OSDç»„æˆï¼Œå½“å‰PGå†…çš„OSDè´Ÿè´£å¤„ç†ç”¨æˆ·çš„è¯»å†™è¯·æ±‚ã€‚ ä¸Šè¡Œé›†(Up Set):åœ¨æŸä¸€ä¸ªOSDæ•…éšœæ—¶ï¼Œéœ€è¦å°†æ•…éšœçš„OSDæ›´æ¢ä¸ºå¯ç”¨çš„OSD,å¹¶ä¸»PGå†…éƒ¨çš„ä¸»OSDåŒæ­¥æ•°æ®åˆ°æ–°çš„OSDä¸Šï¼Œä¾‹å¦‚PGå†…æœ‰OSD1ã€OSD2ã€OSD3ï¼Œå½“OSD3æ•…éšœåéœ€è¦ç”¨OSD4æ›¿æ¢OSD3,é‚£ä¹ˆOSD1. OSD2ã€OSD3å°±æ˜¯ä¸Šè¡Œé›†ï¼Œæ›¿æ¢åOSD1ã€OSD2ã€OSD4å°±æ˜¯æ´»åŠ¨é›†ï¼ŒOSD æ›¿æ¢å®Œæˆåæ´»åŠ¨é›†æœ€ç»ˆè¦æ›¿æ¢ä¸Šè¡Œé›†ã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.4 Active æ­£å¸¸å°±ç»ªçŠ¶æ€æˆ–æ´»è·ƒçŠ¶æ€ï¼ŒActive è¡¨ç¤ºä¸»OSDå’Œå¤‡OSDå¤„äºæ­£å¸¸å·¥ä½œçŠ¶æ€ï¼Œæ­¤æ—¶çš„PGå¯ä»¥æ­£å¸¸å¤„ç†æ¥è‡ªå®¢æˆ·ç«¯çš„è¯»å†™è¯·æ±‚ï¼Œæ­£å¸¸çš„PGé»˜è®¤å°±æ˜¯Active+CleançŠ¶æ€ã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.5 Degraded é™çº§çŠ¶æ€ ä¸€èˆ¬å‡ºç°åœ¨ç£ç›˜å®•æœºåï¼Œå¹¶ä¸”ä¸€æ®µæ—¶é—´æ²¡æœ‰æ¢å¤é™çº§çŠ¶æ€å‡ºç°äºOSDè¢«æ ‡è®°ä¸ºdownä»¥åï¼Œé‚£ä¹ˆå…¶ä»–æ˜ å°„åˆ°æ­¤OSDçš„PGéƒ½ä¼šè½¬æ¢åˆ°é™çº§çŠ¶æ€ã€‚å¦‚æœæ­¤OSDè¿˜èƒ½é‡æ–°å¯åŠ¨å®Œæˆå¹¶å®ŒæˆPeeringæ“ä½œå,é‚£ä¹ˆä½¿ç”¨æ­¤OSDçš„PGå°†é‡æ–°æ¢å¤ä¸ºcleançŠ¶æ€ã€‚å¦‚æœæ­¤OSDè¢«æ ‡è®°ä¸ºdownçš„æ—¶é—´è¶…è¿‡5åˆ†é’Ÿè¿˜æ²¡æœ‰ä¿®å¤ï¼Œé‚£ä¹ˆæ­¤OSDå°†ä¼šè¢«cephè¸¢å‡ºé›†ç¾¤ï¼Œç„¶åcephä¼šå¯¹è¢«é™çº§çš„PGå¯åŠ¨æ¢å¤æ“ä½œï¼Œç›´åˆ°æ‰€æœ‰ç”±äºæ­¤OSDè€Œè¢«é™çº§çš„PGé‡æ–°æ¢å¤ä¸ºcleançŠ¶æ€ã€‚æ¢å¤æ•°æ®ä¼šä»PGå†…çš„ä¸»OSDæ¢å¤ï¼Œå¦‚æœæ˜¯ä¸»OSDæ•…éšœï¼Œé‚£ä¹ˆä¼šåœ¨å‰©ä¸‹çš„ä¸¤ä¸ªå¤‡ç”¨OSDé‡æ–°é€‰æ‹©ä¸€ä¸ªä½œä¸ºä¸»OSD. ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.6 Stale:è¿‡æœŸçŠ¶æ€ å‘ç”Ÿåœ¨OSDä¸»å®•äº†ï¼Œæ•°æ®ä¸æ˜¯æœ€æ–°æ­£å¸¸çŠ¶æ€ä¸‹ï¼Œæ¯ä¸ªä¸»OSDéƒ½è¦å‘¨æœŸæ€§çš„å‘RADOSé›†ç¾¤ä¸­çš„ç›‘è§†å™¨(Mon)æŠ¥å‘Šå…¶ä½œä¸ºä¸»OSDæ‰€æŒæœ‰çš„æ‰€æœ‰PGçš„æœ€æ–°ç»Ÿè®¡æ•°æ®ï¼Œå› ä»»ä½•åŸå› å¯¼è‡´æŸä¸ªOSDæ— æ³•æ­£å¸¸å‘ç›‘è§†å™¨å‘é€æ±‡æŠ¥ä¿¡æ¯çš„ã€æˆ–è€…ç”±å…¶ä»–OSDæŠ¥å‘ŠæŸä¸ªOSDå·²ç»downçš„æ—¶å€™ï¼Œåˆ™æ‰€æœ‰ä»¥æ­¤OSDä¸ºä¸»PGåˆ™ä¼šç«‹å³è¢«æ ‡è®°ä¸ºstale çŠ¶æ€ï¼Œå³ä»–ä»¬çš„ä¸»OSDå·²ç»ä¸æ˜¯æœ€æ–°çš„æ•°æ®äº†ï¼Œå¦‚æœæ˜¯å¤‡ä»½çš„OSDå‘é€downçš„æ—¶å€™ï¼Œåˆ™cephä¼šæ‰§è¡Œä¿®å¤è€Œä¸ä¼šè§¦å‘PGçŠ¶æ€è½¬æ¢ä¸ºstaleçŠ¶æ€ä¸ä¼šåˆ‡æ¢ä¸»ã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.7 undersized ä¸€ä¸»ä¸¤å‰¯æœ¬ï¼Œå¤‡å®•äº† å‡ºç°å‰¯æœ¬æ•°å¤ªä½äº†PGå½“å‰å‰¯æœ¬æ•°å°äºå…¶å­˜å‚¨æ± å®šä¹‰çš„å€¼çš„æ—¶å€™ï¼ŒPGä¼šè½¬æ¢ä¸ºundersixedçŠ¶æ€ï¼Œæ¯”å¦‚ä¸¤ä¸ªå¤‡ä»½OSDéƒ½downäº†ï¼Œé‚£ä¹ˆæ­¤æ—¶PGä¸­å°±åªæœ‰ä¸€ä¸ªä¸»OSDäº†ï¼Œä¸ç¬¦åˆcephæœ€å°‘è¦æ±‚ä¸€ä¸ªä¸»OSDåŠ ä¸€ä¸ªå¤‡OSDçš„è¦æ±‚ï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´ä½¿ç”¨æ­¤OSDçš„PGè½¬æ¢ä¸ºundersizedçŠ¶æ€ï¼Œç›´åˆ°æ·»åŠ å¤‡ä»½OSDæ·»åŠ å®Œæˆï¼Œæˆ–è€…ä¿®å¤å®Œæˆã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:7","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.8 Scrubbing æ¯å¤©è¿›è¡Œæ•°æ®çš„æµ…æ¸…ç†ï¼ˆæ•´ç†å…ƒæ•°æ®ï¼‰ï¼Œæ¯å‘¨è¿›è¡Œæ•°æ®çš„æ·±æ¸…ç†ï¼ˆæ•´ç†å…ƒæ•°æ®å’Œæ•°æ®æœ¬èº«ï¼‰scrubæ˜¯cephå¯¹æ•°æ®çš„æ¸…æ´—çŠ¶æ€ï¼Œç”¨æ¥ä¿è¯æ•°æ®å®Œæ•´æ€§çš„æœºåˆ¶, Cephçš„OSDå®šæœŸå¯åŠ¨scrubçº¿ç¨‹æ¥æ‰«æéƒ¨åˆ†å¯¹è±¡ï¼Œé€šè¿‡ä¸å…¶ä»–å‰¯æœ¬æ¯”å¯¹æ¥å‘ç°æ˜¯å¦ä¸€è‡´ï¼Œ å¦‚æœå­˜åœ¨ä¸ä¸€è‡´,æŠ›å‡ºå¼‚å¸¸æç¤ºç”¨æˆ·æ‰‹åŠ¨è§£å†³ã€‚scrub ä»¥PGä¸ºå•ä½ï¼Œå¯¹äºæ¯ä¸€ä¸ªpg, ceph åˆ†æè¯¥pgä¸‹æ‰€æœ‰çš„object,äº§ç”Ÿä¸€ä¸ªç±»ä¼¼äºå…ƒæ•°æ®ä¿¡æ¯æ‘˜è¦çš„æ•°æ®ç»“æ„,å¦‚å¯¹è±¡å¤§å°ï¼Œå±æ€§ç­‰,å«scrubmap,æ¯”è¾ƒä¸»ä¸å‰¯scrubmap,æ¥ä¿è¯æ˜¯ä¸æ˜¯æœ‰objectä¸¢å¤±æˆ–è€…ä¸åŒ¹é…ï¼Œæ‰«æåˆ†ä¸ºè½»é‡çº§æ‰«æå’Œæ·±åº¦æ‰«æï¼Œè½»é‡çº§æ‰«æä¹Ÿå«åšlight scrubsæˆ–è€…shallow scrubsæˆ–è€…simply scrubså³è½»é‡çº§æ‰«æ.Light scrub(daily)æ¯”è¾ƒobject sizeå’Œå±æ€§ï¼Œdeep scrub (weekly)è¯»å–æ•°æ®éƒ¨åˆ†å¹¶é€šè¿‡checksum(CRC32ç®—æ³•)å¯¹æ¯”å’Œæ•°æ®çš„ä¸€è‡´æ€§,æ·±åº¦æ‰«æè¿‡ç¨‹ä¸­çš„PGä¼šå¤„scrubbing +deepçŠ¶æ€. ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:8","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.9:Recovering: æ­£åœ¨æ¢å¤æ€ï¼Œé›†ç¾¤æ­£åœ¨æ‰§è¡Œè¿ç§»æˆ–åŒæ­¥å¯¹è±¡å’Œä»–ä»¬çš„å‰¯æœ¬ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºæ·»åŠ äº†ä¸€ä¸ªæ–°çš„OSDåˆ°é›†ç¾¤ä¸­æˆ–è€…æŸä¸ªOSDå®•æ‰åï¼ŒPGå¯èƒ½ä¼šè¢«CRUSHç®—æ³•é‡æ–°åˆ†é…ä¸åŒçš„OSD,è€Œç”±äºOSDæ›´æ¢å¯¼è‡´PGå‘ç”Ÿå†…éƒ¨æ•°æ®åŒæ­¥çš„è¿‡ç¨‹ä¸­çš„PGä¼šè¢«æ ‡è®°ä¸ºRecovering. ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:9","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.10 Backfilling æ­£åœ¨åå°å¡«å……æ€,backfillæ˜¯recoveryçš„ä¸€ç§ç‰¹æ®Šåœºæ™¯, æŒ‡peeringå®Œæˆåï¼Œå¦‚æœåŸºäºå½“å‰æƒå¨æ—¥å¿—æ— æ³•å¯¹Up Set (. ä¸Šè¡Œé›†)å½“ä¸­çš„æŸäº›PGå®ä¾‹å®æ–½å¢é‡åŒæ­¥(ä¾‹å¦‚æ‰¿è½½è¿™äº›PGå®ä¾‹çš„OSDç¦»çº¿å¤ªä¹…,æˆ–è€…æ˜¯æ–°çš„OSDåŠ å…¥é›†ç¾¤å¯¼è‡´çš„PGå®ä¾‹æ•´ä½“è¿ç§»)åˆ™é€šè¿‡å®Œå…¨æ‹·è´å½“å‰Primaryæ‰€æœ‰å¯¹è±¡çš„æ–¹å¼è¿›è¡Œå…¨é‡åŒæ­¥ï¼Œæ­¤è¿‡ç¨‹ä¸­çš„PGä¼šå¤„äºbackilling. ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:10","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.8.11 Backfill-toofull æŸä¸ªéœ€è¦è¢«Backfillçš„PGå®ä¾‹ï¼Œå…¶æ‰€åœ¨çš„OSDå¯ç”¨ç©ºé—´ä¸è¶³ï¼ŒBackfill æµç¨‹å½“å‰è¢«æŒ‚èµ·æ—¶PGç»™çš„çŠ¶æ€ã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:8:11","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.9 cephå­˜å‚¨æ± æ“ä½œ å­˜å‚¨æ± çš„ç®¡ç†é€šå¸¸ä¿å­˜åˆ›å»ºã€åˆ—å‡ºã€é‡å‘½åå’Œåˆ é™¤ç­‰æ“ä½œï¼Œç®¡ç†å·¥å…·ä½¿ç”¨ceph osd poolçš„å­å‘½ä»¤åŠå‚æ•°ï¼Œæ¯”å¦‚create/ls/rename/rmç­‰ã€‚cephå®˜æ–¹è¿ç»´æ‰‹å†Œhttp://docs.ceph.org.cn/rados/ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:9:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.9.1 å¸¸ç”¨å‘½ä»¤ åˆ›å»ºå­˜å‚¨æ± å‘½ä»¤æ ¼å¼ $ceph osd pool create \u003cpoolname\u003e pg. num pgp_ num {replicatedlerasure} #åˆ—å‡ºå­˜å‚¨æ± : [ceph@ceph-deploy ceph-cluster]$ ceph osd poolls [detail] #ä¸å¸¦ pool ID mypool myrdb1 .rgw.root default.rgw.control default.rgw.meta default.rgw.log cephfs-metadata cephfs-data #å¸¦pool ID ceph osd poolls #æŸ¥çœ‹è¯¦ç»† ceph osd pool ls detail #æŸ¥çœ‹å­˜å‚¨æ± çš„äº‹ä»¶ä¿¡æ¯ ceph osd pool stats mypool #é‡å‘½åå­˜å‚¨æ±  ceph osd pool rename old-name new-name ceph osd pool rename myrbd1 myrbd2 #æ˜¾ç¤ºå­˜å‚¨æ± ç”¨é‡ ceph df rados df ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:9:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.9.2 åˆ é™¤å­˜å‚¨æ±  cephä¸ºäº†é˜²æ­¢è¯¯åˆ é™¤å­˜å‚¨æ± è®¾ç½®äº†ä¸¤ä¸ªæœºåˆ¶æ¥é˜²æ­¢è¯¯åˆ é™¤æ“ä½œã€‚ ç¬¬ä¸€ä¸ªæœºåˆ¶æ˜¯NODELETE æ ‡å¿—,éœ€è¦è®¾ç½®ä¸ºfalse ä½†æ˜¯é»˜è®¤å°±æ˜¯FALSEã€‚ #åˆ›å»ºä¸€ä¸ªæµ‹è¯•pool ceph osd pool create mypool2 32 32 ceph osd pool get mypool2 nodelete nodeleteï¼šfalse #å¦‚æœè®¾ç½®äº†ä¸ºtrueå°±è¡¨ç¤ºä¸èƒ½åˆ é™¤ï¼Œå¯ä»¥ä½¿ç”¨setæŒ‡ä»¤é‡æ–°è®¾ç½®ä¸ºfalse ceph osd pool set mypool2 nodelete true set pool 9 nodelete to trueç¬¬äºŒä¸ªæœºåˆ¶æ˜¯é›†ç¾¤èŒƒå›´çš„é…ç½®å‚æ•°mon allow pool delete,é»˜è®¤å€¼ä¸ºfalse,å³ç›‘è§†å™¨ä¸å…è®¸åˆ é™¤å­˜å‚¨æ± ï¼Œå¯ä»¥åœ¨ç‰¹å®šåœºåˆä½¿ç”¨tellæŒ‡ä»¤ä¸´æ—¶è®¾ç½®ä¸º(true)å…è®¸åˆ é™¤,åœ¨åˆ é™¤æŒ‡å®šçš„poolä¹‹åå†é‡æ–°è®¾ç½®ä¸ºfalse. $ ceph tell mon.* injectargs --mon-allow-pool-delete=true mon.ceph-mon1:injectargs:mon_allow_pool delete = 'true' mon.ceph-mon2:injectargs:mon_allow_pool delete = 'true' mon.ceph-mon3:injectargs:mon_allow_pool delete = 'true' $ ceph osd pool rm mypool2 mypool2 --yes-i-really-really-mean-it pool 'mypool2' removed","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:9:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.9.3 å­˜å‚¨æ± é…é¢ å­˜å‚¨æ± å¯ä»¥è®¾ç½®ä¸¤ä¸ªé…å¯¹å­˜å‚¨çš„å¯¹è±¡è¿›è¡Œé™åˆ¶ï¼Œä¸€ä¸ªé…é¢æ˜¯æœ€å¤§ç©ºé—´(max_ bytes), å¦å¤–ä¸€ä¸ªé…é¢æ˜¯å¯¹è±¡æœ€å¤§æ•°é‡(max_ objects)ã€‚ #æŸ¥çœ‹å­˜å‚¨æ± é™åˆ¶ $ ceph osd pool get-quota mypool quotas for pool 'mypool': max objects: N/A #é»˜è®¤ä¸é™åˆ¶å¯¹è±¡æ•°é‡ max bytes : N/A #é»˜è®¤ä¸é™åˆ¶ç©ºé—´å¤§å° ---- $ ceph osd pool set-quota mypool max_objects 1000 #é™åˆ¶æœ€å¤§1000ä¸ªå¯¹è±¡ set-quota max_objects = 1000 for pool mypool [ceph@ceph-deploy ceph-cluster]$ ceph osd pool set-quota mypool max_bytes 10737418240 #é™åˆ¶æœ€å¤§10737418240å­—èŠ‚ set-quota max_bytes = 10737418240 for pool mypool","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:9:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.9.4 å­˜å‚¨æ± å¯ç”¨å‚æ•° size: å­˜å‚¨æ± ä¸­çš„å¯¹è±¡å‰¯æœ¬æ•°ï¼Œé»˜è®¤ä¸€ä¸»ä¸¤ä¸ªå¤‡3å‰¯æœ¬ min_size: æä¾›æœåŠ¡æ‰€éœ€è¦çš„æœ€å°å‰¯æœ¬æ•°ï¼Œå¦‚æœå®šä¹‰sizeä¸º3, min_size ä¹Ÿä¸º3,åæ‰ä¸€ä¸ªOSD,å¦‚æœpoolæ± ä¸­æœ‰å‰¯æœ¬åœ¨æ­¤å—OSDä¸Šé¢ï¼Œé‚£ä¹ˆæ­¤poolå°†ä¸æä¾›æœåŠ¡ï¼Œå¦‚æœå°†min_sizeå®šä¹‰ä¸º2ï¼Œé‚£ä¹ˆè¿˜å¯ä»¥æä¾›æœåŠ¡ï¼Œå¦‚æœæä¾›ä¸º1.è¡¨ç¤ºåªè¦æœ‰ä¸€å—å‰¯æœ¬éƒ½æä¾›æœåŠ¡ã€‚ pg_num: æŸ¥çœ‹å½“å‰PGçš„æ•°é‡crush_rule: è®¾ç½®crushç®—æ³•è§„åˆ™crush_ rule: é»˜è®¤ä¸ºå‰¯æœ¬æ± nodelete:æ§åˆ¶æ˜¯å¦å¯åˆ é™¤ï¼Œé»˜è®¤å¯ä»¥nopgchange: æ§åˆ¶æ˜¯å¦å¯æ›´æ”¹å­˜å‚¨æ± çš„pg numå’Œpgp numnosizechange: æ§åˆ¶æ˜¯å¦å¯ä»¥æ›´æ”¹å­˜å‚¨æ± çš„å¤§å°noscrubå’Œnodeep-scrub:æ§åˆ¶æ˜¯å¦ä¸è¿›è¡Œè½»é‡æ‰«ææˆ–æ˜¯å¦æ·±å±‚æ‰«æå­˜å‚¨æ± ï¼Œå¯ä¸´æ—¶è§£å†³é«˜l/0é—®é¢˜scrub_min_interval: é›†ç¾¤å­˜å‚¨æ± çš„æœ€å°æ¸…ç†æ—¶é—´é—´éš”ï¼Œé»˜è®¤å€¼æ²¡æœ‰è®¾ç½®ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶ä¸­çš„osd_scrub_min_interval å‚æ•°æŒ‡å®šé—´éš”æ—¶é—´. scrub_max_interval: æ•´ç†å­˜å‚¨æ± çš„æœ€å¤§æ¸…ç†æ—¶é—´é—´éš”ï¼Œé»˜è®¤å€¼æ²¡æœ‰è®¾ç½®ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶ä¸­çš„osd_scrub_max_interval å‚æ•°æŒ‡å®šã€‚ deep_scrub_interval: æ·±å±‚æ•´ç†å­˜å‚¨æ± çš„æ—¶é—´é—´éš”ï¼Œé»˜è®¤å€¼æ²¡æœ‰è®¾ç½®ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶ä¸­çš„osd_deep_scrub_interval å‚æ•°æŒ‡å®šã€‚ #æŸ¥çœ‹å‰¯æœ¬æ•° ceph osd pool get mypool size size:3 #ä¿®æ”¹å‰¯æœ¬æ•°ä¸º2 ceph osd pool get mypool size 2 #ä¸º2å°±æ˜¯å…è®¸æŒ‚ä¸€ä¸ªOSD ceph osd pool mypool min_size min_size:2 #pg_num:æŸ¥çœ‹å½“å‰PGçš„æ•°é‡ $ ceph osd pool get mypool pg_num pg num: 32 #crush_rule: è®¾ç½®crushç®—æ³•è§„åˆ™ $ ceph osd pool get mypool crush_rule crush_ rule: replicated_rule #é»˜è®¤ä¸ºå‰¯æœ¬æ±  #nodelete:æ§åˆ¶æ˜¯å¦å¯åˆ é™¤ï¼Œé»˜è®¤å¯ä»¥ $ ceph osd pool get mypool nodelete nodelete: false #nopgchange:æ§åˆ¶æ˜¯å¦å¯æ›´æ”¹å­˜å‚¨æ± çš„pg numå’Œpgp num S cenh osd pool get mypool nopgchange #ä¿®æ”¹æŒ‡å®špoolçš„pgæ•°é‡ $ ceph osd pool set mypool pg_num 64 set pool1 pg_num to 64 ##ä¿®æ”¹æŒ‡å®špoolçš„pgpæ•°é‡ $ ceph osd pool set mypool pgp_num 64 #nosizechange:æ§åˆ¶æ˜¯å¦å¯ä»¥æ›´æ”¹å­˜å‚¨æ± çš„å¤§å° $ ceph osd pool get mypool nosizechange nosizechange: false #é»˜è®¤å…è®¸ä¿®æ”¹å­˜å‚¨æ± å¤§å° $ ceph osd pool get-quota mypool quotas for pool 'mypool': max objects: 1 k objects max bytes : 10 GiB #é™åˆ¶å­˜å‚¨æ± æœ€å¤§å†™å…¥å¤§å° ceph osd pool set-quota mypool max bytes 21474836480 #noscrubå’Œnodeep-scrub:æ§åˆ¶æ˜¯å¦ä¸è¿›è¡Œè½»é‡æ‰«ææˆ–æ˜¯å¦æ·±å±‚æ‰«æå­˜å‚¨æ± ï¼Œå¯ä¸´æ—¶è§£å†³é«˜l/0é—®é¢˜ #æŸ¥çœ‹ å½“å‰æ˜¯å¦å…³é—­è½»é‡æ‰«ææ•°æ®ï¼Œé»˜è®¤ä¸ºä¸å…³é—­ï¼Œå³å¼€å¯ $ ceph osd pool get mypool noscrub noscrub: false #å¯ä»¥ä¿®æ”¹æŸä¸ªæŒ‡å®šçš„poolçš„è½»é‡çº§æ‰«ææµ‹é‡ä¸ºtrue,å³ä¸æ‰§è¡Œè½»é‡çº§æ‰«æ $ ceph osd pool set mypool noscrub true set pool 1 noscrub to true #å†æ¬¡ æŸ¥çœ‹å°±ä¸è¿›è¡Œè½»é‡çº§æ‰«æäº† $ ceph osd pool get mypool noscrub noscrub: true #æŸ¥çœ‹å½“å‰æ˜¯å¦å…³é—­æ·±åº¦æ‰«ææ•°æ®ï¼Œé»˜è®¤ä¸ºä¸å…³é—­ï¼Œå³å¼€å¯ $ ceph osd pool get mypool nodeep-scrub nodeep-scrub: false #å†æ¬¡æŸ¥çœ‹å°±ä¸æ‰§è¡Œæ·±åº¦æ‰«æäº† $ ceph osd pool get mypool nodeep-scrub nodeep-scrub: true #scrub_ min_ interval: é›†ç¾¤å­˜å‚¨æ± çš„æœ€å°æ¸…ç†æ—¶é—´é—´éš”ï¼Œé»˜è®¤å€¼æ²¡æœ‰è®¾ç½®ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶ä¸­çš„osd_scrub_min_interval å‚æ•°æŒ‡å®šé—´éš”æ—¶é—´. $ ceph osd pool get mypool scrub min interval Error ENOENT: option 'scrub_min_interval' is not set on pool 'mypool' #scrub_max_interval: æ•´ç†å­˜å‚¨æ± çš„æœ€å¤§æ¸…ç†æ—¶é—´é—´éš”ï¼Œé»˜è®¤å€¼æ²¡æœ‰è®¾ç½®ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶ä¸­çš„osd_scrub_max_interval å‚æ•°æŒ‡å®šã€‚ $ ceph osd pool get mypool scrub max interval Error ENOENT: option 'scrub_max_interval' is not set on pool 'mypool' #deep_scrub_interval: æ·±å±‚æ•´ç†å­˜å‚¨æ± çš„æ—¶é—´é—´éš”ï¼Œé»˜è®¤å€¼æ²¡æœ‰è®¾ç½®ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶ä¸­çš„osd_deep_scrub_interval å‚æ•°æŒ‡å®šã€‚ $ ceph osd pool get mypool deep_scrub_interval Error ENOENT: option 'deep_scrub_interval' is not set on pool 'mypool' #æŸ¥çœ‹ceph nodeçš„é»˜è®¤é…ç½®: [root@ceph-node1 ~]# ll /var/run/ceph/ total 0 Srxr-Xr-x 1 ceph ceph 0 Nov 3 12:22 ceph-osd.3.asok SrwXr-Xr-x 1 ceph ceph 0 Nov 3 12:22 ceph-osd.6.asok SrWXr-Xr-x 1 ceph ceph 0 Nov 3 12:23 ceph-osd.9.asok [root@ceph-node1 ~]# ceph daemon osd.3 config show | grep scrub \"mds_max_scrub_ops_in_progress\": \"5\", \"mon_scrub_inject_crc_mismatch\": \"0.000000\", \"mon_scrub_inject_missing_keys\": \"0.000000\", \"mon_scrub_jinterval\": \"86400\"ï¼Œ \"mon_scrub_max_keys\": \"100\"ï¼Œ \"mon_scrub_timeout\": \"300\",ï¼Œ \"mon_warn_not_deep_scrubbed\": \"0\", \"mon_warn_not_scrubbed\": \"0\", \"osd_debug_deep_scrub_sleep\": \"0.000000\", \"osd_deep_scrub_jinterval\":_\"604800.00000\"ï¼Œ#å®šä¹‰æ·±åº¦æ¸…æ´—é—´éš”ï¼Œ604800ç§’=7å¤© \"osd_deep_scrub_keys\": \"1024\"ï¼Œ \"osd_deep_scrub_Jarge_omap_object_key_threshold\": \"200000\", \"osd_deep_scrub_large_omap_object_value_sum_threshold\": \"1073741824\", \"osd_deep_scrub_randomize.ratio\": \"0.150000\", \"osd_deep_scrub.stride\": \"524288\", \"osd.deep_scrub.update_digest_min_age\": \"7200\"ï¼Œ \"osd.max_scrubs\": \"1\"ï¼Œ #å®šä¹‰ä¸€ä¸ªceph OSD daemonå†…èƒ½å¤ŸåŒæ—¶è¿›è¡Œscrubbingçš„æ“ä½œæ•° ï¼ˆå¯ç”¨å‡ ä¸ªçº¿ç¨‹æ‰«æ é»˜è®¤æ˜¯ä¸€ä¸ªï¼‰ \"osd_op_queue_mclock_scrub_lim\": \"0.001000\", \"osd_op_queue_mclock_scrub_res\": \"0.000000\", \"osd_op_queue_mclock_scrub_wgt\": \"1.000000, \"osd_requested_scrub_priority\": \"120\"ï¼Œ \"osd_scrub_auto_repair\": \"false\", \"osd_scrub_auto_repair_num_errors\": \"5\"ï¼Œ \"osd_scrub_backoff_ratio\": \"0.660000\", \"osd_scrub_begin_hour\": \"0\"ï¼Œ \"osd_scrub_begin_week_day\": \"0\", \"osd_scrub_chunk_max\": \"25\", \"osd_scrub_chunk_","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:9:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.10 å­˜å‚¨æ± å¿«ç…§ å¿«ç…§ç”¨äºè¯»å­˜å‚¨æ± ä¸­çš„æ•°æ®è¿›è¡Œå¤‡ä»½ä¸è¿˜åŸï¼Œåˆ›å»ºå¿«ç…§éœ€è¦å ç”¨çš„ç£ç›˜ç©ºé—´ä¼šæ¯”è¾ƒå¤§,å–å†³äºå­˜å‚¨æ± ä¸­çš„æ•°æ®å¤§å°ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åˆ›å»ºå¿«ç…§: ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:10:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.10.1 åˆ›å»ºå¿«ç…§ $ ceph osd pool ls #å‘½ä»¤1: ceph osd pool mksnap {pool-name} {snap-name} $ ceph osd pool mksnap mypool mypool-snap created pool mypool snap mypool-snap #å‘½ä»¤2: rados -P {pool-name} mksnap {snap-name} $ rados -P mypool mksnap mypool-snap2 created pool mypool snap mypool-snap2","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:10:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.10.2 éªŒè¯å¿«ç…§ $ rados lssnap -p mypool 1 mypool-snap 2020.11.03 16:12:56 2 mypool-snap2 2020.11.03 16:13:40 2 snaps","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:10:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.10.3 å›æ»šå¿«ç…§ æµ‹è¯•ä¸Šä¼ æ–‡ä»¶ååˆ›å»ºå¿«ç…§ï¼Œç…§ååˆ é™¤æ–‡ä»¶å†è¿˜åŸæ–‡ä»¶,åŸºäºå¯¹è±¡è¿˜åŸã€‚rados rollback \u003cobj-name\u003e \u003csnap-name\u003e roll back object to snap \u003csnap-name\u003e #ä¸Šä¼ æ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ rados -P mypool put testile /etc/hosts #éªŒè¯æ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ rados -P mypool ls msg1 testfile my.conf #åˆ›å»ºå¿«ç…§ (ceph@ceph-deploy ceph-cluster]$ ceph pool mksnap mypool mypool-snapshot001 created pool mypool snap mypool-snapshot001 #éªŒè¯å¿«ç…§ [ceph@ceph-deploy ceph-cluster]$ rados lssnap -p mypool 3 mypool-snap 2020.11.04 14:11:41 4 mypool-snap2 2020.11.0414:1 1:49 5 mypool-conf-bak 2020.11.04 14:18:41 6 mypool-snapshot001 2020.11.0414:38:50 4 snaps #åˆ é™¤æ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ rados -P mypool rm testile #åˆ é™¤æ–‡ä»¶åï¼Œæ— æ³•å†æ¬¡åˆ é™¤æ–‡ä»¶ï¼Œæå‡æ–‡ä»¶ä¸å­˜åœ¨ [ceph@ceph-deploy ceph-cluster$ rados -P mypool rm testfile error removing mypool\u003etestfile: (2) No such file or directory #é€šè¿‡å¿«ç…§è¿˜åŸæŸä¸ªæ–‡ä»¶ [ceph@ceph-deploy ceph-cluster]$ rados rollback -P mypool testfile mypool-snapshot001 rolled back pool mypool to snapshot mypool-snapshot001 #å†æ¬¡æ‰§è¡Œåˆ é™¤å°±å¯ä»¥æ‰§è¡ŒæˆåŠŸ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:10:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.10.4 åˆ é™¤å¿«ç…§ ceph osd pool rmsnap \u003cpoolname\u003e \u003csnap\u003e [ceph@ceph-deploy ceph-cluster$ rados Issnap -P mypool 3 mypool-snap 2020.11.0414:11:41 4 mypool-snap2 2020.11.04 14:11:49 5 mypool-conf-bak 2020.11.04 14:18:41 6 mypool-snapshot001 2020.1 1.0414:38:50 4 snaps [ceph@ceph-deploy ceph-cluster]$ ceph osd pool rmsnap mypool mypool-snap removed pool mypool snap mypool-snap [ceph@ceph-deploy ceph-cluster$ rados Issnap -P mypool 4 mypool-snap2 2020.11.04 14:11:49 5 mypool-conf-bak 2020.11.04 14:18:41 6 mvoool-snanshot001 2020.11.04 14:38:50","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:10:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.11 æ•°æ®å‹ç¼© å¦‚æœä½¿ç”¨bulestoreå­˜å‚¨å¼•æ“ï¼Œceph æ”¯æŒç§°ä¸º\"å®æ—¶æ•°æ®å‹ç¼©â€å³è¾¹å‹ç¼©è¾¹ä¿å­˜æ•°æ®çš„åŠŸèƒ½ï¼Œè¯¥åŠŸèƒ½æœ‰åŠ©äºèŠ‚çœç£ç›˜ç©ºé—´ï¼Œå¯ä»¥åœ¨BlueStore OSD ä¸Šåˆ›å»ºçš„æ¯ä¸ªCephæ± ä¸Šå¯ç”¨æˆ–ç¦ç”¨å‹ç¼©ï¼Œä»¥èŠ‚çº¦ç£ç›˜ç©ºé—´ï¼Œé»˜è®¤æ²¡æœ‰å¼€å¯å‹ç¼©ï¼Œéœ€è¦åæœŸé…ç½®å¹¶å¼€å¯ã€‚ ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:11:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.11.1 å¯ç”¨å‹ç¼©å¹¶æŒ‡å®šå‹ç¼©ç®—æ³• å‹ç¼©ä¼šå¯¼è‡´CPUåˆ©ç”¨ç‡åé«˜ ceph-cluster]$ ceph osd pool set \u003cpool name\u003e compression_algorithm snappy #é»˜è®¤ç®— æ³•ä¸ºsnappy:::info snappy:è¯¥é…ç½®ä¸ºæŒ‡å®šå‹ç¼©ä½¿ç”¨çš„ç®—æ³•é»˜è®¤ä¸ºsanppy,è¿˜æœ‰noneã€zlibã€ lz4ã€ zstd å’Œsnappyç­‰ç®—æ³•ï¼Œzstdå‹ç¼©æ¯”å¥½ï¼Œä½†æ¶ˆè€—CPU, lz4 å’Œsnappyå¯¹CPUå ç”¨è¾ƒä½ï¼Œä¸å»ºè®®ä½¿ç”¨zlib. ::: ","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:11:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Ceph"],"content":"4.11.2 æŒ‡å®šå‹ç¼©æ¨¡å¼ ceph-cluster]$ ceph osd pool set \u003cpool name\u003e compression_mode aggressiveaggressive: å‹ç¼©çš„æ¨¡å¼ï¼Œæœ‰noneã€aggressive ã€passive å’Œforce é»˜è®¤none none: ä»ä¸å‹ç¼©æ•°æ®.passive: é™¤éå†™æ“ä½œå…·æœ‰å¯å‹ç¼©çš„æç¤ºé›†ï¼Œå¦åˆ™ä¸è¦å‹ç¼©æ•°æ®.aggressive: å‹ç¼©æ•°æ®ï¼Œé™¤éå†™æ“ä½œå…·æœ‰ä¸å¯å‹ç¼©çš„æç¤ºé›†ã€‚force: æ— è®ºå¦‚ä½•éƒ½å°è¯•å‹ç¼©æ•°æ®ï¼Œå³ä½¿å®¢æˆ·ç«¯æš—ç¤ºæ•°æ®ä¸å¯å‹ç¼©ä¹Ÿä¼šå‹ç¼©ï¼Œä¹Ÿå°±æ˜¯åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½ä½¿ç”¨å‹ç¼©ã€‚ å­˜å‚¨æ± å‹ç¼©è®¾ç½®å‚æ•°:compression_algorithm å‹ç¼©ç®—æ³•compression_mode å‹ç¼©æ¨¡å¼ compression_required_ratio #å‹ç¼©åä¸å‹ç¼©å‰çš„å‹ç¼©æ¯”ï¼Œé»˜è®¤ä¸º.875compression_max_blob_size: #å¤§äºæ­¤çš„å—åœ¨è¢«å‹ç¼©ä¹‹å‰è¢«åˆ†è§£æˆæ›´å°çš„blob(å—)ï¼Œæ­¤è®¾ç½®å°†è¦†ç›–bluestoreå‹ç¼©max blob çš„å…¨å±€è®¾ç½®ã€‚compression_min_blob_size: #å°äºæ­¤çš„å—ä¸å‹ç¼©ï¼Œæ­¤è®¾ç½®å°†è¦†ç›–bluestoreå‹ç¼©min blobçš„å…¨å±€è®¾ç½®ï¼Œ å…¨å±€å‹ç¼©é€‰é¡¹ï¼Œè¿™äº›å¯ä»¥é…ç½®åˆ°ceph.confé…ç½®æ–‡ä»¶ï¼Œä½œç”¨äºæ‰€æœ‰å­˜å‚¨æ± : bluestore_compression_algorithm #å‹ç¼©ç®—æ³• bluestore_compression_mode #å‹ç¼©æ¨¡å¼ bluestore_compression_required_ratio #å‹ç¼©åä¸å‹ç¼©å‰çš„å‹ç¼©æ¯”ï¼Œé»˜è®¤ä¸º.875 bluestore_compression_min_blob_size #å°äºå®ƒçš„å—ä¸ä¼šè¢«å‹ç¼©,é»˜è®¤0 bluestore_compression_max_blob_size #å¤§äºå®ƒçš„å—åœ¨å‹ç¼©å‰ä¼šè¢«æ‹†æˆæ›´å°çš„å—,é»˜è®¤0 bluestore_compression_min_blob_size_ssd #é»˜è®¤ 8k bluestore_compression_max_blob_size_ssd #é»˜è®¤ 64k bluestore_compression_min_blob_size_hdd #é»˜è®¤ 128k bluestore_compression_max_blob_size_hdd #é»˜è®¤ 512k åˆ°node èŠ‚ç‚¹éªŒè¯ [root@ceph-node3 ~]# ceph daemon osd.11 config show | grep compression #ä¿®æ”¹å‹ç¼©ç®—æ³• [ceph@ceph-deploy ~]$ ceph osd pool set mypool compression algorithm snapy set pool 2 compression algorithm to snappy [ceph@ceph-deploy ~]$ ceph osd pool get mypool compression algorithm compression_algorithm:snappy #ä¿®æ”¹å‹ç¼©æ¨¡å¼: [ceph@ceph-deploy ~]$ ceph osd pool set mypool compression mode passive set pool 2 compression mode to passive [ceph@ceph-deploy ~]$ ceph osd pool get mypool compression_mode compression_mode: passive","date":"2023-01-12","objectID":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/:11:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆå››ï¼‰","uri":"/posts/ceph/4.ceph%E9%9B%86%E7%BE%A4%E7%BB%B4%E6%8A%A4/"},{"categories":["Kubernetes"],"content":"å¸¸ç”¨å‘½ä»¤ ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"K8Sçš„å‡ ä¸ªé‡è¦æ¦‚å¿µ 1.ç”¨ä»€ä¹ˆå’Œk8sæ‰“äº¤é“ï¼Ÿ é€šè¿‡k8så£°æ˜å¼API è°ƒç”¨K8Sèµ„æºå¯¹è±¡ã€‚2.æ€ä¹ˆæ‰“äº¤é“ï¼Ÿ é€šè¿‡å†™yamlæ–‡ä»¶è°ƒç”¨å£°æ˜å¼APIã€‚3.æ€ä¹ˆå£°æ˜ï¼Ÿ yamlä¸­å¿…éœ€çš„å­—æ®µï¼š apiVersion - åˆ›å»ºè¯¥å¯¹è±¡æ‰€ä½¿ç”¨çš„Kubernetes APIçš„ç‰ˆæœ¬ kind- æƒ³è¦åˆ›å»ºçš„å¯¹è±¡çš„ç±»å‹ metadata- å¸®åŠ©è¯†åˆ«å¯¹è±¡å”¯ä¸€æ€§çš„æ•°æ®ï¼Œ åŒ…æ‹¬ä¸€ä¸ªnameåç§°ã€å¯é€‰çš„namespace spec æœŸæœ›çŠ¶æ€ status (Podåˆ›å»ºå®Œæˆåk8sè‡ªåŠ¨ç”ŸæˆstatusçŠ¶æ€) specå’Œstatusçš„åŒºåˆ«:specæ˜¯æœŸæœ›çŠ¶æ€statusæ˜¯å®é™…çŠ¶æ€ ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"Pod æ¦‚è¿° podæ˜¯k8sä¸­çš„æœ€å°å•å…ƒã€‚ ä¸€ä¸ªpodä¸­å¯ä»¥è¿è¡Œä¸€ä¸ªå®¹å™¨ï¼Œ ä¹Ÿå¯ä»¥è¿è¡Œå¤šä¸ªå®¹å™¨ã€‚ è¿è¡Œå¤šä¸ªå®¹å™¨çš„è¯ï¼Œè¿™äº›å®¹å™¨æ˜¯ä¸€èµ·è¢«è°ƒåº¦çš„ã€‚ Podçš„ç”Ÿå‘½å‘¨æœŸæ˜¯çŸ­æš‚çš„ï¼Œ ä¸ä¼šè‡ªæ„ˆï¼Œ æ˜¯ç”¨å®Œå°±é”€æ¯çš„å®ä½“ã€‚ ä¸€èˆ¬æˆ‘ä»¬æ˜¯é€šè¿‡Controlleræ¥åˆ›å»ºå’Œç®¡ç†podçš„ã€‚ Podç”Ÿå‘½å‘¨æœŸ åˆå§‹åŒ–å®¹å™¨ã€å¯åŠ¨å‰æ“ä½œã€å°±ç»ªæ¢é’ˆã€å­˜æ´»æ¢é’ˆã€åˆ é™¤podæ“ä½œ livenessProbeå’ŒreadinessProbe æ¢é’ˆ livenessProbeï¼šå­˜æ´»æ¢é’ˆï¼Œæ£€æµ‹åº”ç”¨å‘ç”Ÿæ•…éšœæ—¶ä½¿ç”¨ï¼Œä¸èƒ½æä¾›æœåŠ¡ã€è¶…æ—¶ç­‰æ£€æµ‹å¤±è´¥é‡å¯pod readinessProbeï¼šå°±ç»ªæ¢é’ˆï¼Œæ£€æµ‹podå¯åŠ¨ä¹‹ååº”ç”¨æ˜¯å¦å°±ç»ªï¼Œæ˜¯å¦å¯ä»¥æä¾›æœåŠ¡ï¼Œæ£€æµ‹æˆåŠŸï¼Œpodæ‰å¼€å§‹æ¥æ”¶æµé‡ã€‚ Controller æ§åˆ¶å™¨ Replication Controller ç¬¬ä¸€ä»£podå‰¯æœ¬æ§åˆ¶å™¨**ReplicaSet ** ç¬¬äºŒä»£podå‰¯æœ¬æ§åˆ¶å™¨Deployment ç¬¬ä¸‰ä»£podæ§åˆ¶å™¨ Rc,Rs å’ŒDeployment åŒºåˆ«ï¼š Replication Controllerï¼šå‰¯æœ¬æ§åˆ¶å™¨ï¼ˆselector = !=ï¼‰https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/replicationcontroller/â€¢ https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/ ReplicaSetï¼šå‰¯æœ¬æ§åˆ¶é›†ï¼Œå’Œå‰¯æœ¬æ§åˆ¶å™¨çš„åŒºåˆ«æ˜¯ï¼šå¯¹é€‰æ‹©å™¨çš„æ”¯æŒï¼ˆselector è¿˜æ”¯æŒin notinï¼‰â€¢ https://kubernetes.io/zh/docs/concepts/workloads/controllers/replicaset/ Deploymentï¼šæ¯”rsæ›´é«˜ä¸€çº§çš„æ§åˆ¶å™¨ï¼Œé™¤äº†æœ‰rsçš„åŠŸèƒ½ä¹‹å¤–ï¼Œè¿˜æœ‰å¾ˆå¤šé«˜çº§åŠŸèƒ½,ï¼Œæ¯”å¦‚è¯´æœ€é‡è¦çš„ï¼šæ»šåŠ¨å‡çº§ã€å›æ»šç­‰â€¢ https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/ ä»¥ä¸‹æ˜¯ Deployments çš„å…¸å‹ç”¨ä¾‹ï¼š :::tips åˆ›å»º Deployment ä»¥å°† ReplicaSet ä¸Šçº¿ã€‚ReplicaSet åœ¨åå°åˆ›å»º Podã€‚ æ£€æŸ¥ ReplicaSet çš„ä¸Šçº¿çŠ¶æ€ï¼ŒæŸ¥çœ‹å…¶æ˜¯å¦æˆåŠŸã€‚ é€šè¿‡æ›´æ–° Deployment çš„ PodTemplateSpecï¼Œå£°æ˜ Pod çš„æ–°çŠ¶æ€ ã€‚ æ–°çš„ ReplicaSet ä¼šè¢«åˆ›å»ºï¼ŒDeployment ä»¥å—æ§é€Ÿç‡å°† Pod ä»æ—§ ReplicaSet è¿ç§»åˆ°æ–° ReplicaSetã€‚ æ¯ä¸ªæ–°çš„ ReplicaSet éƒ½ä¼šæ›´æ–° Deployment çš„ä¿®è®¢ç‰ˆæœ¬ã€‚ å¦‚æœ Deployment çš„å½“å‰çŠ¶æ€ä¸ç¨³å®šï¼Œå›æ»šåˆ°è¾ƒæ—©çš„ Deployment ç‰ˆæœ¬ã€‚ æ¯æ¬¡å›æ»šéƒ½ä¼šæ›´æ–° Deployment çš„ä¿®è®¢ç‰ˆæœ¬ã€‚ æ‰©å¤§ Deployment è§„æ¨¡ä»¥æ‰¿æ‹…æ›´å¤šè´Ÿè½½ã€‚ æš‚åœ Deployment çš„ä¸Šçº¿ ä»¥åº”ç”¨å¯¹ PodTemplateSpec æ‰€ä½œçš„å¤šé¡¹ä¿®æ”¹ï¼Œ ç„¶åæ¢å¤å…¶æ‰§è¡Œä»¥å¯åŠ¨æ–°çš„ä¸Šçº¿ç‰ˆæœ¬ã€‚ ä½¿ç”¨ Deployment çŠ¶æ€æ¥åˆ¤å®šä¸Šçº¿è¿‡ç¨‹æ˜¯å¦å‡ºç°åœæ»ã€‚ æ¸…ç†è¾ƒæ—§çš„ä¸å†éœ€è¦çš„ ReplicaSet ã€‚ ::: ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"Service podé‡å¯åipåœ°å€å°±å˜äº†ï¼Œå¦‚ä½•ä¿è¯podé—´è®¿é—®ä¸å—å½±å“ï¼Ÿ é€šè¿‡å£°æ˜ä¸€ä¸ªserviceå¯¹è±¡ï¼ŒæœåŠ¡å’Œåº”ç”¨è¿›è¡Œè§£è€¦ã€‚ ä¸€èˆ¬å¸¸ç”¨çš„æœ‰ä¸¤ç§ï¼š k8sé›†ç¾¤å†…çš„serviceï¼šselectoræŒ‡å®špodï¼Œè‡ªåŠ¨åˆ›å»ºEndpoints k8sé›†ç¾¤å¤–çš„serviceï¼šæ‰‹åŠ¨åˆ›å»ºEndpointsï¼ŒæŒ‡å®šå¤–éƒ¨æœåŠ¡çš„ipï¼Œç«¯å£å’Œåè®® kube-proxyå’Œserviceçš„å…³ç³» kube-proxy ç›‘å¬ç€k8s-apiserverï¼Œä¸€æ—¦serviceèµ„æºå‘ç”Ÿå˜åŒ–ï¼ˆè°ƒç”¨k8s-apiä¿®æ”¹serviceä¿¡æ¯ï¼‰ï¼Œkube-proxyå°±ä¼šç”Ÿæˆå¯¹åº”çš„è´Ÿè½½è°ƒåº¦çš„è°ƒæ•´ï¼Œè¿™æ ·å°±ä¿è¯serviceçš„æœ€æ–°çŠ¶æ€ã€‚ kube-proxyæœ‰ä¸‰ç§è°ƒåº¦æ¨¡å‹ï¼š userspaceï¼šk8s1.1ä¹‹å‰ iptablesï¼š1.2-k8s1.11ä¹‹å‰ ipvsï¼šk8s 1.11ä¹‹åï¼Œå¦‚æœæ²¡æœ‰å¼€å¯ipvsï¼Œåˆ™è‡ªåŠ¨é™çº§ä¸ºiptables ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:2:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"Volume k8s æŠ½è±¡å‡ºçš„ä¸€ä¸ªå¯¹è±¡ï¼Œç”¨æ¥ä¿å­˜æ•°æ®ï¼Œè§£è€¦æ•°æ®å’Œé•œåƒï¼ˆæ•°æ®å­˜é•œåƒé‡Œé¢æ¯æ¬¡æ›´æ–°é•œåƒä¼šç‰¹åˆ«å¤§ï¼‰ï¼Œå®ç°å®¹å™¨é—´æ•°æ®å…±äº«ã€‚ å¸¸ç”¨çš„å‡ ç§å·ï¼š emptyDirï¼šæœ¬åœ°ä¸´æ—¶å· hostPathï¼šæœ¬åœ°å· nfsç­‰ï¼šå…±äº«å· configmap: é…ç½®æ–‡ä»¶ https://kubernetes.io/zh-cn/docs/concepts/storage/volumes/ emptyDir å½“ Pod è¢«åˆ†é…ç»™èŠ‚ç‚¹æ—¶ï¼Œé¦–å…ˆåˆ›å»º emptyDir å·ï¼Œå¹¶ä¸”åªè¦è¯¥Pod åœ¨è¯¥èŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œè¯¥å·å°±ä¼šå­˜åœ¨ã€‚æ­£å¦‚å·çš„åå­—æ‰€è¿°ï¼Œå®ƒæœ€åˆæ˜¯ç©ºçš„ã€‚Pod ä¸­çš„å®¹å™¨å¯ä»¥è¯»å–å’Œå†™å…¥ emptyDir å·ä¸­çš„ç›¸åŒæ–‡ä»¶ï¼Œå°½ç®¡è¯¥å·å¯ä»¥æŒ‚è½½åˆ°æ¯ä¸ªå®¹å™¨ä¸­çš„ç›¸åŒæˆ–ä¸åŒè·¯å¾„ä¸Šã€‚å½“å‡ºäºä»»ä½•åŸå› ä»èŠ‚ç‚¹ä¸­åˆ é™¤ Pod æ—¶ï¼ŒemptyDir ä¸­çš„æ•°æ®å°†è¢«æ°¸ä¹…åˆ é™¤ã€‚ hostPath hostPath å·å°†ä¸»æœºèŠ‚ç‚¹çš„æ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶æˆ–ç›®å½•æŒ‚è½½åˆ°é›†ç¾¤ä¸­ï¼Œpodåˆ é™¤çš„æ—¶å€™ï¼Œå·ä¸ä¼šè¢«åˆ é™¤ï¼Œä½†æ˜¯podå¯èƒ½è°ƒåº¦åˆ°ä¸åŒçš„node æ•°æ®ä¼šå‡ºç°ä¸¢å¤±ã€‚ nfsç­‰å…±äº«å­˜å‚¨ nfs å·å…è®¸å°†ç°æœ‰çš„ NFSï¼ˆç½‘ç»œæ–‡ä»¶ç³»ç»Ÿï¼‰å…±äº«æŒ‚è½½åˆ°æ‚¨çš„å®¹å™¨ä¸­ã€‚ä¸åƒ emptyDirï¼Œå½“åˆ é™¤ Pod æ—¶ï¼Œnfs å·çš„å†…å®¹è¢«ä¿ç•™ï¼Œå·ä»…ä»…æ˜¯è¢«å¸è½½ã€‚è¿™æ„å‘³ç€ NFS å·å¯ä»¥é¢„å¡«å……æ•°æ®ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ pod ä¹‹é—´â€œåˆ‡æ¢â€æ•°æ®ã€‚ NFSå¯ä»¥è¢«å¤šä¸ªå†™å…¥è€…åŒæ—¶æŒ‚è½½ã€‚ åˆ›å»ºå¤šä¸ªpodæµ‹è¯•æŒ‚è½½åŒä¸€ä¸ªNFS apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 1 selector: matchLabels: app: ng-deploy-80 template: metadata: labels: app: ng-deploy-80 spec: containers: - name: ng-deploy-80 image: nginx ports: - containerPort: 80 volumeMounts: - mountPath: /usr/share/nginx/html/mysite name: my-nfs-volume volumes: - name: my-nfs-volume nfs: server: 172.31.7.109 path: /data/magedu/n56 --- apiVersion: v1 kind: Service metadata: name: ng-deploy-80 spec: ports: - name: http port: 81 targetPort: 80 nodePort: 30016 protocol: TCP type: NodePort selector: app: ng-deploy-80åˆ›å»ºå¤šä¸ªpodæµ‹è¯•æ¯ä¸ªpodæŒ‚è½½å¤šä¸ªNFS apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 1 selector: matchLabels: app: ng-deploy-80 template: metadata: labels: app: ng-deploy-80 spec: containers: - name: ng-deploy-80 image: nginx ports: - containerPort: 80 volumeMounts: - mountPath: /usr/share/nginx/html/mysite name: my-nfs-volume - mountPath: /usr/share/nginx/html/js name: my-nfs-js volumes: - name: my-nfs-volume nfs: server: 172.31.7.109 path: /data/magedu/n56 - name: my-nfs-js nfs: server: 172.31.7.109 path: /data/magedu/js --- apiVersion: v1 kind: Service metadata: name: ng-deploy-80 spec: ports: - name: http port: 81 targetPort: 80 nodePort: 30016 protocol: TCP type: NodePort selector: app: ng-deploy-80é‡ç‚¹ï¼š service è®¿é—®æµç¨‹ï¼š k8så†…éƒ¨æœåŠ¡å¯¹å¤–å‘å¸ƒä¸€èˆ¬æœ‰ä¸¤ç§æ–¹å¼ï¼Œnodeportå’Œingress ï¼Œå¦‚æœä½¿ç”¨nodeportæ–¹å¼å°±ä¼šåœ¨æ¯å°nodeèŠ‚ç‚¹éƒ½ä¼šç›‘å¬ä¸€ä¸ªç«¯å£é€šå¸¸æ˜¯30000ä»¥ä¸Šï¼Œnodeportä¸ºä»€ä¹ˆä¸ç›´æ¥è½¬å‘ç»™pod ï¼Ÿ å› ä¸ºç»´æŠ¤nodeportå’Œpodç»‘å®šå…³ç³»æ¯”è¾ƒéš¾ï¼Œé€šè¿‡éœ€è¦serviceè¿›è¡Œè½¬å‘ï¼Œserviceç›¸å½“äºk8så†…éƒ¨çš„è´Ÿè½½å‡è¡¡å™¨è´Ÿè´£è½¬å‘ï¼ŒåŸºäºlabelæ ‡ç­¾åŒ¹é…å’Œç­›é€‰é‚£äº›å…·æœ‰æ ‡ç­¾çš„podã€‚ é»˜è®¤ä½¿ç”¨è½®è¯¢è°ƒåº¦æ–¹å¼ ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:2:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"configmap åŠŸèƒ½ï¼šå°†é…ç½®ä¿¡æ¯å’Œé•œåƒè§£è€¦å°†é…ç½®ä¿¡æ¯æ”¾åˆ°configmapå¯¹è±¡ä¸­ï¼Œç„¶ååœ¨podçš„å¯¹è±¡ä¸­å¯¼å…¥configmapå¯¹è±¡ï¼Œå®ç°å¯¼å…¥é…ç½®æ–‡ä»¶çš„æ“ä½œã€‚yamlå£°æ˜ä¸€ä¸ªConfigMapçš„å¯¹è±¡ï¼Œä½œä¸ºVolumeæŒ‚è½½åˆ°podä¸­ ä½¿ç”¨ Configmap æŒ‚è½½nginx é…ç½®æ–‡ä»¶ apiVersion: v1 kind: ConfigMap metadata: name: nginx-config data: default: | server { listen 80; server_name www.mysite.com; index index.html; location / { root /data/nginx/html; if (!-e $request_filename) { rewrite ^/(.*) /index.html last; } } } --- #apiVersion: extensions/v1beta1 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 1 selector: matchLabels: app: ng-deploy-80 template: metadata: labels: app: ng-deploy-80 spec: containers: - name: ng-deploy-80 image: nginx ports: - containerPort: 80 volumeMounts: - mountPath: /data/nginx/html name: nginx-static-dir - name: nginx-config mountPath: /etc/nginx/conf.d volumes: - name: nginx-static-dir hostPath: path: /data/nginx/linux39 - name: nginx-config configMap: name: nginx-config items: - key: default path: mysite.conf --- apiVersion: v1 kind: Service metadata: name: ng-deploy-80 spec: ports: - name: http port: 81 targetPort: 80 nodePort: 30019 protocol: TCP type: NodePort selector: app: ng-deploy-80ä½¿ç”¨ Configmap æŒ‚è½½ç¯å¢ƒå˜é‡åˆ°pod apiVersion: v1 kind: ConfigMap metadata: name: nginx-config data: username: user1 --- #apiVersion: extensions/v1beta1 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 1 selector: matchLabels: app: ng-deploy-80 template: metadata: labels: app: ng-deploy-80 spec: containers: - name: ng-deploy-80 image: nginx env: - name: MY_PASSWD value: \"123123\" - name: MY_USERNAME valueFrom: configMapKeyRef: name: nginx-config key: username ports: - containerPort: 80","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:2:5","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"Statefulset åŠŸèƒ½ï¼š ä¸ºäº†è§£å†³æœ‰çŠ¶æ€æœåŠ¡çš„é—®é¢˜ æ— çŠ¶æ€æœåŠ¡ï¼ˆæœ‰ä¸»ä»å…³ç³»ã€é›†ç¾¤éƒ¨ç½² ï¼‰ å®ƒæ‰€ç®¡ç†çš„Podæ‹¥æœ‰å›ºå®šçš„Podåç§°ï¼Œä¸»æœºåï¼Œå¯åœé¡ºåº å’Œ Deployment ç±»ä¼¼ï¼Œ StatefulSet ç®¡ç†åŸºäºç›¸åŒå®¹å™¨è§„çº¦çš„ä¸€ç»„ Podã€‚ä½†å’Œ Deployment ä¸åŒçš„æ˜¯ï¼Œ StatefulSet ä¸ºå®ƒä»¬çš„æ¯ä¸ª Pod ç»´æŠ¤äº†ä¸€ä¸ªæœ‰ç²˜æ€§çš„ IDã€‚è¿™äº› Pod æ˜¯åŸºäºç›¸åŒçš„è§„çº¦æ¥åˆ›å»ºçš„ï¼Œ ä½†æ˜¯ä¸èƒ½ç›¸äº’æ›¿æ¢ï¼šæ— è®ºæ€ä¹ˆè°ƒåº¦ï¼Œæ¯ä¸ª Pod éƒ½æœ‰ä¸€ä¸ªæ°¸ä¹…ä¸å˜çš„ IDã€‚ https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/statefulset/ ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:2:6","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"DaemonSet ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:2:7","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"PV/PVC å¯¹å­˜å‚¨æŠ½è±¡ ä¸ç›´æ¥å­˜å‚¨æ•°æ®è€Œæ˜¯åœ¨k8så±‚é¢åšäº†ä¸€ä¸ªéš”ç¦»ï¼Œæƒé™æ§åˆ¶ã€ä¸šåŠ¡éš”ç¦»ï¼ŒæŠŠä¸åŒæ˜¯podæ•°æ®åˆ†å¼€ ç”¨nfsæŒ‚è½½ é‚£ä¹ˆæ¯ä¸ªpodéƒ½èƒ½çœ‹åˆ°ç›¸åŒæ•°æ®ï¼Œå¦‚ä½•åšæ•°æ®éš”ç¦»ï¼Ÿ åœ¨å­˜å‚¨å’Œk8sç›´æ¥å°è£…ä¸€å±‚ PV/PVC PVæ˜¯å¯¹åº•å±‚â½¹ç»œå­˜å‚¨çš„æŠ½è±¡ï¼Œå³å°†â½¹ç»œå­˜å‚¨å®šä¹‰ä¸ºâ¼€ç§å­˜å‚¨èµ„æºï¼Œå°†â¼€ä¸ªæ•´ä½“çš„å­˜å‚¨èµ„æºæ‹†åˆ†æˆå¤šä»½åç»™ä¸åŒçš„ä¸šåŠ¡ä½¿ç”¨ã€‚ PVæ˜¯ç”±ç®¡ç†å‘˜æ·»åŠ çš„çš„â¼€ä¸ªå­˜å‚¨çš„æè¿°ï¼Œæ˜¯â¼€ä¸ªå…¨å±€èµ„æºå³ä¸â¾ªå±äºä»»ä½•namespaceï¼ŒåŒ…å«å­˜å‚¨çš„ç±»å‹ï¼Œå­˜å‚¨çš„â¼¤â¼©å’Œè®¿é—®æ¨¡å¼ç­‰ï¼Œå®ƒçš„â½£å‘½å‘¨æœŸç‹¬â½´äºPodï¼Œä¾‹å¦‚å½“ä½¿â½¤å®ƒçš„Podé”€æ¯æ—¶å¯¹PVæ²¡æœ‰å½±å“ã€‚ **PersistentVolumeClaimï¼ˆPVCï¼‰**æ˜¯â½¤æˆ·å­˜å‚¨çš„è¯·æ±‚ï¼Œå®ƒç±»ä¼¼äºpodï¼ŒPodæ¶ˆè€—èŠ‚ç‚¹èµ„æºï¼ŒPVCæ¶ˆè€—å­˜å‚¨èµ„æºï¼Œ å°±åƒ podå¯ä»¥è¯·æ±‚ç‰¹å®šçº§åˆ«çš„èµ„æºï¼ˆCPUå’Œå†…å­˜ï¼‰ï¼ŒPVCæ˜¯namespaceä¸­çš„èµ„æºï¼Œå¯ä»¥è®¾ç½®ç‰¹å®šçš„ç©ºé—´å¤§å°å’Œè®¿é—®æ¨¡å¼ã€‚ podæ˜¯é€šè¿‡PVCå°†æ•°æ®ä¿å­˜â¾„PVï¼ŒPVåœ¨ä¿å­˜â¾„å­˜å‚¨ã€‚ PersistentVolumeå‚æ•°ï¼š è®¿é—®æ¨¡å¼ accessModes PersistentVolume å·å¯ä»¥ç”¨èµ„æºæä¾›è€…æ‰€æ”¯æŒçš„ä»»ä½•æ–¹å¼æŒ‚è½½åˆ°å®¿ä¸»ç³»ç»Ÿä¸Šã€‚ å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œæä¾›è€…ï¼ˆé©±åŠ¨ï¼‰çš„èƒ½åŠ›ä¸åŒï¼Œæ¯ä¸ª PV å·çš„è®¿é—®æ¨¡å¼éƒ½ä¼šè®¾ç½®ä¸ºå¯¹åº”å·æ‰€æ”¯æŒçš„æ¨¡å¼å€¼ã€‚ ä¾‹å¦‚ï¼ŒNFS å¯ä»¥æ”¯æŒå¤šä¸ªè¯»å†™å®¢æˆ·ï¼Œä½†æ˜¯æŸä¸ªç‰¹å®šçš„ NFS PV å·å¯èƒ½åœ¨æœåŠ¡å™¨ä¸Šä»¥åªè¯»çš„æ–¹å¼å¯¼å‡ºã€‚ æ¯ä¸ª PV å·éƒ½ä¼šè·å¾—è‡ªèº«çš„è®¿é—®æ¨¡å¼é›†åˆï¼Œæè¿°çš„æ˜¯ç‰¹å®š PV å·çš„èƒ½åŠ›ã€‚ è®¿é—®æ¨¡å¼æœ‰ï¼šReadWriteOnceå·å¯ä»¥è¢«ä¸€ä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ–¹å¼æŒ‚è½½ã€‚ ReadWriteOnce è®¿é—®æ¨¡å¼ä¹Ÿå…è®¸è¿è¡Œåœ¨åŒä¸€èŠ‚ç‚¹ä¸Šçš„å¤šä¸ª Pod è®¿é—®å·ã€‚ReadOnlyManyå·å¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹ä»¥åªè¯»æ–¹å¼æŒ‚è½½ã€‚ReadWriteManyå·å¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ–¹å¼æŒ‚è½½ã€‚ReadWriteOncePod # kubectl explain PersistentVolume Capacityï¼š #å½“å‰PVç©ºé—´â¼¤â¼©ï¼Œkubectl explain PersistentVolume.spec.capacity accessModes ï¼šè®¿é—®æ¨¡å¼ï¼Œ#kubectl explain PersistentVolume.spec.accessModes ReadWriteOnce â€“ PVåªèƒ½è¢«å•ä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æƒé™æŒ‚è½½ï¼ŒRWO ReadOnlyMany â€“ PVä»¥å¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹æŒ‚è½½ä½†æ˜¯æƒé™æ˜¯åªè¯»çš„,ROX ReadWriteMany â€“ PVå¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹æ˜¯è¯»å†™â½…å¼æŒ‚è½½ä½¿â½¤,RWXhttps://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#access-modes å®˜â½…æä¾›çš„åŸºäºå„åç«¯å­˜å‚¨åˆ›å»ºçš„PVâ½€æŒçš„è®¿é—®æ¨¡å¼ å›æ”¶æœºåˆ¶ persistentVolumeReclaimPolicy persistentVolumeReclaimPolicy #åˆ é™¤æœºåˆ¶å³åˆ é™¤å­˜å‚¨å·å·æ—¶å€™ï¼Œå·²ç»åˆ›å»ºå¥½çš„å­˜å‚¨å·ç”±ä»¥ä¸‹åˆ é™¤æ“ä½œï¼š #kubectl explain PersistentVolume.spec.persistentVolumeReclaimPolicy Retain â€“ åˆ é™¤PVåä¿æŒåŸè£…ï¼Œæœ€åéœ€è¦ç®¡ç†å‘˜â¼¿åŠ¨åˆ é™¤ Recycle â€“ ç©ºé—´å›æ”¶ï¼ŒåŠåˆ é™¤å­˜å‚¨å·ä¸Šçš„æ‰€æœ‰æ•°æ®(åŒ…æ‹¬â½¬å½•å’Œéšè—â½‚ä»¶),â½¬å‰ä»…â½€æŒNFSå’ŒhostPath Delete â€“ â¾ƒåŠ¨åˆ é™¤å­˜å‚¨å· mountOptions #é™„åŠ çš„æŒ‚è½½é€‰é¡¹åˆ—è¡¨ï¼Œå®ç°æ›´ç²¾ç»†çš„æƒé™æ§åˆ¶ ro #ç­‰https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#reclaim-policy å·æ¨¡å¼ é’ˆå¯¹ PV æŒä¹…å·ï¼ŒKubernetes æ”¯æŒä¸¤ç§å·æ¨¡å¼ï¼ˆvolumeModesï¼‰ï¼šFilesystemï¼ˆæ–‡ä»¶ç³»ç»Ÿï¼‰ å’Œ Blockï¼ˆå—ï¼‰ã€‚ volumeMode æ˜¯ä¸€ä¸ªå¯é€‰çš„ API å‚æ•°ã€‚ å¦‚æœè¯¥å‚æ•°è¢«çœç•¥ï¼Œé»˜è®¤çš„å·æ¨¡å¼æ˜¯ Filesystemã€‚volumeMode å±æ€§è®¾ç½®ä¸º Filesystem çš„å·ä¼šè¢« Pod æŒ‚è½½ï¼ˆMountï¼‰ åˆ°æŸä¸ªç›®å½•ã€‚ å¦‚æœå·çš„å­˜å‚¨æ¥è‡ªæŸå—è®¾å¤‡è€Œè¯¥è®¾å¤‡ç›®å‰ä¸ºç©ºï¼ŒKuberneretes ä¼šåœ¨ç¬¬ä¸€æ¬¡æŒ‚è½½å·ä¹‹å‰åœ¨è®¾å¤‡ä¸Šåˆ›å»ºæ–‡ä»¶ç³»ç»Ÿã€‚ volumeMode #å·ç±»å‹ kubectl explain PersistentVolume.spec.volumeMode å®šä¹‰å­˜å‚¨å·ä½¿â½¤çš„â½‚ä»¶ç³»ç»Ÿæ˜¯å—è®¾å¤‡è¿˜æ˜¯â½‚ä»¶ç³»ç»Ÿï¼Œé»˜è®¤ä¸ºâ½‚ä»¶ç³»ç»Ÿhttps://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#volume-mode PersistentVolumeClaim å‚æ•° #kubectl explain PersistentVolumeClaim accessModes ï¼šPVC è®¿é—®æ¨¡å¼ï¼Œ#kubectl explain PersistentVolumeClaim.spec.volumeMode ReadWriteOnce â€“ PVCåªèƒ½è¢«å•ä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æƒé™æŒ‚è½½ï¼ŒRWO ReadOnlyMany â€“ PVCä»¥å¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹æŒ‚è½½ä½†æ˜¯æƒé™æ˜¯åªè¯»çš„,ROX ReadWriteMany â€“ PVCå¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹æ˜¯è¯»å†™â½…å¼æŒ‚è½½ä½¿â½¤,RWX resourcesï¼š #å®šä¹‰PVCåˆ›å»ºå­˜å‚¨å·çš„ç©ºé—´â¼¤â¼© selectorï¼š #æ ‡ç­¾é€‰æ‹©å™¨ï¼Œé€‰æ‹©è¦ç»‘å®šçš„PV matchLabels #åŒ¹é…æ ‡ç­¾åç§° matchExpressions #åŸºäºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é… volumeName #è¦ç»‘å®šçš„PVåç§° volumeMode #å·ç±»å‹ å®šä¹‰PVCä½¿â½¤çš„â½‚ä»¶ç³»ç»Ÿæ˜¯å—è®¾å¤‡è¿˜æ˜¯â½‚ä»¶ç³»ç»Ÿï¼Œé»˜è®¤ä¸ºâ½‚ä»¶ç³»ç»ŸPVåŠPVCå®æˆ˜æ¡ˆä¾‹ä¹‹zookeeperé›†ç¾¤ åŸºäºPVå’ŒPVCä½œä¸ºåç«¯å­˜å‚¨ï¼Œå®ç°zookeeperé›†ç¾¤ 1.ä¸‹è½½JDK é•œåƒ https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html#license-lightbox docker pull elevy/slim_java:8 docker tag elevy/slim_java:8 harbor.ceamg.com/baseimages/slim_java:8 docker push harbor.ceamg.com/baseimages/slim_java:82.æ„å»ºzookeeper é•œåƒ chmod a+x *.sh chmod a+x bin/*.sh bash build-command.sh bash build-command.sh 2022-1-12_9_16_32#FROM harbor-linux38.local.com/linux38/slim_java:8 FROM harbor.ceamg.com/baseimages/slim_java:8 ENV ZK_VERSION 3.4.14 ADD repositories /etc/apk/repositories # Download Zookeeper COPY zookeeper-3.4.14.tar.gz /tmp/zk.tgz COPY zookeeper-3.4.14.tar.gz.asc /tmp/zk.tgz.asc COPY KEYS /tmp/KEYS RUN apk add --no-cache --virtual .build-deps \\ ca-certificates \\ gnupg \\ tar \\ wget \u0026\u0026 \\ # # Install dependencies apk add --no-cache \\ bash \u0026\u0026 \\ # # # Verify the signature export GNUPGHOME=\"$(mktemp -d)\" \u0026\u0026 \\ gpg -q --batch --import /tmp/KEYS \u0026\u0026 \\ gpg -q --batch --no-auto-key-retrieve --verify /tmp/zk.tgz.asc /tmp/zk.tgz \u0026\u0026 \\ # # Set up directories # mkdir -p /zookeeper/data /zookeeper/wal /zookeeper/log \u0026\u0026 \\ # # Install tar -x -C /zookeeper --strip-components=1 --no-same-owner -f /tmp/zk.tgz \u0026\u0026 \\ # # Slim down cd /zookeeper \u0026\u0026 \\ cp dist-maven/zookeeper-${ZK_VERSION}.jar . \u0026\u0026 \\ rm -rf \\ *.txt \\ *.xml \\ bin/README.txt \\ bin/*.cmd \\ conf/* \\ contrib \\ dist-maven \\ docs \\ lib/*.txt \\ lib/cobertura \\ lib/jdiff \\ recipes \\ src \\ zookeeper-*.asc \\ zookeeper-*.md5 \\ zookeeper-*.sha1 \u0026\u0026 \\ # # Clean up apk del .build-deps \u0026\u0026 \\ rm -rf /tmp/* \"$GNUPGHOME","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-4/:2:8","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"kubernetesAPIèµ„æºå¯¹è±¡ (å››)","uri":"/posts/kubernetes/primary/kubernetes-4/"},{"categories":["Kubernetes"],"content":"1. yamlæ ¼å¼ äººå‘˜åå•: å¼ ä¸‰: å¹´é¾„: 18 # èŒä¸š: Linuxè¿ç»´å·¥ç¨‹å¸ˆ çˆ±å¥½: - çœ‹ä¹¦ - å­¦ä¹  - åŠ ç­ æå››: å¹´é¾„: 20 èŒä¸š: Javaå¼€å‘å·¥ç¨‹å¸ˆ # è¿™æ˜¯èŒä¸š çˆ±å¥½: - å¼€æºæŠ€æœ¯ - å¾®æœåŠ¡ - åˆ†å¸ƒå¼å­˜å‚¨ å¤§å°å†™æ•æ„Ÿ ä½¿ç”¨ç¼©è¿›è¡¨ç¤ºå±‚çº§å…³ç³» ç¼©è¿›æ—¶ä¸å…è®¸ä½¿ç”¨Talé”®ï¼Œåªå…è®¸ä½¿ç”¨ç©ºæ ¼ ç¼©è¿›çš„ç©ºæ ¼æ•°ç›®ä¸é‡è¦ï¼Œåªè¦ç›¸åŒå±‚çº§çš„å…ƒç´ å·¦ä¾§å¯¹é½å³å¯ ä½¿ç”¨â€#â€ è¡¨ç¤ºæ³¨é‡Šï¼Œä»è¿™ä¸ªå­—ç¬¦ä¸€ç›´åˆ°è¡Œå°¾ï¼Œéƒ½ä¼šè¢«è§£æå™¨å¿½ç•¥ æ¯”jsonæ›´é€‚ç”¨äºé…ç½®æ–‡ä»¶","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-3/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"yamlæ–‡ä»¶è¯­æ³•åŸºç¡€ ï¼ˆä¸‰ï¼‰","uri":"/posts/kubernetes/primary/kubernetes-3/"},{"categories":["Kubernetes"],"content":"yamlæ–‡ä»¶ä¸»è¦ç‰¹æ€§ k8sä¸­çš„yamlæ–‡ä»¶ä»¥åŠå…¶ä»–åœºæ™¯çš„yamlæ–‡ä»¶ï¼Œ å¤§éƒ¨åˆ†éƒ½æ˜¯ä»¥ä¸‹ç±»å‹ï¼š ä¸Šä¸‹çº§å…³ç³»åˆ—è¡¨ é”®å€¼å¯¹(ä¹Ÿç§°ä¸ºmapsï¼Œ å³keyï¼švalueæ ¼å¼çš„é”®å€¼å¯¹æ•°æ®)å®¹å™¨åœ¨è¿è¡Œæ—¶æ˜¯åŸºäºå®¿ä¸»æœºçš„å†…æ ¸çš„namespaceéš”ç¦»ç¯å¢ƒ pid ï¼Œå¦‚æœåªæœ‰ç¯å¢ƒæ²¡æœ‰æœåŠ¡å°±é€€å‡ºäº† ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-3/:1:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"yamlæ–‡ä»¶è¯­æ³•åŸºç¡€ ï¼ˆä¸‰ï¼‰","uri":"/posts/kubernetes/primary/kubernetes-3/"},{"categories":["Kubernetes"],"content":"2.yamlä¸jsonå¯¹æ¯” åœ¨çº¿yamlä¸jsonç¼–è¾‘å™¨ï¼šhttp://www.bejson.com/validators/yaml_editor/jsonæ ¼å¼ { 'äººå‘˜åå•': { 'å¼ ä¸‰': { 'å¹´é¾„': 18, 'èŒä¸š': 'Linuxè¿ç»´å·¥ç¨‹å¸ˆ', 'çˆ±å¥½': [ 'çœ‹ä¹¦', 'å­¦ä¹ ', 'åŠ ç­' ] }, 'æå››': { 'å¹´é¾„': 20, 'èŒä¸š': 'Javaå¼€å‘å·¥ç¨‹å¸ˆ', 'çˆ±å¥½': [ 'å¼€æºæŠ€æœ¯', 'å¾®æœåŠ¡', 'åˆ†å¸ƒå¼å­˜ å‚¨' ] } } }","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-3/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"yamlæ–‡ä»¶è¯­æ³•åŸºç¡€ ï¼ˆä¸‰ï¼‰","uri":"/posts/kubernetes/primary/kubernetes-3/"},{"categories":["Kubernetes"],"content":"jsonç‰¹ç‚¹ json ä¸èƒ½æ³¨é‡Šjson å¯è¯»æ€§è¾ƒå·®json è¯­æ³•å¾ˆä¸¥æ ¼æ¯”è¾ƒé€‚ç”¨äºAPI è¿”å›å€¼ï¼Œä¹Ÿå¯ç”¨äºé…ç½®æ–‡ä»¶ ","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-3/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"yamlæ–‡ä»¶è¯­æ³•åŸºç¡€ ï¼ˆä¸‰ï¼‰","uri":"/posts/kubernetes/primary/kubernetes-3/"},{"categories":["Kubernetes"],"content":"3. å®è·µ-4åˆ›å»ºnamespace yamlæ–‡ä»¶ #cat namespaces.yaml apiVersionï¼šv1 #APIç‰ˆæœ¬ kindï¼šNamespace #ç±»å‹ä¸ºnamespac metadataï¼š #å®šä¹‰å…ƒæ•°æ® nameï¼šxin-k8s #namespaceåç§° -------------------------------------- root@master02:~# mkdir /xin-yaml root@master02:~# cd /xin-yaml/ root@master02:/xin-yaml# vim namespaces.yaml root@master02:/xin-yaml# kubectl apply -f namespaces.yaml namespace/xin-k8s created root@master02:/xin-yaml# root@master02:/xin-yaml# kubectl get ns NAME STATUS AGE default Active 2d20h kube-node-lease Active 2d20h kube-public Active 2d20h kube-system Active 2d20h kubernetes-dashboard Active 42h xin-k8s Active 7s","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-3/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"yamlæ–‡ä»¶è¯­æ³•åŸºç¡€ ï¼ˆä¸‰ï¼‰","uri":"/posts/kubernetes/primary/kubernetes-3/"},{"categories":["Kubernetes"],"content":"4.nginx yamlæ–‡ä»¶è¯¦è§£ å¯ä»¥ä½¿ç”¨kubectl explain deployment æŸ¥çœ‹ç‰ˆæœ¬ä¿¡æ¯ root@master02:/xin-yaml# kubectl explain deploy KIND: Deployment VERSION: apps/v1 DESCRIPTION: Deployment enables declarative updates for Pods and ReplicaSets.# cat nginx.yaml kind: Deployment #ç±»å‹ï¼Œæ˜¯deploymentæ§åˆ¶å™¨ï¼Œkubectl explain Deployment apiVersion: extensions/v1 #APIç‰ˆæœ¬ï¼Œ# kubectl explain Deployment.apiVersion metadata: #podçš„å…ƒæ•°æ®ä¿¡æ¯ï¼Œkubectl explain Deployment.metadata labels: #è‡ªå®šä¹‰podçš„æ ‡ç­¾ï¼Œ# kubectl explain Deployment.metadata.labels app: xin01-nginx-deployment-label #æ ‡ç­¾åç§°ä¸ºappå€¼ä¸ºlinux36-nginx-deployment-labelï¼Œåé¢ä¼šç”¨åˆ°æ­¤æ ‡ç­¾ name: xin01-nginx-deployment #podçš„åç§° namespace: xin-01 #podçš„namespaceï¼Œé»˜è®¤æ˜¯defaule spec: #å®šä¹‰deploymentä¸­å®¹å™¨çš„è¯¦ç»†ä¿¡æ¯ï¼Œkubectl explain Deployment.spec replicas: 3 #åˆ›å»ºå‡ºçš„podçš„å‰¯æœ¬æ•°ï¼Œå³å¤šå°‘ä¸ªpodï¼Œé»˜è®¤å€¼ä¸º1 selector: #å®šä¹‰æ ‡ç­¾é€‰æ‹©å™¨ matchLabels: #å®šä¹‰åŒ¹é…çš„æ ‡ç­¾ï¼Œå¿…é¡»è¦è®¾ç½® app: xin01-nginx-deployment-label #åŒ¹é…çš„ç›®æ ‡æ ‡ç­¾ï¼Œ template: #å®šä¹‰æ¨¡æ¿ï¼Œå¿…é¡»å®šä¹‰ï¼Œæ¨¡æ¿æ˜¯èµ·åˆ°æè¿°è¦åˆ›å»ºçš„podçš„ä½œç”¨ metadata: #å®šä¹‰æ¨¡æ¿å…ƒæ•°æ® labels: #å®šä¹‰æ¨¡æ¿labelï¼ŒDeployment.spec.template.metadata.labels app: xin01-nginx-deployment-label #å®šä¹‰æ ‡ç­¾ï¼Œç­‰äºDeployment.spec.selector.matchLabels spec: #å®šä¹‰podä¿¡æ¯ containers: #å®šä¹‰podä¸­å®¹å™¨åˆ—è¡¨ï¼Œå¯ä»¥å¤šä¸ªè‡³å°‘ä¸€ä¸ªï¼Œpodä¸èƒ½åŠ¨æ€å¢å‡å®¹å™¨ - name: xin-nginx-container #å®¹å™¨åç§° image: nginx:1.20.1 #é•œåƒåœ°å€ #command: [\"/apps/tomcat/bin/run_tomcat.sh\"] #å®¹å™¨å¯åŠ¨æ‰§è¡Œçš„å‘½ä»¤æˆ–è„šæœ¬ #imagePullPolicy: IfNotPresent imagePullPolicy: Always #æ‹‰å–é•œåƒç­–ç•¥ ports: #å®šä¹‰å®¹å™¨ç«¯å£åˆ—è¡¨ - containerPort: 80 #å®šä¹‰ä¸€ä¸ªç«¯å£ protocol: TCP #ç«¯å£åè®® name: http #ç«¯å£åç§° - containerPort: 443 #å®šä¹‰ä¸€ä¸ªç«¯å£ protocol: TCP #ç«¯å£åè®® name: https #ç«¯å£åç§° env: #é…ç½®ç¯å¢ƒå˜é‡ - name: \"password\" #å˜é‡åç§°ã€‚å¿…é¡»è¦ç”¨å¼•å·å¼•èµ·æ¥ value: \"123456\" #å½“å‰å˜é‡çš„å€¼ - name: \"age\" #å¦ä¸€ä¸ªå˜é‡åç§° value: \"18\" #å¦ä¸€ä¸ªå˜é‡çš„å€¼ resources: #å¯¹èµ„æºçš„è¯·æ±‚è®¾ç½®å’Œé™åˆ¶è®¾ç½® limits: #èµ„æºé™åˆ¶è®¾ç½®ï¼Œä¸Šé™ cpu: 500m #cpuçš„é™åˆ¶ï¼Œå•ä½ä¸ºcoreæ•°ï¼Œå¯ä»¥å†™0.5æˆ–è€…500mç­‰CPUå‹ç¼©å€¼ memory: 1Gi #å†…å­˜é™åˆ¶ï¼Œå•ä½å¯ä»¥ä¸ºMib/Gibï¼Œå°†ç”¨äºdocker run --memoryå‚æ•° requests: #èµ„æºè¯·æ±‚çš„è®¾ç½® cpu: 200m #cpuè¯·æ±‚æ•°ï¼Œå®¹å™¨å¯åŠ¨çš„åˆå§‹å¯ç”¨æ•°é‡,å¯ä»¥å†™0.5æˆ–è€…500mç­‰CPUå‹ç¼©å€¼ memory: 512Mi #å†…å­˜è¯·æ±‚å¤§å°ï¼Œå®¹å™¨å¯åŠ¨çš„åˆå§‹å¯ç”¨æ•°é‡ï¼Œç”¨äºè°ƒåº¦podæ—¶å€™ä½¿ç”¨ --- kind: Service #ç±»å‹ä¸ºservice apiVersion: v1 #service APIç‰ˆæœ¬ï¼Œ service.apiVersion metadata: #å®šä¹‰serviceå…ƒæ•°æ®ï¼Œservice.metadata labels: #è‡ªå®šä¹‰æ ‡ç­¾ï¼Œservice.metadata.labels app: xin01-nginx #å®šä¹‰serviceæ ‡ç­¾çš„å†…å®¹ name: xin01-nginx-spec #å®šä¹‰serviceçš„åç§°ï¼Œæ­¤åç§°ä¼šè¢«DNSè§£æ namespace: xin-01 #è¯¥serviceéš¶å±äºçš„namespacesåç§°ï¼Œå³æŠŠserviceåˆ›å»ºåˆ°å“ªä¸ªnamespaceé‡Œé¢ spec: #å®šä¹‰serviceçš„è¯¦ç»†ä¿¡æ¯ï¼Œservice.spec type: NodePort #serviceçš„ç±»å‹ï¼Œå®šä¹‰æœåŠ¡çš„è®¿é—®æ–¹å¼ï¼Œé»˜è®¤ä¸ºClusterIPï¼Œ service.spec.type ports: #å®šä¹‰è®¿é—®ç«¯å£ï¼Œ service.spec.ports - name: http #å®šä¹‰ä¸€ä¸ªç«¯å£åç§° port: 80 #service 80ç«¯å£ protocol: TCP #åè®®ç±»å‹ targetPort: 80 #ç›®æ ‡podçš„ç«¯å£ nodePort: 30001 #nodeèŠ‚ç‚¹æš´éœ²çš„ç«¯å£ - name: https #SSL ç«¯å£ port: 443 #service 443ç«¯å£ protocol: TCP #ç«¯å£åè®® targetPort: 443 #ç›®æ ‡podç«¯å£ nodePort: 30043 #nodeèŠ‚ç‚¹æš´éœ²çš„SSLç«¯å£ selector: #serviceçš„æ ‡ç­¾é€‰æ‹©å™¨ï¼Œå®šä¹‰è¦è®¿é—®çš„ç›®æ ‡pod app: xin01-nginx-deployment-label #å°†æµé‡è·¯åˆ°é€‰æ‹©çš„podä¸Šï¼Œé¡»ç­‰äºDeployment.spec.selector.matchLabels","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-3/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"yamlæ–‡ä»¶è¯­æ³•åŸºç¡€ ï¼ˆä¸‰ï¼‰","uri":"/posts/kubernetes/primary/kubernetes-3/"},{"categories":["Kubernetes"],"content":"5.pod èµ„æºæ¸…å•è¯¦ç»†è§£è¯» apiVersion: v1 #ç‰ˆæœ¬å·ï¼Œä¾‹å¦‚ v1 kind: Pod #èµ„æºç±»å‹ï¼Œå¦‚ Pod metadata: #å…ƒæ•°æ® name: string # Pod åå­— namespace: string # Pod æ‰€å±çš„å‘½åç©ºé—´ labels: #è‡ªå®šä¹‰æ ‡ç­¾ - name: string #è‡ªå®šä¹‰æ ‡ç­¾åå­— annotations: #è‡ªå®šä¹‰æ³¨é‡Šåˆ—è¡¨ - name: string spec: # Pod ä¸­å®¹å™¨çš„è¯¦ç»†å®šä¹‰ containers: # Pod ä¸­å®¹å™¨åˆ—è¡¨ - name: string #å®¹å™¨åç§° image: string #å®¹å™¨çš„é•œåƒåç§° imagePullPolicy: [Always | Never | IfNotPresent] #è·å–é•œåƒçš„ç­–ç•¥ Alawys è¡¨ç¤ºä¸‹è½½é•œåƒ IfnotPresent è¡¨ç¤ºä¼˜å…ˆä½¿ç”¨æœ¬åœ°é•œåƒï¼Œå¦åˆ™ä¸‹è½½é•œåƒï¼ŒNerver è¡¨ç¤ºä»…ä½¿ç”¨æœ¬åœ°é•œåƒ command: [string] #å®¹å™¨çš„å¯åŠ¨å‘½ä»¤åˆ—è¡¨ï¼Œå¦‚ä¸æŒ‡å®šï¼Œä½¿ç”¨æ‰“åŒ…æ—¶ä½¿ç”¨çš„å¯åŠ¨å‘½ä»¤ args: [string] #å®¹å™¨çš„å¯åŠ¨å‘½ä»¤å‚æ•°åˆ—è¡¨ workingDir: string #å®¹å™¨çš„å·¥ä½œç›®å½• volumeMounts: #æŒ‚è½½åˆ°å®¹å™¨å†…éƒ¨çš„å­˜å‚¨å·é…ç½® - name: string #å¼•ç”¨ pod å®šä¹‰çš„å…±äº«å­˜å‚¨å·çš„åç§°ï¼Œéœ€ç”¨ volumes[]éƒ¨åˆ†å®šä¹‰çš„çš„å·å mountPath: string #å­˜å‚¨å·åœ¨å®¹å™¨å†… mount çš„ç»å¯¹è·¯å¾„ï¼Œåº”å°‘äº 512 å­—ç¬¦ readOnly: boolean #æ˜¯å¦ä¸ºåªè¯»æ¨¡å¼ ports: #éœ€è¦æš´éœ²çš„ç«¯å£åº“å· - name: string #ç«¯å£å·åç§° containerPort: int #å®¹å™¨éœ€è¦ç›‘å¬çš„ç«¯å£å· hostPort: int #å®¹å™¨æ‰€åœ¨ä¸»æœºéœ€è¦ç›‘å¬çš„ç«¯å£å·ï¼Œé»˜è®¤ä¸ Container ç›¸åŒ protocol: string #ç«¯å£åè®®ï¼Œæ”¯æŒ TCP å’Œ UDPï¼Œé»˜è®¤ TCP env: #å®¹å™¨è¿è¡Œå‰éœ€è®¾ç½®çš„ç¯å¢ƒå˜é‡åˆ—è¡¨ - name: string #ç¯å¢ƒå˜é‡åç§° value: string #ç¯å¢ƒå˜é‡çš„å€¼ resources: #èµ„æºé™åˆ¶å’Œè¯·æ±‚çš„è®¾ç½® limits: #èµ„æºé™åˆ¶çš„è®¾ç½® cpu: string #cpu çš„é™åˆ¶ï¼Œå•ä½ä¸º core æ•° memory: string #å†…å­˜é™åˆ¶ï¼Œå•ä½å¯ä»¥ä¸º Mib/Gib requests: #èµ„æºè¯·æ±‚çš„è®¾ç½® cpu: string #cpu è¯·æ±‚ï¼Œå®¹å™¨å¯åŠ¨çš„åˆå§‹å¯ç”¨æ•°é‡ memory: string #å†…å­˜è¯·æ±‚ï¼Œå®¹å™¨å¯åŠ¨çš„åˆå§‹å¯ç”¨å†…å­˜ livenessProbe: #å¯¹ Pod å†…ä¸ªå®¹å™¨å¥åº·æ£€æŸ¥çš„è®¾ç½®ï¼Œå½“æ¢æµ‹æ— å“åº”å‡ æ¬¡åå°†è‡ªåŠ¨é‡å¯è¯¥å®¹å™¨ï¼Œæ£€æŸ¥æ–¹æ³•æœ‰ execã€httpGet å’Œ tcpSocketï¼Œå¯¹ä¸€ä¸ªå®¹å™¨åªéœ€è®¾ç½®å…¶ä¸­ä¸€ç§æ–¹æ³•å³å¯ exec: #å¯¹ Pod å®¹å™¨å†…æ£€æŸ¥æ–¹å¼è®¾ç½®ä¸º exec æ–¹å¼ command: [string] #exec æ–¹å¼éœ€è¦åˆ¶å®šçš„å‘½ä»¤æˆ–è„šæœ¬ httpGet: #å¯¹ Pod å†…ä¸ªå®¹å™¨å¥åº·æ£€æŸ¥æ–¹æ³•è®¾ç½®ä¸º HttpGetï¼Œéœ€è¦åˆ¶å®š Pathã€port path: string port: number host: string scheme: string HttpHeaders: - name: string value: string tcpSocket: #å¯¹ Pod å†…ä¸ªå®¹å™¨å¥åº·æ£€æŸ¥æ–¹å¼è®¾ç½®ä¸º tcpSocket æ–¹å¼ port: number initialDelaySeconds: 0 #å®¹å™¨å¯åŠ¨å®Œæˆåé¦–æ¬¡æ¢æµ‹çš„æ—¶é—´ï¼Œå•ä½ä¸ºç§’ timeoutSeconds: 0 #å¯¹å®¹å™¨å¥åº·æ£€æŸ¥æ¢æµ‹ç­‰å¾…å“åº”çš„è¶…æ—¶æ—¶é—´ï¼Œå•ä½ç§’ï¼Œé»˜è®¤ 1 ç§’ periodSeconds: 0 #å¯¹å®¹å™¨ç›‘æ§æ£€æŸ¥çš„å®šæœŸæ¢æµ‹æ—¶é—´è®¾ç½®ï¼Œå•ä½ç§’ï¼Œé»˜è®¤ 10 ç§’ä¸€æ¬¡ successThreshold: 0 failureThreshold: 0 securityContext: privileged:false restartPolicy: [Always | Never | OnFailure]#Pod çš„é‡å¯ç­–ç•¥ï¼ŒAlways è¡¨ç¤ºä¸€æ—¦ä¸ç®¡ä»¥ä½•ç§æ–¹å¼ç»ˆæ­¢è¿è¡Œï¼Œkubelet éƒ½å°†é‡å¯ï¼ŒOnFailure è¡¨ç¤ºåªæœ‰ Pod ä»¥é 0 é€€å‡ºç é€€å‡ºæ‰é‡å¯ï¼ŒNerver è¡¨ç¤ºä¸å†é‡å¯è¯¥ Pod nodeSelector: obeject #è®¾ç½® NodeSelector è¡¨ç¤ºå°†è¯¥ Pod è°ƒåº¦åˆ°åŒ…å«è¿™ä¸ª label çš„ nodeä¸Šï¼Œä»¥ keyï¼švalue çš„æ ¼å¼æŒ‡å®š imagePullSecrets: #Pull é•œåƒæ—¶ä½¿ç”¨çš„ secret åç§°ï¼Œä»¥ keyï¼šsecretkey æ ¼å¼æŒ‡å®š - name: string hostNetwork:false #æ˜¯å¦ä½¿ç”¨ä¸»æœºç½‘ç»œæ¨¡å¼ï¼Œé»˜è®¤ä¸º falseï¼Œå¦‚æœè®¾ç½®ä¸º trueï¼Œè¡¨ç¤ºä½¿ç”¨å®¿ä¸»æœºç½‘ç»œ volumes: #åœ¨è¯¥ pod ä¸Šå®šä¹‰å…±äº«å­˜å‚¨å·åˆ—è¡¨ - name: string #å…±äº«å­˜å‚¨å·åç§° ï¼ˆvolumes ç±»å‹æœ‰å¾ˆå¤šç§ï¼‰ emptyDir: {} #ç±»å‹ä¸º emtyDir çš„å­˜å‚¨å·ï¼Œä¸ Pod åŒç”Ÿå‘½å‘¨æœŸçš„ä¸€ä¸ªä¸´æ—¶ç›®å½•ã€‚ä¸ºç©ºå€¼ hostPath: string #ç±»å‹ä¸º hostPath çš„å­˜å‚¨å·ï¼Œè¡¨ç¤ºæŒ‚è½½ Pod æ‰€åœ¨å®¿ä¸»æœºçš„ç›®å½• path: string #Pod æ‰€åœ¨å®¿ä¸»æœºçš„ç›®å½•ï¼Œå°†è¢«ç”¨äºåŒæœŸä¸­ mount çš„ç›®å½• secret: #ç±»å‹ä¸º secret çš„å­˜å‚¨å·ï¼ŒæŒ‚è½½é›†ç¾¤ä¸å®šä¹‰çš„ secre å¯¹è±¡åˆ°å®¹å™¨å†…éƒ¨ scretname: string items: - key: string path: string configMap: #ç±»å‹ä¸º configMap çš„å­˜å‚¨å·ï¼ŒæŒ‚è½½é¢„å®šä¹‰çš„ configMap å¯¹è±¡åˆ°å®¹å™¨å†…éƒ¨ name: string items: - key: string path: string#test-pod apiVersion: v1 #æŒ‡å®šapiç‰ˆæœ¬ï¼Œæ­¤å€¼å¿…é¡»åœ¨kubectl apiversionä¸­ kind: Pod #æŒ‡å®šåˆ›å»ºèµ„æºçš„è§’è‰²/ç±»å‹ metadata: #èµ„æºçš„å…ƒæ•°æ®/å±æ€§ name: test-pod #èµ„æºçš„åå­—ï¼Œåœ¨åŒä¸€ä¸ªnamespaceä¸­å¿…é¡»å”¯ä¸€ labels: #è®¾å®šèµ„æºçš„æ ‡ç­¾ k8s-app: apache version: v1 kubernetes.io/cluster-service: \"true\" annotations: #è‡ªå®šä¹‰æ³¨è§£åˆ—è¡¨ - name: String #è‡ªå®šä¹‰æ³¨è§£åå­— spec: #specification of the resource content æŒ‡å®šè¯¥èµ„æºçš„å†…å®¹ restartPolicy: Always #è¡¨æ˜è¯¥å®¹å™¨ä¸€ç›´è¿è¡Œï¼Œé»˜è®¤k8sçš„ç­–ç•¥ï¼Œåœ¨æ­¤å®¹å™¨é€€å‡ºåï¼Œä¼šç«‹å³åˆ›å»ºä¸€ä¸ªç›¸åŒçš„å®¹å™¨ nodeSelector: #èŠ‚ç‚¹é€‰æ‹©ï¼Œå…ˆç»™ä¸»æœºæ‰“æ ‡ç­¾kubectl label nodes kube-node1 zone=node1 zone: node1 containers: - name: test-pod #å®¹å™¨çš„åå­— image: 10.192.21.18:5000/test/chat:latest #å®¹å™¨ä½¿ç”¨çš„é•œåƒåœ°å€ imagePullPolicy: Never #ä¸‰ä¸ªé€‰æ‹©Alwaysã€Neverã€IfNotPresentï¼Œæ¯æ¬¡å¯åŠ¨æ—¶æ£€æŸ¥å’Œæ›´æ–°ï¼ˆä»registeryï¼‰imagesçš„ç­–ç•¥ï¼Œ # Alwaysï¼Œæ¯æ¬¡éƒ½æ£€æŸ¥ # Neverï¼Œæ¯æ¬¡éƒ½ä¸æ£€æŸ¥ï¼ˆä¸ç®¡æœ¬åœ°æ˜¯å¦æœ‰ï¼‰ # IfNotPresentï¼Œå¦‚æœæœ¬åœ°æœ‰å°±ä¸æ£€æŸ¥ï¼Œå¦‚æœæ²¡æœ‰å°±æ‹‰å– command: ['sh'] #å¯åŠ¨å®¹å™¨çš„è¿è¡Œå‘½ä»¤ï¼Œå°†è¦†ç›–å®¹å™¨ä¸­çš„Entrypoint,å¯¹åº”Dockefileä¸­çš„ENTRYPOINT args: [\"$(str)\"] #å¯åŠ¨å®¹å™¨çš„å‘½ä»¤å‚æ•°ï¼Œå¯¹åº”Dockerfileä¸­CMDå‚æ•° env: #æŒ‡å®šå®¹å™¨ä¸­çš„ç¯å¢ƒå˜é‡ - name: str #å˜é‡çš„åå­— value: \"/etc/run.sh\" #å˜é‡çš„å€¼ resources: #èµ„æºç®¡ç† requests: #å®¹å™¨è¿è¡Œæ—¶ï¼Œæœ€ä½èµ„æºéœ€æ±‚ï¼Œä¹Ÿå°±æ˜¯è¯´æœ€å°‘éœ€è¦å¤šå°‘èµ„æºå®¹å™¨æ‰èƒ½æ­£å¸¸è¿è¡Œ cpu: 0.1 #CPUèµ„æºï¼ˆæ ¸æ•°ï¼‰ï¼Œä¸¤ç§æ–¹å¼ï¼Œæµ®ç‚¹æ•°æˆ–è€…æ˜¯æ•´æ•°+mï¼Œ0.1=100mï¼Œæœ€å°‘å€¼ä¸º0.001æ ¸ï¼ˆ1mï¼‰ memory: 32Mi #å†…å­˜ä½¿ç”¨é‡ limits: #èµ„æºé™åˆ¶ cpu: 0.5 memory: 1000Mi ports: - containerPort: 80 #å®¹å™¨å¼€å‘å¯¹å¤–çš„ç«¯å£ name: httpd #åç§° protocol: TCP livenessProbe: #podå†…å®¹å™¨å¥åº·æ£€æŸ¥çš„è®¾ç½® httpGet: #é€šè¿‡httpgetæ£€æŸ¥å¥åº·ï¼Œè¿”å›200-399ä¹‹é—´ï¼Œåˆ™è®¤ä¸ºå®¹å™¨æ­£å¸¸ path: / #URIåœ°å€ port: 80 #host: 127.0.0.1 #ä¸»æœºåœ°å€ scheme: HTTP initialDelaySeconds: 180 #è¡¨æ˜ç¬¬ä¸€æ¬¡æ£€æµ‹åœ¨å®¹å™¨å¯åŠ¨åå¤šé•¿æ—¶é—´åå¼€å§‹ timeoutSeconds: 5 #æ£€æµ‹çš„è¶…æ—¶æ—¶é—´ periodSeconds: 15 #æ£€æŸ¥é—´éš”æ—¶é—´ #ä¹Ÿå¯ä»¥ç”¨è¿™ç§æ–¹æ³• #exec: æ‰§è¡Œå‘½ä»¤çš„æ–¹æ³•è¿›è¡Œç›‘æµ‹ï¼Œå¦‚æœå…¶é€€å‡ºç ä¸ä¸º0ï¼Œåˆ™è®¤ä¸ºå®¹å™¨æ­£å¸¸ # command: # - cat # - /tmp/health #ä¹Ÿå¯ä»¥ç”¨è¿™ç§æ–¹æ³• #tcpSocket: //é€šè¿‡tcpSocketæ£€æŸ¥å¥åº· # port: num","date":"2023-01-12","objectID":"/posts/kubernetes/primary/kubernetes-3/:5:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"yamlæ–‡ä»¶è¯­æ³•åŸºç¡€ ï¼ˆä¸‰ï¼‰","uri":"/posts/kubernetes/primary/kubernetes-3/"},{"categories":["Ceph"],"content":"https://docs.ceph.com/en/latest/cephfs/é“¾æ¥ Ceph FSå³Ceph Filesy Stem,å¯ä»¥å®ç°æ–‡ä»¶ç³»ç»Ÿå…±äº«åŠŸèƒ½,å®¢æˆ·ç«¯é€šè¿‡cephåè®®æŒ‚è½½å¹¶ä½¿ç”¨cephé›†ç¾¤ä½œä¸ºæ•°æ®å­˜å‚¨æœåŠ¡å™¨ã€‚ Ceph FSåœ¨å…¬å¸ä¸­ä½¿ç”¨å¸¸åœºæ™¯ç›¸å¯¹æ¯”è¾ƒå¤šï¼Œä¸»è¦ç”¨äºåŠ¨é™åˆ†ç¦»ï¼Œå¤šæœåŠ¡æ•°æ®å…±äº«ä¾‹å¦‚Nginx ã€‚ Cephè¢«å¤šä¸ªæœåŠ¡åŒæ—¶æŒ‚è½½ï¼Œå†™å…¥æ•°æ®æ—¶èƒ½å®æ—¶åŒæ­¥ï¼Œç±»ä¼¼NFSã€‚ å®¢æˆ·ç«¯é€šè¿‡cephåè®®æŒ‚è½½Linuxå†…æ ¸ç‰ˆæœ¬\u003e2.6.34 å°±å†…ç½®Cpehæ¨¡å—æ— éœ€å®‰è£… MDSå­˜å‚¨æ± ç”¨äºå­˜å‚¨Ceph FSä¸Šå­˜å‚¨çš„æ–‡ä»¶ç›¸å…³çš„å…ƒæ•°æ®Ceph FSéœ€è¦è¿è¡ŒMeta Data Services(MDS)æœåŠ¡ï¼Œå…¶å®ˆæŠ¤è¿›ç¨‹ä¸ºceph-mds, ceph-mdsè¿›ç¨‹ç®¡ç†ä¸cephFSä¸Šå­˜å‚¨çš„æ–‡ä»¶ç›¸å…³çš„å…ƒæ•°æ®ï¼Œå¹¶åè°ƒå¯¹cephå­˜å‚¨é›†ç¾¤çš„è®¿é—®ã€‚ mate data poolï¼šç”¨äºå­˜å‚¨Ceph FSä¸Šå­˜å‚¨çš„æ–‡ä»¶ç›¸å…³çš„å…ƒæ•°æ®ï¼Œpoolåç§°å¯ä»¥éšæ„æŒ‡å®šã€‚**ceph data pool **ï¼šç”¨æ¥ä¿å­˜å®¢æˆ·ç«¯ä¸Šä¼ åˆ°Cephçš„æ•°æ®ã€‚ ","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:0:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"3.1 éƒ¨ç½²MDSæœåŠ¡ åœ¨æŒ‡å®šçš„ceph-mdsæœåŠ¡å™¨,éƒ¨ç½²ceph-mdsæœåŠ¡ï¼Œå¯ä»¥å’Œå…¶å®ƒæœåŠ¡å™¨æ··ç”¨(å¦‚ceph-mon.ceph-mgr) Ubuntu: #æŸ¥çœ‹å½“å‰å¯ç”¨ç‰ˆæœ¬ root@ceph-mgr1:~# sudo su - root root@ceph-mgr1:~# apt-cache madison ceph-mds #é€‰æ‹©ç‰ˆæœ¬å®‰è£… root@ceph-mgr1:~# apt install ceph-mds=16.2.5-1bionicCentOS: Centos: [root@ceph-mgr1 ~]# yum install ceph-mds -yéƒ¨ç½²ï¼š [ceph@ceph-deploy ceph-cluster]$ ceph-deploymds create ceph-mgr1","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"3.2 éªŒè¯ MDS æœåŠ¡ MDSæœåŠ¡ç›®å‰è¿˜æ— æ³•æ­£å¸¸ä½¿ç”¨ï¼Œéœ€è¦ä¸ºMDSåˆ›å»ºå­˜å‚¨æ± ç”¨äºä¿å­˜MDSçš„æ•°æ®. [ceph@ceph-deploy ceph-clusterI$ ceph mds stat 1 up:standby #å½“å‰ä¸ºå¤‡ç”¨çŠ¶æ€ï¼Œéœ€è¦åˆ†é…poolæ‰å¯ä»¥ä½¿ç”¨ï¼Œ","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"3.3 åˆ›å»ºCephFS metadataå’Œdataå­˜å‚¨æ± : ä½¿ç”¨CephFSä¹‹å‰éœ€è¦äº‹å…ˆäºé›†ç¾¤ä¸­åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿï¼Œå¹¶ä¸ºå…¶åˆ†åˆ«æŒ‡å®šå…ƒæ•°æ®å’Œæ•°æ®ç›¸å…³çš„å­˜å‚¨æ± ï¼Œå¦‚ä¸‹å‘½ä»¤å°†åˆ›å»ºåä¸ºmycephfsçš„æ–‡ä»¶ç³»ç»Ÿï¼Œå®ƒä½¿ç”¨cephfs-metadataä½œä¸ºå…ƒæ•°æ®å­˜å‚¨æ± ï¼Œä½¿ç”¨cephfs-dataä¸ºæ•°æ®å­˜å‚¨æ± : #ä¿å­˜ metadataçš„pool [ceph@ceph-deploy ceph-cluster]$ ceph osd pool create cephfs-metadata 32 32 pool 'cephfs-metadata' created #ç”Ÿäº§ç¯å¢ƒä¸‹matedataæ•°æ®çš„pgæ•°é‡ä¸º16ä¸ªå°±å¯ä»¥äº†ï¼ˆæ•°æ®é‡å° 10å‡ ä¸ªTçš„æ•°é‡å…ƒæ•°æ®æ‰å‡ ä¸ªGï¼‰ #ä¿å­˜å®¢æˆ·ç«¯æ•°æ®çš„pool [ceph@ceph-deploy ceph-cluster]$ ceph osd pool create cephfs-data 64 64 pool 'cephfs-data' created [ceph@ceph-deploy ceph-cluster]$ ceph -S #å½“å‰cephçŠ¶æ€ #æŸ¥çœ‹å½“å‰å­˜å‚¨æ±  ceph@ceph-dep Loy :~/ ceph-cluster$ ceph osd pool ls device health_ metrics 32 mypool myrbd1 .rgw.root default.rgw.Log default.rgw.control default.rgw.meta cephfs-metadata cepnfs-data","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"3.4 åˆ›å»ºCeph FS å¹¶éªŒè¯ Ceph FSåœ¨æ—©æœŸç‰ˆæœ¬ä¸­ä¸€ä¸ªé›†ç¾¤ä¸­åªèƒ½åˆ›å»ºä¸€ä¸ªï¼Œç°åœ¨æ”¯æŒå¯ç”¨å¤šä¸ª ceph fs new fs_name metadata data #--allow-dangerous-metadata-overlay:å…è®¸éå®‰å…¨çš„å…ƒæ•°æ®å†™å…¥ [ceph@ceph-deploy ceph-cluster]$ ceph fs new mycephfs cephfs-metadata cephfs-data #æŸ¥çœ‹Ceph FSçŠ¶æ€ cephaceph-dep Loy:~/ ceph-cluster$ ceph -S cluster: id: 5ac860ab- 9a4e- 4edd 9da2 e3de293a8d44 health: HEALTH 0K se rvices : mon: 3 daemons, auorum ceph-mon1 , ceph-mon2 , ceph-mon3 (age 48m) mgr: ceph-mg r1(active, since 47m), standbys: ceph-mgr2 mds: 1/1 daemons up osd:20 osds: 20 up (since 47m), 20 in(since 6d) rgw: 1 daemon active (1 hosts, 1 zones ) data : voLumes: 1/1 healthy pools: 10 pools, 329 pgs objects: 253 objects, 89 MiB usage : 562 MiB used, 2.0 TiB / 2.0 TiB avail pgs: 329 act ive+c Lean io: Client : 1.3 KiB/S wr ,0 op/s rd, 4 op/s wr cephaceph-deploy :~/ceph-cluster$ ceph mds stat mycephfs:1 {0=ceph-mgr1=up: active} #activeè¡¨ç¤ºå¯ç”¨æˆåŠŸ","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"3.5 å®¢æˆ·ç«¯æŒ‚è½½Ceph FS åœ¨cephçš„å®¢æˆ·ç«¯æµ‹è¯•CephFSçš„æŒ‚è½½ï¼Œéœ€è¦æŒ‡å®šmonèŠ‚ç‚¹ï¼ˆè´Ÿè´£æä¾›è®¤è¯ï¼‰çš„6789ç«¯å£: ï¼ˆ6789å°±æ˜¯CephFSå¯¹å¤–æä¾›æŒ‚è½½çš„ç«¯å£ï¼‰ #ä½¿ç”¨adminæƒé™æŒ‚è½½ [ceph@ceph-deploy ceph-clusterl$ cat ceph.client.admin.keyring [client.admin] key = AQCrVhZhof2zKxAATltgtgAdDteHSAGFEyE/nw== caps mds = \"allow *\" caps mgr = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\"ubuntuåŠcentos client æŒ‚è½½(å†…æ ¸ç‰ˆæœ¬2.6.34åœ¨3.6.34åŠä»¥ä¸Š) #ä½¿ç”¨keyæŒ‚è½½ #ipå†™moné›†ç¾¤ä¸­çš„ä»»æ„ä¸€ä¸ªéƒ½è¡Œï¼Œä¹Ÿå¯ä»¥å†™ä¸‰ä¸ªæä¾›é«˜å¯ç”¨ #æŒ‚è½½åˆ°/mntç›®å½• root@ceph-client3-ubuntu1 804:-# mount -t ceph 172.31.6.101:6789:/ /mnt -o name=admin,secret=AQCrVhZhof2zKxAATltgtgAdDteHSAGFEyE/mw==æŸ¥çœ‹æŒ‚è½½æƒ…å†µ åœ¨ä»»ä½•ä¸€ä¸ªèŠ‚ç‚¹å˜æ›´æ•°æ®ï¼Œä¼šç«‹å³åœ¨å…¶ä»–å®¢æˆ·ç«¯åŒæ­¥æ˜¾ç¤ºï¼Œéå¸¸é€‚åˆå¤šèŠ‚ç‚¹çš„webæœåŠ¡ã€‚ ","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:5:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"æ¨¡æ‹Ÿwebå¤šèŠ‚ç‚¹æœåŠ¡åœºæ™¯ä¸‹ï¼Œæ•°æ®åŒæ­¥æ•ˆæœ #å®‰è£…nginx yum install epel-release -y yum install nginx -y #åˆ›å»ºæ•°æ®ç›®å½• mkdir /data/nginx/statics #æŒ‚è½½ root@ceph-client3-ubuntu1804:~# mountä¸€t ceph 172.31.6.101:6789:/ /data/nginx/statics -o name=admin ,secret=AQA3dhdhMd/UABAA2SNpJ+hcK1dD5L2Hj5XMg== vim /etc/ngxin.conf server { listen 80; listen [::] : 80; server_name _; root /data/nginx/statics; cd /data/nginx/statics #ä¸Šä¼ æ–‡ä»¶å°½ç®¡å†…æ ¸ä¸­è‡ªå¸¦CephFSç»„ä»¶ï¼Œå› ä¸ºæ€§èƒ½å…³ç³»è¿˜æ˜¯å»ºè®®ä½¿ç”¨æœ€æ–°çš„å†…æ ¸æ¨¡å—ï¼Œå®‰è£…Ceph ceph common ï¼ˆceph çš„å…¬å…±ç»„ä»¶ï¼‰ Ubuntuæºï¼š vim /etc/ deb https://mirrors.tuna.tsinghua.edu.cn/ceph/debian-pacific bionic main #å¯¼å…¥key wget -q -O- 'https ://download.ceph.com/keys/release.asc' | sudo apt-key add - apt update #å¯¼å…¥key wget -q -O- 'https://mirrors.tuna.tsinghua.edu.cn/ceph/keys/release.asc' | sudo apt-key add -CentOS å®‰è£…16ç‰ˆæœ¬ä¹‹å‰çš„å®¢æˆ·ç«¯ wget https://mirrors.tuna.tsinghua.edu.cn/ceph/rpm-15.2.15/el7/x86_64/ceph-common-15.2.15-0.el7.x86_64.rpm","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:5:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"16ç‰ˆæœ¬çš„CephFSçŠ¶æ€ ","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:5:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"13ç‰ˆæœ¬çš„CephFSçŠ¶æ€ å‹æµ‹å·¥å…·ï¼šJmeter ","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:5:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"3.6 å‘½ä»¤æ€»ç»“ åˆ—å‡ºå­˜å‚¨æ± å¹¶æ˜¾ç¤ºid $ ceph osd lspools $ ceph osd Ispools 1 device_ health metrics 2 mypool 3 cephfs-metadata 4 cephfs-dataæŸ¥çœ‹pgçŠ¶æ€ $ceph pg stat $ceph pg stat 129 pgs: 129 active+clean; 319 KIB data, 1.1 GiB used, 2.0 TiB / 2.0 TiB availæŸ¥çœ‹æŒ‡å®špoolæˆ–æ‰€æœ‰çš„poolçš„çŠ¶æ€ $ ceph osd pool stats mypool pool myrdb1 id 2 nothing is going onæŸ¥çœ‹é›†ç¾¤å­˜å‚¨çŠ¶æ€ $ ceph df detailæŸ¥çœ‹osdçš„çŠ¶æ€ ceph osd statæ˜¾ç¤ºOSDåº•å±‚è¯¦ç»†ä¿¡æ¯ ceph osd dumpæ˜¾ç¤ºOSDå’ŒnodeèŠ‚ç‚¹å¯¹äºå…³ç³» ceph osd treeæŸ¥çœ‹monèŠ‚ç‚¹çŠ¶æ€ ceph mon stat æŸ¥çœ‹monè¯¦ç»†ä¿¡æ¯ ceph mon dump","date":"2023-01-11","objectID":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/:6:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤ç»´æŠ¤ ï¼ˆä¸‰ï¼‰","uri":"/posts/ceph/3.ceph-fs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"categories":["Ceph"],"content":"æ¨èé…ç½® CPU 16C æˆ– 32C åŒè·¯å†…å­˜ 64Gä»¥ä¸Šç£ç›˜ NVME ä¼ä¸šçº§SSD æ¨è intel D7 P5520 æ•°æ®ä¸­å¿ƒä¼ä¸šçº§å›ºæ€ç¡¬ç›˜U.2 nvmeåè®®æœåŠ¡å™¨å·¥ä½œç«™SSD P5520 3.84TB intel è‹±ç‰¹å°” S4510/S4520 æ•°æ®ä¸­å¿ƒä¼ä¸šçº§å›ºæ€ç¡¬ç›˜SATA3 S4520 3.84T mon æœåŠ¡å™¨ 16C 32G 200GMgr æœåŠ¡å™¨ 8C 16G 200GCeph-deploy 4c 8G 120G","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"ä¸€ã€éƒ¨ç½²æ–¹å¼ ceph-ansibleï¼šhttps://github.com/ceph/ceph-ansible #python ceph-saltï¼šhttps://github.com/ceph/ceph-salt #python ceph-containerï¼šhttps://github.com/ceph/ceph-container #shell ceph-chefï¼šhttps://github.com/ceph/ceph-chef #Ruby ceph-deployï¼šhttps://github.com/ceph/ceph-deploy #python ceph-deployæ˜¯ä¸€ä¸ª ceph å®˜æ–¹ç»´æŠ¤çš„åŸºäº ceph-deploy å‘½ä»¤è¡Œéƒ¨ç½² ceph é›†ç¾¤çš„å·¥å…·ï¼ŒåŸºäº ssh æ‰§è¡Œå¯ä»¥ sudo æƒé™çš„ shell å‘½ä»¤ä»¥åŠä¸€äº› python è„šæœ¬ å®ç° ceph é›†ç¾¤çš„éƒ¨ç½²å’Œç®¡ç†ç»´æŠ¤ã€‚ Ceph-deploy åªç”¨äºéƒ¨ç½²å’Œç®¡ç† ceph é›†ç¾¤ï¼Œå®¢æˆ·ç«¯éœ€è¦è®¿é—® cephï¼Œéœ€è¦éƒ¨ç½²å®¢æˆ·ç«¯å·¥å…·ã€‚ ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"äºŒã€æœåŠ¡å™¨å‡†å¤‡ ç¡¬ä»¶æ¨èï¼šhttps://docs.ceph.com/en/latest/start/hardware-recommendations/# ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"2.1 OSDæœåŠ¡å™¨ ä¸‰å°æœåŠ¡å™¨ä½œä¸º ceph é›†ç¾¤ OSD å­˜å‚¨æœåŠ¡å™¨ï¼Œæ¯å°æœåŠ¡å™¨æ”¯æŒä¸¤ä¸ªç½‘ç»œï¼Œpublic ç½‘ç»œé’ˆå¯¹å®¢æˆ·ç«¯è®¿é—®ï¼Œcluster ç½‘ç»œç”¨äºé›†ç¾¤ç®¡ç†åŠæ•°æ®åŒæ­¥ï¼Œæ¯å°ä¸‰å—æˆ–ä»¥ä¸Šçš„ç£ç›˜ã€‚ 10.1.0.30/192.168.10.240\r10.0.0.31/192.168.10.241\r10.0.0.32/192.168.10.242\rä¸‰å°å­˜å‚¨æœåŠ¡å™¨ç£ç›˜åˆ’åˆ†ï¼š /dev/sdb /dev/sdc /dev/sdd /dev/sde /dev/sdf #200G ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:3:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"2.2 Mon ç›‘è§†æœåŠ¡å™¨ ä¸‰å°æœåŠ¡å™¨ä½œä¸º ceph é›†ç¾¤ Mon ç›‘è§†æœåŠ¡å™¨ï¼Œæ¯å°æœåŠ¡å™¨å¯ä»¥å’Œ ceph é›†ç¾¤çš„ cluster ç½‘ç»œé€šä¿¡ã€‚ 10.1.0.33/192.168.10.243\r10.0.0.34/192.168.10.244\r10.0.0.35/192.168.10.245","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:3:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"2.3 ceph-mgr ç®¡ç†æœåŠ¡å™¨ ä¸¤ä¸ª ceph-mgr ç®¡ç†æœåŠ¡å™¨ï¼Œå¯ä»¥å’Œ ceph é›†ç¾¤çš„ cluster ç½‘ç»œé€šä¿¡ã€‚ 10.1.0.30/192.168.10.240\r10.0.0.31/192.168.10.241","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:3:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"2.4 Ceph-deploy éƒ¨ç½²æœåŠ¡å™¨ ä¸€ä¸ªæœåŠ¡å™¨ç”¨äºéƒ¨ç½² ceph é›†ç¾¤å³å®‰è£… Ceph-deployï¼Œä¹Ÿå¯ä»¥å’Œ ceph-mgr ç­‰å¤ç”¨ã€‚ 10.1.0.31/192.168.10.248 ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:3:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"ä¸‰ã€ æœåŠ¡å™¨ç¯å¢ƒå‡†å¤‡ ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"3.1 é…ç½®é›†ç¾¤ç½‘ç»œ #æ›´æ”¹ç½‘å¡åç§°ä¸ºeth*: sudo vim /etc/default/grub GRUB_DEFAULT=0 GRUB_TIMEOUT_STYLE=hidden GRUB_TIMEOUT=0 GRUB_DISTRIBUTOR=`lsb_release -i -s 2\u003e /dev/null || echo Debian` GRUB_CMDLINE_LINUX_DEFAULT=\"maybe-ubiquity\" GRUB_CMDLINE_LINUX=\"net.ifnames=0 biosdevname=0\" ~$ sudo update-grub Sourcing file `/etc/default/grub' Generating grub configuration file ... Found linux image: /boot/vmlinuz-4.15.0-55-generic Found initrd image: /boot/initrd.img-4.15.0-55-generic done#é…ç½®clusterå’Œpublicç½‘ç»œ vim /etc/apt/sources.list # This is the network config written by 'subiquity' network: ethernets: eth0: dhcp4: no dhcp6: no addresses: - 10.1.0.39/24 gateway4: 10.1.0.254 nameservers: addresses: - 223.5.5.5 eth1: dhcp4: no dhcp6: no addresses: [192.168.10.239/24] version: 2 #ç”Ÿæ•ˆ netplan apply #éªŒè¯ä¸¤å—ç½‘å¡IPåœ°å€ 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP group default qlen 1000 link/ether fe:fc:fe:cf:34:9d brd ff:ff:ff:ff:ff:ff inet 10.1.0.39/24 brd 10.1.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::fcfc:feff:fecf:349d/64 scope link valid_lft forever preferred_lft forever 3: eth1: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP group default qlen 1000 link/ether fe:fc:fe:79:6f:6e brd ff:ff:ff:ff:ff:ff inet 192.168.10.239/24 brd 192.168.10.255 scope global eth1 valid_lft forever preferred_lft forever inet6 fe80::fcfc:feff:fe79:6f6e/64 scope link valid_lft forever preferred_lft forever","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:4:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"3.2 é…ç½®ä¸»æœºåè§£æ vim /etc/hosts 10.1.0.39 ceph-node1.xx.local ceph-node1 10.1.0.40 ceph-node2.xx.local ceph-node2 10.1.0.41 ceph-node3.xx.local ceph-node3 10.1.0.39 ceph-mon1.xx.local ceph-mon1 10.1.0.40 ceph-mon2.xx.local ceph-mon2 10.1.0.41 ceph-mon3.xx.local ceph-mon3 10.1.0.40 ceph-mgr1.xx.local ceph-mgr1 10.1.0.41 ceph-mgr2.xx.local ceph-mgr2 10.1.0.39 ceph-deploy.xx.local ceph-deploy","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:4:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"3.3 é…ç½®aptæº https://download.ceph.com/ #Cephå®˜æ–¹æº https://mirrors.aliyun.com/ceph/ #é˜¿é‡Œäº‘é•œåƒä»“åº“ http://mirrors.163.com/ceph/ #ç½‘æ˜“é•œåƒä»“åº“ https://mirrors.tuna.tsinghua.edu.cn/ceph/ #æ¸…åå¤§å­¦é•œåƒæºæ‰€æœ‰èŠ‚ç‚¹æ·»åŠ ceph æº wget -q -O- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add - echo deb https://download.ceph.com/debian-pacific/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list sudo apt update","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:4:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"3.4 æ—¶é—´åŒæ­¥ #è®¾ç½®æ—¶åŒº timedatectl set-timezone Asia/Shanghai #å®‰è£…chrony #ä¸‰èŠ‚ç‚¹å®‰è£… apt install chrony -y ##æœåŠ¡ç«¯é…ç½® vim /etc/chrony/chrony.conf # Welcome to the chrony configuration file. See chrony.conf(5) for more # information about usuable directives. # This will use (up to): # - 4 sources from ntp.ubuntu.com which some are ipv6 enabled # - 2 sources from 2.ubuntu.pool.ntp.org which is ipv6 enabled as well # - 1 source from [01].ubuntu.pool.ntp.org each (ipv4 only atm) # This means by default, up to 6 dual-stack and up to 2 additional IPv4-only # sources will be used. # At the same time it retains some protection against one of the entries being # down (compare to just using one of the lines). See (LP: #1754358) for the # discussion. # # About using servers from the NTP Pool Project in general see (LP: #104525). # Approved by Ubuntu Technical Board on 2011-02-08. # See http://www.pool.ntp.org/join.html for more information. # å› ä¸ºæƒ³ä¿®æ”¹æœ¬åœ°æ—¶é—´ï¼Œä¸å»å’Œå…¶ä»–æœåŠ¡å™¨åŒæ­¥ï¼Œå°†ä¸‹é¢è¿™å››ä¸ªpoolæ³¨é‡Šæ‰ pool ntp.ubuntu.com iburst maxsources 4 #pool 0.ubuntu.pool.ntp.org iburst maxsources 1 #pool 1.ubuntu.pool.ntp.org iburst maxsources 1 #pool 2.ubuntu.pool.ntp.org iburst maxsources 2 # æ·»åŠ è‡ªå·±ä½œä¸ºæœåŠ¡å™¨ #server 192.168.1.1 iburst # ä¸ºäº†æ–¹ä¾¿å®¢æˆ·ç«¯è¿æ¥æƒé™è®¾ç½®ä¸ºå…è®¸æ‰€æœ‰ allow all # å½“æ— æ³•å’Œå…¶ä»–åŒæ­¥æ—¶ï¼Œä½¿ç”¨æœ¬åœ°çš„æ—¶é—´å»ç»™å®¢æˆ·ç«¯åŒæ­¥ #æ³¨é‡Šï¼šå€¼10å¯ä»¥è¢«å…¶ä»–å€¼å–ä»£ï¼ˆ1~15ï¼‰ï¼Œstratum 1è¡¨ç¤ºè®¡ç®—æœºå…·æœ‰ç›´æ¥è¿æ¥çš„çœŸå®æ—¶é—´çš„å‚è€ƒæ—¶é—´æºï¼Œä¾‹å¦‚gpsï¼ŒåŸå­é’Ÿéƒ½å’ŒçœŸå®æ—¶é—´å¾ˆæ¥è¿‘æ¬¸ï¼Œ #stratum 2è¡¨ç¤ºè®¡ç®—æœºæœ‰ä¸€ä¸ªstratum 1çš„è®¡ç®—æœºä½œä¸ºåŒæ­¥æ—¶é—´æºï¼Œstratum 3è¡¨ç¤ºè¯¥è®¡ç®—æœºæœ‰ä¸€ä¸ªstratum 10çš„è®¡ç®—æœºä½œä¸ºåŒæ­¥æ—¶é—´æºã€‚ #é€‰æ‹©stratum 10.è¿™ä¸ªå€¼æ˜¯æ¯”è¾ƒå¤§çš„ï¼Œè¡¨ç¤ºè·ç¦»æœ‰çœŸå®æ—¶é—´çš„æœåŠ¡å™¨æ¯”è¾ƒè¿œï¼Œå®ƒçš„æ—¶é—´ä¸å¤ªå¯é ï¼Œå› æ­¤ï¼Œlocalå‘½ä»¤é€‰å–stratum 10å¯ä»¥ #é˜²æ­¢æœºå™¨æœ¬èº«çš„æ—¶é—´ä¸çœŸå®æ—¶é—´æ··æ·†ï¼Œå¯ä»¥ä¿è¯è¯¥æœºå™¨ä¸ä¼šå°†æœ¬èº«çš„æ—¶é—´æˆç»™é‚£äº›å¯ä»¥è¿æ¥åŒæ­¥åˆ°çœŸå®æ—¶é—´çš„ntpæœåŠ¡å™¨çš„ntpå®¢æˆ·ç«¯ã€‘ local stratum 10 # This directive specify the location of the file containing ID/key pairs for # NTP authentication. keyfile /etc/chrony/chrony.keys # This directive specify the file into which chronyd will store the rate # information. driftfile /var/lib/chrony/chrony.drift # Uncomment the following line to turn logging on. #log tracking measurements statistics # Log files location. logdir /var/log/chrony # Stop bad estimates upsetting machine clock. maxupdateskew 100.0 # This directive enables kernel synchronisation (every 11 minutes) of the # real-time clock. Note that it canâ€™t be used along with the 'rtcfile' directive. rtcsync # Step the system clock instead of slewing it if the adjustment is larger than # one second, but only in the first three clock updates. makestep 1 3#å®¢æˆ·ç«¯ # This will use (up to): # - 4 sources from ntp.ubuntu.com which some are ipv6 enabled # - 2 sources from 2.ubuntu.pool.ntp.org which is ipv6 enabled as well # - 1 source from [01].ubuntu.pool.ntp.org each (ipv4 only atm) # This means by default, up to 6 dual-stack and up to 2 additional IPv4-only # sources will be used. # At the same time it retains some protection against one of the entries being # down (compare to just using one of the lines). See (LP: #1754358) for the # discussion. # # About using servers from the NTP Pool Project in general see (LP: #104525). # Approved by Ubuntu Technical Board on 2011-02-08. # See http://www.pool.ntp.org/join.html for more information. pool 10.1.0.39 iburst maxsources 4 #pool 0.ubuntu.pool.ntp.org iburst maxsources 1 #pool 1.ubuntu.pool.ntp.org iburst maxsources 1 #pool 2.ubuntu.pool.ntp.org iburst maxsources 2 # This directive specify the location of the file containing ID/key pairs for # NTP authentication. keyfile /etc/chrony/chrony.keys # This directive specify the file into which chronyd will store the rate # information. driftfile /var/lib/chrony/chrony.drift # Uncomment the following line to turn logging on. #log tracking measurements statistics # Log files location. logdir /var/log/chrony # Stop bad estimates upsetting machine clock. maxupdateskew 100.0 # This directive enables kernel synchronisation (every 11 minutes) of the # real-time clock. Note that it canâ€™t be used along with the 'rtcfile' directive. rtcsync # Step the system clock instead of slewing it if the adjustment is larger than # one second, but only in the first three clock updates. makestep 1 3#æŸ¥çœ‹ ntp_servers çŠ¶æ€ chronyc source","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:4:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"3.5 åˆ›å»ºæ™®é€šç”¨æˆ· æ¨èä½¿ç”¨æŒ‡å®šçš„æ™®é€šç”¨æˆ·éƒ¨ç½²å’Œè¿è¡Œ ceph é›†ç¾¤ï¼Œæ™®é€šç”¨æˆ·åªè¦èƒ½ä»¥éäº¤äº’æ–¹å¼æ‰§è¡Œ sudo å‘½ä»¤æ‰§è¡Œä¸€äº›ç‰¹æƒå‘½ä»¤å³å¯ï¼Œæ–°ç‰ˆçš„ ceph-deploy å¯ä»¥æŒ‡å®šåŒ…å« root çš„åœ¨å†…åªè¦å¯ä»¥æ‰§è¡Œ sudo å‘½ä»¤çš„ç”¨æˆ·ï¼Œä¸è¿‡ä»ç„¶æ¨èä½¿ç”¨æ™®é€šç”¨æˆ·ï¼Œæ¯”å¦‚ cephã€cephuserã€cephadmin è¿™æ ·çš„ç”¨æˆ·å»ç®¡ç† ceph é›†ç¾¤ã€‚ åœ¨åŒ…å« ceph-deploy èŠ‚ç‚¹çš„å­˜å‚¨èŠ‚ç‚¹ã€mon èŠ‚ç‚¹å’Œ mgr èŠ‚ç‚¹ç­‰åˆ›å»º ceph ç”¨æˆ·ã€‚ #åˆ›å»ºç”¨æˆ· groupadd -r -g 20235 xceo \u0026\u0026 useradd -r -m -s /bin/bash -u 20235 -g 20235 xceo \u0026\u0026 echo xceo:ceamg.com | chpasswd ~ #:id xceo uid=20235(xceo) gid=20235(xceo) groups=20235(xceo) #å…è®¸ceph ç”¨æˆ·ä»¥sudoæ‰§è¡Œç‰¹æ®Šæƒé™ echo \"ceph ALL=(ALL:ALL) NOPASSWD:ALL\" \u003e\u003e /etc/sudoers","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:4:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"3.6 é…ç½®å…å¯†ç™»å½• root@ceph-node1:~ su - xceo ceph@ceph-node1:~$ ceph@ceph-node1:~$ ssh-keygen ssh-copy-id ceph@10.1.0.40 ssh-copy-id ceph@10.1.0.41 ssh ceph-mon1.xx.local ssh ceph-mon2.xx.local ssh ceph-mon3.xx.local ssh ceph-mgr1.xx.local ssh ceph-mgr2.xx.local ssh ceph-node1.xx.local ssh ceph-node2.xx.local ssh ceph-node3.xx.local ssh ceph-deploy.xx.local","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:4:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"3.7 å…¶ä»–åŸºæœ¬ä¼˜åŒ– ~$ vi /etc/sysctl.conf æ·»åŠ ï¼š fs.file-max = 10000000000 fs.nr_open = 1000000000 ~$ vi /etc/security/limits.conf #rootè´¦æˆ·çš„èµ„æºè½¯é™åˆ¶å’Œç¡¬é™åˆ¶ root soft core unlimited root hard core unlimited root soft nproc 1000000 root hard nproc 1000000 root soft nofile 1000000 root hard nofile 1000000 root soft memlock 32000 root hard memlock 32000 root soft msgqueue 8192000 root hard msgqueue 8192000 #å…¶ä»–è´¦æˆ·çš„èµ„æºè½¯é™åˆ¶å’Œç¡¬é™åˆ¶ * soft core unlimited * hard core unlimited * soft nproc 1000000 * hard nproc 1000000 * soft nofile 1000000 * hard nofile 1000000 * soft memlock 32000 * hard memlock 32000 * soft msgqueue 8192000 * hard msgqueue 8192000 # å°†è¿™ä¸¤ä¸ªä¿®æ”¹è¿‡çš„æ–‡ä»¶æ‹·è´åˆ°å…¶ä»–èŠ‚ç‚¹ ~$ scp /etc/sysctl.conf ceph-node2:/etc/ ~$ scp /etc/sysctl.conf ceph-node3:/etc/ ~$ scp /etc/security/limits.conf ceph-node2:/etc/security/ ~$ scp /etc/security/limits.conf ceph-node3:/etc/security/ # åœ¨ä¸‰å°è™šæ‹Ÿæœºä¸Šåˆ†åˆ«æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œè®©å†…æ ¸å‚æ•°ç”Ÿæ•ˆï¼Œå¹¶é‡å¯ ~$ sysctl -p ~$ reboot","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:4:7","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"å››ã€éƒ¨ç½² RADOS é›†ç¾¤ ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.1 å®‰è£…Ceph-Deploy éƒ¨ç½²å·¥å…· #æŸ¥çœ‹å¯ç”¨ç‰ˆæœ¬ root@ceph-node1[15:45:17]~ #:apt-cache madison ceph-deploy ceph-deploy | 2.0.1-0ubuntu1.1 | https://mirrors.tuna.tsinghua.edu.cn/ubuntu focal-updates/universe amd64 Packages ceph-deploy | 2.0.1-0ubuntu1 | https://mirrors.tuna.tsinghua.edu.cn/ubuntu focal/universe amd64 Packages root@ceph-node1[15:45:17]~ #:apt install ceph-deploy -y","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.2 å®‰è£… python 2.7 root@ceph-mon1[09:49:37]~ apt install python2.7 #æ‰€æœ‰æœºå™¨è®¾ç½®è½¯é“¾æ¥ ln -sv /usr/bin/python2.7 /usr/bin/python2 #å®‰è£…å¥½å æ‰§è¡Œpython2æµ‹è¯• å¦‚æœå¯ä»¥æ‰§è¡Œï¼Œè¯´æ˜å®‰è£…å¥½äº† root@ceph-mon1[09:49:37]~ #:python2 Python 2.7.18 (default, Jul 1 2022, 12:27:04) [GCC 9.4.0] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.3 åˆå§‹åŒ–Ceph-Deploy #åˆ‡æ¢åˆ°xceoè´¦æˆ·åˆ›å»ºé›†ç¾¤ç›®å½• ~$su - xceo ~$ pwd /home/xceo ~$ mkdir ceph-cluster ~$ cd ceph-cluster/ ~/ceph-cluster$ #æŸ¥çœ‹çš„ç»“æœå¦‚ä¸‹ï¼š xceo@ceph-mon1:~/ceph-cluster$ ceph-deploy --help usage: ceph-deploy [-h] [-v | -q] [--version] [--username USERNAME] [--overwrite-conf] [--ceph-conf CEPH_CONF] COMMAND ... Easy Ceph deployment -^- / \\ |O o| ceph-deploy v2.0.1 ).-.( '/|||\\` | '|` | '|` Full documentation can be found at: http://ceph.com/ceph-deploy/docsceph-deploy ä½¿ç”¨å¸®åŠ© ceph-deploy --help\rnewï¼šå¼€å§‹éƒ¨ç½²ä¸€ä¸ªæ–°çš„ ceph å­˜å‚¨é›†ç¾¤ï¼Œå¹¶ç”Ÿæˆ CLUSTER.conf é›†ç¾¤é…ç½®æ–‡ä»¶å’Œ keyring è®¤è¯æ–‡ä»¶ã€‚ install: åœ¨è¿œç¨‹ä¸»æœºä¸Šå®‰è£… ceph ç›¸å…³çš„è½¯ä»¶åŒ…, å¯ä»¥é€šè¿‡--release æŒ‡å®šå®‰è£…çš„ç‰ˆæœ¬ã€‚ rgwï¼šç®¡ç† RGW å®ˆæŠ¤ç¨‹åº(RADOSGW,å¯¹è±¡å­˜å‚¨ç½‘å…³)ã€‚ mgrï¼šç®¡ç† MGR å®ˆæŠ¤ç¨‹åº(ceph-mgr,Ceph Manager DaemonCeph ç®¡ç†å™¨å®ˆæŠ¤ç¨‹åº)ã€‚ mdsï¼šç®¡ç† MDS å®ˆæŠ¤ç¨‹åº(Ceph Metadata Serverï¼Œceph æºæ•°æ®æœåŠ¡å™¨)ã€‚ monï¼šç®¡ç† MON å®ˆæŠ¤ç¨‹åº(ceph-mon,ceph ç›‘è§†å™¨)ã€‚ gatherkeysï¼šä»æŒ‡å®šè·å–æä¾›æ–°èŠ‚ç‚¹çš„éªŒè¯ keysï¼Œè¿™äº› keys ä¼šåœ¨æ·»åŠ æ–°çš„ MON/OSD/MDS åŠ å…¥çš„æ—¶å€™ä½¿ç”¨ã€‚ diskï¼šç®¡ç†è¿œç¨‹ä¸»æœºç£ç›˜ã€‚ osdï¼šåœ¨è¿œç¨‹ä¸»æœºå‡†å¤‡æ•°æ®ç£ç›˜ï¼Œå³å°†æŒ‡å®šè¿œç¨‹ä¸»æœºçš„æŒ‡å®šç£ç›˜æ·»åŠ åˆ° ceph é›†ç¾¤ä½œä¸º osd ä½¿ç”¨ã€‚\rrepoï¼šè¿œç¨‹ä¸»æœºä»“åº“ç®¡ç†ã€‚ adminï¼šæ¨é€ ceph é›†ç¾¤é…ç½®æ–‡ä»¶å’Œ client.admin è®¤è¯æ–‡ä»¶åˆ°è¿œç¨‹ä¸»æœºã€‚ configï¼šå°† ceph.conf é…ç½®æ–‡ä»¶æ¨é€åˆ°è¿œç¨‹ä¸»æœºæˆ–ä»è¿œç¨‹ä¸»æœºæ‹·è´ã€‚ uninstallï¼šä»è¿œç«¯ä¸»æœºåˆ é™¤å®‰è£…åŒ…ã€‚ purgedataï¼šä»/var/lib/ceph åˆ é™¤ ceph æ•°æ®,ä¼šåˆ é™¤/etc/ceph ä¸‹çš„å†…å®¹ã€‚ purge: åˆ é™¤è¿œç«¯ä¸»æœºçš„å®‰è£…åŒ…å’Œæ‰€æœ‰æ•°æ®ã€‚ forgetkeysï¼šä»æœ¬åœ°ä¸»æœºåˆ é™¤æ‰€æœ‰çš„éªŒè¯ keyring, åŒ…æ‹¬ client.admin, monitor, bootstrap ç­‰è®¤è¯æ–‡ä»¶ã€‚ pkgï¼šç®¡ç†è¿œç«¯ä¸»æœºçš„å®‰è£…åŒ…ã€‚ calamariï¼šå®‰è£…å¹¶é…ç½®ä¸€ä¸ª calamari web èŠ‚ç‚¹ï¼Œcalamari æ˜¯ä¸€ä¸ª web ç›‘æ§å¹³å°ã€‚","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.4 ç”Ÿæˆmoné…ç½®æ–‡ä»¶ åœ¨ç®¡ç†èŠ‚ç‚¹åˆå§‹åŒ–monèŠ‚ç‚¹ xceo@ceph-node1:~/ceph-cluster$ ceph-deploy new --cluster-network 192.168.10.0/24 --public-network 10.1.0.0/24 ceph-mon1.xx.local [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy new --cluster-network 192.168.10.0/24 --public-network 10.1.0.0/24 ceph-mon1.xx.local [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] mon : ['ceph-mon1.xx.local'] [ceph_deploy.cli][INFO ] ssh_copykey : True [ceph_deploy.cli][INFO ] fsid : None [ceph_deploy.cli][INFO ] cluster_network : 192.168.10.0/24 [ceph_deploy.cli][INFO ] public_network : 10.1.0.0/24 [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7fa0a0be30a0\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction new at 0x7fa0a0bdaf70\u003e [ceph_deploy.new][DEBUG ] Creating new cluster named ceph [ceph_deploy.new][INFO ] making sure passwordless SSH succeeds [ceph-mon1.xx.local][DEBUG ] connected to host: ceph-node1 [ceph-mon1.xx.local][INFO ] Running command: ssh -CT -o BatchMode=yes ceph-mon1.xx.local [ceph-mon1.xx.local][DEBUG ] connection detected need for sudo [ceph-mon1.xx.local][DEBUG ] connected to host: ceph-mon1.xx.local [ceph-mon1.xx.local][INFO ] Running command: sudo /bin/ip link show [ceph-mon1.xx.local][INFO ] Running command: sudo /bin/ip addr show [ceph-mon1.xx.local][DEBUG ] IP addresses found: ['10.1.0.39', '192.168.10.239'] [ceph_deploy.new][DEBUG ] Resolving host ceph-mon1.xx.local [ceph_deploy.new][DEBUG ] Monitor ceph-mon1 at 10.1.0.39 [ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph-mon1'] [ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.39'] [ceph_deploy.new][DEBUG ] Creating a random mon key... [ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring... [ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...ï¼Œæ˜¯å¦ç”Ÿæˆé…ç½®æ–‡ä»¶ xceo@ceph-node1:~/ceph-cluster$ ll total 24 drwxrwxr-x 2 xceo xceo 4096 May 26 16:29 ./ drwxr-xr-x 5 xceo xceo 4096 May 26 16:15 ../ -rw-rw-r-- 1 xceo xceo 259 May 26 16:29 ceph.conf -rw-rw-r-- 1 xceo xceo 7307 May 26 16:29 ceph-deploy-ceph.log -rw------- 1 xceo xceo 73 May 26 16:29 ceph.mon.keyring xceo@ceph-node1:~/ceph-cluster$ cat ceph.conf [global] fsid = 31fdd971-2963-459b-9d6f-588f1811993f public_network = 10.1.0.0/24 cluster_network = 192.168.10.0/24 mon_initial_members = ceph-mon1 mon_host = 10.1.0.39 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephxåœ¨å®‰è£…è¿‡ç¨‹ä¸­ä¼šæŠ¥å¦‚ä¸‹é”™è¯¯ï¼š [ceph_deploy][ERROR ] RuntimeError: AttributeError: module â€˜platformâ€™ has no attribute â€™linux_distributionâ€™ è¿™æ˜¯ç”±äºpython3.7åä¸å†æ”¯æŒplatform.linux_distribution ä¿®æ”¹æ–¹æ³•ï¼š ä¿®æ”¹/usr/lib/python3/dist-packages/ceph_deploy/hosts/remotes.pyæ–‡ä»¶ä¸ºå¦‚ä¸‹æ‰€ç¤º def platform_information(_linux_distribution=None): \"\"\" detect platform information from remote host \"\"\" \"\"\" linux_distribution = _linux_distribution or platform.linux_distribution distro, release, codename = linux_distribution() \"\"\" distro = release = codename = None try: linux_distribution = _linux_distribution or platform.linux_distribution distro, release, codename = linux_distribution() except AttributeError: passéªŒè¯åˆå§‹åŒ–å®Œæˆä¹‹åï¼Œä¼šå¾—åˆ°ä¸‰ä¸ªæ–‡ä»¶ å¦‚ä¸‹ï¼š xceo@ceph-node1:~/ceph-cluster$ ls ceph.conf ceph-deploy-ceph.log ceph.mon.keyring ------------------------------------------------- ceph.conf # é…ç½®æ–‡ä»¶ ceph-deploy-ceph.log #éƒ¨ç½²çš„æ—¥å¿— ceph.mon.keyring #mon.keyring","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.5 åˆå§‹åŒ–nodeèŠ‚ç‚¹ #no-adjust-repos æ˜¯ä¸æŒ‡å®šæº ä¹‹å‰æœ‰é…ç½®å¥½ #ä½¿ç”¨æ™®é€šè´¦æˆ·ä¸‹æ“ä½œ ï¼ˆåœ¨ceph-clusterä¸‹æ“ä½œä¼šæœ‰æŠ¥é”™ï¼‰ xceo@ceph-mon1:~/ceph-cluster$ cd ~ ceph-deploy install --no-adjust-repos --nogpgcheck ceph-node1 ceph-node2 ceph-node3 ï¼ˆä¸æŒ‡å®šç‰ˆæœ¬ï¼‰ ceph-deploy install --no-adjust-repos --nogpgcheck --release pacific ceph-node1 ceph-node2 ceph-node3ï¼ˆæŒ‡å®šç‰ˆæœ¬ï¼‰xceo@ceph-node1:~/ceph-cluster$ ceph-deploy install --no-adjust-repos --nogpgcheck --release pacific ceph-node1 ceph-node2 ceph-node3","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.5 åˆå§‹åŒ–monèŠ‚ç‚¹ åœ¨ä¸‰ä¸ª mon èŠ‚ç‚¹å®‰è£… ceph-mon #æ³¨æ„å®‰è£…monæ—¶hostnameè¦å’ŒCeph.confé…ç½®æ–‡ä»¶ä¸­monä¸»æœºåä¸€æ · root@ceph-mon1[10:40:52]~ #:apt-cache madison ceph-mon ceph-mon | 16.2.13-1focal | https://download.ceph.com/debian-pacific focal/main amd64 Packages ceph-mon | 15.2.17-0ubuntu0.20.04.4 | http://mirrors.tuna.tsinghua.edu.cn/ubuntu focal-updates/main amd64 Packages ceph-mon | 15.2.17-0ubuntu0.20.04.3 | http://mirrors.tuna.tsinghua.edu.cn/ubuntu focal-security/main amd64 Packages ceph-mon | 15.2.1-0ubuntu1 | http://mirrors.tuna.tsinghua.edu.cn/ubuntu focal/main amd64 Packages #æŒ‡å®šç‰ˆæœ¬ apt -y install 16.2.13-1focal xceo@ceph-mon1:~/ceph-cluster$ ceph-deploy mon create-initial [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy mon create-initial [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] subcommand : create-initial [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7fb775ca7a60\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction mon at 0x7fb775d12700\u003e [ceph_deploy.cli][INFO ] keyrings : None [ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph-mon1 [ceph_deploy.mon][DEBUG ] detecting platform for host ceph-mon1 ... [ceph-mon1][DEBUG ] connection detected need for sudo [ceph-mon1][DEBUG ] connected to host: ceph-mon1 [ceph_deploy.mon][INFO ] distro info: ubuntu 20.04 focal [ceph-mon1][DEBUG ] determining if provided host has same hostname in remote [ceph-mon1][DEBUG ] deploying mon to ceph-mon1 [ceph-mon1][DEBUG ] remote hostname: ceph-mon1 [ceph-mon1][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph-mon1/done [ceph-mon1][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph-mon1/done [ceph-mon1][INFO ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph-mon1.mon.keyring [ceph-mon1][INFO ] Running command: sudo ceph-mon --cluster ceph --mkfs -i ceph-mon1 --keyring /var/lib/ceph/tmp/ceph-ceph-mon1.mon.keyring --setuser 64045 --setgroup 64045 [ceph-mon1][INFO ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph-mon1.mon.keyring [ceph-mon1][INFO ] Running command: sudo systemctl enable ceph.target [ceph-mon1][INFO ] Running command: sudo systemctl enable ceph-mon@ceph-mon1 [ceph-mon1][WARNIN] Created symlink /etc/systemd/system/ceph-mon.target.wants/ceph-mon@ceph-mon1.service â†’ /lib/systemd/system/ceph-mon@.service. [ceph-mon1][INFO ] Running command: sudo systemctl start ceph-mon@ceph-mon1 [ceph-mon1][INFO ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-mon1.asok mon_status [ceph-mon1][DEBUG ] ******************************************************************************** [ceph-mon1][DEBUG ] status for monitor: mon.ceph-mon1 [ceph-mon1][DEBUG ] { [ceph-mon1][DEBUG ] \"election_epoch\": 3, [ceph-mon1][DEBUG ] \"extra_probe_peers\": [], [ceph-mon1][DEBUG ] \"feature_map\": { [ceph-mon1][DEBUG ] \"mon\": [ [ceph-mon1][DEBUG ] { [ceph-mon1][DEBUG ] \"features\": \"0x3f01cfbdfffdffff\", [ceph-mon1][DEBUG ] \"num\": 1, [ceph-mon1][DEBUG ] \"release\": \"luminous\" [ceph-mon1][DEBUG ] } [ceph-mon1][DEBUG ] ] [ceph-mon1][DEBUG ] }, [ceph-mon1][DEBUG ] \"features\": { [ceph-mon1][DEBUG ] \"quorum_con\": \"4540138314316775423\", [ceph-mon1][DEBUG ] \"quorum_mon\": [ [ceph-mon1][DEBUG ] \"kraken\", [ceph-mon1][DEBUG ] \"luminous\", [ceph-mon1][DEBUG ] \"mimic\", [ceph-mon1][DEBUG ] \"osdmap-prune\", [ceph-mon1][DEBUG ] \"nautilus\", [ceph-mon1][DEBUG ] \"octopus\", [ceph-mon1][DEBUG ] \"pacific\", [ceph-mon1][DEBUG ] \"elector-pinging\" [ceph-mon1][DEBUG ] ], [ceph-mon1][DEBUG ] \"required_con\": \"2449958747317026820\", [ceph-mon1][DEBUG ] \"required_mon\": [ [ceph-mon1][DEBUG ] \"kraken\", [ceph-mon1][DEBUG ] \"lum","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:6","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.6 åˆ†å‘adminå¯†é’¥åˆ°nodeèŠ‚ç‚¹ï¼ˆéå¿…é¡»ï¼‰ ä¿å­˜å¥½ç”Ÿæˆçš„ceph.client.admin.keyringæ–‡ä»¶ åœ¨deployå’ŒnodeèŠ‚ç‚¹ä¸Šå®‰è£… ceph- common sudo apt install ceph-common -yxceo@ceph-mon1:~/ceph-cluster$ ceph-deploy --overwrite-conf admin ceph-node1 ceph-node2 ceph-node3 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy --overwrite-conf admin ceph-node1 ceph-node2 ceph-node3 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] client : ['ceph-node1', 'ceph-node2', 'ceph-node3'] [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7f19678e51f0\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction admin at 0x7f1967e2f040\u003e [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node1 [ceph-node1][DEBUG ] connection detected need for sudo [ceph-node1][DEBUG ] connected to host: ceph-node1 [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node2 [ceph-node2][DEBUG ] connection detected need for sudo [ceph-node2][DEBUG ] connected to host: ceph-node2 [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node3 [ceph-node3][DEBUG ] connection detected need for sudo [ceph-node3][DEBUG ] connected to host: ceph-node3 è®¤è¯æ–‡ä»¶çš„å±ä¸»å’Œå±ç»„ä¸ºäº†å®‰å…¨è€ƒè™‘ï¼Œé»˜è®¤è®¾ç½®ä¸ºäº†root ç”¨æˆ·å’Œrootç»„ï¼Œå¦‚æœéœ€è¦cephç”¨æˆ·ä¹Ÿèƒ½æ‰§è¡Œceph å‘½ä»¤,é‚£ä¹ˆå°±éœ€è¦å¯¹ceph ç”¨æˆ·è¿›è¡Œæˆæƒ setfacl -m u:ceph:rw /etc/ceph/ceph.client.admin.keyring åœ¨deployä¸»æœºæ‰§è¡Œ xceo@ceph-mon1:~$ sudo apt install acl root@ceph-mon1[14:11:31]~ #:setfacl -m u:xceo:rw /etc/ceph/ceph.client.admin.keyring xceo@ceph-mon1:~$ ceph -s cluster: id: 62be32df-9cb4-474f-8727-d5c4bbceaf97 health: HEALTH_WARN mon is allowing insecure global_id reclaim services: mon: 1 daemons, quorum ceph-mon1 (age 112m) mgr: no daemons active osd: 0 osds: 0 up, 0 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:7","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.7 éƒ¨ç½²Ceph-MgrèŠ‚ç‚¹ mgrèŠ‚ç‚¹éœ€è¦è¯»å–cephçš„é…ç½®æ–‡ä»¶ï¼Œå³/etc/cephç›®å½•ä¸­çš„é…ç½®æ–‡ä»¶ #åœ¨mgrèŠ‚ç‚¹æå‰å°†mgræœåŠ¡å®‰è£… apt install ceph-mgr -y xceo@ceph-mon1:~/ceph-cluster$ ceph-deploy mgr create ceph-mgr1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy mgr create ceph-mgr1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7fd8738734c0\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction mgr at 0x7fd87392ec10\u003e [ceph_deploy.cli][INFO ] mgr : [('ceph-mgr1', 'ceph-mgr1')] [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts ceph-mgr1:ceph-mgr1 The authenticity of host 'ceph-mgr1 (10.1.0.40)' can't be established. ECDSA key fingerprint is SHA256:lhRjKQBhgEhjbqcfKBb6oyle8C9EIOzu48QUoaeISIE. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'ceph-mgr1' (ECDSA) to the list of known hosts. [ceph-mgr1][DEBUG ] connection detected need for sudo [ceph-mgr1][DEBUG ] connected to host: ceph-mgr1 [ceph_deploy.mgr][INFO ] Distro info: ubuntu 20.04 focal [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph-mgr1 [ceph-mgr1][WARNIN] mgr keyring does not exist yet, creating one [ceph-mgr1][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.ceph-mgr1 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-ceph-mgr1/keyring [ceph-mgr1][INFO ] Running command: sudo systemctl enable ceph-mgr@ceph-mgr1 [ceph-mgr1][WARNIN] Created symlink /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@ceph-mgr1.service â†’ /lib/systemd/system/ceph-mgr@.service. [ceph-mgr1][INFO ] Running command: sudo systemctl start ceph-mgr@ceph-mgr1 [ceph-mgr1][INFO ] Running command: sudo systemctl enable ceph.target xceo@ceph-mon1:~/ceph-cluster$ ceph-deploy mgr create ceph-mgr2 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy mgr create ceph-mgr2 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7f5b7f96b4c0\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction mgr at 0x7f5b7fa26c10\u003e [ceph_deploy.cli][INFO ] mgr : [('ceph-mgr2', 'ceph-mgr2')] [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts ceph-mgr2:ceph-mgr2 The authenticity of host 'ceph-mgr2 (10.1.0.41)' can't be established. ECDSA key fingerprint is SHA256:lhRjKQBhgEhjbqcfKBb6oyle8C9EIOzu48QUoaeISIE. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'ceph-mgr2' (ECDSA) to the list of known hosts. [ceph-mgr2][DEBUG ] connection detected need for sudo [ceph-mgr2][DEBUG ] connected to host: ceph-mgr2 [ceph_deploy.mgr][INFO ] Distro info: ubuntu 20.04 focal [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph-mgr2 [ceph-mgr2][WARNIN] mgr keyring does not exist yet, creating one [ceph-mgr2][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth ge","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:8","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.8 åˆå§‹åŒ– OSD èŠ‚ç‚¹ #åœ¨deployä¸»æœºæ‰§è¡Œ ceph-deploy install --release pacific ceph-node1 ceph-node2 ceph-node3 #è¿™æ­¥åœ¨åˆå§‹åŒ–nodeèŠ‚ç‚¹å·²ç»åšè¿‡ #æ“¦é™¤ç£ç›˜ä¹‹å‰é€šè¿‡deployèŠ‚ç‚¹å¯¹nodeèŠ‚ç‚¹æ‰§è¡Œå®‰è£…cephåŸºæœ¬è¿è¡Œç¯å¢ƒ æŠ¥é”™ File \"/usr/lib/python3/dist-packages/ceph_deploy/util/decorators.py\", line 69, in newfunc #åˆ—å‡ºè¿œç«¯å­˜å‚¨nodeèŠ‚ç‚¹çš„ç£ç›˜ä¿¡æ¯ xceo@ceph-mon1:~/ceph-cluster$ sudo ceph-deploy disk list ceph-node2 [ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy disk list ceph-node2 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] subcommand : list [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7ff31b4353a0\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction disk at 0x7ff31b4d2a60\u003e [ceph_deploy.cli][INFO ] host : ['ceph-node2'] [ceph_deploy.cli][INFO ] debug : False The authenticity of host 'ceph-node2 (10.1.0.40)' can't be established. ECDSA key fingerprint is SHA256:lhRjKQBhgEhjbqcfKBb6oyle8C9EIOzu48QUoaeISIE. Are you sure you want to continue connecting (yes/no/[fingerprint])? ^C[ceph_deploy][ERROR ] KeyboardInterrupt xceo@ceph-mon1:~/ceph-cluster$ ceph-deploy disk list ceph-node2 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy disk list ceph-node2 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] subcommand : list [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7f4c4cac53d0\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction disk at 0x7f4c4cb62af0\u003e [ceph_deploy.cli][INFO ] host : ['ceph-node2'] [ceph_deploy.cli][INFO ] debug : False [ceph-node2][DEBUG ] connection detected need for sudo [ceph-node2][DEBUG ] connected to host: ceph-node2 [ceph-node2][INFO ] Running command: sudo fdisk -l [ceph_deploy][ERROR ] Traceback (most recent call last): [ceph_deploy][ERROR ] File \"/usr/lib/python3/dist-packages/ceph_deploy/util/decorators.py\", line 69, in newfunc [ceph_deploy][ERROR ] return f(*a, **kw) [ceph_deploy][ERROR ] File \"/usr/lib/python3/dist-packages/ceph_deploy/cli.py\", line 166, in _main [ceph_deploy][ERROR ] return args.func(args) [ceph_deploy][ERROR ] File \"/usr/lib/python3/dist-packages/ceph_deploy/osd.py\", line 434, in disk [ceph_deploy][ERROR ] disk_list(args, cfg) [ceph_deploy][ERROR ] File \"/usr/lib/python3/dist-packages/ceph_deploy/osd.py\", line 375, in disk_list [ceph_deploy][ERROR ] if line.startswith('Disk /'): [ceph_deploy][ERROR ] TypeError: startswith first arg must be bytes or a tuple of bytes, not str [ceph_deploy][ERROR ] è§£å†³æ–¹æ³• sudo vim /usr/lib/python3/dist-packages/ceph_deploy/osd.pyä¸­ if line.startswith('Disk /'): #æ›¿æ¢ä¸º if line.startswith(b'Disk /'): ceph-deploy disk list ceph-node1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy disk list ceph-node1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] subcommand : list [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7f90a9868310\u003e [ceph_deploy.cli][INFO ] default_release : ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:9","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"4.9 æ·»åŠ OSD èŠ‚ç‚¹ Dataï¼šå³cephä¿å­˜çš„å¯¹è±¡æ•°æ® blockï¼šrocks DB æ•°æ®å³å…ƒæ•°æ® block-walï¼š æ•°æ®åº“çš„ wal æ—¥å¿— æ·»åŠ OSDèŠ‚ç‚¹å‰çš„å‘Šè­¦ #æ·»åŠ ç£ç›˜ xceo@ceph-mon1:~/ceph-cluster$ ceph-deploy osd create ceph-node1 --data /dev/vdb [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy osd create ceph-node1 --data /dev/vdb [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7fef2b8bbfa0\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction osd at 0x7fef2b959a60\u003e [ceph_deploy.cli][INFO ] data : /dev/vdb [ceph_deploy.cli][INFO ] journal : None [ceph_deploy.cli][INFO ] zap_disk : False [ceph_deploy.cli][INFO ] fs_type : xfs [ceph_deploy.cli][INFO ] dmcrypt : False [ceph_deploy.cli][INFO ] dmcrypt_key_dir : /etc/ceph/dmcrypt-keys [ceph_deploy.cli][INFO ] filestore : None [ceph_deploy.cli][INFO ] bluestore : None [ceph_deploy.cli][INFO ] block_db : None [ceph_deploy.cli][INFO ] block_wal : None [ceph_deploy.cli][INFO ] host : ceph-node1 [ceph_deploy.cli][INFO ] debug : False [ceph_deploy.osd][DEBUG ] Creating OSD on cluster ceph with data device /dev/vdb [ceph-node1][DEBUG ] connection detected need for sudo [ceph-node1][DEBUG ] connected to host: ceph-node1 [ceph_deploy.osd][INFO ] Distro info: ubuntu 20.04 focal [ceph_deploy.osd][DEBUG ] Deploying osd to ceph-node1 [ceph-node1][INFO ] Running command: sudo /usr/sbin/ceph-volume --cluster ceph lvm create --bluestore --data /dev/vdb [ceph-node1][WARNIN] Running command: /usr/bin/ceph-authtool --gen-print-key [ceph-node1][WARNIN] Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring -i - osd new d9637751-9b7f-42d6-b9d8-2718039162b5 [ceph-node1][WARNIN] Running command: vgcreate --force --yes ceph-ac4ab09d-3655-4447-a0e3-d0d79f3b326a /dev/vdb [ceph-node1][WARNIN] stdout: Physical volume \"/dev/vdb\" successfully created. [ceph-node1][WARNIN] stdout: Volume group \"ceph-ac4ab09d-3655-4447-a0e3-d0d79f3b326a\" successfully created [ceph-node1][WARNIN] Running command: lvcreate --yes -l 30719 -n osd-block-d9637751-9b7f-42d6-b9d8-2718039162b5 ceph-ac4ab09d-3655-4447-a0e3-d0d79f3b326a [ceph-node1][WARNIN] stdout: Logical volume \"osd-block-d9637751-9b7f-42d6-b9d8-2718039162b5\" created. [ceph-node1][WARNIN] Running command: /usr/bin/ceph-authtool --gen-print-key [ceph-node1][WARNIN] Running command: /usr/bin/mount -t tmpfs tmpfs /var/lib/ceph/osd/ceph-0 [ceph-node1][WARNIN] --\u003e Executable selinuxenabled not in PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin [ceph-node1][WARNIN] Running command: /usr/bin/chown -h ceph:ceph /dev/ceph-ac4ab09d-3655-4447-a0e3-d0d79f3b326a/osd-block-d9637751-9b7f-42d6-b9d8-2718039162b5 [ceph-node1][WARNIN] Running command: /usr/bin/chown -R ceph:ceph /dev/dm-0 [ceph-node1][WARNIN] Running command: /usr/bin/ln -s /dev/ceph-ac4ab09d-3655-4447-a0e3-d0d79f3b326a/osd-block-d9637751-9b7f-42d6-b9d8-2718039162b5 /var/lib/ceph/osd/ceph-0/block [ceph-node1][WARNIN] Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /var/lib/ceph/osd/ceph-0/activate.monmap [ceph-node1][WARNIN] stderr: 2023-05-29T14:48:36.998+0800 7f3b7f4e2700 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.bootstrap-osd.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory [ceph-node1][WARNIN] 2023-05-29T14:48:36.998+0800 7f3b7f4e2700 -1 AuthRegistry(0x7f3b7805bc18) no keyr","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:5:10","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"äº”ã€ éªŒè¯ Ceph é›†ç¾¤ ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:6:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"5.1 ä»RADOS ç§»é™¤OSD è¿™ä¸ªæ­¥éª¤ä¸»è¦åšäº†è§£ï¼Œä¸€èˆ¬ä¸å¸¸ç”¨ Cephé›†ç¾¤ä¸­çš„ä¸€ä¸ªOSDæ˜¯ä¸€ä¸ªnodeèŠ‚ç‚¹çš„æœåŠ¡è¿›ç¨‹ä¸”å¯¹åº”äºä¸€ä¸ªç‰©ç†ç£ç›˜è®¾å¤‡ï¼Œæ˜¯ä¸€ä¸ªä¸“ç”¨çš„å®ˆæŠ¤è¿›ç¨‹ã€‚ åœ¨æŸOSDè®¾å¤‡å‡ºç°æ•…éšœï¼Œæˆ–ç®¡ç†å‘˜å¤„äºç®¡ç†ä¹‹éœ€ç¡®å®è¦ç§»é™¤ç‰¹å®šçš„OSDè®¾å¤‡æ—¶ï¼Œéœ€è¦å…ˆåœæ­¢ç›¸å…³çš„å®ˆæŠ¤è¿›ç¨‹ï¼Œè€Œåå†è¿›è¡Œç§»é™¤æ“ä½œï¼Œå¯¹äºlinuxä»¥åŠä»¥åçš„ç‰ˆæœ¬æ¥è¯´ï¼Œåœæ­¢å’Œç§»é™¤å‘½ä»¤çš„æ ¼å¼åˆ†åˆ«å¦‚ä¸‹ï¼š åœç”¨è®¾å¤‡ï¼š ceph osd out {osd-num} åœæ­¢è¿›ç¨‹ï¼š sudo systemctl stop ceph-osd@{osd-num} ç§»é™¤è®¾å¤‡ï¼š ceph osd purge {id} --yes-i-really-mean-itOSD çš„é…ç½®ä¿¡æ¯å­˜åœ¨äº ceph.conf é…ç½®æ–‡ä»¶ä¸­ï¼Œ ç®¡ç†å‘˜åœ¨åˆ é™¤ OSD ä¹‹åæ‰‹åŠ¨å°†å…¶åˆ é™¤ #äº CRUSH è¿è¡Œå›¾ä¸­ç§»é™¤è®¾å¤‡ ceph osd crush remove {name} #ç§»é™¤ OSD çš„è®¤è¯ keyï¼š ceph auth del osd.{osd-num} #æœ€åç§»é™¤ OSD è®¾å¤‡ï¼š ceph osd rm {osd-num}","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:6:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"5.2 æµ‹è¯•ä¸Šä¼ å’Œä¸‹è½½æ•°æ® RADOSå‘½ä»¤ å­˜å–æ•°æ®æ—¶ï¼Œ å®¢æˆ·ç«¯å¿…é¡»é¦–å…ˆè¿æ¥è‡³ RADOS é›†ç¾¤ä¸ŠæŸå­˜å‚¨æ± ï¼Œ ç„¶åæ ¹æ®å¯¹è±¡åç§°ç”±ç›¸å…³çš„CRUSH è§„åˆ™å®Œæˆæ•°æ®å¯¹è±¡å¯»å€ã€‚ äºæ˜¯ï¼Œ ä¸ºäº†æµ‹è¯•é›†ç¾¤çš„æ•°æ®å­˜å–åŠŸèƒ½ï¼Œ è¿™é‡Œé¦–å…ˆåˆ›å»ºä¸€ä¸ªç”¨äºæµ‹è¯•çš„å­˜å‚¨æ±  mypoolï¼Œ å¹¶è®¾å®šå…¶ PG æ•°é‡ä¸º 32 ä¸ª åˆ›å»ºpool root@ceph-mon1[20:03:36]~ #:ceph osd pool create mypool 32 32 #åˆ›å»º pool 'mypool' created #æˆ–è€…rados lspools #éªŒè¯ root@ceph-mon1[20:44:54]~ #:ceph osd pool ls device_health_metrics mypool ceph pg ls-by-pool mypool | awk '{print $1,$2,$15}' #éªŒè¯PG ä¸ PGP ç»„åˆ root@ceph-mon1[20:45:22]~ #:ceph pg ls-by-pool mypool | awk '{print $1,$2,$15}' PG OBJECTS ACTING 2.0 0 [8,10,3]p8 2.1 0 [2,13,9]p2 2.2 0 [5,1,10]p5 2.3 0 [5,4,14]p5 2.4 0 [1,12,6]p1 2.5 0 [12,4,8]p12 2.6 0 [1,13,9]p1 2.7 0 [6,13,2]p6 2.8 0 [8,13,0]p8 2.9 0 [4,9,12]p4 2.a 0 [11,4,8]p11 2.b 0 [13,7,4]p13 2.c 0 [12,0,5]p12 2.d 0 [12,8,3]p12 2.e 0 [2,13,8]p2 2.f 0 [11,8,0]p11 2.10 0 [10,1,8]p10 2.11 0 [6,1,12]p6 2.12 0 [10,3,9]p10 2.13 0 [13,6,3]p13 2.14 0 [8,13,0]p8 2.15 0 [10,1,5]p10 2.16 0 [8,12,1]p8 2.17 0 [6,14,2]p6 2.18 0 [13,9,2]p13 2.19 0 [3,6,13]p3 2.1a 0 [6,14,2]p6 2.1b 0 [11,7,3]p11 2.1c 0 [10,7,1]p10 2.1d 0 [10,7,0]p10 2.1e 0 [3,13,5]p3 2.1f 0 [4,7,14]p4 * NOTE: afterwardsä¸Šä¼ æ–‡ä»¶ sudo rados put msg1 /var/log/syslog --pool=mypool #æŠŠæ¶ˆæ¯æ–‡ä»¶ä¸Šä¼ åˆ° mypool å¹¶æŒ‡å®šå¯¹è±¡ id ä¸º msg1 rados ls --pool=mypool #åˆ—å‡ºæ–‡ä»¶ root@ceph-mon1[20:58:42]~ #:rados ls --pool=mypool msg1 #å¯ä»¥è·å–åˆ°å­˜å‚¨æ± ä¸­æ•°æ®å¯¹è±¡çš„å…·ä½“ä½ç½®ä¿¡æ¯ï¼š root@ceph-mon1[21:00:22]~ #:ceph osd map mypool msg1 osdmap e86 pool 'mypool' (2) object 'msg1' -\u003e pg 2.c833d430 (2.10) -\u003e up ([10,1,8], p10) acting ([10,1,8], p10) ------------------------------------------------------------------------------- è¡¨ç¤ºæ–‡ä»¶å­˜å‚¨äº†å­˜å‚¨æ±  id ä¸º 2 çš„ c833d430 çš„ PG ä¸Š,10 ä¸ºå½“å‰ PG çš„ id, 2.10 è¡¨ç¤ºæ•°æ®æ˜¯åœ¨ id ä¸º 2 çš„å­˜å‚¨æ± ä¸­ id ä¸º 10 çš„ PG ä¸­å­˜å‚¨ï¼Œåœ¨çº¿çš„ OSD ç¼–å· 10,1,8ï¼Œä¸» OSD ä¸º 10ï¼Œæ´»åŠ¨ çš„OSD 10,1,8ï¼Œä¸‰ä¸ªOSDè¡¨ç¤ºæ•°æ®æ”¾ä¸€å…±3ä¸ªå‰¯æœ¬ï¼ŒPGä¸­çš„OSDæ˜¯cephçš„crushç®—æ³•è®¡ç®— ç®—å‡ºä¸‰ä»½æ•°æ®ä¿å­˜åœ¨å“ªäº›OSDã€‚ ä¸‹è½½æ–‡ä»¶ #ä¸‹è½½mypoolé‡Œçš„msg1æ–‡ä»¶ æ”¾åœ¨æœ¬åœ°ç›®å½•çš„åå­— sudo rados get msg1 --pool=mypool /opt/my.txt xceo@ceph-mon1:~/ceph-cluster$ sudo rados get msg1 --pool=mypool /opt/my.txt xceo@ceph-mon1:~/ceph-cluster$ ll -ls /opt/my.txt 860 -rw-r--r-- 1 root root 879881 May 30 09:10 /opt/my.txtä¿®æ”¹æ–‡ä»¶ #å°†/etc/passwd ä¸Šä¼ åˆ°mypoolä¸‹çš„ msg1æ–‡ä»¶ä¸­ xceo@ceph-mon1:~/ceph-cluster$ sudo rados put msg1 /etc/passwd --pool=mypool #é‡æ–°ä»mypoolé‡Œä¸‹è½½msg1 å¹¶å­˜æ”¾æœ¬åœ°ç›®å½•é‡å‘½åä¸º/opt/my3.txt xceo@ceph-mon1:~/ceph-cluster$ sudo rados get msg1 --pool=mypool /opt/my3.txt xceo@ceph-mon1:~/ceph-cluster$ head /opt/my3.txt root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin bin:x:2:2:bin:/bin:/usr/sbin/nologin sys:x:3:3:sys:/dev:/usr/sbin/nologin sync:x:4:65534:sync:/bin:/bin/sync games:x:5:60:games:/usr/games:/usr/sbin/nologin man:x:6:12:man:/var/cache/man:/usr/sbin/nologin lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin mail:x:8:8:mail:/var/mail:/usr/sbin/nologin news:x:9:9:news:/var/spool/news:/usr/sbin/nologinåˆ é™¤æ–‡ä»¶ sudo rados rm msg1 --pool=mypool rados ls --pool=mypool","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:6:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"å…­ã€æ‰©å±• ceph å®ç°é«˜å¯ç”¨ ä¸»è¦æ˜¯æ‰©å±•cephé›†ç¾¤çš„monèŠ‚ç‚¹ä»¥åŠmgrèŠ‚ç‚¹ ä»¥å®ç°é›†ç¾¤é«˜å¯ç”¨ ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:7:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"6.1 æ‰©å±• ceph-mon èŠ‚ç‚¹ åœ¨mon2 mon3 ä¸Šå®‰è£…ceph-mon Ceph-mon æ˜¯åŸç”Ÿå…·å¤‡è‡ªå™¬ä»¥å®ç°é«˜å¯ç”¨æœºåˆ¶çš„ ceph æœåŠ¡ï¼ŒèŠ‚ç‚¹æ•°é‡é€šå¸¸æ˜¯å¥‡æ•° #ubuntuä¸Šå®‰è£…æŒ‡å®šç‰ˆæœ¬ apt install ceph-mon=16.2.13-1focal #åœ¨ceph-deployæ“ä½œå°†mon3æ·»åŠ  ceph-deploy mon add ceph-mon2 ceph-mon3 #æ·»åŠ ceph-mon2 xceo@ceph-mon1:~/ceph-cluster$ ceph-deploy mon add ceph-mon2 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/xceo/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /usr/bin/ceph-deploy mon add ceph-mon2 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] subcommand : add [ceph_deploy.cli][INFO ] cd_conf : \u003cceph_deploy.conf.cephdeploy.Conf object at 0x7f4eea93da90\u003e [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] func : \u003cfunction mon at 0x7f4eea9a8700\u003e [ceph_deploy.cli][INFO ] address : None [ceph_deploy.cli][INFO ] mon : ['ceph-mon2'] [ceph_deploy.mon][INFO ] ensuring configuration of new mon host: ceph-mon2 [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-mon2 [ceph-mon2][DEBUG ] connection detected need for sudo [ceph-mon2][DEBUG ] connected to host: ceph-mon2 [ceph_deploy.mon][DEBUG ] Adding mon to cluster ceph, host ceph-mon2 [ceph_deploy.mon][DEBUG ] using mon address by resolving host: 10.1.0.40 [ceph_deploy.mon][DEBUG ] detecting platform for host ceph-mon2 ... [ceph-mon2][DEBUG ] connection detected need for sudo [ceph-mon2][DEBUG ] connected to host: ceph-mon2 [ceph_deploy.mon][INFO ] distro info: ubuntu 20.04 focal [ceph-mon2][DEBUG ] determining if provided host has same hostname in remote [ceph-mon2][DEBUG ] adding mon to ceph-mon2 [ceph-mon2][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph-mon2/done [ceph-mon2][INFO ] Running command: sudo systemctl enable ceph.target [ceph-mon2][INFO ] Running command: sudo systemctl enable ceph-mon@ceph-mon2 [ceph-mon2][INFO ] Running command: sudo systemctl start ceph-mon@ceph-mon2 [ceph-mon2][INFO ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-mon2.asok mon_status [ceph-mon2][WARNIN] ceph-mon2 is not defined in `mon initial members` [ceph-mon2][WARNIN] monitor ceph-mon2 does not exist in monmap [ceph-mon2][INFO ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-mon2.asok mon_status [ceph-mon2][DEBUG ] ******************************************************************************** [ceph-mon2][DEBUG ] status for monitor: mon.ceph-mon2 [ceph-mon2][DEBUG ] { [ceph-mon2][DEBUG ] \"election_epoch\": 0, [ceph-mon2][DEBUG ] \"extra_probe_peers\": [], [ceph-mon2][DEBUG ] \"feature_map\": { [ceph-mon2][DEBUG ] \"mon\": [ [ceph-mon2][DEBUG ] { [ceph-mon2][DEBUG ] \"features\": \"0x3f01cfbdfffdffff\", [ceph-mon2][DEBUG ] \"num\": 1, [ceph-mon2][DEBUG ] \"release\": \"luminous\" [ceph-mon2][DEBUG ] } [ceph-mon2][DEBUG ] ] [ceph-mon2][DEBUG ] }, [ceph-mon2][DEBUG ] \"features\": { [ceph-mon2][DEBUG ] \"quorum_con\": \"0\", [ceph-mon2][DEBUG ] \"quorum_mon\": [], [ceph-mon2][DEBUG ] \"required_con\": \"2449958197560098820\", [ceph-mon2][DEBUG ] \"required_mon\": [ [ceph-mon2][DEBUG ] \"kraken\", [ceph-mon2][DEBUG ] \"luminous\", [ceph-mon2][DEBUG ] \"mimic\", [ceph-mon2][DEBUG ] \"osdmap-prune\", [ceph-mon2][DEBUG ] \"nautilus\", [ceph-mon2][DEBUG ] \"octopus\", [ceph-mon2][DEBUG ] \"pacific\", [ceph-mon2][DEBUG ] \"elector-pinging\" [ceph-mon2][DEBUG ] ] [ceph-mon2][DEBUG ] }, [ceph-mon2][DEBUG ] \"monmap\": { [ceph-mon2][DEBUG ] \"created\": \"2023-05-29T04:19:43.502249Z\", [ceph-mon2][DEBUG ] \"disallowed_leaders: \": \"\", [ceph-mon2][DEBUG ] \"election_strategy\": 1, [ceph-mon2][DEBUG ] \"epoch\": 1, [ceph-mon2][DEBUG ] \"features\": { [ceph-mon2][DEBUG ] \"optional\": [], [ceph-mon2][DEBUG ] \"persistent\": [ [ceph-mon2][DEBUG ] \"kraken\", [ceph-mon2][DEBUG ] \"luminous\", [ceph-mon2][DEBUG ] \"mimic\", [ceph-mon2][DEBUG ] \"osdmap-pru","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:7:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Ceph"],"content":"6.2 æ‰©å±•Ceph-Mgr èŠ‚ç‚¹ #åœ¨mgrä¸»æœºå®‰è£…mgr apt install ceph-mgr -y # åŒæ­¥é… ç½®æ–‡ä»¶åˆ°ceph-mg2 èŠ‚ç‚¹ ceph-deploy admin ceph-mgr2 ceph-deploy mgr create ceph-mgr2 ","date":"2023-01-10","objectID":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/:7:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/ceph/2.ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"å‰è¨€ KubernetesäºŒè¿›åˆ¶éƒ¨ç½²ç›¸å¯¹äºä½¿ç”¨è‡ªåŠ¨åŒ–å·¥å…·ï¼ˆå¦‚kubeadmï¼‰è€Œè¨€ï¼Œæ¶‰åŠæ›´å¤šçš„æ‰‹åŠ¨æ­¥éª¤å’Œé…ç½®è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œè¿™ç§éƒ¨ç½²æ–¹å¼åœ¨ä¸€äº›æƒ…å¢ƒä¸‹å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚é€šè¿‡æ‰‹åŠ¨ä¸‹è½½ã€é…ç½®å’Œå¯åŠ¨Kubernetesçš„å„ä¸ªç»„ä»¶ï¼Œç”¨æˆ·èƒ½å¤Ÿè·å¾—æ›´é«˜ç¨‹åº¦çš„å®šåˆ¶æ€§å’Œç²¾ç»†æ§åˆ¶æƒï¼Œä»¥ä¾¿æ ¹æ®ç‰¹å®šéœ€æ±‚è¿›è¡Œè°ƒæ•´ã€‚è¿™ç§çµæ´»æ€§ä½¿ç”¨æˆ·èƒ½å¤Ÿé€‰æ‹©æ‰€éœ€çš„Kubernetesç‰ˆæœ¬ã€ç‰¹å®šçš„ç»„ä»¶é…ç½®ï¼Œä»¥åŠè‡ªå®šä¹‰çš„ç½‘ç»œå’Œå­˜å‚¨æ–¹æ¡ˆã€‚ åŒæ—¶ï¼Œé€šè¿‡æ·±å…¥å‚ä¸æ¯ä¸ªéƒ¨ç½²æ­¥éª¤ï¼Œç”¨æˆ·å¯ä»¥æ›´åŠ æ·±å…¥åœ°ç†è§£Kubernetesçš„å†…éƒ¨å·¥ä½œæœºåˆ¶å’Œç»„ä»¶ä¹‹é—´çš„å…³ç³»ã€‚è¿™ç§æ·±å…¥äº†è§£å¯¹äºæ’æŸ¥é—®é¢˜ã€ä¼˜åŒ–æ€§èƒ½ä»¥åŠå®ç°å®šåˆ¶çš„é›†ç¾¤æ¶æ„è‡³å…³é‡è¦ã€‚æ­¤å¤–ï¼ŒäºŒè¿›åˆ¶éƒ¨ç½²è¿˜å…è®¸ç”¨æˆ·åœ¨æ²¡æœ‰ç½‘ç»œè¿æ¥çš„ç¯å¢ƒä¸­è¿›è¡Œéƒ¨ç½²ï¼Œè¿™åœ¨æŸäº›é™åˆ¶æ€§ç½‘ç»œç¯å¢ƒä¸‹éå¸¸æœ‰ç”¨ã€‚å¯¹äºç‰¹æ®Šåœºæ™¯ï¼Œå¦‚éœ€è¦å®šåˆ¶åŒ–çš„è®¤è¯ã€æˆæƒå’Œç½‘ç»œè®¾ç½®ï¼Œæ‰‹åŠ¨éƒ¨ç½²èƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³éœ€æ±‚ã€‚ ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒKubernetesçš„äºŒè¿›åˆ¶éƒ¨ç½²éœ€è¦æ›´å¤šçš„æ—¶é—´ã€æŠ€æœ¯çŸ¥è¯†å’Œèµ„æºæŠ•å…¥ã€‚ç›¸è¾ƒäºè‡ªåŠ¨åŒ–å·¥å…·ï¼Œå®ƒå¯èƒ½å¢åŠ äº†å‡ºé”™çš„é£é™©ï¼Œéœ€è¦æ›´å¤šçš„ç›‘æ§å’Œç»´æŠ¤å·¥ä½œã€‚å› æ­¤ï¼Œåœ¨é€‰æ‹©éƒ¨ç½²æ–¹å¼æ—¶ï¼Œåº”è¯¥æ ¹æ®è‡ªèº«çš„æŠ€èƒ½æ°´å¹³ã€æ—¶é—´æˆæœ¬å’Œé¡¹ç›®éœ€æ±‚æ¥é€‰æ‹©é€‚åˆè‡ªå·±çš„éƒ¨ç½²æ–¹å¼ã€‚ k8s-å®æˆ˜æ¡ˆä¾‹_v1.21.x-éƒ¨ç½².pdf ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"1.åŸºç¡€ç¯å¢ƒé…ç½® ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"1.1 æ—¶é—´åŒæ­¥ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime cat /etc/default/locale LANG=en_US.UTF-8 LC_TIME=en_DK.UTF-8 */5 * * * * /usr/sbin/ntpdate time1.aliyun.com \u0026\u003e /dev/null \u0026\u0026 hwclock -w/usr/sbin/ntpdate","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:2:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"1.2 å®‰è£docker root@master01:/home/ceamg# cd /apps/docker/ root@master01:/apps/docker# tar xvf docker-19.03.15-binary-install.tar.gz root@master01:/apps/docker# ll total 153128 drwxr-xr-x 2 root root 4096 Apr 11 2021 ./ drwxr-xr-x 3 root root 4096 Jan 2 03:52 ../ -rw-r--r-- 1 root root 647 Apr 11 2021 containerd.service -rw-r--r-- 1 root root 78156440 Jan 2 03:57 docker-19.03.15-binary-install.tar.gz -rw-r--r-- 1 root root 62436240 Feb 5 2021 docker-19.03.15.tgz -rwxr-xr-x 1 root root 16168192 Jun 24 2019 docker-compose-Linux-x86_64_1.24.1* -rwxr-xr-x 1 root root 2708 Apr 11 2021 docker-install.sh* -rw-r--r-- 1 root root 1683 Apr 11 2021 docker.service -rw-r--r-- 1 root root 197 Apr 11 2021 docker.socket -rw-r--r-- 1 root root 454 Apr 11 2021 limits.conf -rw-r--r-- 1 root root 257 Apr 11 2021 sysctl.conf#!/bin/bash DIR=`pwd` PACKAGE_NAME=\"docker-19.03.15.tgz\" DOCKER_FILE=${DIR}/${PACKAGE_NAME} centos_install_docker(){ grep \"Kernel\" /etc/issue \u0026\u003e /dev/null if [ $? -eq 0 ];then /bin/echo \"å½“å‰ç³»ç»Ÿæ˜¯`cat /etc/redhat-release`,å³å°†å¼€å§‹ç³»ç»Ÿåˆå§‹åŒ–ã€é…ç½®docker-composeä¸å®‰è£…docker\" \u0026\u0026 sleep 1 systemctl stop firewalld \u0026\u0026 systemctl disable firewalld \u0026\u0026 echo \"é˜²ç«å¢™å·²å…³é—­\" \u0026\u0026 sleep 1 systemctl stop NetworkManager \u0026\u0026 systemctl disable NetworkManager \u0026\u0026 echo \"NetworkManager\" \u0026\u0026 sleep 1 sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux \u0026\u0026 setenforce 0 \u0026\u0026 echo \"selinux å·²å…³é—­\" \u0026\u0026 sleep 1 \\cp ${DIR}/limits.conf /etc/security/limits.conf \\cp ${DIR}/sysctl.conf /etc/sysctl.conf /bin/tar xvf ${DOCKER_FILE} \\cp docker/* /usr/bin \\cp containerd.service /lib/systemd/system/containerd.service \\cp docker.service /lib/systemd/system/docker.service \\cp docker.socket /lib/systemd/system/docker.socket \\cp ${DIR}/docker-compose-Linux-x86_64_1.24.1 /usr/bin/docker-compose groupadd docker \u0026\u0026 useradd docker -g docker id -u magedu \u0026\u003e /dev/null if [ $? -ne 0 ];then useradd magedu usermod magedu -G docker fi systemctl enable containerd.service \u0026\u0026 systemctl restart containerd.service systemctl enable docker.service \u0026\u0026 systemctl restart docker.service systemctl enable docker.socket \u0026\u0026 systemctl restart docker.socket fi } ubuntu_install_docker(){ grep \"Ubuntu\" /etc/issue \u0026\u003e /dev/null if [ $? -eq 0 ];then /bin/echo \"å½“å‰ç³»ç»Ÿæ˜¯`cat /etc/issue`,å³å°†å¼€å§‹ç³»ç»Ÿåˆå§‹åŒ–ã€é…ç½®docker-composeä¸å®‰è£…docker\" \u0026\u0026 sleep 1 \\cp ${DIR}/limits.conf /etc/security/limits.conf \\cp ${DIR}/sysctl.conf /etc/sysctl.conf /bin/tar xvf ${DOCKER_FILE} \\cp docker/* /usr/bin \\cp containerd.service /lib/systemd/system/containerd.service \\cp docker.service /lib/systemd/system/docker.service \\cp docker.socket /lib/systemd/system/docker.socket \\cp ${DIR}/docker-compose-Linux-x86_64_1.24.1 /usr/bin/docker-compose ulimit -n 1000000 /bin/su -c - ceamg \"ulimit -n 1000000\" /bin/echo \"docker å®‰è£…å®Œæˆ!\" \u0026\u0026 sleep 1 id -u magedu \u0026\u003e /dev/null if [ $? -ne 0 ];then groupadd -r docker useradd -r -m -g docker docker fi systemctl enable containerd.service \u0026\u0026 systemctl restart containerd.service systemctl enable docker.service \u0026\u0026 systemctl restart docker.service systemctl enable docker.socket \u0026\u0026 systemctl restart docker.socket fi } main(){ centos_install_docker ubuntu_install_docker } mainsudo tee /etc/docker/daemon.json \u003c\u003c-'EOF' { \"registry-mirrors\": [\"https://lc2kkql3.mirror.aliyuncs.com\"], \"storage-driver\": \"overlay\", \"data-root\": \"/data/docker\" } EOF sudo systemctl daemon-reload sudo systemctl restart dockerroot@master01:~# cat /etc/sysctl.conf net.ipv4.ip_forward=1 vm.max_map_count=262144 kernel.pid_max=4194303 fs.file-max=1000000 net.ipv4.tcp_max_tw_buckets=6000 net.netfilter.nf_conntrack_max=2097152 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 vm.swappiness=0root@master01:/apps/docker# bash docker-install.sh å½“å‰ç³»ç»Ÿæ˜¯Ubuntu 20.04.3 LTS \\n \\l,å³å°†å¼€å§‹ç³»ç»Ÿåˆå§‹åŒ–ã€é…ç½®docker-composeä¸å®‰è£…docker docker/ docker/dockerd docker/docker-proxy docker/containerd-shim docker/docker-init docker/docker docker/runc docker/ctr docker/containerd su: user jack does not exist docker å®‰è£…å®Œæˆ! Created symlink /etc/systemd/system/multi-user.target.wants/co","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:2:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"1.3 å®‰è£…ansible #éƒ¨ç½²èŠ‚ç‚¹å®‰è£…ansible root@master01:~# apt install python3-pip git root@master01:~# pip3 install ansible -i https://mirrors.aliyun.com/pypi/simple/ root@master01:~# ansible --version ansible [core 2.13.7] config file = None configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /usr/local/lib/python3.8/dist-packages/ansible ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections executable location = /usr/local/bin/ansible python version = 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0] jinja version = 3.1.2 libyaml = True","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:2:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"1.4 é…ç½®é›†ç¾¤å…ç§˜é’¥ç™»å½• #â½£æˆå¯†é’¥å¯¹ root@k8s-master1:~# ssh-keygen #å®‰è£…sshpasså‘½ä»¤â½¤äºåŒæ­¥å…¬é’¥åˆ°å„k8sæœåŠ¡å™¨ # apt-get install sshpass #åˆ†å‘å…¬é’¥è„šæœ¬ï¼š root@k8s-master1:~# cat scp-key.sh #!/bin/bash #â½¬æ ‡ä¸»æœºåˆ—è¡¨ IP=\" 10.1.0.32 10.1.0.33 10.1.0.34 10.1.0.35 10.1.0.38 \" for node in ${IP};do sshpass -p ceamg.com ssh-copy-id ${node} -o StrictHostKeyChecking=no if [ $? -eq 0 ];then echo \"${node} ç§˜é’¥copyå®Œæˆ\" else echo \"${node} ç§˜é’¥copyå¤±è´¥\" fi done","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:2:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"1.5 éƒ¨ç½²èŠ‚ç‚¹ä¸‹è½½kubeaszéƒ¨ç½²é¡¹â½¬åŠç»„ä»¶ ä½¿â½¤ **master01 **ä½œä¸ºéƒ¨ç½²èŠ‚ç‚¹GitHub - easzlab/kubeasz: ä½¿ç”¨Ansibleè„šæœ¬å®‰è£…K8Sé›†ç¾¤ï¼Œä»‹ç»ç»„ä»¶äº¤äº’åŸç†ï¼Œæ–¹ä¾¿ç›´æ¥ï¼Œä¸å—å›½å†…ç½‘ç»œç¯å¢ƒå½±å“ root@k8s-master1:~# export release=3.3.1 root@k8s-master1:~# curl -C- -fLO --retry 3 https://github.com/easzlab/kubeasz/releases/download/${release}/ezdownroot@master01:~# chmod a+x ezdown root@master01:~# ./ezdown -D 2023-01-02 13:28:24 INFO Action begin: download_all 2023-01-02 13:28:24 INFO downloading docker binaries, version 19.03.15 --2023-01-02 13:28:24-- https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/static/stable/x86_64/docker-19.03.15.tgz Resolving mirrors.tuna.tsinghua.edu.cn (mirrors.tuna.tsinghua.edu.cn)... 101.6.15.130, 2402:f000:1:400::2 Connecting to mirrors.tuna.tsinghua.edu.cn (mirrors.tuna.tsinghua.edu.cn)|101.6.15.130|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 62436240 (60M) [application/octet-stream] Saving to: â€˜docker-19.03.15.tgzâ€™ docker-19.03.15.tgz 100%[========================================================================================================================\u003e] 59.54M 11.2MB/s in 5.5s 2023-01-02 13:28:29 (10.9 MB/s) - â€˜docker-19.03.15.tgzâ€™ saved [62436240/62436240] 2023-01-02 13:28:31 WARN docker is already running. 2023-01-02 13:28:31 INFO downloading kubeasz: 3.3.1 2023-01-02 13:28:31 DEBUG run a temporary container Unable to find image 'easzlab/kubeasz:3.3.1' locally 3.3.1: Pulling from easzlab/kubeasz Status: Image is up to date for easzlab/kubeasz:3.3.1 docker.io/easzlab/kubeasz:3.3.1 2023-01-02 13:41:44 INFO Action successed: download_all root@master01:~# cd /etc/kubeasz/ root@master01:/etc/kubeasz/down# ll total 1136932 drwxr-xr-x 2 root root 4096 Jan 2 13:41 ./ drwxrwxr-x 12 root root 4096 Jan 2 13:32 ../ -rw------- 1 root root 383673856 Jan 2 13:35 calico_v3.19.4.tar -rw------- 1 root root 48941568 Jan 2 13:36 coredns_1.9.3.tar -rw------- 1 root root 246784000 Jan 2 13:39 dashboard_v2.5.1.tar -rw-r--r-- 1 root root 62436240 Feb 1 2021 docker-19.03.15.tgz -rw------- 1 root root 106171392 Jan 2 13:37 k8s-dns-node-cache_1.21.1.tar -rw------- 1 root root 179129856 Jan 2 13:41 kubeasz_3.3.1.tar -rw------- 1 root root 43832320 Jan 2 13:40 metrics-scraper_v1.0.8.tar -rw------- 1 root root 65683968 Jan 2 13:41 metrics-server_v0.5.2.tar -rw------- 1 root root 721408 Jan 2 13:41 pause_3.7.tar -rw------- 1 root root 26815488 Jan 2 13:32 registry-2.tarä¸Šè¿°è„šæœ¬è¿è¡ŒæˆåŠŸåï¼Œæ‰€æœ‰æ–‡ä»¶ï¼ˆkubeaszä»£ç ã€äºŒè¿›åˆ¶ã€ç¦»çº¿é•œåƒï¼‰å‡å·²æ•´ç†å¥½æ”¾å…¥ç›®å½•/etc/kubeasz ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:2:5","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"2.éƒ¨ç½² harbor é•œåƒä»“åº“ ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"2.1 åˆ›å»ºè‡ªç­¾sslè¯ä¹¦ #æœ¬åœ°è§£æ root@harbor01:~# echo \"10.1.0.38 harbor.ceamg.com \u003e\u003e /etc/hosts\" mkdir -p /data/cert cd /data/cert #åˆ›å»ºcaå’Œharborè¯ä¹¦è¯·æ±‚ openssl genrsa -out ca.key 4096 openssl req -x509 -new -nodes -sha512 -days 7300 -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=harbor.ceamg.com\" -key ca.key -out ca.crt openssl genrsa -out harbor.ceamg.com.key 4096 openssl req -sha512 -new -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=harbor.ceamg.com\" -key harbor.ceamg.com.key -out harbor.ceamg.com.csr #åˆ›å»ºv3æ–‡ä»¶ cat \u003e v3.ext \u003c\u003c-EOF authorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment extendedKeyUsage = serverAuth subjectAltName = @alt_names [alt_names] DNS.1=harbor.ceamg.com DNS.2=harbor DNS.3=ks-allinone EOF #ä½¿ç”¨v3æ–‡ä»¶ç­¾å‘harborè¯ä¹¦ openssl x509 -req -sha512 -days 7300 -extfile v3.ext -CA ca.crt -CAkey ca.key -CAcreateserial -in harbor.ceamg.com.csr -out harbor.ceamg.com.crt #è½¬æ¢æˆcert openssl x509 -inform PEM -in harbor.ceamg.com.crt -out harbor.ceamg.com.cert #æ·»åŠ æ ¹è¯ä¹¦è®©ç³»ç»Ÿä¿¡ä»»è¯ä¹¦ root@harbor01:/data/cert# cp harbor.ceamg.com.crt /usr/local/share/ca-certificates/ root@harbor01:/data/cert# update-ca-certificates Updating certificates in /etc/ssl/certs... rehash: warning: skipping ca-certificates.crt,it does not contain exactly one certificate or CRL 1 added, 0 removed; done. Running hooks in /etc/ca-certificates/update.d... done. #update-ca-certificateså‘½ä»¤å°†PEMæ ¼å¼çš„æ ¹è¯ä¹¦å†…å®¹é™„åŠ åˆ°/etc/ssl/certs/ca-certificates.crt ï¼Œè€Œ/etc/ssl/certs/ca-certificates.crt åŒ…å«äº†ç³»ç»Ÿè‡ªå¸¦çš„å„ç§å¯ä¿¡æ ¹è¯ä¹¦.","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:3:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"2.2 ä¿®æ”¹harboré…ç½® root@harbor01:/apps/harbor/harbor# cp harbor.yml.tmpl harbor.ymlroot@harbor01:/apps/harbor/harbor# grep -v \"#\" harbor.yml | grep -v \"^$\" hostname: harbor.ceamg.com http: port: 80 https: port: 443 certificate: /data/cert/harbor.ceamg.com.crt private_key: /apps/harbor/certs/harbor.ceamg.com.key harbor_admin_password: ceamg.com database: password: root123 max_idle_conns: 100 max_open_conns: 900 conn_max_lifetime: 5m conn_max_idle_time: 0 data_volume: /data trivy: ignore_unfixed: false skip_update: false offline_scan: false security_check: vuln insecure: false jobservice: max_job_workers: 10 notification: webhook_job_max_retry: 10 chart: absolute_url: disabled log: level: info local: rotate_count: 50 rotate_size: 200M location: /var/log/harbor _version: 2.7.0 proxy: http_proxy: https_proxy: no_proxy: components: - core - jobservice - trivy upload_purging: enabled: true age: 168h interval: 24h dryrun: false cache: enabled: false expire_hours: 24","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:3:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"2.3 å®‰è£…harbor Harbor â€“ Reconfigure Harbor and Manage the Harbor Lifecycle æœ‰æ‰«æâ€“with-trivy ,æœ‰è®¤è¯â€“with-notaryï¼Œæœ‰helm charts æ¨¡å—é€€å‡ºâ€“with-chartmuseum å…¶ä¸­â€“with-clairå·²å¼ƒç”¨ #æ›´æ–°é…ç½®æ–‡ä»¶ root@harbor01:/apps/harbor/harbor# ./prepare root@harbor01:/apps/harbor/harbor# ./install.sh --with-notary --with-trivy --with-chartmuseum [Step 0]: checking if docker is installed ... Note: docker version: 19.03.15 [Step 1]: checking docker-compose is installed ... Note: docker-compose version: 1.24.1 [Step 2]: loading Harbor images ... 8991ee7e1c66: Loading layer [==================================================\u003e] 37.72MB/37.72MB caef0c5d2fe0: Loading layer [==================================================\u003e] 43.84MB/43.84MB d0ae0913849c: Loading layer [==================================================\u003e] 66.03MB/66.03MB d6c3137fc4e6: Loading layer [==================================================\u003e] 18.2MB/18.2MB db156fb6962c: Loading layer [==================================================\u003e] 65.54kB/65.54kB 578a990cf79f: Loading layer [==================================================\u003e] 2.56kB/2.56kB 9415b3c8b317: Loading layer [==================================================\u003e] 1.536kB/1.536kB bdb2dfba8b17: Loading layer [==================================================\u003e] 12.29kB/12.29kB 6a1b6c491cd2: Loading layer [==================================================\u003e] 2.613MB/2.613MB c35c2488b48b: Loading layer [==================================================\u003e] 407kB/407kB Loaded image: goharbor/prepare:v2.7.0 Loaded image: goharbor/harbor-db:v2.7.0 Loaded image: goharbor/harbor-core:v2.7.0 Loaded image: goharbor/harbor-log:v2.7.0 Loaded image: goharbor/harbor-exporter:v2.7.0 Loaded image: goharbor/nginx-photon:v2.7.0 Loaded image: goharbor/chartmuseum-photon:v2.7.0 Loaded image: goharbor/harbor-portal:v2.7.0 Loaded image: goharbor/harbor-jobservice:v2.7.0 Loaded image: goharbor/harbor-registryctl:v2.7.0 Loaded image: goharbor/registry-photon:v2.7.0 Loaded image: goharbor/notary-server-photon:v2.7.0 Loaded image: goharbor/redis-photon:v2.7.0 Loaded image: goharbor/notary-signer-photon:v2.7.0 Loaded image: goharbor/trivy-adapter-photon:v2.7.0 [Step 3]: preparing environment ... [Step 4]: preparing harbor configs ... prepare base dir is set to /apps/harbor/harbor Generated configuration file: /config/portal/nginx.conf Generated configuration file: /config/log/logrotate.conf Generated configuration file: /config/log/rsyslog_docker.conf Generated configuration file: /config/nginx/nginx.conf Generated configuration file: /config/core/env Generated configuration file: /config/core/app.conf Generated configuration file: /config/registry/config.yml Generated configuration file: /config/registryctl/env Generated configuration file: /config/registryctl/config.yml Generated configuration file: /config/db/env Generated configuration file: /config/jobservice/env Generated configuration file: /config/jobservice/config.yml Generated and saved secret to file: /data/secret/keys/secretkey Successfully called func: create_root_cert Generated configuration file: /config/trivy-adapter/env Generated configuration file: /compose_location/docker-compose.yml Clean up the input dir Note: stopping existing Harbor instance ... Removing network harbor_harbor WARNING: Network harbor_harbor not found. [Step 5]: starting Harbor ... Creating network \"harbor_harbor\" with the default driver Creating harbor-log ... done Creating redis ... done Creating harbor-portal ... done Creating registry ... done Creating harbor-db ... done Creating registryctl ... done Creating trivy-adapter ... done Creating harbor-core ... done Creating harbor-jobservice ... done Creating nginx ... done âœ” ----Harbor has been installed and started successfully.----","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:3:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"2.4 harbor è°ƒè¯• #å…³é—­ harbor $~ sudo docker-compose down -v #æ›´æ–°é…ç½® vim /apps/harbor.yml prepare #é‡æ–°ç”Ÿæˆé…ç½®æ–‡ä»¶,å¢åŠ ä¸Šå…¶ä»–chartåŠŸèƒ½ç­‰ sudo prepare --with-notary --with-trivy --with-chartmuseum #å¯åŠ¨ harbor $~ sudo docker-compose up -d","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:3:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"3.åˆ›å»ºé›†ç¾¤é…ç½®å®ä¾‹ ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:4:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"3.1 â½£æˆk8sé›†ç¾¤ hostsâ½‚ä»¶ root@master01:/etc/kubeasz# ./ezctl new k8s-01 2023-01-03 04:52:33 DEBUG generate custom cluster files in /etc/kubeasz/clusters/k8s-01 2023-01-03 04:52:33 DEBUG set versions 2023-01-03 04:52:33 DEBUG cluster k8s-01: files successfully created. 2023-01-03 04:52:33 INFO next steps 1: to config '/etc/kubeasz/clusters/k8s-01/hosts' 2023-01-03 04:52:33 INFO next steps 2: to config '/etc/kubeasz/clusters/k8s-01/config.yml'# 'NEW_INSTALL': 'true' to install a harbor server; 'false' to integrate with existed one [harbor] 10.1.0.38 NEW_INSTALL=false # [optional] loadbalance for accessing k8s from outside [ex_lb] #192.168.1.6 LB_ROLE=backup EX_APISERVER_VIP=192.168.1.250 EX_APISERVER_PORT=8443 #192.168.1.7 LB_ROLE=master EX_APISERVER_VIP=192.168.1.250 EX_APISERVER_PORT=8443 # [optional] ntp server for the cluster [chrony] #192.168.1.1 [all:vars] # --------- Main Variables --------------- # Secure port for apiservers SECURE_PORT=\"6443\" # Cluster container-runtime supported: docker, containerd # if k8s version \u003e= 1.24, docker is not supported CONTAINER_RUNTIME=\"containerd\" # Network plugins supported: calico, flannel, kube-router, cilium, kube-ovn CLUSTER_NETWORK=\"calico\" # Service proxy mode of kube-proxy: 'iptables' or 'ipvs' PROXY_MODE=\"ipvs\" # K8S Service CIDR, not overlap with node(host) networking SERVICE_CIDR=\"10.10.0.0/16\" # Cluster CIDR (Pod CIDR), not overlap with node(host) networking CLUSTER_CIDR=\"10.20.0.0/16\" # NodePort Range NODE_PORT_RANGE=\"30000-65535\" # Cluster DNS Domain CLUSTER_DNS_DOMAIN=\"ceamg.local\" # -------- Additional Variables (don't change the default value right now) --- # Binaries Directory bin_dir=\"/usr/local/bin\" # Deploy Directory (kubeasz workspace) base_dir=\"/etc/kubeasz\" # Directory for a specific cluster cluster_dir=\"{{ base_dir }}/clusters/k8s-01\" # CA and other components cert/key Directory ca_dir=\"/etc/kubernetes/ssl\"","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:4:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"3.1 â½£æˆk8sé›†ç¾¤ config â½‚ä»¶ root@master01:/etc/kubeasz# vim /etc/kubeasz/clusters/k8s-01/config.yml ############################ # prepare ############################ # å¯é€‰ç¦»çº¿å®‰è£…ç³»ç»Ÿè½¯ä»¶åŒ… (offline|online) INSTALL_SOURCE: \"online\" # å¯é€‰è¿›è¡Œç³»ç»Ÿå®‰å…¨åŠ å›º github.com/dev-sec/ansible-collection-hardening OS_HARDEN: false ############################ # role:deploy ############################ # default: ca will expire in 100 years # default: certs issued by the ca will expire in 50 years CA_EXPIRY: \"876000h\" CERT_EXPIRY: \"438000h\" # kubeconfig é…ç½®å‚æ•° CLUSTER_NAME: \"cluster1\" CONTEXT_NAME: \"context-{{ CLUSTER_NAME }}\" # k8s version K8S_VER: \"1.24.2\" ############################ # role:etcd ############################ # è®¾ç½®ä¸åŒçš„walç›®å½•ï¼Œå¯ä»¥é¿å…ç£ç›˜ioç«äº‰ï¼Œæé«˜æ€§èƒ½ ETCD_DATA_DIR: \"/var/lib/etcd\" ETCD_WAL_DIR: \"\" ############################ # role:runtime [containerd,docker] ############################ # ------------------------------------------- containerd # [.]å¯ç”¨å®¹å™¨ä»“åº“é•œåƒ ENABLE_MIRROR_REGISTRY: true # [containerd]åŸºç¡€å®¹å™¨é•œåƒ SANDBOX_IMAGE: \"easzlab.io.local:5000/easzlab/pause:3.7\" # [containerd]å®¹å™¨æŒä¹…åŒ–å­˜å‚¨ç›®å½• CONTAINERD_STORAGE_DIR: \"/var/lib/containerd\" # ------------------------------------------- docker # [docker]å®¹å™¨å­˜å‚¨ç›®å½• DOCKER_STORAGE_DIR: \"/var/lib/docker\" # [docker]å¼€å¯Restful API ENABLE_REMOTE_API: false # [docker]ä¿¡ä»»çš„HTTPä»“åº“ INSECURE_REG: '[\"http://easzlab.io.local:5000\"]' ############################ # role:kube-master ############################ # k8s é›†ç¾¤ master èŠ‚ç‚¹è¯ä¹¦é…ç½®ï¼Œå¯ä»¥æ·»åŠ å¤šä¸ªipå’ŒåŸŸåï¼ˆæ¯”å¦‚å¢åŠ å…¬ç½‘ipå’ŒåŸŸåï¼‰ MASTER_CERT_HOSTS: - \"10.1.1.1\" - \"k8s.easzlab.io\" #- \"www.test.com\" # node èŠ‚ç‚¹ä¸Š pod ç½‘æ®µæ©ç é•¿åº¦ï¼ˆå†³å®šæ¯ä¸ªèŠ‚ç‚¹æœ€å¤šèƒ½åˆ†é…çš„pod ipåœ°å€ï¼‰ # å¦‚æœflannel ä½¿ç”¨ --kube-subnet-mgr å‚æ•°ï¼Œé‚£ä¹ˆå®ƒå°†è¯»å–è¯¥è®¾ç½®ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ†é…podç½‘æ®µ # https://github.com/coreos/flannel/issues/847 NODE_CIDR_LEN: 24 ############################ # role:kube-node ############################ # Kubelet æ ¹ç›®å½• KUBELET_ROOT_DIR: \"/var/lib/kubelet\" # nodeèŠ‚ç‚¹æœ€å¤§pod æ•° MAX_PODS: 300 # é…ç½®ä¸ºkubeç»„ä»¶ï¼ˆkubelet,kube-proxy,dockerdç­‰ï¼‰é¢„ç•™çš„èµ„æºé‡ # æ•°å€¼è®¾ç½®è¯¦è§templates/kubelet-config.yaml.j2 KUBE_RESERVED_ENABLED: \"yes\" # k8s å®˜æ–¹ä¸å»ºè®®è‰ç‡å¼€å¯ system-reserved, é™¤éä½ åŸºäºé•¿æœŸç›‘æ§ï¼Œäº†è§£ç³»ç»Ÿçš„èµ„æºå ç”¨çŠ¶å†µï¼› # å¹¶ä¸”éšç€ç³»ç»Ÿè¿è¡Œæ—¶é—´ï¼Œéœ€è¦é€‚å½“å¢åŠ èµ„æºé¢„ç•™ï¼Œæ•°å€¼è®¾ç½®è¯¦è§templates/kubelet-config.yaml.j2 # ç³»ç»Ÿé¢„ç•™è®¾ç½®åŸºäº 4c/8g è™šæœºï¼Œæœ€å°åŒ–å®‰è£…ç³»ç»ŸæœåŠ¡ï¼Œå¦‚æœä½¿ç”¨é«˜æ€§èƒ½ç‰©ç†æœºå¯ä»¥é€‚å½“å¢åŠ é¢„ç•™ # å¦å¤–ï¼Œé›†ç¾¤å®‰è£…æ—¶å€™apiserverç­‰èµ„æºå ç”¨ä¼šçŸ­æ—¶è¾ƒå¤§ï¼Œå»ºè®®è‡³å°‘é¢„ç•™1gå†…å­˜ SYS_RESERVED_ENABLED: \"no\" ############################ # role:network [flannel,calico,cilium,kube-ovn,kube-router] ############################ # ------------------------------------------- flannel # [flannel]è®¾ç½®flannel åç«¯\"host-gw\",\"vxlan\"ç­‰ FLANNEL_BACKEND: \"vxlan\" DIRECT_ROUTING: false # [flannel] flanneld_image: \"quay.io/coreos/flannel:v0.10.0-amd64\" flannelVer: \"v0.15.1\" flanneld_image: \"easzlab.io.local:5000/easzlab/flannel:{{ flannelVer }}\" # ------------------------------------------- calico # [calico]è®¾ç½® CALICO_IPV4POOL_IPIP=â€œoffâ€,å¯ä»¥æé«˜ç½‘ç»œæ€§èƒ½ï¼Œæ¡ä»¶é™åˆ¶è¯¦è§ docs/setup/calico.md CALICO_IPV4POOL_IPIP: \"Always\" # [calico]è®¾ç½® calico-nodeä½¿ç”¨çš„host IPï¼Œbgpé‚»å±…é€šè¿‡è¯¥åœ°å€å»ºç«‹ï¼Œå¯æ‰‹å·¥æŒ‡å®šä¹Ÿå¯ä»¥è‡ªåŠ¨å‘ç° IP_AUTODETECTION_METHOD: \"can-reach={{ groups['kube_master'][0] }}\" # [calico]è®¾ç½®calico ç½‘ç»œ backend: brid, vxlan, none CALICO_NETWORKING_BACKEND: \"brid\" # [calico]è®¾ç½®calico æ˜¯å¦ä½¿ç”¨route reflectors # å¦‚æœé›†ç¾¤è§„æ¨¡è¶…è¿‡50ä¸ªèŠ‚ç‚¹ï¼Œå»ºè®®å¯ç”¨è¯¥ç‰¹æ€§ CALICO_RR_ENABLED: false # CALICO_RR_NODES é…ç½®route reflectorsçš„èŠ‚ç‚¹ï¼Œå¦‚æœæœªè®¾ç½®é»˜è®¤ä½¿ç”¨é›†ç¾¤masterèŠ‚ç‚¹ # CALICO_RR_NODES: [\"192.168.1.1\", \"192.168.1.2\"] CALICO_RR_NODES: [] # [calico]æ›´æ–°æ”¯æŒcalico ç‰ˆæœ¬: [v3.3.x] [v3.4.x] [v3.8.x] [v3.15.x] calico_ver: \"v3.19.4\" # [calico]calico ä¸»ç‰ˆæœ¬ calico_ver_main: \"{{ calico_ver.split('.')[0] }}.{{ calico_ver.split('.')[1] }}\" # ------------------------------------------- cilium # [cilium]é•œåƒç‰ˆæœ¬ cilium_ver: \"1.11.6\" cilium_connectivity_check: true cilium_hubble_enabled: false cilium_hubble_ui_enabled: false # ------------------------------------------- kube-ovn # [kube-ovn]é€‰æ‹© OVN DB and OVN Control Plane èŠ‚ç‚¹ï¼Œé»˜è®¤ä¸ºç¬¬ä¸€ä¸ªmasterèŠ‚ç‚¹ OVN_DB_NODE: \"{{ groups['kube_master'][0] }}\" # [kube-ovn]ç¦»çº¿é•œåƒtaråŒ… kube_ovn_ver: \"v1.5.3\" # ------------------------------------------- kube-router # [kube-router]å…¬æœ‰äº‘ä¸Šå­˜åœ¨é™åˆ¶ï¼Œä¸€èˆ¬éœ€è¦å§‹ç»ˆå¼€å¯ ipinipï¼›è‡ªæœ‰ç¯å¢ƒå¯ä»¥è®¾ç½®ä¸º \"subnet\" OVERLAY_TYPE: \"full\" # [kube-router]NetworkPolicy æ”¯æŒå¼€å…³ FIREWALL_ENABLE: true # [k","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:4:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"4.æ­¥éª¤1-åŸºç¡€ç¯å¢ƒåˆå§‹åŒ– root@master01:/etc/kubeasz# ./ezctl help setup Usage: ezctl setup \u003ccluster\u003e \u003cstep\u003e available steps: 01 prepare to prepare CA/certs \u0026 kubeconfig \u0026 other system settings 02 etcd to setup the etcd cluster 03 container-runtime to setup the container runtime(docker or containerd) 04 kube-master to setup the master nodes 05 kube-node to setup the worker nodes 06 network to setup the network plugin 07 cluster-addon to setup other useful plugins 90 all to run 01~07 all at once 10 ex-lb to install external loadbalance for accessing k8s from outside 11 harbor to install a new harbor server or to integrate with an existed one examples: ./ezctl setup test-k8s 01 (or ./ezctl setup test-k8s prepare) ./ezctl setup test-k8s 02 (or ./ezctl setup test-k8s etcd) ./ezctl setup test-k8s all ./ezctl setup test-k8s 04 -t restart_master vim playbooks/01.prepare.yml #ç³»ç»ŸåŸºç¡€åˆå§‹åŒ–ä¸»æœºé…ç½® root@master01:/etc/kubeasz# ./ezctl setup k8s-01 01 #å‡†å¤‡CAå’ŒåŸºç¡€ç³»ç»Ÿè®¾ç½®","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:5:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"5.æ­¥éª¤2-éƒ¨ç½²etcdé›†ç¾¤ å¯æ›´æ”¹å¯åŠ¨è„šæœ¬è·¯å¾„åŠç‰ˆæœ¬ç­‰â¾ƒå®šä¹‰é…ç½® root@master01:/etc/kubeasz# ./ezctl setup k8s-01 02 ansible-playbook -i clusters/k8s-01/hosts -e @clusters/k8s-01/config.yml playbooks/02.etcd.yml 2023-01-03 13:39:13 INFO cluster:k8s-01 setup step:02 begins in 5s, press any key to abortå¥åº·æ£€æŸ¥ export NODE_IPS=\"10.1.0.34 10.1.0.35\" root@etcd01:~# for ip in ${NODE_IPS}; do ETCDCTL_API=3 /usr/local/bin/etcdctl --endpoints=https://${ip}:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem endpoint health; done https://10.1.0.34:2379 is healthy: successfully committed proposal: took = 14.95631ms https://10.1.0.35:2379 is healthy: successfully committed proposal: took = 15.037491ms æ³¨ï¼šä»¥ä¸Šè¿”å›ä¿¡æ¯è¡¨ç¤ºetcdé›†ç¾¤è¿â¾æ­£å¸¸ï¼Œå¦åˆ™å¼‚å¸¸ï¼éƒ¨ç½²containerd åŒæ­¥dockerè¯ä¹¦è„šæœ¬ï¼š #!/bin/bash #â½¬æ ‡ä¸»æœºåˆ—è¡¨ IP=\" 10.1.0.32 10.1.0.33 10.1.0.34 10.1.0.35 \" for node in ${IP};do sshpass -p ceamg.com ssh-copy-id ${node} -o StrictHostKeyChecking=no if [ $? -eq 0 ];then echo \"${node} ç§˜é’¥copyå®Œæˆ\" echo \"${node} ç§˜é’¥copyå®Œæˆ,å‡†å¤‡ç¯å¢ƒåˆå§‹åŒ–.....\" ssh ${node} \"mkdir /etc/containerd/certs.d/harbor.ceamg.com -p\" echo \"Harbor è¯ä¹¦åˆ›å»ºæˆåŠŸ!\" scp /etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.cert /etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.crt /etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.key /etc/containerd/certs.d/harbor.ceamg.com/ca.crt ${node}:/etc/containerd/certs.d/harbor.ceamg.com/ echo \"Harbor è¯ä¹¦æ‹·è´æˆåŠŸ!\" ssh ${node} \"echo \"10.1.0.38 harbor.ceamg.com\" \u003e\u003e /etc/hosts\" echo \"host è§£ææ·»åŠ å®Œæˆ\" #scp -r /root/.docker ${node}:/root/ #echo \"Harbor è®¤è¯ä»¶æ‹·å®Œæˆ!\" else echo \"${node} ç§˜é’¥copyå¤±è´¥\" fi done #æ‰§â¾è„šæœ¬è¿›â¾è¯ä¹¦åˆ†å‘ root@k8s-master1:/etc/kubeasz# bash /root/scp-key.sh","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:6:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"6.æ­¥éª¤3-éƒ¨ç½²è¿è¡Œæ—¶ç¯å¢ƒ é¡¹ç›®æ ¹æ®k8sç‰ˆæœ¬æä¾›ä¸åŒçš„é»˜è®¤å®¹å™¨è¿è¡Œæ—¶ï¼š k8s ç‰ˆæœ¬ \u003c 1.24 æ—¶ï¼Œæ”¯æŒdocker containerd å¯é€‰ k8s ç‰ˆæœ¬ \u003e= 1.24 æ—¶ï¼Œä»…æ”¯æŒ containerd ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:7:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"6.1 kubeasz é›†æˆå®‰è£… containerd æ³¨æ„ï¼šk8s 1.24ä»¥åï¼Œé¡¹ç›®å·²ç»è®¾ç½®é»˜è®¤å®¹å™¨è¿è¡Œæ—¶ä¸º containerdï¼Œæ— éœ€æ‰‹åŠ¨ä¿®æ”¹ ./ezctl setup k8s-01 05","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:7:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"6.2 é…ç½®containerd å¯¹æ¥ç§æœ‰harborä»“åº“ ä¿®æ”¹roleæ¨¡æ¿æ–‡ä»¶ vim roles/containerd/templates/config.toml.j2ä¸»è¦ä¿®æ”¹å¦‚ä¸‹ï¼š [plugins.\"io.containerd.grpc.v1.cri\".registry] [plugins.\"io.containerd.grpc.v1.cri\".registry.auths] [plugins.\"io.containerd.grpc.v1.cri\".registry.configs] [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"https://harbor.ceamg.com\"] username = \"admin\" password = \"ceamg.com\" [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"easzlab.io.local:5000\".tls] insecure_skip_verify = true [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"harbor.ceamg.com\".tls] insecure_skip_verify = true ca_file = \"/etc/containerd/certs.d/harbor.ceamg.com/ca.crt\" cert_file = \"/etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.cert\" key_file = \"/etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.key\" [plugins.\"io.containerd.grpc.v1.cri\".registry.headers] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"easzlab.io.local:5000\"] endpoint = [\"http://easzlab.io.local:5000\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"harbor.ceamg.com\"] endpoint = [\"https://harbor.ceamg.com\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"] endpoint = [\"https://lc2kkql3.mirror.aliyuncs.com\",\"https://docker.mirrors.ustc.edu.cn\", \"http://hub-mirror.c.163.com\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"gcr.io\"] endpoint = [\"https://gcr.mirrors.ustc.edu.cn\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.gcr.io\"] endpoint = [\"https://gcr.mirrors.ustc.edu.cn/google-containers/\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"quay.io\"] endpoint = [\"https://quay.mirrors.ustc.edu.cn\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.auths.\"https://harbor.ceamg.com\"] [plugins.\"io.containerd.grpc.v1.cri\".x509_key_pair_streaming] tls_cert_file = \"\" tls_key_file = \"\"","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:7:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"6.3 containerd ä½¿ç”¨è¯ä¹¦å¯¹æ¥harborå®ç°ä¸Šä¼ ä¸‹è½½ 6.3.1 ä½¿ç”¨è„šæœ¬åŒæ­¥è¯ä¹¦åˆ°å®¢æˆ·ç«¯ #!/bin/bash #ç›®æ ‡ä¸»æœºåˆ—è¡¨ IP=\" 10.1.0.32 10.1.0.33 10.1.0.34 10.1.0.35 \" for node in ${IP};do sshpass -p ceamg.com ssh-copy-id ${node} -o StrictHostKeyChecking=no if [ $? -eq 0 ];then echo \"${node} ç§˜é’¥copyå®Œæˆ\" echo \"${node} ç§˜é’¥copyå®Œæˆ,å‡†å¤‡ç¯å¢ƒåˆå§‹åŒ–.....\" ssh ${node} \"mkdir /etc/containerd/certs.d/harbor.ceamg.com -p\" echo \"Harbor è¯ä¹¦åˆ›å»ºæˆåŠŸ!\" scp /etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.cert /etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.crt /etc/containerd/certs.d/harbor.ceamg.com/harbor.ceamg.com.key /etc/containerd/certs.d/harbor.ceamg.com/ca.crt ${node}:/etc/containerd/certs.d/harbor.ceamg.com/ echo \"Harbor è¯ä¹¦æ‹·è´æˆåŠŸ!\" ssh ${node} \"echo \"10.1.0.38 harbor.ceamg.com\" \u003e\u003e /etc/hosts\" echo \"host è§£ææ·»åŠ å®Œæˆ\" #scp -r /root/.docker ${node}:/root/ #echo \"Harbor è®¤è¯ä»¶æ‹·å®Œæˆ!\" else echo \"${node} ç§˜é’¥copyå¤±è´¥\" fi done6.3.2 æµ‹è¯•containerd å®¢æˆ·ç«¯ä½¿ç”¨è¯ä¹¦ç™»å½•harbor æ¨é€é•œåƒ nerdctl.pdf root@master01:/etc/containerd/certs.d/harbor.ceamg.com# ls ca.crt harbor.ceamg.com.cert harbor.ceamg.com.crt harbor.ceamg.com.key root@master01:/etc/containerd/certs.d/harbor.ceamg.com# nerdctl login harbor.ceamg.com WARNING: Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded root@master01:/etc/containerd/certs.d/harbor.ceamg.com# nerdctl images REPOSITORY TAG IMAGE ID CREATED PLATFORM SIZE BLOB SIZE nginx latest 0047b729188a 4 hours ago linux/amd64 149.4 MiB 54.2 MiB harbor.ceamg.com/library/nginx latest 0047b729188a 3 hours ago linux/amd64 149.4 MiB 54.2 MiB root@master01:/etc/containerd/certs.d/harbor.ceamg.com# nerdctl push harbor.ceamg.com/library/nginx INFO[0000] pushing as a reduced-platform image (application/vnd.docker.distribution.manifest.list.v2+json, sha256:3f727bfae5cee62f35f014637b350dbc1d0b416bdd1717b61c5ce5b036771aa0) index-sha256:3f727bfae5cee62f35f014637b350dbc1d0b416bdd1717b61c5ce5b036771aa0: done |++++++++++++++++++++++++++++++++++++++| manifest-sha256:9a821cadb1b13cb782ec66445325045b2213459008a41c72d8d87cde94b33c8c: done |++++++++++++++++++++++++++++++++++++++| config-sha256:1403e55ab369cd1c8039c34e6b4d47ca40bbde39c371254c7cba14756f472f52: done |++++++++++++++++++++++++++++++++++++++| elapsed: 1.1 s total: 9.3 Ki (8.5 KiB/s) ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:7:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"7.æ­¥éª¤4-éƒ¨ç½²master cat playbooks/04.kube-master.yml - hosts: kube_master roles: - kube-lb # å››å±‚è´Ÿè½½å‡è¡¡ï¼Œç›‘å¬åœ¨127.0.0.1:6443ï¼Œè½¬å‘åˆ°çœŸå®masterèŠ‚ç‚¹apiserveræœåŠ¡ - kube-master # - kube-node # å› ä¸ºç½‘ç»œã€ç›‘æ§ç­‰daemonsetç»„ä»¶ï¼ŒmasterèŠ‚ç‚¹ä¹Ÿæ¨èå®‰è£…kubeletå’Œkube-proxyæœåŠ¡ ... root@master01:/etc/kubeasz# ./ezctl setup k8s-01 04 ansible-playbook -i clusters/k8s-01/hosts -e @clusters/k8s-01/config.yml playbooks/04.kube-master.yml 2023-01-03 14:07:04 INFO cluster:k8s-01 setup step:04 begins in 5s, press any key to abort:éªŒè¯ master é›†ç¾¤ # æŸ¥çœ‹è¿›ç¨‹çŠ¶æ€ systemctl status kube-apiserver systemctl status kube-controller-manager systemctl status kube-scheduler # æŸ¥çœ‹è¿›ç¨‹è¿è¡Œæ—¥å¿— journalctl -u kube-apiserver journalctl -u kube-controller-manager journalctl -u kube-scheduleræ‰§è¡Œ kubectl get componentstatus å¯ä»¥çœ‹åˆ° root@master01:/etc/kubeasz# kubectl get componentstatus Warning: v1 ComponentStatus is deprecated in v1.19+ NAME STATUS MESSAGE ERROR scheduler Healthy ok controller-manager Healthy ok etcd-1 Healthy {\"health\":\"true\",\"reason\":\"\"} etcd-0 Healthy {\"health\":\"true\",\"reason\":\"\"} ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:8:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"8.æ­¥éª¤5-éƒ¨ç½²nodeèŠ‚ç‚¹ kube_node æ˜¯é›†ç¾¤ä¸­è¿è¡Œå·¥ä½œè´Ÿè½½çš„èŠ‚ç‚¹ï¼Œå‰ç½®æ¡ä»¶éœ€è¦å…ˆéƒ¨ç½²å¥½kube_masterèŠ‚ç‚¹ï¼Œå®ƒéœ€è¦éƒ¨ç½²å¦‚ä¸‹ç»„ä»¶ï¼š cat playbooks/05.kube-node.yml - hosts: kube_node roles: - { role: kube-lb, when: \"inventory_hostname not in groups['kube_master']\" } - { role: kube-node, when: \"inventory_hostname not in groups['kube_master']\" } kube-lbï¼šç”±nginxè£å‰ªç¼–è¯‘çš„å››å±‚è´Ÿè½½å‡è¡¡ï¼Œç”¨äºå°†è¯·æ±‚è½¬å‘åˆ°ä¸»èŠ‚ç‚¹çš„ apiserveræœåŠ¡ kubeletï¼škube_nodeä¸Šæœ€ä¸»è¦çš„ç»„ä»¶ kube-proxyï¼š å‘å¸ƒåº”ç”¨æœåŠ¡ä¸è´Ÿè½½å‡è¡¡ root@master01:/etc/kubeasz# ./ezctl setup k8s-01 05 ansible-playbook -i clusters/k8s-01/hosts -e @clusters/k8s-01/config.yml playbooks/05.kube-node.yml 2023-01-04 09:06:25 INFO cluster:k8s-01 setup step:05 begins in 5s, press any key to abort:éªŒè¯ node çŠ¶æ€ systemctl status kubelet # æŸ¥çœ‹çŠ¶æ€ systemctl status kube-proxy journalctl -u kubelet # æŸ¥çœ‹æ—¥å¿— journalctl -u kube-proxy è¿è¡Œ kubectl get node å¯ä»¥çœ‹åˆ°ç±»ä¼¼ root@worker01:/etc/containerd/certs.d/harbor.ceamg.com# kubectl get nodes NAME STATUS ROLES AGE VERSION 10.1.0.31 Ready,SchedulingDisabled master 21h v1.24.2 10.1.0.32 Ready node 21h v1.24.2 10.1.0.33 Ready node 21h v1.24.2","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:9:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"9.æ­¥éª¤6-éƒ¨ç½²ç½‘ç»œç»„ä»¶ é¦–å…ˆå›é¡¾ä¸‹K8Sç½‘ç»œè®¾è®¡åŸåˆ™ï¼Œåœ¨é…ç½®é›†ç¾¤ç½‘ç»œæ’ä»¶æˆ–è€…å®è·µK8S åº”ç”¨/æœåŠ¡éƒ¨ç½²è¯·ç‰¢è®°è¿™äº›åŸåˆ™ï¼š 1.æ¯ä¸ªPodéƒ½æ‹¥æœ‰ä¸€ä¸ªç‹¬ç«‹IPåœ°å€ï¼ŒPodå†…æ‰€æœ‰å®¹å™¨å…±äº«ä¸€ä¸ªç½‘ç»œå‘½åç©ºé—´ 2.é›†ç¾¤å†…æ‰€æœ‰Podéƒ½åœ¨ä¸€ä¸ªç›´æ¥è¿é€šçš„æ‰å¹³ç½‘ç»œä¸­ï¼Œå¯é€šè¿‡IPç›´æ¥è®¿é—® æ‰€æœ‰å®¹å™¨ä¹‹é—´æ— éœ€NATå°±å¯ä»¥ç›´æ¥äº’ç›¸è®¿é—® æ‰€æœ‰Nodeå’Œæ‰€æœ‰å®¹å™¨ä¹‹é—´æ— éœ€NATå°±å¯ä»¥ç›´æ¥äº’ç›¸è®¿é—® å®¹å™¨è‡ªå·±çœ‹åˆ°çš„IPè·Ÿå…¶ä»–å®¹å™¨çœ‹åˆ°çš„ä¸€æ · 3.Service cluster IPåªå¯åœ¨é›†ç¾¤å†…éƒ¨è®¿é—®ï¼Œå¤–éƒ¨è¯·æ±‚éœ€è¦é€šè¿‡NodePortã€LoadBalanceæˆ–è€…Ingressæ¥è®¿é—® calico æ˜¯k8sç¤¾åŒºæœ€æµè¡Œçš„ç½‘ç»œæ’ä»¶ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯k8s-conformance test é»˜è®¤ä½¿ç”¨çš„ç½‘ç»œæ’ä»¶ï¼ŒåŠŸèƒ½ä¸°å¯Œï¼Œæ”¯æŒnetwork policyï¼›æ˜¯å½“å‰kubeaszé¡¹ç›®çš„é»˜è®¤ç½‘ç»œæ’ä»¶ã€‚ å¦‚æœéœ€è¦å®‰è£…calicoï¼Œè¯·åœ¨clusters/xxxx/hostsæ–‡ä»¶ä¸­è®¾ç½®å˜é‡ CLUSTER_NETWORK=\"calico\" ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:10:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"9.1 ä½¿â½¤calicoâ½¹ç»œç»„ä»¶ vim clusters/k8s-01/config.yml # ------------------------------------------- calico # [calico]è®¾ç½® CALICO_IPV4POOL_IPIP=â€œoffâ€,å¯ä»¥æé«˜ç½‘ç»œæ€§èƒ½ï¼Œæ¡ä»¶é™åˆ¶è¯¦è§ docs/setup/calico.md CALICO_IPV4POOL_IPIP: \"Always\" # [calico]è®¾ç½® calico-nodeä½¿ç”¨çš„host IPï¼Œbgpé‚»å±…é€šè¿‡è¯¥åœ°å€å»ºç«‹ï¼Œå¯æ‰‹å·¥æŒ‡å®šä¹Ÿå¯ä»¥è‡ªåŠ¨å‘ç° IP_AUTODETECTION_METHOD: \"can-reach={{ groups['kube_master'][0] }}\" # [calico]è®¾ç½®calico ç½‘ç»œ backend: brid, vxlan, none CALICO_NETWORKING_BACKEND: \"brid\" # [calico]è®¾ç½®calico æ˜¯å¦ä½¿ç”¨route reflectors # å¦‚æœé›†ç¾¤è§„æ¨¡è¶…è¿‡50ä¸ªèŠ‚ç‚¹ï¼Œå»ºè®®å¯ç”¨è¯¥ç‰¹æ€§ CALICO_RR_ENABLED: false # CALICO_RR_NODES é…ç½®route reflectorsçš„èŠ‚ç‚¹ï¼Œå¦‚æœæœªè®¾ç½®é»˜è®¤ä½¿ç”¨é›†ç¾¤masterèŠ‚ç‚¹ # CALICO_RR_NODES: [\"192.168.1.1\", \"192.168.1.2\"] CALICO_RR_NODES: [] # [calico]æ›´æ–°æ”¯æŒcalico ç‰ˆæœ¬: [v3.3.x] [v3.4.x] [v3.8.x] [v3.15.x] calico_ver: \"v3.19.4\" # [calico]calico ä¸»ç‰ˆæœ¬ calico_ver_main: \"{{ calico_ver.split('.')[0] }}.{{ calico_ver.split('.')[1] }}\"./ezctl setup k8s-01 06","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:10:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"9.2 éªŒè¯calicoç½‘ç»œ æ‰§è¡Œcalicoå®‰è£…æˆåŠŸåå¯ä»¥éªŒè¯å¦‚ä¸‹ï¼š(éœ€è¦ç­‰å¾…é•œåƒä¸‹è½½å®Œæˆï¼Œæœ‰æ—¶å€™å³ä¾¿ä¸Šä¸€æ­¥å·²ç»é…ç½®äº†dockerå›½å†…åŠ é€Ÿï¼Œè¿˜æ˜¯å¯èƒ½æ¯”è¾ƒæ…¢ï¼Œè¯·ç¡®è®¤ä»¥ä¸‹å®¹å™¨è¿è¡Œèµ·æ¥ä»¥åï¼Œå†æ‰§è¡Œåç»­éªŒè¯æ­¥éª¤) ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:10:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"9.3 æŸ¥çœ‹æ‰€æœ‰calicoèŠ‚ç‚¹çŠ¶æ€ root@master01:/etc/kubeasz# kubectl get pod -A -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system calico-kube-controllers-5c8bb696bb-hf2cp 1/1 Running 0 6m10s 10.1.0.33 10.1.0.33 \u003cnone\u003e \u003cnone\u003e kube-system calico-node-6nlt6 1/1 Running 0 6m10s 10.1.0.32 10.1.0.32 \u003cnone\u003e \u003cnone\u003e kube-system calico-node-fd6rj 1/1 Running 0 6m10s 10.1.0.33 10.1.0.33 \u003cnone\u003e \u003cnone\u003e kube-system calico-node-lhgh4 1/1 Running 0 6m10s 10.1.0.31 10.1.0.31 \u003cnone\u003e \u003cnone\u003eroot@master01:/etc/kubeasz# calicoctl node status Calico process is running. IPv4 BGP status +--------------+-------------------+-------+----------+-------------+ | PEER ADDRESS | PEER TYPE | STATE | SINCE | INFO | +--------------+-------------------+-------+----------+-------------+ | 10.1.0.32 | node-to-node mesh | up | 04:16:44 | Established | | 10.1.0.33 | node-to-node mesh | up | 04:16:43 | Established | +--------------+-------------------+-------+----------+-------------+","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:10:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"9.4 åˆ›å»ºå®¹å™¨æµ‹è¯•ç½‘ç»œé€šä¿¡ root@master01:/etc/kubeasz# kubectl run net-test1 --image=harbor.ceamg.com/library/alpine sleep 360000 pod/net-test1 created root@master01:/etc/kubeasz# kubectl run net-test2 --image=harbor.ceamg.com/library/alpine sleep 360000 pod/net-test2 created root@master01:/etc/kubeasz# kubectl run net-test3 --image=harbor.ceamg.com/library/alpine sleep 360000 pod/net-test3 created root@master01:/etc/kubeasz# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES net-test1 1/1 Running 0 19s 10.20.5.3 10.1.0.32 \u003cnone\u003e \u003cnone\u003e net-test2 1/1 Running 0 15s 10.20.30.67 10.1.0.33 \u003cnone\u003e \u003cnone\u003e net-test3 1/1 Running 0 12s 10.20.30.68 10.1.0.33 \u003cnone\u003e \u003cnone\u003e test 1/1 Running 0 16m 10.20.5.1 10.1.0.32 \u003cnone\u003e \u003cnone\u003eroot@master01:/etc/kubeasz# kubectl exec -it net-test1 -- sh / # ping 10.20.30.67 PING 10.20.30.67 (10.20.30.67): 56 data bytes 64 bytes from 10.20.30.67: seq=0 ttl=62 time=0.481 ms ^C --- 10.20.30.67 ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 0.481/0.481/0.481 ms / # ping 10.20.30.68 PING 10.20.30.68 (10.20.30.68): 56 data bytes 64 bytes from 10.20.30.68: seq=0 ttl=62 time=0.631 ms 64 bytes from 10.20.30.68: seq=1 ttl=62 time=1.360 ms 64 bytes from 10.20.30.68: seq=2 ttl=62 time=0.420 ms ^C --- 10.20.30.68 ping statistics --- 3 packets transmitted, 3 packets received, 0% packet loss round-trip min/avg/max = 0.420/0.803/1.360 ms / # ping 223.5.5.5 PING 223.5.5.5 (223.5.5.5): 56 data bytes 64 bytes from 223.5.5.5: seq=0 ttl=114 time=7.597 ms 64 bytes from 223.5.5.5: seq=1 ttl=114 time=7.072 ms 64 bytes from 223.5.5.5: seq=2 ttl=114 time=7.583 ms ^C --- 223.5.5.5 ping statistics --- 3 packets transmitted, 3 packets received, 0% packet loss round-trip min/avg/max = 7.072/7.417/7.597 ms","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:10:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"10.æ­¥éª¤7-å®‰è£…é›†ç¾¤æ’ä»¶-coredns DNS æ˜¯ k8s é›†ç¾¤é¦–è¦éƒ¨ç½²çš„ç»„ä»¶ï¼Œå®ƒä¸ºé›†ç¾¤ä¸­çš„å…¶ä»– pods æä¾›åŸŸåè§£ææœåŠ¡ï¼›ä¸»è¦å¯ä»¥è§£æ é›†ç¾¤æœåŠ¡å SVC å’Œ Pod hostnameï¼›ç›®å‰å»ºè®®éƒ¨ç½² corednsã€‚ ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:11:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"10.1 ä¸‹è½½äºŒè¿›åˆ¶åŒ… kubernetes/CHANGELOG-1.24.md at master Â· kubernetes/kubernetes root@master01:/usr/local/src# ll total 489740 drwxr-xr-x 2 root root 4096 Jan 4 13:09 ./ drwxr-xr-x 13 root root 4096 Jan 1 13:20 ../ -rw-r--r-- 1 root root 30495559 Jan 4 13:09 kubernetes-client-linux-amd64.tar.gz -rw-r--r-- 1 root root 123361203 Jan 4 13:09 kubernetes-node-linux-amd64.tar.gz -rw-r--r-- 1 root root 347075448 Jan 4 13:09 kubernetes-server-linux-amd64.tar.gz -rw-r--r-- 1 root root 532769 Jan 4 13:09 kubernetes.tar.gz #è§£å‹å root@master01:/usr/local/src/kubernetes# ll total 36996 drwxr-xr-x 10 root root 4096 Dec 8 18:31 ./ drwxr-xr-x 3 root root 4096 Jan 4 13:11 ../ drwxr-xr-x 2 root root 4096 Dec 8 18:26 addons/ drwxr-xr-x 3 root root 4096 Dec 8 18:31 client/ drwxr-xr-x 9 root root 4096 Dec 8 18:31 cluster/ drwxr-xr-x 2 root root 4096 Dec 8 18:31 docs/ drwxr-xr-x 3 root root 4096 Dec 8 18:31 hack/ -rw-r--r-- 1 root root 37826576 Dec 8 18:26 kubernetes-src.tar.gz drwxr-xr-x 4 root root 4096 Dec 8 18:31 LICENSES/ drwxr-xr-x 3 root root 4096 Dec 8 18:25 node/ -rw-r--r-- 1 root root 4443 Dec 8 18:31 README.md drwxr-xr-x 3 root root 4096 Dec 8 18:31 server/ -rw-r--r-- 1 root root 8 Dec 8 18:31 version #æ’ä»¶ç›®å½• root@master01:/usr/local/src/kubernetes/cluster/addons# ll total 80 drwxr-xr-x 18 root root 4096 Dec 8 18:31 ./ drwxr-xr-x 9 root root 4096 Dec 8 18:31 ../ drwxr-xr-x 2 root root 4096 Dec 8 18:31 addon-manager/ drwxr-xr-x 3 root root 4096 Dec 8 18:31 calico-policy-controller/ drwxr-xr-x 3 root root 4096 Dec 8 18:31 cluster-loadbalancing/ drwxr-xr-x 3 root root 4096 Dec 8 18:31 device-plugins/ drwxr-xr-x 5 root root 4096 Dec 8 18:31 dns/ drwxr-xr-x 2 root root 4096 Dec 8 18:31 dns-horizontal-autoscaler/ drwxr-xr-x 4 root root 4096 Dec 8 18:31 fluentd-gcp/ drwxr-xr-x 3 root root 4096 Dec 8 18:31 ip-masq-agent/ drwxr-xr-x 2 root root 4096 Dec 8 18:31 kube-proxy/ drwxr-xr-x 3 root root 4096 Dec 8 18:31 metadata-agent/ drwxr-xr-x 3 root root 4096 Dec 8 18:31 metadata-proxy/ drwxr-xr-x 2 root root 4096 Dec 8 18:31 metrics-server/ drwxr-xr-x 5 root root 4096 Dec 8 18:31 node-problem-detector/ -rw-r--r-- 1 root root 104 Dec 8 18:31 OWNERS drwxr-xr-x 8 root root 4096 Dec 8 18:31 rbac/ -rw-r--r-- 1 root root 1655 Dec 8 18:31 README.md drwxr-xr-x 8 root root 4096 Dec 8 18:31 storage-class/ drwxr-xr-x 4 root root 4096 Dec 8 18:31 volumesnapshots/ root@master01:/usr/local/src/kubernetes/cluster/addons/dns/coredns# ll total 44 drwxr-xr-x 2 root root 4096 Dec 8 18:31 ./ drwxr-xr-x 5 root root 4096 Dec 8 18:31 ../ -rw-r--r-- 1 root root 5060 Dec 8 18:31 coredns.yaml.base -rw-r--r-- 1 root root 5110 Dec 8 18:31 coredns.yaml.in -rw-r--r-- 1 root root 5112 Dec 8 18:31 coredns.yaml.sed -rw-r--r-- 1 root root 1075 Dec 8 18:31 Makefile -rw-r--r-- 1 root root 344 Dec 8 18:31 transforms2salt.sed -rw-r--r-- 1 root root 287 Dec 8 18:31 transforms2sed.sed cp coredns.yaml.base /root/ mv /root/coredns.yaml.base /root/coredns-ceamg.yaml vim /root/coredns-ceamg.yaml","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:11:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"10.2 ä¿®æ”¹é…ç½®æ–‡ä»¶ ä¸»è¦é…ç½®å‚æ•°ï¼š error: #é”™è¯¯â½‡å¿—è¾“å‡ºåˆ°stdoutã€‚ healthï¼š #CoreDNSçš„è¿â¾çŠ¶å†µæŠ¥å‘Šä¸ºhttp://localhost:8080/health. cacheï¼š #å¯â½¤corednsç¼“å­˜ã€‚ reloadï¼š#é…ç½®â¾ƒåŠ¨é‡æ–°åŠ è½½é…ç½®â½‚ä»¶ï¼Œå¦‚æœä¿®æ”¹äº†ConfigMapçš„é…ç½®ï¼Œä¼šåœ¨ä¸¤åˆ†é’Ÿåâ½£æ•ˆ. loadbalanceï¼š#â¼€ä¸ªåŸŸåæœ‰å¤šä¸ªè®°å½•ä¼šè¢«è½®è¯¢è§£æã€‚ cache 30 #ç¼“å­˜æ—¶é—´ kubernetesï¼š#CoreDNSå°†æ ¹æ®æŒ‡å®šçš„service domainåç§°åœ¨Kubernetes SVCä¸­è¿›â¾åŸŸåè§£æã€‚ forwardï¼š #ä¸æ˜¯Kubernetesé›†ç¾¤åŸŸå†…çš„åŸŸåæŸ¥è¯¢éƒ½è¿›â¾è½¬å‘æŒ‡å®šçš„æœåŠ¡å™¨ï¼ˆ/etc/resolv.confï¼‰ prometheusï¼š#CoreDNSçš„æŒ‡æ ‡æ•°æ®å¯ä»¥é…ç½®Prometheus è®¿é—®http://coredns svc:9153/metrics è¿›â¾æ”¶é›†ã€‚ readyï¼š#å½“coredns æœåŠ¡å¯åŠ¨å®Œæˆåä¼šè¿›â¾åœ¨çŠ¶æ€ç›‘æµ‹ï¼Œä¼šæœ‰ä¸ªURL è·¯å¾„ä¸º/readyè¿”å›200çŠ¶æ€ç ï¼Œå¦åˆ™è¿”å›æŠ¥é”™ã€‚kubernetes __DNS__DOMAIN_æ˜¯ clusters/k8s-01/hosts ä¸­å¡«å†™çš„å†…å®¹CLUSTER_DNS_DOMAIN # Cluster DNS Domain CLUSTER_DNS_DOMAIN=\"ceamg.local\"212 clusterIP: __DNS__SERVER__æ˜¯clusters/k8s-01/hosts ä¸­å¡«å†™çš„å†…å®¹SERVICE_CIDR ç¬¬äºŒä¸ªIP ä¹Ÿå°±æ˜¯ 10.10.0.2 # K8S Service CIDR, not overlap with node(host) networking SERVICE_CIDR=\"10.10.0.0/16 / # cat /etc/resolv.conf search default.svc.ceamg.local svc.ceamg.local ceamg.local nameserver 10.10.0.2ä¿®æ”¹å¦‚ä¸‹è¡Œå†…å®¹ï¼š 77 kubernetes ceamg.local in-addr.arpa ip6.arpa { 83 forward . 192.168.0.15 { 142 image: harbor.ceamg.com/baseimages/coredns:v1.8.6 145 limits: 146 memory: 2048Mi 147 requests: 148 cpu: 1000m 149 memory: 1024Mi 212 clusterIP: 10.10.0.2 209 spec: 210 type: NodePort 211 selector: 212 k8s-app: kube-dns 213 clusterIP: 10.10.0.2 214 ports: 215 - name: dns 216 port: 53 217 protocol: UDP 218 - name: dns-tcp 219 port: 53 220 protocol: TCP 221 - name: metrics 222 port: 9153 223 protocol: TCP 224 targetPort: 9153 225 nodePort: 30009 æŸ¥çœ‹èµ„æºæ ¼å¼ï¼š kubectl explain ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:11:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"10.3 ä¸‹è½½é•œåƒå¹¶æ¨é€åˆ°harbor root@master01:/usr/local/src/kubernetes/cluster/addons/dns/coredns# nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.6 root@master01:/usr/local/src/kubernetes/cluster/addons/dns/coredns# nerdctl tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.6 harbor.ceamg.com/baseimages/coredns:v1.8.6 root@master01:/usr/local/src/kubernetes/cluster/addons/dns/coredns# nerdctl push harbor.ceamg.com/baseimages/coredns:v1.8.6 INFO[0000] pushing as a reduced-platform image (application/vnd.docker.distribution.manifest.list.v2+json, sha256:53011ff05d62cd740ae785a98f646ace63374073b0e564a35d4cea008f040940) ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:11:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"10.4 å®‰è£…coredns root@master01:/usr/local/src/kubernetes/cluster/addons/dns/coredns# kubectl apply -f /root/coredns-ceamg.yaml serviceaccount/coredns created clusterrole.rbac.authorization.k8s.io/system:coredns created clusterrolebinding.rbac.authorization.k8s.io/system:coredns created configmap/coredns created deployment.apps/coredns created service/kube-dns created root@master01:~# kubectl get pod -A NAMESPACE NAME READY STATUS RESTARTS AGE default net-test1 1/1 Running 0 25m default net-test2 1/1 Running 0 25m default net-test3 1/1 Running 0 25m default net-test4 1/1 Running 0 49m kube-system calico-kube-controllers-5c8bb696bb-hf2cp 1/1 Running 1 (57m ago) 151m kube-system calico-node-6nlt6 1/1 Running 0 151m kube-system calico-node-fd6rj 1/1 Running 0 151m kube-system calico-node-lhgh4 1/1 Running 0 151m kube-system coredns-6c496b89f6-hd8vf 1/1 Running 0 3s","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:11:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"10.5 å¯åŠ¨å®¹å™¨æµ‹è¯•åŸŸåè§£æ root@master01:~# kubectl exec -it net-test1 error: you must specify at least one command for the container root@master01:~# kubectl exec -it net-test1 -- sh / # / # ping www.baidu.com PING www.baidu.com (110.242.68.3): 56 data bytes 64 bytes from 110.242.68.3: seq=0 ttl=49 time=9.778 ms --- www.baidu.com ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 9.778/9.778/9.778 ms / # / # cat /etc/resolv.conf search default.svc.ceamg.local svc.ceamg.local ceamg.local nameserver 10.10.0.2 options ndots:5","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:11:5","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"10.6 æµ‹è¯• prometheus ç›‘æ§é¡¹ http://10.1.0.31:30009/metrics ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:11:6","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11. æ­¥éª¤8-å®‰è£…é›†ç¾¤æ’ä»¶-dashboard https://github.com/kubernetes/dashboard ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11.1 ä¸‹è½½å¯¹åº”kubernetesç‰ˆæœ¬çš„dashboard Compatibility Kubernetes version 1.21 1.22 1.23 1.24 Compatibility ? ? ? âœ“ âœ“ Fully supported version range. ? Due to breaking changes between Kubernetes API versions, some features might not work correctly in the Dashboard. # Copyright 2017 The Kubernetes Authors. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. apiVersion: v1 kind: Namespace metadata: name: kubernetes-dashboard --- apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard --- kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-certs namespace: kubernetes-dashboard type: Opaque --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-csrf namespace: kubernetes-dashboard type: Opaque data: csrf: \"\" --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-key-holder namespace: kubernetes-dashboard type: Opaque --- kind: ConfigMap apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-settings namespace: kubernetes-dashboard --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard rules: # Allow Dashboard to get, update and delete Dashboard exclusive secrets. - apiGroups: [\"\"] resources: [\"secrets\"] resourceNames: [\"kubernetes-dashboard-key-holder\", \"kubernetes-dashboard-certs\", \"kubernetes-dashboard-csrf\"] verbs: [\"get\", \"update\", \"delete\"] # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map. - apiGroups: [\"\"] resources: [\"configmaps\"] resourceNames: [\"kubernetes-dashboard-settings\"] verbs: [\"get\", \"update\"] # Allow Dashboard to get metrics. - apiGroups: [\"\"] resources: [\"services\"] resourceNames: [\"heapster\", \"dashboard-metrics-scraper\"] verbs: [\"proxy\"] - apiGroups: [\"\"] resources: [\"services/proxy\"] resourceNames: [\"heapster\", \"http:heapster:\", \"https:heapster:\", \"dashboard-metrics-scraper\", \"http:dashboard-metrics-scraper\"] verbs: [\"get\"] --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard rules: # Allow Metrics Scraper to get metrics from the Metrics server - apiGroups: [\"metrics.k8s.io\"] resources: [\"pods\", \"nodes\"] verbs: [\"get\", \"list\", \"watch\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: kubernetes-dashboard subjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: kubernetes-dashboard roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kubernetes-dashboard subjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard --- kind: Deployment apiVersion: apps/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: replicas: 1 revisionHis","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11.2 ä¿®æ”¹serviceæš´éœ²æ–¹å¼ 32 kind: Service 33 apiVersion: v1 34 metadata: 35 labels: 36 k8s-app: kubernetes-dashboard 37 name: kubernetes-dashboard 38 namespace: kubernetes-dashboard 39 spec: 40 type: NodePort 41 ports: 42 - port: 443 43 targetPort: 8443 44 nodePort: 30010 45 selector: 46 k8s-app: kubernetes-dashboard","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11.3 ä¸‹è½½é•œåƒæ¨é€åˆ°harbor root@master01:~# cat k8s-dashboard-ceamg.yml | grep image image: kubernetesui/dashboard:v2.6.1 imagePullPolicy: Always image: kubernetesui/metrics-scraper:v1.0.8 root@master01:~#nerdctl pull kubernetesui/dashboard:v2.6.1 root@master01:~# nerdctl pull kubernetesui/metrics-scraper:v1.0.8 root@master01:~# nerdctl tag kubernetesui/dashboard:v2.6.1 harbor.ceamg.com/baseimages/dashboard:v2.6.1 root@master01:~# nerdctl push harbor.ceamg.com/baseimages/dashboard:v2.6.1 INFO[0000] pushing as a reduced-platform image (application/vnd.docker.distribution.manifest.list.v2+json, sha256:f12df071f8bad3e1965b5246095bd3f78df0eb76ceabcc0878d42849d33e4a10) index-sha256:f12df071f8bad3e1965b5246095bd3f78df0eb76ceabcc0878d42849d33e4a10: done |++++++++++++++++++++++++++++++++++++++| manifest-sha256:d95e1adbe846450bf9451f9c95ab33865115909cf3962960af5983bb916cf320: done |++++++++++++++++++++++++++++++++++++++| config-sha256:783e2b6d87ed93a9f9fee34e84c2b029b7a9572b2f41f761437e58af9c26827f: done |++++++++++++++++++++++++++++++++++++++| elapsed: 3.2 s total: 2.5 Ki (814.0 B/s) root@master01:~# root@master01:~# nerdctl tag kubernetesui/metrics-scraper:v1.0.8 harbor.ceamg.com/baseimages/metrics-scraper:v1.0.8 root@master01:~# nerdctl push harbor.ceamg.com/baseimages/metrics-scraper:v1.0.8 INFO[0000] pushing as a reduced-platform image (application/vnd.docker.distribution.manifest.list.v2+json, sha256:9fdef455b4f9a8ee315a0aa3bd71787cfd929e759da3b4d7e65aaa56510d747b) index-sha256:9fdef455b4f9a8ee315a0aa3bd71787cfd929e759da3b4d7e65aaa56510d747b: done |++++++++++++++++++++++++++++++++++++++| manifest-sha256:43227e8286fd379ee0415a5e2156a9439c4056807e3caa38e1dd413b0644807a: done |++++++++++++++++++++++++++++++++++++++| config-sha256:115053965e86b2df4d78af78d7951b8644839d20a03820c6df59a261103315f7: done |++++++++++++++++++++++++++++++++++++++| elapsed: 0.8 s total: 2.2 Ki (2.7 KiB/s) ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11.4 ä¿®æ”¹é•œåƒåœ°å€ 195 image: harbor.ceamg.com/baseimages/dashboard:v2.6.1 280 image: harbor.ceamg.com/baseimages/metrics-scraper:v1.0.8","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11.5 å®‰è£…dashboardç»„ä»¶ kubectl apply -f k8s-dashboard-ceamg.yml","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:5","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11.6 æŸ¥çœ‹ç»„ä»¶è¿è¡ŒçŠ¶æ€ root@master01:~# kubectl get pod -A NAMESPACE NAME READY STATUS RESTARTS AGE default net-test1 1/1 Running 0 99m default net-test2 1/1 Running 0 99m default net-test3 1/1 Running 0 99m default net-test4 1/1 Running 0 123m kube-system calico-kube-controllers-5c8bb696bb-hf2cp 1/1 Running 1 (131m ago) 3h45m kube-system calico-node-6nlt6 1/1 Running 0 3h45m kube-system calico-node-fd6rj 1/1 Running 0 3h45m kube-system calico-node-lhgh4 1/1 Running 0 3h45m kube-system coredns-6c496b89f6-hd8vf 1/1 Running 0 73m kubernetes-dashboard dashboard-metrics-scraper-8b9c56ffb-tjjc4 1/1 Running 0 14s kubernetes-dashboard kubernetes-dashboard-6f9f585c48-vv2pz 1/1 Running 0 14s","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:6","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11.7 è·å–ç™»é™† token apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard root@master01:~# kubectl apply -f admin-user.yml serviceaccount/admin-user created clusterrolebinding.rbac.authorization.k8s.io/admin-user created:::warning æ³¨æ„ï¼šv1.24.0 æ›´æ–°ä¹‹åè¿›è¡Œåˆ›å»º ServiceAccount ä¸ä¼šè‡ªåŠ¨ç”Ÿæˆ Secret éœ€è¦å¯¹å…¶æ‰‹åŠ¨åˆ›å»º ::: # åˆ›å»ºtoken root@master01:~# kubectl -n kubernetes-dashboard create token admin-user --duration 604800s eyJhbGciOiJSUzI1NiIsImtpZCI6ImptTldRRDRZZVVSdXRhaU1RNUtyQmJUSmVTbW55VThqNHhLU1l6U3B4R28ifQ.eyJhdWQiOlsiYXBpIiwiaXN0aW8tY2EiXSwiZXhwIjoxNjczNDI1MDI3LCJpYXQiOjE2NzI4MjAyMjcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2YyIsImt1YmVybmV0ZXMuaW8iOnsibmFtZXNwYWNlIjoia3ViZXJuZXRlcy1kYXNoYm9hcmQiLCJzZXJ2aWNlYWNjb3VudCI6eyJuYW1lIjoiYWRtaW4tdXNlciIsInVpZCI6IjdhNTAzN2E4LTQ2MGEtNGM3YS05NWQ5LTNjM2JkNGQ0YTUyZSJ9fSwibmJmIjoxNjcyODIwMjI3LCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.ciX6c6hUe8NqPHWp7GteAecZ75L50sKL0l0jk6hETJM9xUVkE-knhm-wQWogOCq1vJMWtg_qeYqsyxfFAMbXdnGgXUXH3tuLVe0NcSHfGVa0BBfjUqODODoAcKdEWJJqdTO_QCfzHTTGkBDZoPgqjALBFzMVh_anlUdeSehRtTh6y2L0dsMRbWuEp1YI8phXumRGIbsrRDOenCycfyPh2AUEChMhD_uYS85z2tDVbno-1y4sSoSiPPn-awUEAxo-ly7zIOUz_b6ZiMhM6nGTuJ-7Jyxq4A8f2pj-iyXA_ve3g1Y4AaInd1aaZhCQ_82rOpmHP0Idyzg_lqEneltBawæ–¹å¼äºŒæ‰‹åŠ¨åˆ›å»ºsecrit root@master01:/zookeeper# kubectl apply -f secrit secret/admin-user created apiVersion: v1 kind: Secret type: kubernetes.io/service-account-token metadata: name: admin-user namespace: kubernetes-dashboard annotations: kubernetes.io/service-account.name: \"admin-user\" root@master01:/zookeeper# kubectl -n kubernetes-dashboard describe sa admin-user Name: admin-user Namespace: kubernetes-dashboard Labels: \u003cnone\u003e Annotations: \u003cnone\u003e Image pull secrets: \u003cnone\u003e Mountable secrets: \u003cnone\u003e Tokens: admin-user Events: \u003cnone\u003e root@master01:/zookeeper# kubectl -n kubernetes-dashboard describe secrets admin-user Name: admin-user Namespace: kubernetes-dashboard Labels: \u003cnone\u003e Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 7a5037a8-460a-4c7a-95d9-3c3bd4d4a52e Type: kubernetes.io/service-account-token Data ==== namespace: 20 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6ImptTldRRDRZZVVSdXRhaU1RNUtyQmJUSmVTbW55VThqNHhLU1l6U3B4R28ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI3YTUwMzdhOC00NjBhLTRjN2EtOTVkOS0zYzNiZDRkNGE1MmUiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.YIZ1UepKs7WzebxKMOVIPkmz0KLkIyV59S7D0x4sBpefqseX6lSfV_YbhDjQv0dm6ne9HJ85dHzF1-qmSJEO_EW3m-aNOfmem7jkqr8XDUIgHceeKZimauTodKvApsWWD_Flsk7r2nin-MoNkOJ5mi6g5Pu3iQuKhQINl3G9Wwch5c-5FV0l-RBWR1rw9rVby6fh1jfkAhMWGL7lWKJeAA6fE2dTJVSJ-ZhW_bzwPTTDKNhIlpRsyKEnFXwWmK9Jqoxq8y5H0iJIhbvkYCxwUG2Gjjfi6jIWhJvWo20_kTq5Cy-7BNXafBI5D6VKmFwHFyOLBQcvkntN2IpVRNcfbA ca.crt: 1302 byteshttps://blog.csdn.net/qq_41619571/article/details/127217339 ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:7","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"11.8 ç™»å½•æµ‹è¯• ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:12:8","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"12. é›†ç¾¤ç®¡ç† é›†ç¾¤ç®¡ç†ä¸»è¦æ˜¯æ·»åŠ masterã€æ·»åŠ nodeã€åˆ é™¤masterä¸åˆ é™¤nodeç­‰èŠ‚ç‚¹ç®¡ç†åŠç›‘æ§ ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:13:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"12.1 æ·»åŠ nodeèŠ‚ç‚¹ ./ezctl add-node k8s-01 10.1.0.39","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:13:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"12.2 æ·»åŠ master èŠ‚ç‚¹ root@master01:/etc/kubeasz# ./ezctl add-master k8s-01 10.1.0.30master èŠ‚ç‚¹æ·»åŠ åä¼šå‘ nodeèŠ‚ç‚¹ /etc/kube-lb/conf/kube-lb.conf ä¸­æ·»åŠ åå‘ä»£ç†èŠ‚ç‚¹ user root; worker_processes 1; error_log /etc/kube-lb/logs/error.log warn; events { worker_connections 3000; } stream { upstream backend { server 10.1.0.30:6443 max_fails=2 fail_timeout=3s; server 10.1.0.31:6443 max_fails=2 fail_timeout=3s; } server { listen 127.0.0.1:6443; proxy_connect_timeout 1s; proxy_pass backend; } }","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:13:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"12.3 éªŒè¯å½“å‰èŠ‚ç‚¹ root@master02:~# kubectl get nodes NAME STATUS ROLES AGE VERSION 10.1.0.30 Ready,SchedulingDisabled master 15m v1.24.2 10.1.0.31 Ready,SchedulingDisabled master 44h v1.24.2 10.1.0.32 Ready node 44h v1.24.2 10.1.0.33 Ready node 44h v1.24.2 root@master02:~# calicoctl node status Calico process is running. IPv4 BGP status +--------------+-------------------+-------+----------+-------------+ | PEER ADDRESS | PEER TYPE | STATE | SINCE | INFO | +--------------+-------------------+-------+----------+-------------+ | 10.1.0.31 | node-to-node mesh | up | 02:47:43 | Established | | 10.1.0.32 | node-to-node mesh | up | 02:47:12 | Established | | 10.1.0.33 | node-to-node mesh | up | 02:47:31 | Established | +--------------+-------------------+-------+----------+-------------+ IPv6 BGP status No IPv6 peers found.","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:13:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"13. é›†ç¾¤å‡çº§ å…ˆå‡çº§master ä¿è¯é›†ç¾¤ä¸­è‡³å°‘æœ‰ä¸€ä¸ªmasterèŠ‚ç‚¹å¯ç”¨ ï¼Œåœ¨nodeèŠ‚ç‚¹nginxåå‘ä»£ç†ä¸­æ³¨é‡Šæ‰è¦å‡çº§çš„masterèŠ‚ç‚¹ã€‚ ","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:14:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"13.1 å‡çº§masterèŠ‚ç‚¹ åœ¨å„ä¸ªnodeèŠ‚ç‚¹åå‘ä»£ç†é…ç½®ä¸­æ³¨é‡Šæ‰è¦å‡çº§çš„masterèŠ‚ç‚¹ vim /etc/kube-lb/conf/kube-lb.conf user root; worker_processes 1; error_log /etc/kube-lb/logs/error.log warn; events { worker_connections 3000; } stream { upstream backend { #server 10.1.0.30:6443 max_fails=2 fail_timeout=3s; server 10.1.0.31:6443 max_fails=2 fail_timeout=3s; } server { listen 127.0.0.1:6443; proxy_connect_timeout 1s; proxy_pass backend; } } #é‡å¯æœåŠ¡ root@worker01:~# systemctl restart kube-lb.servicenodeèŠ‚ç‚¹å‡çº§éœ€è¦åœæœåŠ¡ï¼Œéœ€è¦å…³é—­kubelet å’Œ kube-proxyæœåŠ¡æ›¿æ¢äºŒè¿›åˆ¶æ–‡ä»¶ kube-apiserver kube-controller-manager kubectl kubelet kube-proxy kube-scheduler å»githubæ‰¾åˆ°æƒ³è¦å‡çº§çš„ç‰ˆæœ¬ä¸‹è½½äºŒè¿›åˆ¶æ–‡ä»¶ï¼š https://github.com/kubernetes/kubernetes/releases root@master01:/usr/local/src# ll total 489744 drwxr-xr-x 3 root root 4096 Jan 4 13:11 ./ drwxr-xr-x 13 root root 4096 Jan 1 13:20 ../ drwxr-xr-x 10 root root 4096 Dec 8 18:31 kubernetes/ -rw-r--r-- 1 root root 30495559 Jan 4 13:09 kubernetes-client-linux-amd64.tar.gz -rw-r--r-- 1 root root 123361203 Jan 4 13:09 kubernetes-node-linux-amd64.tar.gz -rw-r--r-- 1 root root 347075448 Jan 4 13:09 kubernetes-server-linux-amd64.tar.gz -rw-r--r-- 1 root root 532769 Jan 4 13:09 kubernetes.tar.gzäºŒè¿›åˆ¶æ–‡ä»¶åœ¨/server/binç›®å½•ä¸‹é¢ root@master01:/usr/local/src/kubernetes/server/bin# ll -ls total 1090008 4 drwxr-xr-x 2 root root 4096 Dec 8 18:26 ./ 4 drwxr-xr-x 3 root root 4096 Dec 8 18:31 ../ 54176 -rwxr-xr-x 1 root root 55476224 Dec 8 18:26 apiextensions-apiserver* 43380 -rwxr-xr-x 1 root root 44421120 Dec 8 18:26 kubeadm* 48408 -rwxr-xr-x 1 root root 49569792 Dec 8 18:26 kube-aggregator* 123032 -rwxr-xr-x 1 root root 125980672 Dec 8 18:26 kube-apiserver* 4 -rw-r--r-- 1 root root 8 Dec 8 18:25 kube-apiserver.docker_tag 128092 -rw------- 1 root root 131165184 Dec 8 18:25 kube-apiserver.tar 112896 -rwxr-xr-x 1 root root 115605504 Dec 8 18:26 kube-controller-manager* 4 -rw-r--r-- 1 root root 8 Dec 8 18:25 kube-controller-manager.docker_tag 117960 -rw------- 1 root root 120790016 Dec 8 18:25 kube-controller-manager.tar 44680 -rwxr-xr-x 1 root root 45752320 Dec 8 18:26 kubectl* 53796 -rwxr-xr-x 1 root root 55085992 Dec 8 18:26 kubectl-convert* 113376 -rwxr-xr-x 1 root root 116095704 Dec 8 18:26 kubelet* 1452 -rwxr-xr-x 1 root root 1486848 Dec 8 18:26 kube-log-runner* 40820 -rwxr-xr-x 1 root root 41799680 Dec 8 18:26 kube-proxy* 4 -rw-r--r-- 1 root root 8 Dec 8 18:25 kube-proxy.docker_tag 109280 -rw------- 1 root root 111901184 Dec 8 18:25 kube-proxy.tar 46096 -rwxr-xr-x 1 root root 47202304 Dec 8 18:26 kube-scheduler* 4 -rw-r--r-- 1 root root 8 Dec 8 18:25 kube-scheduler.docker_tag 51160 -rw------- 1 root root 52386816 Dec 8 18:25 kube-scheduler.tar 1380 -rwxr-xr-x 1 root root 1413120 Dec 8 18:26 mounter*root@master01:/usr/local/src/kubernetes/server/bin# ./kube-apiserver --version Kubernetes v1.24.9 #å½“å‰ç‰ˆæœ¬ root@master01:/usr/local/src/kubernetes/server/bin# /etc/kubeasz/bin/kube-apiserver --version Kubernetes v1.24.2åœæ­¢æœåŠ¡ systemctl stop kube-proxy kube-controller-manager kubelet kube-scheduler kube-apiserveræ›¿æ¢äºŒè¿›åˆ¶æ–‡ä»¶ root@master01:/usr/local/src/kubernetes/server/bin# scp kube-apiserver kube-controller-manager kubelet kube-scheduler kube-proxy 10.1.0.30:/usr/local/bin kube-apiserver 100% 120MB 129.5MB/s 00:00 kube-controller-manager 100% 110MB 128.8MB/s 00:00 kubelet 100% 111MB 137.1MB/s 00:00 kube-scheduler 100% 45MB 128.5MB/s 00:00 kube-proxy 100% 40MB 132.0MB/s 00:00å¯åŠ¨æœåŠ¡ systemctl start kube-proxy kube-controller-manager kubelet kube-scheduler kube-apiserveréªŒè¯ç‰ˆæœ¬ root@master02:~# kubectl get nodes NAME STATUS ROLES AGE VERSION 10.1.0.30 Ready,SchedulingDisabled master 136m v1.24.9 10.1.0.31 Ready,SchedulingDisabled master 46h v1.24.2 10.1.0.32 Ready node 46h v1.24.2 10.1.0.33 Ready node 46h v1.24.2åœ¨å¦å¤–çš„masterèŠ‚ç‚¹ä¸Šé‡å¤ä»¥ä¸Šæ“ä½œ root@master01:/usr/local/src/kubernetes/server/bin# systemctl stop kube-proxy kube-controller-manager kubelet kube-scheduler kube-apiserver root@master01:/usr/local/src/kubernetes/server/bin# \\cp kube-apiserver kube-controller-manager kubelet kube-scheduler kube-proxy /usr/local/bin root@m","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:14:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"13.2 å‡çº§nodeèŠ‚ç‚¹ nodeèŠ‚ç‚¹åªéœ€è¦æ›¿æ¢kubelet å’Œ kube-proxy ä¸¤ä¸ª å…³é—­æœåŠ¡ root@worker01:~# systemctl stop kubelet.service kube-proxy.serviceæ›¿æ¢äºŒè¿›åˆ¶æ–‡ä»¶ root@master01:/usr/local/src/kubernetes/server/bin# scp kubelet kube-proxy 10.1.0.32:/usr/local/bin kubelet 100% 111MB 134.8MB/s 00:00 kube-proxy 100% 40MB 139.3MB/s 00:00 root@master01:/usr/local/src/kubernetes/server/bin# scp kubelet kube-proxy 10.1.0.33:/usr/local/binå¯åŠ¨æœåŠ¡ root@worker01:~# systemctl start kubelet.service kube-proxy.serviceéªŒè¯ç‰ˆæœ¬ root@master02:~# kubectl get nodes NAME STATUS ROLES AGE VERSION 10.1.0.30 Ready,SchedulingDisabled master 157m v1.24.9 10.1.0.31 Ready,SchedulingDisabled master 47h v1.24.9 10.1.0.32 Ready node 46h v1.24.9 10.1.0.33 Ready node 46h v1.24.9","date":"2023-01-06","objectID":"/posts/kubernetes/primary/kubernetes-1/:14:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥"],"title":"Kubernetes äºŒè¿›åˆ¶éƒ¨ç½² (ä¸€)","uri":"/posts/kubernetes/primary/kubernetes-1/"},{"categories":["Kubernetes"],"content":"etcdæ˜¯CoreOSå›¢é˜Ÿäº2013å¹´6æœˆå‘èµ·çš„å¼€æºé¡¹ç›®ï¼Œå®ƒçš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªé«˜å¯ç”¨çš„åˆ† å¸ƒå¼é”®å€¼(key-value)æ•°æ®åº“ã€‚etcdå†…éƒ¨é‡‡ç”¨raftåè®®ä½œä¸º-è‡´æ€§ç®—æ³•ï¼ŒetcdåŸºäºGoè¯­è¨€å®ç°ã€‚ å®˜æ–¹ç½‘ç«™ï¼šhttps://etcd.iogithubåœ°å€: https://github.com/etcd-io/etcdå®˜æ–¹ç¡¬ä»¶æ¨èï¼šhttps://etcd.io/docs/v3.4/op-guide/hardware/ ä¸ºä»€ä¹ˆk8sä½¿ç”¨etcdï¼Ÿ Etcd ç‰¹æœ‰ä¼˜åŠ¿ å®Œå…¨å¤åˆ¶: é›†ç¾¤ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½å¯ä»¥ä½¿ç”¨å®Œæ•´çš„å­˜æ¡£é«˜å¯ç”¨æ€§: Etcdå¯ç”¨äºé¿å…ç¡¬ä»¶çš„å•ç‚¹æ•…éšœæˆ–ç½‘ç»œé—®é¢˜ä¸€è‡´æ€§: æ¯æ¬¡è¯»å–éƒ½ä¼šè¿”å›è·¨å¤šä¸»æœºçš„æœ€æ–°å†™å…¥ç®€å•: åŒ…æ‹¬ä¸€ä¸ªå®šä¹‰è‰¯å¥½ã€é¢å‘ç”¨æˆ·çš„API (gRPC)å®‰å…¨: å®ç°äº†å¸¦æœ‰å¯é€‰çš„å®¢æˆ·ç«¯è¯ä¹¦èº«ä»½éªŒè¯çš„è‡ªåŠ¨åŒ–TLSå¿«é€Ÿ: æ¯ç§’10000æ¬¡å†™å…¥çš„åŸºå‡†é€Ÿåº¦å¯é : ä½¿ç”¨Raftç®—æ³•å®ç°äº†å­˜å‚¨çš„åˆç†åˆ†å¸ƒEtcdçš„å·¥ä½œåŸç† etcd å­˜å‚¨è¿™k8sæ•´ä¸ªé›†ç¾¤çš„æ•°æ®ï¼Œä¸€å®šè¦åšå¥½å®šæœŸå¤‡ä»½ å› ä¸ºetcdæ•°æ®å­˜å‚¨åœ¨ç¡¬ç›˜ä¸Šï¼Œè¯»å†™IOé€Ÿåº¦å…³ç³»ç€é›†ç¾¤ä¸­podçš„è¿è¡Œï¼Œetcdé›†ç¾¤æœ€å¥½ä½¿ç”¨å›ºæ€ç¡¬ç›˜å¹¶ä¸”å†…å­˜è¦å¤§ä¸€ç‚¹ã€‚ ä¸­é—´ä»¶ï¼š å¤åˆ¶å¼é›†ç¾¤ mysql é›†ç¾¤ zookeeper etcd redis å“¨å…µ åˆ†ç‰‡å¼ï¼š redis cluster kafka elasticsearchå¯åŠ¨è„šæœ¬å‚æ•°: root@k8s-etcd1:-# cat /etc/systemd/system/etcd. service Description=Etcd Server After=network.target After=network-online.target Wants=network-online.target Documentation=https://github.com/coreos [Service] Type=notify WorkingDirectory=/var/lib/etcd/ #æ•°æ®ä¿å­˜ç›®å½•ExecStart=/usr/local/bin/etcd \\ #äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„ --name=etcd1 \\ #å½“å‰node åç§° --cert-file=/etc/etcd/ssl/etcd.pem --key-file=/etc/etcd/ssl/etcd-key.pem --peer-cert-file=/etc/etcd/ssl/etcd.pem --peer-key-file=/etc/etcd/ssl/etcd-key.pem --trusted-ca-file=/etc/kubernetes/ssl/ca.pem --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem --initial-advertise-peer-urls=https://192.168.7.101:2380 \\ #é€šå‘Šè‡ªå·±çš„é›†ç¾¤ç«¯å£ --listen-peer-urls=https://192.168.7.101:2380 \\ #é›†ç¾¤ä¹‹é—´é€šè®¯ç«¯å£ --listen-client-urls=https://192.168.7.101:2379,http://127.0.0.1:2379 \\ #å®¢æˆ·ç«¯è®¿é—®åœ°å€ --advertise-client-urls=https://192.168.7.101:2379 \\ #é€šå‘Šè‡ªå·±çš„å®¢æˆ·ç«¯ç«¯å£ --initial-cluster-token=etcd-cluster-0 \\ #åˆ›å»ºé›†ç¾¤ä½¿ç”¨çš„tokenï¼Œä¸€ä¸ªé›†ç¾¤å†…çš„èŠ‚ç‚¹ä¿æŒä¸€è‡´ --initial-cluster=etcd1=https://192.168.7.101:2380,etcd2=https://192.168.7.102:2380,etcd3=https://192.168.7.103:2380 \\ #é›†ç¾¤æ‰€æœ‰çš„èŠ‚ç‚¹ä¿¡æ¯ --initial-cluster-state=new \\ #æ–°å»ºé›†ç¾¤çš„æ—¶å€™çš„å€¼ä¸ºnew,å¦‚æœæ˜¯å·²ç»å­˜åœ¨çš„é›†ç¾¤ä¸ºexistingã€‚ --data-dir=/var/lib/etcd #æ•°æ®ç›®å½•è·¯å¾„ Restart=on-failure RestartSec=5 LimitNOFILE=65536 [Install] WantedBy=multi-user.target","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:0:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"éªŒè¯å½“å‰etcdæ‰€æœ‰æˆå‘˜çŠ¶æ€ 1.å¿ƒè·³ä¿¡æ¯ #export NODE_IPS=\"172.31.7.101 172.31.7.102 172.31.7.103\" # for ip in ${NODE_IPS}; do ETCDCTL_API=3 /usr/local/bin/etcdctl --endpoints=https://${ip}:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem endpoint health; done2. æ˜¾ç¤ºé›†ç¾¤æˆå‘˜ä¿¡æ¯ ETCDCTL_API=3 /usr/local/bin/etcdctl --write-out=table member list --endpoints=https://172.31.7.101:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem3.ä»¥è¡¨æ ¼æ–¹å¼æ˜¾ç¤ºèŠ‚ç‚¹è¯¦ç»†çŠ¶æ€ export NODE_IPS=\"172.31.7.101 172.31.7.102 172.31.7.103\" for ip in ${NODE_IPS}; do ETCDCTL_API=3 /usr/local/bin/etcdctl --write-out=table endpoint status --endpoints=https://${ip}:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem; done","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:0:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"æŸ¥çœ‹etcdæ•°æ®ä¿¡æ¯ æŸ¥çœ‹etcdé›†ç¾¤ä¸­ä¿å­˜çš„æ•°æ® ","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:1:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"1.æŸ¥çœ‹æ‰€æœ‰key ETCDCTL_API=3 etcdctl get / --prefix --keys-only #ä»¥è·¯å¾„çš„æ–¹å¼æ‰€æœ‰keyä¿¡æ¯ #podä¿¡æ¯ ETCDCTL_API=3 etcdctl get / --prefix --keys-only | grep pod #namespaceä¿¡æ¯ ETCDCTL_API=3 etcdctl get / --prefix --keys-only | grep namespaces #æ§åˆ¶å™¨ä¿¡æ¯ ETCDCTL_API=3 etcdctl get / --prefix --keys-only | grep deployment #calicoç»„ä»¶ä¿¡æ¯ ETCDCTL_API=3 etcdctl get / --prefix --keys-only | grep calico","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:1:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"2.æŸ¥çœ‹æŒ‡å®škey root@etcd01:~# ETCDCTL_API=3 etcdctl get /calico/ipam/v2/assignment/ipv4/block/10.20.241.64-26 /calico/ipam/v2/assignment/ipv4/block/10.20.241.64-26 {\"cidr\":\"10.20.241.64/26\",\"affinity\":\"host:master01\",\"allocations\":[0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"unallocated\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],\"attributes\":[{\"handle_id\":\"ipip-tunnel-addr-master01\",\"secondary\":{\"node\":\"master01\",\"type\":\"ipipTunnelAddress\"}}],\"deleted\":false}","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:1:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"3.æŸ¥çœ‹æ‰€æœ‰calicoçš„æ•°æ® root@etcd01:~# ETCDCTL_API=3 etcdctl get /calico --keys-only --prefix | grep calico","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:1:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"etcdå¢åˆ æ”¹æŸ¥æ•°æ® #æ·»åŠ æ•°æ® root@etcd01:~# etcdctl put /name \"xin\" #æŸ¥è¯¢æ•°æ® root@etcd01:~# etcdctl get /name /name xin #ç›´æ¥è¦†ç›–å°±æ˜¯æ›´æ–°æ•°æ® root@etcd01:~# etcdctl get /name /name xxx #åˆ é™¤æ•°æ® root@etcd01:~# etcdctl del /name 1 root@etcd01:~# etcdctl get /name #åˆ é™¤pod root@etcd01:~# etcdctl del /registry/pods/default/net-test1 1 root@master02:~# kubectl get pods -A |grep net-test1 default net-test1 1/1 Running 0 24h root@master02:~# kubectl get pods -A |grep net-test1","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:1:4","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"etcdæ•°æ®watchæœºåˆ¶ åŸºäºä¸æ–­ç›‘çœ‹æ•°æ®ï¼Œå‘ç”Ÿå˜åŒ–å°±ä¸»åŠ¨è§¦å‘é€šçŸ¥å®¢æˆ·ç«¯ï¼ŒEtcd v3 çš„watchæœºåˆ¶æ”¯æŒwatchæŸä¸ªå›ºå®šçš„keyï¼Œä¹Ÿæ”¯æŒwatchä¸€ä¸ªèŒƒå›´ã€‚ åœ¨etcd node1ä¸Šwatchä¸€ä¸ªkey ï¼Œåœ¨etcdnode2ä¿®æ”¹æ•°æ®ï¼ŒéªŒè¯etcdnode1æ˜¯å¦èƒ½å¤Ÿå‘ç°æ•°æ®å˜åŒ– root@etcd02:~# etcdctl put /data/name xin123 OK root@etcd01:~# etcdctl watch /data/name PUT /data/name xin123","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:2:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"etcd æ•°æ®æ‰‹åŠ¨å¤‡ä»½ä¸æ¢å¤ WALæ˜¯write ahead logçš„ç¼©å†™ï¼Œé¡¾åæ€ä¹‰ï¼Œä¹Ÿå°±æ˜¯åœ¨æ‰§è¡ŒçœŸæ­£çš„å†™æ“ä½œä¹‹å‰å…ˆå†™ä¸€ä¸ªæ—¥å¿—ï¼Œé¢„å†™æ—¥å¿—ã€‚wal: å­˜æ”¾é¢„å†™å¼æ—¥å¿—,æœ€å¤§çš„ä½œç”¨æ˜¯è®°å½•äº†æ•´ä¸ªæ•°æ®å˜åŒ–çš„å…¨éƒ¨å†ç¨‹ã€‚åœ¨etcdä¸­ï¼Œæ‰€æœ‰æ•°æ®çš„ä¿®æ”¹åœ¨æäº¤å‰ï¼Œéƒ½è¦å…ˆå†™å…¥åˆ°WALä¸­ã€‚ ","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:3:0","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":" #V3ç‰ˆæœ¬å¤‡ä»½æ•°æ® root@etcd01:~# ETCDCTL_API=3 etcdctl snapshot save etcd-xin-0105.db {\"level\":\"info\",\"ts\":\"2023-01-05T15:15:28.192+0800\",\"caller\":\"snapshot/v3_snapshot.go:65\",\"msg\":\"created temporary db file\",\"path\":\"etcd-xin-0105.db.part\"} {\"level\":\"info\",\"ts\":\"2023-01-05T15:15:28.195+0800\",\"logger\":\"client\",\"caller\":\"v3/maintenance.go:211\",\"msg\":\"opened snapshot stream; downloading\"} {\"level\":\"info\",\"ts\":\"2023-01-05T15:15:28.195+0800\",\"caller\":\"snapshot/v3_snapshot.go:73\",\"msg\":\"fetching snapshot\",\"endpoint\":\"127.0.0.1:2379\"} {\"level\":\"info\",\"ts\":\"2023-01-05T15:15:28.227+0800\",\"logger\":\"client\",\"caller\":\"v3/maintenance.go:219\",\"msg\":\"completed snapshot read; closing\"} {\"level\":\"info\",\"ts\":\"2023-01-05T15:15:28.245+0800\",\"caller\":\"snapshot/v3_snapshot.go:88\",\"msg\":\"fetched snapshot\",\"endpoint\":\"127.0.0.1:2379\",\"size\":\"3.0 MB\",\"took\":\"now\"} {\"level\":\"info\",\"ts\":\"2023-01-05T15:15:28.245+0800\",\"caller\":\"snapshot/v3_snapshot.go:97\",\"msg\":\"saved\",\"path\":\"etcd-xin-0105.db\"} Snapshot saved at etcd-xin-0105.db #V3ç‰ˆæœ¬æ•°æ®æ¢å¤ --data-dir æ•°æ®å­˜å‚¨ç›®å½• root@etcd01:~# ETCDCTL_API=3 etcdctl snapshot restore etcd-xin-0105.db --data-dir=/tmp/etcd root@etcd01:~# mkdir /data/etcd-backup-dir/ -p root@etcd01:~# cat script.sh #!/bin/bash source /etc/profile DATE=`date +%Y-%m-%d_%H-%M-%S` ETCDCTL_API=3 /usr/local/bin/etcdctl snapshot save /data/etcd-backup-dir/etcd-snapshot-${DATE}.db 0 */12 * * * /bin/bash /root/etcd-backup.sh \u0026\u003e /dev/null","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:3:1","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"ä½¿ç”¨kubeasz å¤‡ä»½ä¸æ¢å¤æ•°æ® æ¢å¤æ•°æ®æœŸé—´master èŠ‚ç‚¹ kube-apiserver/scheduler/controller-manager æœåŠ¡ä¸å¯ç”¨ ./ezctl backup k8s-01 kubectl delete pod net-test1 ./ezctl restore k8s-01","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:3:2","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Kubernetes"],"content":"ETCD æ•°æ®æ¢å¤æµç¨‹ å½“etcdé›†ç¾¤å®•æœºæ•°é‡è¶…è¿‡é›†ç¾¤æ€»èŠ‚ç‚¹æ•°ä¸€åŠä»¥ä¸Šçš„æ—¶å€™(å¦‚æ€»æ•°ä¸ºä¸‰å°å®•æœºä¸¤å°)ï¼Œå°±ä¼šå¯¼è‡´æ•´åˆé›†ç¾¤å®•æœºï¼ŒåæœŸéœ€è¦é‡æ–°æ¢å¤æ•°æ®ï¼Œåˆ™æ¢å¤æµç¨‹å¦‚ä¸‹: æ¢å¤æœåŠ¡å™¨ç³»ç»Ÿ é‡æ–°éƒ¨ç½²ETCDé›†ç¾¤ åœæ­¢kube-apiserver/controller-manager/scheduler/kubelet/kube-proxy åœæ­¢ETCDé›†ç¾¤ å„ETCDèŠ‚ç‚¹æ¢å¤åŒä¸€ä»½å¤‡ä»½æ•°æ® å¯åŠ¨å„èŠ‚ç‚¹å¹¶éªŒè¯ETCDé›†ç¾¤ å¯åŠ¨kube-apiserver/controller-manager/scheduler/kubelet/kube-proxy éªŒè¯k8s masterçŠ¶æ€åŠpodæ•°æ® ","date":"2023-01-05","objectID":"/posts/kubernetes/primary/kubernetes-2/:3:3","tags":["k8sè¿›é˜¶è®­ç»ƒè¥","Etcd"],"title":"etcd å®¢æˆ·ç«¯ä½¿ç”¨ã€æ•°æ®å¤‡ä»½ä¸æ¢å¤ ï¼ˆäºŒï¼‰","uri":"/posts/kubernetes/primary/kubernetes-2/"},{"categories":["Ceph"],"content":"åˆ†å¸ƒå¼å­˜å‚¨ç®€ä»‹ åˆ†å¸ƒå¼å­˜å‚¨çš„æ•°æ®åˆ†ä¸ºæ•°æ®å’Œå…ƒæ•°æ®ï¼Œå…ƒæ•°æ®å³æ˜¯æ–‡ä»¶çš„å±æ€§ä¿¡æ¯(æ–‡ä»¶åã€æƒé™(å±ä¸»ã€å±ç»„)ã€å¤§å°ã€æ—¶é—´æˆ³ç­‰)ï¼Œåœ¨åˆ†å¸ƒå¼å­˜å‚¨ä¸­å½“å®¢æˆ·ç«¯æˆ–è€…åº”ç”¨ç¨‹åºäº§ç”Ÿçš„å®¢æˆ·ç«¯æ•°æ®è¢«å†™å…¥åˆ°åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿçš„æ—¶å€™,ä¼šæœ‰ä¸€ä¸ªæœåŠ¡(Name Node)æä¾›æ–‡ä»¶å…ƒæ•°æ®çš„è·¯ç”±åŠŸèƒ½ï¼Œå‘Šè¯‰åº”ç”¨ç¨‹åºå»å“ªä¸ªæœåŠ¡å™¨å»è¯·æ±‚æ–‡ä»¶å†…å®¹ï¼Œç„¶åå†æœ‰(Data Node)æä¾›æ•°æ®çš„è¯»å†™è¯·æ±‚åŠæ•°æ®çš„é«˜å¯ç”¨åŠŸèƒ½ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:1:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"1. Ceph æ¦‚è¿° Ceph æ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿï¼ŒåŒæ—¶æ”¯æŒå¯¹è±¡å­˜å‚¨ã€å—è®¾å¤‡ã€æ–‡ä»¶ç³»ç»Ÿã€‚ Ceph æ˜¯ä¸€ä¸ªå¯¹è±¡(object)å¼å­˜å‚¨ç³»ç»Ÿï¼Œå®ƒæŠŠæ¯ä¸€ä¸ªå¾…ç®¡ç†çš„æ•°æ®æµ(æ–‡ä»¶ç­‰æ•°æ®)åˆ‡åˆ†ä¸ºä¸€åˆ°å¤šä¸ªå›ºå®šå¤§å°(é»˜è®¤ 4 å…†)çš„å¯¹è±¡æ•°æ®ï¼Œå¹¶ä»¥å…¶ä¸ºåŸå­å•å…ƒ(åŸå­æ˜¯æ„æˆå…ƒç´ çš„æœ€å°å•å…ƒ)å®Œæˆæ•°æ®çš„è¯»å†™ã€‚ å¯¹è±¡æ•°æ®çš„åº•å±‚å­˜å‚¨æœåŠ¡æ˜¯ç”±å¤šä¸ªå­˜å‚¨ä¸»æœº(host)ç»„æˆçš„å­˜å‚¨é›†ç¾¤ï¼Œè¯¥é›†ç¾¤ä¹Ÿè¢«ç§°ä¹‹ä¸ºRADOS(reliable automatic distributed obiect store)å­˜å‚¨é›†ç¾¤ï¼Œå³å¯é çš„ã€è‡ªåŠ¨åŒ–çš„ã€åˆ†å¸ƒå¼çš„å¯¹è±¡å­˜å‚¨ç³»ç»Ÿã€‚ LibRADOS æ˜¯ RADOS å­˜å‚¨é›†ç¾¤çš„ APIï¼Œæ”¯æŒ C/C++/JAVA/python/ruby/php ç­‰ç¼–ç¨‹è¯­è¨€å®¢æˆ·ç«¯ã€‚ å¦‚æœæ¯å°æœåŠ¡å™¨ä¸Šæœ‰4å—ç£ç›˜ï¼Œé‚£ä¹ˆå°±ä¼šè‡ªåŠ¨å¯åŠ¨å››ä¸ªOSDè¿›ç¨‹ã€‚å¹¶ä¸”ä¸€å—ç£ç›˜å¯ä»¥ç”¨äºå¤šä¸ªOSDå­˜å‚¨æ± ã€‚ ä¸ºä½•è¦ç”¨Ceph? é«˜æ€§èƒ½ : æ‘’å¼ƒäº†ä¼ ç»Ÿçš„é›†ä¸­å¼å­˜å‚¨å…ƒæ•°æ®å¯»å€çš„æ–¹æ¡ˆï¼Œé‡‡ç”¨CRUSHç®—æ³•ï¼Œæ•°æ®åˆ†å¸ƒå‡è¡¡ï¼Œå¹¶è¡Œåº¦é«˜ã€‚ è€ƒè™‘äº†å®¹ç¾çš„éš”ç¦»ï¼Œèƒ½å¤Ÿå®ç°å„ç±»è´Ÿè½½çš„å‰¯æœ¬æ”¾ç½®è§„åˆ™ï¼Œä¾‹å¦‚è·¨æœºæˆ¿ã€æœºæ¶æ„ŸçŸ¥ç­‰ã€‚ èƒ½å¤Ÿæ”¯æŒä¸Šåƒä¸ªå­˜å‚¨èŠ‚ç‚¹çš„è§„æ¨¡ï¼Œæ”¯æŒTBåˆ°PBçº§çš„æ•°æ®ã€‚ é«˜å¯ç”¨ : å‰¯æœ¬æ•°å¯ä»¥çµæ´»æ§åˆ¶ æ”¯æŒæ•…éšœåŸŸåˆ†éš”ï¼Œæ•°æ®å¼ºä¸€ç›´æ€§ å¤šæ•…éšœåœºæ™¯è‡ªåŠ¨è¿›è¡Œä¿®å¤è‡ªæ„ˆ æ²¡æœ‰å•ç‚¹æ•…éšœï¼Œè‡ªåŠ¨ç®¡ç†ï¼Œé«˜å¯æ‰©å±•æ€§ å»ä¸­å¿ƒåŒ– : æ‰©å±•çµæ´» éšç€èŠ‚ç‚¹å¢åŠ è€Œçº¿æ€§å¢é•¿ ç‰¹æ€§ä¸°å¯Œ : æ”¯æŒä¸‰ç§å­˜å‚¨æ¥å£ : å—å­˜å‚¨ã€æ–‡ä»¶å­˜å‚¨ã€å¯¹è±¡å­˜å‚¨ æ”¯æŒè‡ªå®šä¹‰æ¥å£ï¼Œæ”¯æŒå¤šç§è¯­è¨€é©±åŠ¨ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:2:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"1.1 Ceph çš„å‘å±•å² Ceph é¡¹ç›®èµ·æºäº äº2003 å¹´åœ¨åŠ å·å¤§å­¦åœ£å…‹é²å…¹åˆ†æ ¡æ”»è¯»åšå£«æœŸé—´çš„ç ”ç©¶è¯¾é¢˜ (Lustre ç¯å¢ƒä¸­çš„å¯æ‰©å±•é—®é¢˜)ã€‚ Lustre æ˜¯ä¸€ç§å¹³è¡Œåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ,æ—©åœ¨ 1999 å¹´ï¼Œç”±çš®ç‰¹Â·å¸ƒæ‹‰å§†(Peter Braam)åˆ›å»ºçš„é›†ç¾¤æ–‡ä»¶ç³»ç»Ÿå…¬å¸(Cluster File Systems inc)å¼€å§‹ç ”å‘,å¹¶äº2003 å¹´å‘å¸ƒ Lustre 1.0 ç‰ˆæœ¬ã€‚ 2007 å¹´ Sage Weil(å¡å¥‡Â·å¨å°”)æ¯•ä¸šåï¼ŒSage Weil ç»§ç»­å…¨èŒä»äº‹ Ceph å·¥ä½œ , 2010 å¹´3æœˆ19 æ—¥ï¼ŒLinus Torvalds å°† Ceph å®¢æˆ·ç«¯åˆå¹¶åˆ° 2010 å¹´5æœˆ16 æ—¥å‘å¸ƒçš„ Linux å†…æ ¸ç‰ˆæœ¬ 2.6.34, 2012å¹´Sage Weil åˆ›å»ºäº†Inktank Storage ç”¨äºä¸º Ceph æä¾›ä¸“ä¸šæœåŠ¡å’Œæ”¯æŒ,2014å¹´4æœˆRedhat ä»¥1.75äº¿ç¾å…ƒæ”¶è´­inktank å…¬å¸å¹¶å¼€æºã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:2:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"1.2 Ceph çš„è®¾è®¡æ€æƒ³ Ceph çš„è®¾è®¡æ—¨åœ¨å®ç°ä»¥ä¸‹ç›®æ ‡: æ¯ä¸€ç»„ä»¶çš†å¯æ‰©å±•ã€‚ æ— å•ç‚¹æ•…éšœã€‚ åŸºäºè½¯ä»¶(è€Œéä¸“ç”¨è®¾å¤‡)å¹¶ä¸”å¼€æº(æ— ä¾›åº”å•†é”å®š)åœ¨ç°æœ‰çš„å»‰ä»·ç¡¬ä»¶ä¸Šè¿è¡Œã€‚ å°½å¯èƒ½è‡ªåŠ¨ç®¡ç†ï¼Œå‡å°‘ç”¨æˆ·å¹²é¢„ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:2:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"1.3 Cephçš„ç‰ˆæœ¬å†å² Ceph çš„ç¬¬ä¸€ä¸ªç‰ˆæœ¬æ˜¯ 0.1,å‘å¸ƒç›®æœŸä¸º 2008 å¹´1æœˆ,å¤šå¹´æ¥ Ceph çš„ç‰ˆæœ¬å·ä¸€ç›´é‡‡ç”¨é€’å½’æ›´æ–°çš„æ–¹å¼æ²¡å˜ç›´åˆ° 2015 å¹´4æœˆ 0.941(Hammer çš„ç¬¬ä¸€ä¸ªä¿®æ­£ç‰ˆ)å‘å¸ƒå,ä¸ºäº†é¿å…0.99(ä»¥åŠ0.100 æˆ– 1.00),åæœŸçš„å‘½åæ–¹å¼å‘ç”Ÿäº†æ”¹å˜: x.0.z- å¼€å‘ç‰ˆ (ç»™æ—©æœŸæµ‹è¯•è€…å’Œå‹‡å£«ä»¬) x.1.z - å€™é€‰ç‰ˆ (ç”¨äºæµ‹è¯•é›†ç¾¤ã€é«˜æ‰‹ä»¬) x.2.z- ç¨³å®šã€ä¿®æ­£ç‰ˆ (ç»™ç”¨æˆ·ä»¬) xå°†ä»9 ç®—èµ·å®ƒä»£è¡¨ Infernalis(é¦–å­—æ¯Iæ˜¯è‹±æ–‡å•è¯ä¸­çš„ç¬¬ä¹ä¸ªå­—æ¯),è¿™æ ·æˆ‘ä»¬ç¬¬ä¹ä¸ªå‘å¸ƒå‘¨æœŸçš„ç¬¬ä¸€ä¸ªå¼€å‘ç‰ˆå°±æ˜¯ 9.0.0,åç»­çš„å¼€å‘ç‰ˆä¾æ¬¡æ˜¯ 9.0.0-\u003e9.0.1-\u003e9.0.2 ç­‰,æµ‹è¯•ç‰ˆæœ¬å°±æ˜¯9.1.0-\u003e9.1.1-\u003e9.1.2,ç¨³å®šç‰ˆæœ¬å°±æ˜¯9.2.0-\u003e9.2.1-\u003e9.2.2ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:2:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"2. Ceph é›†ç¾¤è§’è‰²å®šä¹‰ ä¸€ä¸ªCephé›†ç¾¤çš„ç»„æˆéƒ¨åˆ†ï¼š è‹¥å¹²çš„ Ceph OSD(å¯¹è±¡å­˜å‚¨å®ˆæŠ¤ç¨‹åº) è‡³å°‘éœ€è¦ä¸€ä¸ª Ceph Monitors ç›‘è§†å™¨ (1,3,5,7â€¦) ä¸¤ä¸ªæˆ–ä»¥ä¸Šçš„Cephç®¡ç†å™¨managers,è¿è¡ŒCephæ–‡ä»¶ç³»ç»Ÿå®¢æˆ·ç«¯æ—¶,è¿˜éœ€è¦é«˜å¯ç”¨çš„Ceph Metadata Server(æ–‡ä»¶ç³»ç»Ÿå…ƒæ•°æ®æœåŠ¡å™¨) RADOS cluster:ç”±å¤šå°host å­˜å‚¨æœåŠ¡å™¨ç»„æˆçš„Ceph é›†ç¾¤ OSD(Object Storage Daemon)ï¼šæ¯å°å­˜å‚¨æœåŠ¡å™¨çš„ç£ç›˜ç»„æˆçš„å­˜å‚¨ç©ºé—´ Mon(Monitor)ï¼šCeph çš„ç›‘è§†å™¨,ç»´æŠ¤OSD å’ŒPG çš„é›†ç¾¤çŠ¶æ€ï¼Œä¸€ä¸ªCeph é›†ç¾¤è‡³å°‘è¦æœ‰ä¸€ä¸ªmonï¼Œå¯ä»¥æ˜¯ä¸€ä¸‰äº”ä¸ƒç­‰ç­‰è¿™æ ·çš„å¥‡æ•°ä¸ªã€‚ Mgr(Manager)ï¼šè´Ÿè´£è·Ÿè¸ªè¿è¡Œæ—¶æŒ‡æ ‡å’ŒCeph é›†ç¾¤çš„å½“å‰çŠ¶æ€ï¼ŒåŒ…æ‹¬å­˜å‚¨åˆ©ç”¨ç‡ï¼Œå½“å‰æ€§ èƒ½æŒ‡æ ‡å’Œç³»ç»Ÿè´Ÿè½½ç­‰ã€‚ Ceph OSDs: Ceph OSD å®ˆæŠ¤è¿›ç¨‹ ï¼ˆCeph OSDï¼‰çš„åŠŸèƒ½æ˜¯å­˜å‚¨æ•°æ®ï¼Œå¤„ç†æ•°æ®çš„å¤åˆ¶ã€æ¢å¤ã€å›å¡«ã€åœ¨å‡è¡¡ï¼Œå¹¶é€šè¿‡æŸ¥å…¶OSD å®ˆæŠ¤è¿›ç¨‹çš„å¿ƒè·³æ¥å‘Ceph Monitors æä¾›ä¸€äº›ç›‘æ§ä¿¡æ¯ã€‚å½“Cephå­˜å‚¨é›†ç¾¤è®¾å®šä¸º2ä¸ªå‰¯æœ¬æ—¶ï¼Œè‡³å°‘éœ€è¦2ä¸ªOSDå®ˆæŠ¤è¿›ç¨‹ã€‚è¿™æ ·é›†ç¾¤æ‰èƒ½è¾¾åˆ° active+clean çŠ¶æ€(Ceph é»˜è®¤æœ‰3ä¸ªå‰¯æœ¬ï¼Œä½†ä½ å¯ä»¥è°ƒæ•´å‰¯æœ¬æ•°)ã€‚ Monitors: Ceph Monitor ç»´æŠ¤ç€å±•ç¤ºé›†ç¾¤çŠ¶æ€çš„å„ç§å›¾è¡¨ã€åŒ…æ‹¬ç›‘è§†å›¾ã€OSDå›¾ã€å½’ç½®ç»„ï¼ˆPGï¼‰å›¾ã€å’ŒCRUSHå›¾ã€‚Cephä¿å­˜ç€å‘ç”Ÿåœ¨Monitorsã€OSDå’ŒPGä¸Šçš„æ¯ä¸€æ¬¡çŠ¶æ€å˜æ›´çš„å†å²è®°å½•ä¿¡æ¯ï¼ˆç§°ä¸ºepochï¼‰ã€‚ MDSs: Cephå…ƒæ•°æ®æœåŠ¡å™¨ï¼ˆMDSï¼‰ä¸ºCephæ–‡ä»¶ç³»ç»Ÿå­˜å‚¨å…ƒæ•°æ®ï¼ˆä¹Ÿå°±æ˜¯è¯´ï¼ŒCephå—è®¾å¤‡å’ŒCephå¯¹è±¡å­˜å‚¨ä¸ä½¿ç”¨MDSï¼‰ã€‚å…ƒæ•°æ®æœåŠ¡å™¨ä½¿å¾—POSIXæ–‡ä»¶ç³»ç»Ÿçš„ç”¨æˆ·ä»¬ï¼Œå¯ä»¥åœ¨ä¸å¯¹ Ceph å­˜å‚¨é›†ç¾¤é€ æˆè´Ÿæ‹…çš„å‰æä¸‹ï¼Œæ‰§è¡Œè¯¸å¦‚ lsã€find ç­‰åŸºæœ¬å‘½ä»¤ã€‚ CephæŠŠå®¢æˆ·ç«¯æ•°æ®ä¿å­˜ä¸ºå­˜å‚¨æ± å†…çš„å¯¹è±¡ã€‚é€šè¿‡ä½¿ç”¨CRUSHç®—æ³•ï¼ŒCephå¯ä»¥è®¡ç®—å‡ºå“ªä¸ªå½’ç½®ç»„ï¼ˆPGï¼‰åº”è¯¥æŒæœ‰æŒ‡å®šçš„å¯¹è±¡(Object)ï¼Œç„¶åè¿›ä¸€æ­¥è®¡ç®—å‡ºå“ªä¸ªOSDå®ˆæŠ¤è¿›ç¨‹æŒæœ‰è¯¥å½’ç½®ç»„ã€‚CRUSHç®—æ³•ä½¿å¾—Cephå­˜å‚¨é›†ç¾¤èƒ½å¤ŸåŠ¨æ€åœ°ä¼¸ç¼©ã€å†å‡è¡¡å’Œä¿®å¤ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:3:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"2.1 Monitor(Ceph-mon) Ceph ç›‘è§†å™¨ åœ¨ä¸€ä¸ªä¸»æœºä¸Šè¿è¡Œçš„ä¸€ä¸ªå®ˆæŠ¤è¿›ç¨‹ï¼Œç”¨äºç»´æŠ¤é›†ç¾¤çŠ¶æ€æ˜ å°„(maintains maps of the cluster state)ï¼Œæ¯”å¦‚Ceph é›†ç¾¤ä¸­æœ‰å¤šå°‘å­˜å‚¨æ± ã€æ¯ä¸ªå­˜å‚¨æ± æœ‰å¤šå°‘PG ä»¥åŠå­˜å‚¨æ± å’ŒPGçš„æ˜ å°„å…³ç³»ç­‰ï¼Œ monitor map, manager map, the OSD map, the MDS map, and the CRUSH mapï¼Œè¿™äº›æ˜ å°„æ˜¯Ceph å®ˆæŠ¤ç¨‹åºç›¸äº’åè°ƒæ‰€éœ€çš„å…³é”®ç¾¤é›†çŠ¶æ€ï¼Œæ­¤å¤–ç›‘è§†å™¨è¿˜è´Ÿè´£ç®¡ç†å®ˆæŠ¤ç¨‹åºå’Œå®¢æˆ·ç«¯ä¹‹é—´çš„èº«ä»½éªŒè¯(è®¤è¯ä½¿ç”¨CephX åè®®)ã€‚é€šå¸¸è‡³å°‘éœ€è¦ä¸‰ä¸ªç›‘è§†å™¨æ‰èƒ½å®ç°å†—ä½™å’Œé«˜å¯ç”¨æ€§ã€‚ ç›‘è§†å™¨ï¼Œç»´æŠ¤é›†ç¾¤çŠ¶æ€çš„å¤šç§æ˜ å°„ï¼ŒåŒæ—¶æä¾›è®¤è¯å’Œæ—¥å¿—è®°å½•æœåŠ¡ï¼ŒåŒ…æ‹¬æœ‰å…³monitor èŠ‚ç‚¹ç«¯åˆ°ç«¯çš„ä¿¡æ¯ï¼Œå…¶ä¸­åŒ…æ‹¬ Ceph é›†ç¾¤IDï¼Œç›‘æ§ä¸»æœºåå’ŒIPä»¥åŠç«¯å£ã€‚ å¹¶ä¸”å­˜å‚¨å½“å‰ç‰ˆæœ¬ä¿¡æ¯ä»¥åŠæœ€æ–°æ›´æ”¹ä¿¡æ¯ï¼Œé€šè¿‡ â€œCeph mon dump\"æŸ¥çœ‹ monitor mapã€‚ Ceph osd unset noout #é‡å¯æœåŠ¡å™¨ä¸è¸¢å‡ºç£ç›˜ï¼Œé‡å¯å‰è®¾ç½® Ceph -s ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:3:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"2.2 Managers(Ceph-mgr)çš„åŠŸèƒ½ï¼š åœ¨ä¸€ä¸ªä¸»æœºä¸Šè¿è¡Œçš„ä¸€ä¸ªå®ˆæŠ¤è¿›ç¨‹ï¼ŒCeph Manager å®ˆæŠ¤ç¨‹åºï¼ˆCeph-mgrï¼‰è´Ÿè´£è·Ÿè¸ªè¿è¡Œæ—¶æŒ‡æ ‡å’ŒCeph é›†ç¾¤çš„å½“å‰çŠ¶æ€ï¼ŒåŒ…æ‹¬å­˜å‚¨åˆ©ç”¨ç‡ï¼Œå½“å‰æ€§èƒ½æŒ‡æ ‡å’Œç³»ç»Ÿè´Ÿè½½ã€‚Ceph Manager å®ˆæŠ¤ç¨‹åºè¿˜æ‰˜ç®¡åŸºäºpython çš„æ¨¡å—æ¥ç®¡ç†å’Œå…¬å¼€Ceph é›†ç¾¤ä¿¡æ¯ï¼ŒåŒ…æ‹¬åŸºäºWebçš„Ceph ä»ªè¡¨æ¿å’ŒREST APIã€‚ é«˜å¯ç”¨æ€§é€šå¸¸è‡³å°‘éœ€è¦ä¸¤ä¸ªç®¡ç†å™¨ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:3:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"2.3 Ceph OSDs(å¯¹è±¡å­˜å‚¨å®ˆæŠ¤ç¨‹åºCeph-osd) å³å¯¹è±¡å­˜å‚¨å®ˆæŠ¤ç¨‹åºï¼Œä½†æ˜¯å®ƒå¹¶éé’ˆå¯¹å¯¹è±¡å­˜å‚¨ã€‚æä¾›å­˜å‚¨æ•°æ®ï¼Œæ“ä½œç³»ç»Ÿä¸Šçš„ä¸€ä¸ªç£ç›˜å°±æ˜¯ä¸€ä¸ªOSD å®ˆæŠ¤ç¨‹åºã€‚ æ˜¯ç‰©ç†ç£ç›˜é©±åŠ¨å™¨ï¼Œå°†æ•°æ®ä»¥å¯¹è±¡çš„å½¢å¼å­˜å‚¨åˆ°é›†ç¾¤ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹çš„ç‰©ç†ç£ç›˜ä¸Šã€‚ OSDè´Ÿè´£å­˜å‚¨æ•°æ®ã€å¤„ç†æ•°æ®å¤åˆ¶ã€æ¢å¤ã€å›ï¼ˆBackfillingï¼‰ã€å†å¹³è¡¡ã€‚å®Œæˆå­˜å‚¨æ•°æ®çš„å·¥ä½œç»å¤§å¤šæ•°æ˜¯ç”± OSD daemon è¿›ç¨‹å®ç°ã€‚ åœ¨æ„å»º Ceph OSDçš„æ—¶å€™ï¼Œå»ºè®®é‡‡ç”¨SSD ç£ç›˜ä»¥åŠxfsæ–‡ä»¶ç³»ç»Ÿæ¥æ ¼å¼åŒ–åˆ†åŒºã€‚ æ­¤å¤–OSDè¿˜å¯¹å…¶å®ƒOSDè¿›è¡Œå¿ƒè·³æ£€æµ‹ï¼Œæ£€æµ‹ç»“æœæ±‡æŠ¥ç»™Monitorã€‚ é€šå¸¸è‡³å°‘éœ€è¦3 ä¸ªCeph OSD æ‰èƒ½å®ç°å†—ä½™å’Œé«˜å¯ç”¨æ€§ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:3:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"2.4 MDS(Ceph å…ƒæ•°æ®æœåŠ¡å™¨Ceph-mds) Ceph å…ƒæ•°æ®ï¼Œä¸»è¦ä¿å­˜çš„æ˜¯Cephæ–‡ä»¶ç³»ç»Ÿ(NFS/CIFS)çš„å…ƒæ•°æ®ã€‚ æ³¨æ„ï¼šCephçš„å—å­˜å‚¨å’ŒCephå¯¹è±¡å­˜å‚¨éƒ½ä¸éœ€è¦MDSã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:3:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"2.5 Ceph çš„ç®¡ç†èŠ‚ç‚¹ 1.Ceph çš„å¸¸ç”¨ç®¡ç†æ¥å£æ˜¯ä¸€ç»„å‘½ä»¤è¡Œå·¥å…·ç¨‹åºï¼Œä¾‹å¦‚radosã€Cephã€rbd ç­‰å‘½ä»¤ï¼ŒCeph ç®¡ç†å‘˜å¯ä»¥ä»æŸä¸ªç‰¹å®šçš„Ceph-mon èŠ‚ç‚¹æ‰§è¡Œç®¡ç†æ“ä½œã€‚ 2.æ¨èä½¿ç”¨éƒ¨ç½²ä¸“ç”¨çš„ç®¡ç†èŠ‚ç‚¹å¯¹Ceph è¿›è¡Œé…ç½®ç®¡ç†ã€å‡çº§ä¸åæœŸç»´æŠ¤ï¼Œæ–¹ä¾¿åæœŸæƒé™ç®¡ç†ï¼Œç®¡ç†èŠ‚ç‚¹çš„æƒé™åªå¯¹ç®¡ç†äººå‘˜å¼€æ”¾ï¼Œå¯ä»¥é¿å…ä¸€äº›ä¸å¿…è¦çš„è¯¯æ“ä½œçš„å‘ç”Ÿã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:3:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"3.Cephçš„é€»è¾‘æ¶æ„ pool å­˜å‚¨æ± ã€åˆ†åŒºï¼Œå­˜å‚¨æ± çš„å¤§å°å–å†³äºåº•å±‚çš„å­˜å‚¨ç©ºé—´,æˆ‘ä»¬åœ¨åˆ›å»ºpoolå­˜å‚¨æ± æ—¶éœ€è¦æŒ‡å®špgçš„ä¸ªæ•°ï¼Œæ¥åˆ›å»ºpgã€‚åˆ›å»ºpgéœ€è¦ç”¨åˆ°crushç®—æ³•ï¼Œcrushç®—æ³•å†³å®šäº†pgä¸osd daemonçš„å¯¹åº”å…³ç³»ï¼Œæ‰€ä»¥è¯´ï¼Œåœ¨å®¢æˆ·ç«¯å¾€cephä¸­å†™å…¥æ•°æ®ä¹‹å‰ï¼Œpgä¸osd daemonçš„å¯¹åº”å…³ç³»æ˜¯å·²ç»ç¡®å®šçš„ã€‚è™½ç„¶æ˜¯ç¡®å®šçš„ï¼Œä½†æ˜¯pgä¸osd daemonçš„å¯¹åº”å…³ç³»æ˜¯åŠ¨æ€çš„ã€‚ PG(placement group) pgæ˜¯cephä¸­åˆ†é…æ•°æ®çš„æœ€å°å•ä½ï¼Œä¸€ä¸ªpgå†…åŒ…å«å¤šä¸ªosd daemonï¼Œä¸€ä¸ªpool ä¸­æœ‰å¤šå°‘ä¸ªPG å¯ä»¥é€šè¿‡å…¬å¼è®¡ç®—ã€‚ OSD(Object Storage Daemon,å¯¹è±¡å­˜å‚¨è®¾å¤‡) : æ¯ä¸€å—ç£ç›˜éƒ½æ˜¯ä¸€ä¸ªosdï¼Œä¸€ä¸ªä¸»æœºç”±ä¸€ä¸ªæˆ–å¤šä¸ªosd ç»„æˆã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:4:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"3.1 poolå­˜å‚¨æ± è¯¦è§£ Cephçš„poolæœ‰å››å¤§å±æ€§ æ‰€æœ‰æ€§å’Œè®¿é—®æƒé™ å¯¹è±¡å‰¯æœ¬æ•°ç›®ï¼Œé»˜è®¤poolæ± ä¸­çš„ä¸€ä¸ªpgåªåŒ…å«ä¸¤ä¸ªosd daemonï¼Œå³ä¸€ä»½æ•°æ®äº¤ç»™pgåä¼šå­˜ä¸‹2ä¸ªå‰¯æœ¬ï¼Œç”Ÿäº§ç¯å¢ƒæ¨èè®¾ç½®ä¸º3ä¸ªå‰¯æœ¬ã€‚ pgæ•°ç›®ï¼Œpgæ˜¯poolçš„å­˜å‚¨å•ä½ï¼Œpoolçš„å­˜å‚¨ç©ºé—´å°±ç”±pgç»„æˆ crushè§„åˆ™é›†åˆã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:4:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"3.2 pg æ•°ä¸osd daemonä¹‹é—´å¯¹åº”å…³ç³»çš„å½±å“ åˆ›å»ºpoolæ—¶éœ€è¦ç¡®å®šå…¶pgçš„æ•°ç›®ï¼Œåœ¨poolè¢«åˆ›å»ºåä¹Ÿå¯ä»¥è°ƒæ•´è¯¥æ•°å­—ï¼Œä½†æ˜¯å¢åŠ æ± ä¸­çš„pgæ•°æ˜¯å½±å“cephé›†ç¾¤çš„é‡å¤§äº‹ä»¶ä¹‹ä¸€ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é¿å…è¿™ä¹ˆåšã€‚å› ä¸ºpoolä¸­çš„pgçš„æ•°ç›®ä¼šå½±å“åˆ°ï¼š æ•°æ®çš„å‡åŒ€åˆ†å¸ƒæ€§ èµ„æºæ¶ˆè€—ï¼špgä½œä¸ºä¸€ä¸ªé€»è¾‘å®ä½“ï¼Œå®ƒéœ€è¦æ¶ˆè€—ä¸€å®šçš„èµ„æºï¼ŒåŒ…æ‹¬å†…å­˜ï¼ŒCPUå’Œå¸¦å®½ï¼Œå¤ªå¤šçš„pgçš„è¯ï¼Œåˆ™å ç”¨èµ„æºä¼šè¿‡å¤š æ¸…ç†æ—¶é—´ï¼šCephçš„æ¸…ç†å·¥ä½œæ˜¯ä»¥pgä¸ºå•ä½è¿›è¡Œçš„ã€‚å¦‚æœä¸€ä¸ªpgå†…çš„æ•°æ®å¤ªå¤šï¼Œåˆ™å…¶æ¸…ç†æ—¶é—´ä¼šå¾ˆé•¿ æ•°æ®çš„æŒä¹…æ€§ï¼špoolä¸­çš„pgä¸ªæ•°åº”è¯¥éšç€osd daemonçš„å¢å¤šè€Œå¢å¤šï¼Œè¿™æ ·crushç®—æ³•å¯ä»¥å°†pgå’Œosdçš„å¯¹åº”å…³ç³»å°½é‡å‡åŒ€ä¸€äº›ï¼Œé™ä½åŒä¸€ä¸ªosdå±äºå¾ˆå¤šä¸ªpgçš„å‡ ç‡ï¼Œå¦‚æœä¸€ä¸ªosdçœŸçš„å±äºå¾ˆå¤šå¾ˆå¤špgï¼Œè¿™æ ·å¯èƒ½ä¼šå¾ˆç³Ÿç³•ï¼Œå¯èƒ½ä¼šå‡ºç°å¦‚ä¸‹æƒ…å†µï¼š å‡è®¾æˆ‘ä»¬poolå‰¯æœ¬çš„sizeä¸º3ï¼Œåˆ™è¡¨ç¤ºæ¯ä¸€ä¸ªpgå°†æ•°æ®å­˜æ”¾åœ¨3ä¸ªosdä¸Šã€‚ä¸€æ—¦æŸä¸ªosd daemonæŒ‚æ‰ï¼Œå› ä¸ºä¸€ä¸ªosd daemonåŒæ—¶å±äºå¾ˆå¤šä¸ªpgï¼Œåˆ™æ­¤æ—¶ä¼šå‡ºç°å¾ˆå¤špgåªæœ‰2ä¸ªå‰¯æœ¬çš„æƒ…å†µï¼Œè¿™ä¸ªæ—¶å€™é€šè¿‡crushç®—æ³•å¼€å§‹è¿›è¡Œæ•°æ®æ¢å¤ã€‚åœ¨æ•°æ®æ¢å¤çš„è¿‡ç¨‹ä¸­ï¼Œå› ä¸ºæ•°æ®é‡è¿‡å¤§ï¼Œåˆæœ‰ä¸€ä¸ªosd daemon(ä¹Ÿå±äºå¾ˆå¤šå¾ˆå¤špg)æ‰›ä¸ä½å‹åŠ›ä¹Ÿå´©æºƒæ‰äº†ï¼Œé‚£ä¹ˆå°†ä¼šæœ‰ä¸€éƒ¨åˆ†pgåªæœ‰ä¸€ä¸ªå‰¯æœ¬ã€‚è¿™ä¸ªæ—¶å€™é€šè¿‡crushç®—æ³•å†æ¬¡å¼€å§‹è¿›è¡Œæ•°æ®æ¢å¤ï¼Œæƒ…å†µç»§ç»­æ¶åŒ–ï¼Œå¦‚æœå†æœ‰ç¬¬ä¸‰ä¸ªosd daemonæŒ‚æ‰ï¼Œé‚£ä¹ˆå°±å¯èƒ½ä¼šå‡ºç°éƒ¨åˆ†æ•°æ®çš„ä¸¢å¤±ã€‚ç”±æ­¤å¯è§ï¼Œosd daemonä¸Šçš„pgç»„æ•°ç›®: ä¸èƒ½è¿‡å°ï¼Œè¿‡å°åˆ™æ•°æ®åˆ†å¸ƒä¸å‡åŒ€\rä¸èƒ½è¿‡å¤§ï¼Œè¿‡å¤§åˆ™ä¸€ä¸ªosd daemonæŒ‚æ‰å½±å“èŒƒå›´ä¼šå¾ˆå¹¿ï¼Œè¿™ä¼šå¢å¤§æ•°æ®ä¸¢å¤±çš„é£é™©\rosd daemonä¸Šçš„pgç»„æ•°ç›®åº”è¯¥æ˜¯åœ¨åˆç†èŒƒå›´å†…çš„ï¼Œæˆ‘ä»¬æ— æ³•å†³å®špgç»„ä¸osd daemonä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œè¿™ä¸ªæ˜¯ç”±crushç®—æ³•å†³å®šçš„ã€‚ä½†æ˜¯æˆ‘ä»¬å¯ä»¥åœ¨åˆ›å»ºpoolæ± æ—¶ï¼Œå¯ä»¥æŒ‡å®špoolæ± å†…æ‰€åŒ…å«pgçš„æ•°é‡ï¼Œåªè¦æŠŠpgçš„æ•°é‡è®¾ç½®åˆç†ï¼Œcrushç®—æ³•è‡ªç„¶ä¼šä¿è¯æ•°æ®å‡åŒ€ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:4:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"3.3 æŒ‡å®špoolæ± ä¸­pgçš„æ•°é‡ å¦‚ä½•ç®—å‡ºä¸€ä¸ªpoolæ± å†…åº”è¯¥æœ‰å¤šå°‘ä¸ªpgæ•°ï¼Ÿ Target PGs per OSDï¼šcrushç®—æ³•ä¸ºæ¯ä¸ªosd daemonåˆ†é…çš„pgæ•°(å®˜ç½‘å»ºè®®100æˆ–200ä¸ª) OSD#ï¼šosd daemonçš„æ€»æ•° %DATAï¼šè¯¥å­˜å‚¨æ± çš„ç©ºé—´å cephé›†ç¾¤æ•´ä½“å­˜å‚¨ç©ºé—´çš„ç™¾åˆ†æ¯” Sizeï¼špoolæ± ä¸­çš„å‰¯æœ¬æ•° è®¡ç®—å…¬å¼ï¼š (Target PGs per OSD)âœ–(OSD#)âœ–(%DATA)/Sizeå¦‚æœå¦‚æœcephé›†ç¾¤å¾ˆé•¿ä¸€æ®µæ—¶é—´éƒ½ä¸ä¼šæ‹“å±•,æˆ‘ä»¬osd daemonçš„æ€»æ•°ä¸º9,è¯¥å­˜å‚¨æ± å ç”¨æ•´ä¸ªcephé›†ç¾¤æ•´ä½“å­˜å‚¨ç©ºé—´çš„ç™¾åˆ†æ¯”ä¸º1%(10G/1000G),poolæ± ä¸­çš„å‰¯æœ¬æ•°ä¸º3ä¸ª,é‚£ä¹ˆæˆ‘ä»¬åœ¨poolæ± ä¸­è®¾ç½®pgçš„æ•°é‡ä¸ºå¤šå°‘åˆç†? 100 * 9 * 0.01 / 3 = 3 (ä¸ª)å®˜ç½‘ä¹Ÿç»™å‡ºäº†ä¸€äº›å‚è€ƒåŸåˆ™ osd daemonçš„æ€»æ•°å°‘äº5ä¸ªï¼Œå»ºè®®å°†poolä¸­çš„pgæ•°è®¾ä¸º128\rosd daemonçš„æ€»æ•°5åˆ°10ä¸ªï¼Œå»ºè®®å°†poolä¸­çš„pgæ•°è®¾ä¸º512\rosd daemonçš„æ€»æ•°10åˆ°50ä¸ªï¼Œå»ºè®®å°†poolä¸­çš„pgæ•°è®¾ä¸º4093\rosd daemonçš„æ€»æ•°ä¸º50ä¸ªä»¥ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®˜ç½‘çš„å·¥å…·è¿›è¡Œè®¡ç®—ï¼Œæ¥ç¡®å®špoolæ± ä¸­pgçš„ä¸ªæ•°ã€‚cephå®˜ç½‘è®¡ç®—å·¥å…·ç½‘å€ï¼šhttps://ceph.com/pgcalc/ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:4:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"3.4 Cephä¸­poolæ± çš„ä¸¤ç§ç±»å‹ Replicated pool(é»˜è®¤) å‰¯æœ¬å‹poolï¼Œé€šè¿‡ç”Ÿäº§å¯¹è±¡çš„å¤šä»½æ‹·è´ ä¼˜ç‚¹ : ä¿è¯äº†æ•°æ®çš„å®‰å…¨ ç¼ºç‚¹ : æµªè´¹ç©ºé—´ï¼Œå¦‚æœè®¾ç½®çš„pgå¯¹åº”ä¸‰ä¸ªå‰¯æœ¬ï¼Œé‚£ä¹ˆç©ºé—´åªèƒ½ç”¨åˆ°åŸæ¥ç©ºé—´çš„ä¸‰åˆ†ä¹‹ä¸€ Erasure-coded pool ç‰¹ç‚¹ : æ²¡æœ‰å‰¯æœ¬ï¼Œå¯ä»¥æŠŠç©ºé—´ç™¾åˆ†ä¹‹ç™¾åˆ©ç”¨èµ·æ¥ï¼Œä½†æ˜¯æ²¡æœ‰å‰¯æœ¬åŠŸèƒ½(æ— æ³•ä¿è¯æ•°æ®çš„å®‰å…¨) ä¸æ”¯æŒcephçš„å‹ç¼©ï¼Œä¸æ”¯æŒcephåƒåœ¾å›æ”¶çš„åŠŸèƒ½ç­‰ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:4:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"3.5 Cephç½‘ç»œåˆ’åˆ† Cephæ¨èä¸»è¦ä½¿ç”¨ä¸¤ä¸ªç½‘ç»œï¼Œè¿™ä¹ˆåšï¼Œæ³¨æ„ä»æ€§èƒ½(OSDèŠ‚ç‚¹ä¹‹é—´ä¼šæœ‰å¤§é‡çš„æ•°æ®æ‹·è´æ“ä½œ)å’Œå®‰å…¨æ€§(ä¸¤ç½‘åˆ†ç¦»)è€ƒè™‘ã€‚ å‰ç«¯(å—åŒ—)ç½‘ç»œ : è¿æ¥å®¢æˆ·ç«¯å’Œé›†ç¾¤ åç«¯(ä¸œè¥¿)ç½‘ç»œ : è¿æ¥cephå„ä¸ªå­˜å‚¨èŠ‚ç‚¹ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:4:5","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"4. Cephæ•°æ®å†™å…¥æµç¨‹ Ceph é›†ç¾¤éƒ¨ç½²å¥½ä¹‹å,è¦å…ˆåˆ›å»ºå­˜å‚¨æ± æ‰èƒ½å‘Ceph å†™å…¥æ•°æ®ï¼Œæ–‡ä»¶åœ¨å‘Ceph ä¿å­˜ä¹‹å‰è¦å…ˆè¿›è¡Œä¸€è‡´æ€§hash è®¡ç®—ï¼Œè®¡ç®—åä¼šæŠŠæ–‡ä»¶ä¿å­˜åœ¨æŸä¸ªå¯¹åº”çš„PG çš„ï¼Œæ­¤æ–‡ä»¶ä¸€å®šå±äºæŸä¸ªpool çš„ä¸€ä¸ªPGï¼Œåœ¨é€šè¿‡PG ä¿å­˜åœ¨OSD ä¸Šã€‚æ•°æ®å¯¹è±¡åœ¨å†™åˆ°ä¸»OSD ä¹‹åå†åŒæ­¥å¯¹ä»OSD ä»¥å®ç°æ•°æ®çš„é«˜å¯ç”¨ã€‚ ç¬¬ä¸€æ­¥: è®¡ç®—æ–‡ä»¶åˆ°å¯¹è±¡çš„æ˜ å°„: Fileæ”¾åˆ°Cephé›†ç¾¤åï¼Œå…ˆæŠŠæ–‡ä»¶è¿›è¡Œåˆ†å‰²ï¼Œåˆ†å‰²ä¸ºç­‰å¤§å°çš„å°å—ï¼Œå°å—å«objectï¼ˆé»˜è®¤ä¸º4Mï¼‰\rè®¡ç®—æ–‡ä»¶åˆ°å¯¹è±¡çš„æ˜ å°„,å‡å¦‚file ä¸ºå®¢æˆ·ç«¯è¦è¯»å†™çš„æ–‡ä»¶,å¾—åˆ°oid(object id) = ino + ono\rino:inode number (INO)ï¼ŒFile çš„å…ƒæ•°æ®åºåˆ—å·ï¼ŒFile çš„å”¯ä¸€idã€‚\rono:object number (ONO)ï¼ŒFile åˆ‡åˆ†äº§ç”Ÿçš„æŸä¸ªobject çš„åºå·ï¼Œé»˜è®¤ä»¥4M åˆ‡åˆ†ä¸€ä¸ªå—å¤§å°ã€‚\ræ¯”å¦‚ï¼šä¸€ä¸ªæ–‡ä»¶FileIDä¸ºAï¼Œå®ƒè¢«åˆ‡æˆäº†ä¸¤ä¸ªå¯¹è±¡ï¼Œä¸€ä¸ªå¯¹è±¡ç¼–å·0ï¼Œå¦ä¸€ä¸ªç¼–å·1ï¼Œé‚£ä¹ˆè¿™ä¸¤ä¸ªæ–‡ä»¶çš„oidåˆ™ä¸ºA0ä¸A1ã€‚\r1ï¼‰ç”±Cephé›†ç¾¤æŒ‡å®šçš„é™æ€Hsahå‡½æ•°è®¡ç®—Objectçš„oidï¼Œè·å–åˆ°å…¶Hashå€¼ã€‚\r2ï¼‰å°†è¯¥Hashå€¼ä¸maskè¿›è¡Œä¸æ“ä½œï¼Œä»è€Œè·å¾—PG IDã€‚ç¬¬äºŒæ­¥ï¼šé€šè¿‡hash ç®—æ³•è®¡ç®—å‡ºæ–‡ä»¶å¯¹åº”çš„pool ä¸­çš„PG: å°å—è·Ÿæ®ä¸€å®šç®—æ³•è·Ÿè§„å¾‹ï¼Œç®—æ³•æ˜¯å“ˆå¸Œç®—æ³•ï¼Œæ”¾ç½®åˆ°PGç»„é‡Œã€‚\ré€šè¿‡ä¸€è‡´æ€§HASH è®¡ç®—Object åˆ°PGï¼Œ Object -\u003e PG æ˜ å°„hash(oid) \u0026 mask-\u003e pgidç¬¬ä¸‰æ­¥: é€šè¿‡CRUSH ç®—æ³•æŠŠå¯¹è±¡æ˜ å°„åˆ°PG ä¸­çš„OSD: å†æŠŠPGæ”¾åˆ°OSDé‡Œé¢ã€‚\ré€šè¿‡CRUSH ç®—æ³•è®¡ç®—PG åˆ°OSDï¼ŒPG -\u003e OSD æ˜ å°„ï¼š[CRUSH(pgid)-\u003e(osd1,osd2,osd3)]ç¬¬å››æ­¥ï¼šPG ä¸­çš„ä¸»OSD å°†å¯¹è±¡å†™å…¥åˆ°ç¡¬ç›˜ã€‚ ç¬¬äº”æ­¥: ä¸»OSD å°†æ•°æ®åŒæ­¥ç»™å¤‡ä»½OSD,å¹¶ç­‰å¾…å¤‡ä»½OSD è¿”å›ç¡®è®¤ã€‚ ç¬¬å…­æ­¥: å¤‡ä»½OSDè¿”å›ç¡®è®¤åï¼Œä¸»OSD å°†å†™å…¥å®Œæˆè¿”å›ç»™å®¢æˆ·ç«¯ã€‚ Cephä¸­æ•°æ®å†™å…¥ï¼Œä¼šæœ‰ä¸‰æ¬¡æ˜ å°„ ï¼ˆ1ï¼‰File -\u003e objectæ˜ å°„\rï¼ˆ2ï¼‰Object -\u003e PGæ˜ å°„ï¼Œhash(oid) \u0026 mask -\u003e pgid\rï¼ˆ3ï¼‰PG -\u003e OSDæ˜ å°„ï¼ŒCRUSHç®—æ³• ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:5:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"5.å…ƒæ•°æ®çš„ä¿å­˜æ–¹å¼ Ceph å¯¹è±¡æ•°æ®çš„å…ƒæ•°æ®ä¿¡æ¯æ”¾åœ¨å“ªé‡Œå‘¢? å¯¹è±¡æ•°æ®çš„å…ƒæ•°æ®ä»¥ key-value çš„å½¢å¼å­˜åœ¨ï¼Œ åœ¨RADOS ä¸­æœ‰ä¸¤ç§å®ç°ï¼šxattrs å’Œ omapï¼š Ceph å¯é€‰åç«¯æ”¯æŒå¤šç§å­˜å‚¨å¼•æ“ï¼Œæ¯”å¦‚ filestoreï¼Œkvstoreï¼Œmemstoreï¼Œç›®å‰æ˜¯ä»¥ kvstore çš„ å½¢å¼å­˜å‚¨å¯¹è±¡æ•°æ®çš„å…ƒæ•°æ®ä¿¡æ¯ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:6:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"5.1 xattr æ‰©å±•å±æ€§ æ˜¯å°†å…ƒæ•°æ®ä¿å­˜åœ¨å¯¹è±¡å¯¹åº”æ–‡ä»¶æ•°æ®ä¸­å¹¶ä¿å­˜åˆ°ç³»ç»Ÿç£ç›˜ä¸Šï¼Œè¿™è¦æ±‚æ”¯æŒå¯¹è±¡å­˜å‚¨çš„ æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼ˆä¸€èˆ¬æ˜¯ XFSï¼‰æ”¯æŒæ‰©å±•å±æ€§ã€‚å…ƒæ•°æ®å’Œæ•°æ®æ”¾ä¸€èµ· ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:6:1","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"5.2 omap(object map å¯¹è±¡æ˜ å°„) omapæ˜¯ object map çš„ç®€ç§°ï¼Œæ˜¯å°†å…ƒæ•°æ®ä¿å­˜åœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¹‹å¤–çš„ç‹¬ç«‹ key-value å­˜å‚¨ ç³»ç»Ÿä¸­ï¼Œåœ¨ä½¿ç”¨ filestore æ—¶æ˜¯ leveldbï¼Œåœ¨ä½¿ç”¨ bluestore æ—¶æ˜¯ rocksdbï¼Œç”±äº filestore å­˜åœ¨åŠŸèƒ½é—®é¢˜(éœ€è¦å°†ç£ç›˜æ ¼å¼åŒ–ä¸º XFS æ ¼å¼)åŠå…ƒæ•°æ®é«˜å¯ç”¨é—®é¢˜ç­‰é—®é¢˜ï¼Œå› æ­¤åœ¨ç›®å‰ Ceph ä¸»è¦ä½¿ç”¨ bluestoreã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:6:2","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"5.3 Filestoreä¸LevelDB å­˜å‚¨ç³»ç»Ÿ Ceph æ—©æœŸåŸºäº filestore ä½¿ç”¨ google çš„ levelDB ä¿å­˜å¯¹è±¡çš„å…ƒæ•°æ®ï¼ŒLevelDb æ˜¯ä¸€ä¸ªæŒä¹…åŒ–å­˜ å‚¨çš„ KV ç³»ç»Ÿï¼Œå’Œ Redis è¿™ç§å†…å­˜å‹çš„ KV ç³»ç»Ÿä¸åŒï¼ŒLevelDb ä¸ä¼šåƒ Redis ä¸€æ ·å°†æ•°æ®æ”¾åœ¨å†…å­˜ä»è€Œå ç”¨å¤§é‡çš„å†…å­˜ç©ºé—´ï¼Œè€Œæ˜¯å°†å¤§éƒ¨åˆ†æ•°æ®å­˜å‚¨åˆ°ç£ç›˜ä¸Šï¼Œä½†æ˜¯éœ€è¦æŠŠç£ç›˜ä¸Šçš„ levelDB ç©ºé—´æ ¼å¼åŒ–ä¸ºæ–‡ä»¶ç³»ç»Ÿ(XFS). FileStore å°†æ•°æ®ä¿å­˜åˆ°ä¸ Posix å…¼å®¹çš„æ–‡ä»¶ç³»ç»Ÿ(ä¾‹å¦‚ Btrfsã€XFSã€Ext4)ã€‚åœ¨ Ceph åç«¯ä½¿ç”¨ä¼ ç»Ÿçš„ Linux æ–‡ä»¶ç³»ç»Ÿå°½ç®¡æä¾›äº†ä¸€äº›å¥½å¤„ï¼Œä½†ä¹Ÿæœ‰ä»£ä»·ï¼Œå¦‚æ€§èƒ½ã€ å¯¹è±¡å±æ€§ä¸ç£ç›˜æœ¬åœ°æ–‡ ä»¶ç³»ç»Ÿå±æ€§åŒ¹é…å­˜åœ¨é™åˆ¶ç­‰ã€‚ Filestore æ•°æ®å†™å…¥çš„è¿‡ç¨‹ 1ã€å…ˆæŠŠè¦å†™å…¥çš„æ•°æ®å…¨éƒ¨å°è£…æˆä¸€ä¸ªäº‹åŠ¡ï¼Œå…¶æ•´ç†ä½œä¸ºä¸€æ¡æ—¥å¿—ï¼Œå†™å…¥æ—¥å¿—ç£ç›˜ï¼ˆä¸€èˆ¬æŠŠ æ—¥å¿—æ”¾åœ¨ ssd ä¸Šæé«˜æ€§ èƒ½ï¼‰ï¼Œè¿™ä¸ªè¿‡ç¨‹å«æ—¥å¿—çš„æäº¤ï¼ˆjournalsubmitï¼‰ã€‚\r2ã€æŠŠæ•°æ®å†™å…¥å¯¹è±¡æ–‡ä»¶çš„ç£ç›˜ä¸­ï¼ˆä¹Ÿå°±æ˜¯ OSD çš„ç£ç›˜ä¸­ï¼‰ï¼Œè¿™ä¸ªè¿‡ç¨‹å«æ—¥å¿—çš„åº”ç”¨(journal apply)ã€‚è¿™ä¸ªè¿‡ç¨‹ä¸ä¸€å®šå†™å…¥ç£ç›˜ï¼Œæœ‰å¯èƒ½ç¼“å­˜åœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿçš„ page cache ä¸­ã€‚ å½“ç³»ç»Ÿåœ¨æ—¥å¿—æäº¤çš„è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œç³»ç»Ÿé‡å¯åï¼Œç›´æ¥ä¸¢å¼ƒä¸å®Œæ•´çš„æ—¥å¿—æ¡ç›®ï¼Œè¯¥æ¡æ—¥å¿—å¯¹åº” çš„å®é™…å¯¹è±¡æ•°æ®å¹¶æ²¡æœ‰ä¿®æ”¹ï¼Œæ•°æ®ä¿è¯äº†ä¸€è‡´æ€§ã€‚å½“æ—¥å¿—åœ¨åº”ç”¨è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œç”±äºæ—¥å¿—å·²å†™ å…¥åˆ°ç£ç›˜ä¸­ï¼Œç³»ç»Ÿé‡å¯åï¼Œé‡æ”¾ï¼ˆreplayï¼‰æ—¥å¿—ï¼Œè¿™æ ·ä¿è¯æ–°æ•°æ®é‡æ–°å®Œæ•´çš„å†™å…¥ï¼Œä¿è¯äº† æ•°æ®çš„ä¸€è‡´æ€§FileStore æ—¥å¿—çš„ä¸‰ä¸ªé˜¶æ®µ æ—¥å¿—çš„æäº¤ï¼ˆjournal submitï¼‰ï¼šæ—¥å¿—å†™å…¥æ—¥å¿—ç£ç›˜ã€‚ æ—¥å¿—çš„åº”ç”¨(journal apply)ï¼šæ—¥å¿—å¯¹åº”çš„ä¿®æ”¹æ›´æ–°åˆ°å¯¹è±¡çš„ç£ç›˜æ–‡ä»¶ä¸­ã€‚è¿™ä¸ªè¿‡ç¨‹ä¸ä¸€å®šå†™å…¥ ç£ç›˜ï¼Œæœ‰å¯èƒ½ç¼“å­˜åœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿçš„ page cache ä¸­ã€‚ æ—¥å¿—çš„åŒæ­¥ï¼ˆjournal sync æˆ–è€… journal commitï¼‰ï¼šç¡®å®šæ—¥å¿—å¯¹åº”çš„ä¿®æ”¹æ“ä½œå·²ç»åˆ·åˆ°ç£ç›˜ä¸­","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:6:3","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"5.4 BlueStore ä¸ RocksDB å­˜å‚¨ç³»ç»Ÿ â€‹ ç”±äº levelDB ä¾ç„¶éœ€è¦éœ€è¦ç£ç›˜æ–‡ä»¶ç³»ç»Ÿçš„æ”¯æŒï¼ŒåæœŸ Facebok å¯¹ levelDB è¿›è¡Œæ”¹è¿›ä¸º RocksDBï¼ŒRocksDB å°†å¯¹è±¡æ•°æ®çš„å…ƒæ•°æ®ä¿å­˜åœ¨ RocksDBï¼Œä½†æ˜¯ RocksDB çš„æ•°æ®åˆæ”¾åœ¨å“ªé‡Œå‘¢ï¼Ÿ æ”¾åœ¨å†…å­˜æ€•ä¸¢å¤±ï¼Œæ”¾åœ¨æœ¬åœ°ç£ç›˜ä½†æ˜¯è§£å†³ä¸äº†é«˜å¯ç”¨ï¼ŒCeph å¯¹è±¡æ•°æ®æ”¾åœ¨äº†æ¯ä¸ª OSD ä¸­ï¼Œé‚£ä¹ˆå°±åœ¨åœ¨å½“å‰ OSD ä¸­åˆ’åˆ†å‡ºä¸€éƒ¨åˆ†ç©ºé—´ï¼Œæ ¼å¼åŒ–ä¸º BlueFS æ–‡ä»¶ç³»ç»Ÿç”¨äºä¿å­˜ RocksDB ä¸­çš„å…ƒæ•°æ®ä¿¡æ¯(ç§°ä¸º BlueStore)ï¼Œå¹¶å®ç°å…ƒæ•°æ®çš„é«˜å¯ç”¨ï¼Œ BlueStore æœ€å¤§çš„ç‰¹ç‚¹æ˜¯æ„å»ºåœ¨è£¸ç£ç›˜è®¾å¤‡ä¹‹ä¸Šï¼Œå¹¶ä¸”å¯¹è¯¸å¦‚ SSD ç­‰æ–°çš„å­˜å‚¨è®¾å¤‡åšäº†å¾ˆå¤šä¼˜åŒ–å·¥ä½œã€‚ å¯¹å…¨ SSD åŠå…¨ NVMe SSD é—ªå­˜é€‚é… ç»•è¿‡æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå±‚ï¼Œç›´æ¥ç®¡ç†è£¸è®¾å¤‡ï¼Œç¼©çŸ­ IO è·¯å¾„ ä¸¥æ ¼åˆ†ç¦»å…ƒæ•°æ®å’Œæ•°æ®ï¼Œæé«˜ç´¢å¼•æ•ˆç‡ã€‚ æœŸæœ›å¸¦æ¥è‡³å°‘ 2 å€çš„å†™æ€§èƒ½æå‡å’ŒåŒç­‰è¯»æ€§èƒ½ å¢åŠ æ•°æ®æ ¡éªŒåŠæ•°æ®å‹ç¼©ç­‰åŠŸèƒ½ã€‚ è§£å†³æ—¥å¿—â€œåŒå†™â€é—®é¢˜ã€‚ ä½¿ç”¨ KV ç´¢å¼•ï¼Œè§£å†³æ–‡ä»¶ç³»ç»Ÿç›®å½•ç»“æ„éå†æ•ˆç‡ä½çš„é—®é¢˜ æ”¯æŒå¤šç§è®¾å¤‡ç±»å‹ã€‚ BlueStore çš„é€»è¾‘æ¶æ„å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæ¨¡å—çš„åˆ’åˆ†éƒ½è¿˜æ¯”è¾ƒæ¸…æ™°ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸‹å„æ¨¡å—çš„ä½œç”¨: Allocator:è´Ÿè´£è£¸è®¾å¤‡çš„ç©ºé—´ç®¡ç†åˆ†é…ã€‚ RocksDBï¼š æ˜¯ facebook åŸºäº leveldb å¼€å‘çš„ä¸€æ¬¾ kv æ•°æ®åº“ï¼ŒBlueStore å°†å…ƒæ•°æ®å…¨éƒ¨å­˜æ”¾è‡³ RocksDB ä¸­ï¼Œè¿™äº›å…ƒæ•°æ®åŒ…æ‹¬å­˜å‚¨é¢„å†™å¼æ—¥å¿—ã€æ•°æ®å¯¹è±¡å…ƒæ•°æ®ã€Ceph çš„ omap æ•° æ®ä¿¡æ¯ã€ä»¥åŠåˆ†é…å™¨çš„å…ƒæ•°æ® ã€‚ RocksDB é€šè¿‡ä¸­é—´å±‚ BlueRocksDB è®¿é—®æ–‡ä»¶ç³»ç»Ÿçš„æ¥å£ã€‚è¿™ä¸ªæ–‡ä»¶ç³»ç»Ÿä¸ä¼ ç»Ÿçš„ Linux æ–‡ä»¶ç³»ç»Ÿ(ä¾‹å¦‚ Ext4 å’Œ XFS)æ˜¯ä¸åŒçš„ï¼Œå®ƒä¸æ˜¯åœ¨ VFS ä¸‹é¢çš„é€šç”¨æ–‡ä»¶ç³»ç»Ÿï¼Œè€Œæ˜¯ä¸€ä¸ªç”¨ æˆ·æ€çš„é€»è¾‘ã€‚BlueFS é€šè¿‡å‡½æ•°æ¥å£(APIï¼Œé POSIX)çš„æ–¹å¼ä¸º BlueRocksDB æä¾›ç±»ä¼¼æ–‡ä»¶ç³»ç»Ÿçš„èƒ½åŠ›ã€‚ BlueRocksEnvï¼šè¿™æ˜¯ RocksDB ä¸ BlueFS äº¤äº’çš„æ¥å£ï¼›RocksDB æä¾›äº†æ–‡ä»¶æ“ä½œçš„æ¥å£ EnvWrapper(Env å°è£…å™¨)ï¼Œå¯ä»¥é€šè¿‡ç»§æ‰¿å®ç°è¯¥æ¥å£æ¥è‡ªå®šä¹‰åº•å±‚çš„è¯»å†™æ“ä½œï¼ŒBlueRocksEnv å°±æ˜¯ç»§æ‰¿è‡ª EnvWrapper å®ç°å¯¹ BlueFS çš„è¯»å†™ã€‚ BlueFSï¼šBlueFSæ˜¯BlueStoreé’ˆå¯¹RocksDBå¼€å‘çš„è½»é‡çº§æ–‡ä»¶ç³»ç»Ÿï¼Œç”¨äºå­˜æ”¾RocksDBäº§ç”Ÿçš„.sst å’Œ.log ç­‰æ–‡ä»¶ã€‚ BlockDeciveï¼šBlueStore æŠ›å¼ƒäº†ä¼ ç»Ÿçš„ ext4ã€xfs æ–‡ä»¶ç³»ç»Ÿï¼Œä½¿ç”¨ç›´æ¥ç®¡ç†è£¸ç›˜çš„æ–¹å¼ï¼›BlueStore æ”¯æŒåŒæ—¶ä½¿ç”¨å¤šç§ä¸åŒç±»å‹çš„è®¾å¤‡ï¼Œåœ¨é€»è¾‘ä¸Š BlueStore å°†å­˜å‚¨ç©ºé—´åˆ’åˆ†ä¸ºä¸‰å±‚ï¼šæ…¢é€Ÿï¼ˆSlowï¼‰ ç©ºé—´ã€é«˜é€Ÿï¼ˆDBï¼‰ç©ºé—´ã€è¶…é«˜é€Ÿï¼ˆWALï¼‰ç©ºé—´ï¼Œä¸åŒçš„ç©ºé—´å¯ä»¥æŒ‡å®šä½¿ç”¨ä¸åŒçš„è®¾å¤‡ç±»å‹ï¼Œ å½“ç„¶ä¹Ÿå¯ä½¿ç”¨åŒä¸€å—è®¾å¤‡ BlueStore çš„è®¾è®¡è€ƒè™‘äº† FileStore ä¸­å­˜åœ¨çš„ä¸€äº›ç¡¬ä¼¤ï¼ŒæŠ›å¼ƒäº†ä¼ ç»Ÿçš„æ–‡ä»¶ç³»ç»Ÿç›´æ¥ç®¡ç†è£¸è®¾å¤‡ï¼Œç¼©çŸ­äº† IO è·¯å¾„ï¼ŒåŒæ—¶é‡‡ç”¨ ROW çš„æ–¹å¼ï¼Œé¿å…äº†æ—¥å¿—åŒå†™çš„é—®é¢˜ï¼Œåœ¨å†™å…¥æ€§èƒ½ä¸Šæœ‰äº†æå¤§çš„æé«˜ã€‚ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:6:4","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["Ceph"],"content":"6. CRUSH ç®—æ³•ç®€ä»‹ â€‹ Controllers replication under scalable hashing ï¼šå¯æ§çš„ã€å¯å¤åˆ¶çš„ã€å¯ä¼¸ç¼©çš„ä¸€è‡´æ€§ hash ç®—æ³•ã€‚ Ceph ä½¿ç”¨ CURSH ç®—æ³•æ¥å­˜æ”¾å’Œç®¡ç†æ•°æ®ï¼Œå®ƒæ˜¯ Ceph çš„æ™ºèƒ½æ•°æ®åˆ†å‘æœºåˆ¶ã€‚ Ceph ä½¿ç”¨ CRUSH ç®—æ³•æ¥å‡†ç¡®è®¡ç®—æ•°æ®åº”è¯¥è¢«ä¿å­˜åˆ°å“ªé‡Œï¼Œä»¥åŠåº”è¯¥ä»å“ªé‡Œè¯»å–,å’Œä¿å­˜å…ƒæ•°æ®ä¸åŒ,æ˜¯CRUSH æŒ‰éœ€è®¡ç®—å‡ºå…ƒæ•°æ®ï¼Œå› æ­¤å®ƒå°±æ¶ˆé™¤äº†å¯¹ä¸­å¿ƒå¼çš„æœåŠ¡å™¨ï¼ç½‘å…³çš„éœ€æ±‚,å®ƒä½¿å¾— Ceph å®¢æˆ·ç«¯èƒ½å¤Ÿè®¡ç®—å‡ºå…ƒæ•°æ®ï¼Œè¯¥è¿‡ç¨‹ä¹Ÿç§°ä¸ºCRUSH æŸ¥æ‰¾ï¼Œç„¶åå’Œ OSD ç›´æ¥é€šä¿¡ã€‚ å¦‚æœæ˜¯æŠŠå¯¹è±¡ç›´æ¥æ˜ å°„åˆ° OSD ä¹‹ä¸Šä¼šå¯¼è‡´å¯¹è±¡ä¸ OSD çš„å¯¹åº”å…³ç³»è¿‡äºç´§å¯†å’Œè€¦åˆï¼Œå½“ OSD ç”±äºæ•…éšœå‘ç”Ÿå˜æ›´æ—¶å°†ä¼šå¯¹æ•´ä¸ª Ceph é›†ç¾¤äº§ç”Ÿå½±å“ã€‚ äºæ˜¯ Ceph å°†ä¸€ä¸ªå¯¹è±¡æ˜ å°„åˆ° RADOS é›†ç¾¤çš„æ—¶å€™åˆ†ä¸ºä¸¤æ­¥èµ°ï¼š é¦–å…ˆä½¿ç”¨ä¸€è‡´æ€§ hash ç®—æ³•å°†å¯¹è±¡åç§°æ˜ å°„åˆ° PG ç„¶åå°† PG ID åŸºäº CRUSH ç®—æ³•æ˜ å°„åˆ° OSD å³å¯æŸ¥åˆ°å¯¹è±¡ã€‚ ä»¥ä¸Šä¸¤ä¸ªè¿‡ç¨‹éƒ½æ˜¯ä»¥â€å®æ—¶è®¡ç®—â€çš„æ–¹å¼å®Œæˆï¼Œè€Œæ²¡æœ‰ä½¿ç”¨ä¼ ç»Ÿçš„æŸ¥è¯¢æ•°æ®ä¸å—è®¾å¤‡çš„å¯¹åº”è¡¨çš„æ–¹å¼ï¼Œè¿™æ ·æœ‰æ•ˆé¿å…äº†ç»„ä»¶çš„â€ä¸­å¿ƒåŒ–â€é—®é¢˜ï¼Œä¹Ÿè§£å†³äº†æŸ¥è¯¢æ€§èƒ½å’Œå†—ä½™é—®é¢˜ã€‚è¿™ä½¿å¾— Ceph é›†ç¾¤æ‰©å±•ä¸å†å—æŸ¥è¯¢çš„æ€§èƒ½é™åˆ¶ï¼ŒCRUSH ç®—æ³•ç”±MonèŠ‚ç‚¹è®¡ç®—,æ ¹æ®ä½¿ç”¨é‡ç›¸åº”å¢åŠ MonèŠ‚ç‚¹æ•°é‡ã€‚ è¿™ä¸ªå®æ—¶è®¡ç®—æ“ä½œä½¿ç”¨çš„å°±æ˜¯ CRUSH ç®—æ³• Controllers replication under scalable hashing å¯æ§çš„ã€å¯å¤åˆ¶çš„ã€å¯ä¼¸ç¼©çš„ä¸€è‡´æ€§ hash ç®—æ³•ã€‚CRUSH æ˜¯ä¸€ç§åˆ†å¸ƒå¼ç®—æ³•ï¼Œç±»ä¼¼äºä¸€è‡´æ€§ hash ç®—æ³•ï¼Œç”¨äºä¸º RADOS å­˜å‚¨é›†ç¾¤æ§åˆ¶æ•°æ®çš„åˆ†é…ï¼Œ ","date":"2023-01-02","objectID":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/:7:0","tags":["åˆ†å¸ƒå¼å­˜å‚¨"],"title":"Ceph ç†è®ºè¯¦è§£ (ä¸€)","uri":"/posts/ceph/1.ceph%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3/"},{"categories":["å°è®°"],"content":"Gitå¸¸ç”¨å‘½ä»¤ä¸å¸¸è§é—®é¢˜ ","date":"2022-06-02","objectID":"/posts/notes/git/:1:0","tags":["Git"],"title":"Gitå¸¸ç”¨å‘½ä»¤ä¸å¸¸è§é—®é¢˜","uri":"/posts/notes/git/"},{"categories":["å°è®°"],"content":"git error: Your local changes to the following files would be overwritten by merge è§£å†³æ–¹æ¡ˆ èƒŒæ™¯ å›¢é˜Ÿå…¶ä»–æˆå‘˜ä¿®æ”¹äº†æŸæ–‡ä»¶å¹¶å·²æäº¤å…¥åº“ï¼Œä½ åœ¨pullä¹‹å‰ä¿®æ”¹äº†æœ¬åœ°è¯¥æ–‡ä»¶ï¼Œç­‰ä½ ä¿®æ”¹å®Œä»£ç å†pullæ—¶ï¼Œè¿™æ—¶ä¼šæŠ¥é”™å¦‚ä¸‹é”™è¯¯ï¼š error: Your local changes to the following files would be overwritten by merge è§£å†³æ–¹æ¡ˆ æ ¹æ®æ˜¯å¦è¦ä¿å­˜æœ¬åœ°ä¿®æ”¹ï¼Œæœ‰ä»¥ä¸‹ä¸¤ç§è§£å†³æ–¹æ¡ˆ ä¿ç•™ä¿®æ”¹ #æ‰§è¡Œä»¥ä¸‹ä¸‰æ¡å‘½ä»¤ git stash #å°å­˜ä¿®æ”¹ git pull origin master git stash pop #æŠŠä¿®æ”¹è¿˜åŸæ³¨ï¼š git stashï¼šå¤‡ä»½å½“å‰å·¥ä½œåŒºå†…å®¹ï¼Œä»æœ€è¿‘çš„ä¸€æ¬¡æäº¤ä¸­è¯»å–ç›¸å…³å†…å®¹ï¼Œè®©å·¥ä½œåŒºä¿è¯å’Œä¸Šæ¬¡æäº¤çš„å†…å®¹ä¸€è‡´ã€‚åŒæ—¶ï¼Œå°†å½“å‰å·¥ä½œåŒºå†…å®¹ä¿å­˜åˆ°Gitæ ˆä¸­ git pullï¼šæ‹‰å–æœåŠ¡å™¨ä¸Šå½“å‰åˆ†æ”¯ä»£ç ã€‚ git stash popï¼šä»Gitæ ˆä¸­è¯»å–æœ€è¿‘ä¸€æ¬¡ä¿å­˜çš„å†…å®¹ï¼Œæ¢å¤å·¥ä½œåŒºç›¸å…³å†…å®¹ã€‚åŒæ—¶ï¼Œç”¨æˆ·å¯èƒ½è¿›è¡Œå¤šæ¬¡stashæ“ä½œï¼Œéœ€è¦ä¿è¯åstashçš„æœ€å…ˆè¢«å–åˆ°ï¼Œæ‰€ä»¥ç”¨æ ˆï¼ˆå…ˆè¿›åå‡ºï¼‰æ¥ç®¡ç†ï¼›popå–æ ˆé¡¶çš„å†…å®¹å¹¶æ¢å¤ git stash listï¼šæ˜¾ç¤ºGitæ ˆå†…çš„æ‰€æœ‰å¤‡ä»½ï¼Œå¯ä»¥åˆ©ç”¨è¿™ä¸ªåˆ—è¡¨æ¥å†³å®šä»é‚£ä¸ªåœ°æ–¹æ¢å¤ã€‚ git stash clearï¼šæ¸…ç©ºGitæ ˆ 2.åºŸå¼ƒä¿®æ”¹ æ ¸å¿ƒæ€æƒ³å°±æ˜¯ç‰ˆæœ¬å›é€€ï¼Œå…·ä½“å‘½ä»¤å¦‚ä¸‹ git reset --hard git pull origin masteræ³¨ï¼šä¸å»ºè®®ä½¿ç”¨ç¬¬äºŒç§ã€‚é™¤éä½ å†ä¸‰ç¡®å®šä¸éœ€è¦æœ¬åœ°çš„ä¿®æ”¹äº†ã€‚ ","date":"2022-06-02","objectID":"/posts/notes/git/:1:1","tags":["Git"],"title":"Gitå¸¸ç”¨å‘½ä»¤ä¸å¸¸è§é—®é¢˜","uri":"/posts/notes/git/"},{"categories":["å°è®°"],"content":"ä½¿ç”¨gitæ—¶æ˜¾ç¤ºuntracked filesï¼ˆæœªç›‘æ§ï¼‰è§£å†³åŠæ³• é—®é¢˜ï¼š git status æ—¶é™¤äº†æ˜¾ç¤ºè‡ªå·±ä¿®æ”¹çš„æ–‡ä»¶ï¼Œè¿˜å¤šäº†ä¸¤ä¸ªæ–‡ä»¶ï¼Œæ˜¾ç¤ºå¦‚ä¸‹ï¼š $ git status On branch main Your branch is up to date with 'origin/main'. Untracked files: (use \"git add \u003cfile\u003e...\" to include in what will be committed) .package-lock.jsonåœ¨ç¼–è¯‘gitåº“æ‹‰ä¸‹æ¥çš„ä»£ç æ—¶ï¼Œå¾€å¾€ä¼šäº§ç”Ÿä¸€äº›ä¸­é—´æ–‡ä»¶ï¼Œè¿™äº›æ–‡ä»¶æˆ‘ä»¬æ ¹æœ¬ä¸éœ€è¦ï¼Œå°¤å…¶æ˜¯åœ¨æˆäº§ç¯èŠ‚åšé¢„ç¼–è¯‘ï¼Œæ£€æŸ¥ä»£ç æäº¤æ˜¯å¦èƒ½ç¼–è¯‘é€šè¿‡è¿™ç§caseæ—¶ï¼Œæˆ‘ä»¬å¾€å¾€éœ€è¦ç¼–è¯‘å®Œæˆåä¸ç®¡æ­£ç¡®ä¸å¦ï¼Œè¿˜åŸç°åœºï¼Œä»¥æ–¹ä¾¿ä¸‹æ¬¡syncä»£ç æ—¶ä¸å—ä¸Šä¸€æ¬¡çš„ç¼–è¯‘å½±å“ã€‚ è§£å†³åŠæ³•ï¼šåˆ é™¤gitåº“ä¸­untracked filesï¼ˆæœªç›‘æ§ï¼‰çš„æ–‡ä»¶ï¼š #1.åˆ é™¤ untracked filesï¼š git clean -f #2.è¿ untracked çš„ç›®å½•ä¹Ÿä¸€èµ·åˆ æ‰ï¼š git clean -fd #3.è¿ gitignore çš„untrack æ–‡ä»¶/ç›®å½•ä¹Ÿä¸€èµ·åˆ æ‰ ï¼ˆæ…ç”¨ï¼Œä¸€èˆ¬è¿™ä¸ªæ˜¯ç”¨æ¥åˆ æ‰ç¼–è¯‘å‡ºæ¥çš„ .oä¹‹ç±»çš„æ–‡ä»¶ç”¨çš„ï¼‰ git clean -xfdæ³¨æ„ï¼š åœ¨ç”¨ä¸Šè¿° git clean å‰ï¼Œå¼ºçƒˆå»ºè®®åŠ ä¸Š -n å‚æ•°æ¥å…ˆçœ‹çœ‹ä¼šåˆ æ‰å“ªäº›æ–‡ä»¶ï¼Œé˜²æ­¢é‡è¦æ–‡ä»¶è¢«è¯¯åˆ ï¼š git clean -nxfd\rgit clean -nf\rgit clean -nfd","date":"2022-06-02","objectID":"/posts/notes/git/:1:2","tags":["Git"],"title":"Gitå¸¸ç”¨å‘½ä»¤ä¸å¸¸è§é—®é¢˜","uri":"/posts/notes/git/"},{"categories":["Kafka"],"content":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ– ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:0:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"ä¸€ã€ä¸ºä»€ä¹ˆä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—? ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:1:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"1.KafkaçŸ¥è¯†ç‚¹æ€ç»´å¯¼å›¾ ä»¥ç”µå•†ä¸ºä¸šåŠ¡èƒŒæ™¯ æ¶ˆæ¯é˜Ÿåˆ—è§£å†³çš„å…·ä½“é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ â€“ é€šä¿¡é—®é¢˜ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:1:1","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"2.ä½¿ç”¨åŒæ­¥çš„é€šè®¯æ–¹å¼æ¥è§£å†³å¤šä¸ªæœåŠ¡ä¹‹é—´çš„é€šè®¯ åŒæ­¥çš„é€šè®¯æ–¹å¼ä¼šå­˜åœ¨æ€§èƒ½å’Œç¨³å®šæ€§çš„é—®é¢˜ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:1:2","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.ä½¿ç”¨å¼‚æ­¥é€šè®¯æ–¹å¼ åœ¨ä¸šåŠ¡çš„ä¸Šæ¸¸ä¸ä¸‹æ¸¸é—´åŠ å…¥ é€šè®¯æ¨¡å— ï¼ˆæ¶ˆæ¯é˜Ÿåˆ— å­˜å‚¨æ¶ˆæ¯çš„é˜Ÿåˆ—ï¼‰ æœ€ç»ˆä¸€è‡´æ€§ é’ˆå¯¹åŒæ­¥çš„é€šè®¯æ–¹å¼æ¥è¯´ï¼Œå¼‚æ­¥çš„æ–¹å¼ï¼Œå¯ä»¥è®©ä¸Šæ¸¸å¿«é€ŸæˆåŠŸï¼Œæå¤§æé«˜äº†ç³»ç»Ÿçš„ååé‡ã€‚è€Œä¸”åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œé€šè¿‡ä¸‹æ¸¸å¤šä¸ªæœåŠ¡çš„åˆ†å¸ƒå¼äº‹åŠ¡ä¿éšœï¼Œä¹Ÿèƒ½ä¿è¯ä¸šåŠ¡æ‰§è¡Œä¹‹åçš„æœ€ç»ˆä¸€è‡´æ€§ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:1:3","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"äºŒã€æ¶ˆæ¯é˜Ÿåˆ—çš„æµæ´¾ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:2:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"1.ä»€ä¹ˆæ˜¯MQ ï¼Ÿ Message Queueï¼ˆMQï¼‰ï¼Œæ¶ˆæ¯é˜Ÿåˆ—ä¸­é—´ä»¶ã€‚ å¾ˆå¤šäººéƒ½è¯´ï¼š MQ é€šè¿‡å°†æ¶ˆæ¯çš„å‘é€å’Œæ¥æ”¶åˆ†ç¦»æ¥å®ç°åº”ç”¨ç¨‹åºçš„å¼‚æ­¥å’Œè§£å¶ï¼Œè¿™ä¸ªç»™äººçš„ç›´è§‰æ˜¯â€”â€”MQ æ˜¯å¼‚æ­¥çš„ï¼Œç”¨æ¥è§£è€¦çš„ï¼Œä½†æ˜¯è¿™ä¸ªåªæ˜¯ MQ çš„æ•ˆæœè€Œä¸æ˜¯ç›®çš„ã€‚ MQ çœŸæ­£çš„ç›®çš„æ˜¯ä¸ºäº†é€šè®¯ï¼Œå±è”½åº•å±‚å¤æ‚çš„é€šè®¯åè®®ï¼Œå®šä¹‰äº†ä¸€å¥—åº”ç”¨å±‚çš„ã€æ›´åŠ ç®€å•çš„é€šè®¯åè®®ã€‚ ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿä¸­ä¸¤ä¸ªæ¨¡å—ä¹‹é—´é€šè®¯è¦ä¹ˆæ˜¯ HTTPï¼Œè¦ä¹ˆæ˜¯è‡ªå·±å¼€å‘çš„ TCPï¼Œä½†æ˜¯è¿™ä¸¤ç§åè®®å…¶å®éƒ½æ˜¯åŸå§‹çš„åè®®ã€‚ HTTP åè®®å¾ˆéš¾å®ç°ä¸¤ç«¯é€šè®¯â€”â€”æ¨¡å— A å¯ä»¥è°ƒç”¨ Bï¼ŒB ä¹Ÿå¯ä»¥ä¸»åŠ¨è°ƒç”¨ Aï¼Œå¦‚æœè¦åšåˆ°è¿™ä¸ªä¸¤ç«¯éƒ½è¦èƒŒä¸Š WebServerï¼Œè€Œä¸”è¿˜ä¸æ”¯æŒé•¿è¿æ¥ï¼ˆHTTP 2.0 çš„åº“æ ¹æœ¬æ‰¾ä¸åˆ°ï¼‰ã€‚ TCP å°±æ›´åŠ åŸå§‹äº†ï¼Œç²˜åŒ…ã€å¿ƒè·³ã€ç§æœ‰çš„åè®®ï¼Œæƒ³ä¸€æƒ³å¤´çš®å°±å‘éº»ã€‚ MQ æ‰€è¦åšçš„å°±æ˜¯åœ¨è¿™äº›åè®®ä¹‹ä¸Šæ„å»ºä¸€ä¸ªç®€å•çš„â€œåè®®â€â€”â€”ç”Ÿäº§è€…/æ¶ˆè´¹è€…æ¨¡å‹ã€‚ MQ å¸¦ç»™æˆ‘çš„â€œåè®®â€ä¸æ˜¯å…·ä½“çš„é€šè®¯åè®®ï¼Œè€Œæ˜¯æ›´é«˜å±‚æ¬¡é€šè®¯æ¨¡å‹ã€‚ å®ƒå®šä¹‰äº†ä¸¤ä¸ªå¯¹è±¡â€”â€”å‘é€æ•°æ®çš„å«ç”Ÿäº§è€…ï¼Œæ¥æ”¶æ•°æ®çš„å«æ¶ˆè´¹è€…ï¼› æä¾›ä¸€ä¸ª SDK è®©æˆ‘ä»¬å¯ä»¥å®šä¹‰è‡ªå·±çš„ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…å®ç°æ¶ˆæ¯é€šè®¯è€Œæ— è§†åº•å±‚é€šè®¯åè®®ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:2:1","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"2.ä¸­é—´ä»¶é€‰å‹ ç›®å‰æ¶ˆæ¯é˜Ÿåˆ—çš„ä¸­é—´ä»¶é€‰å‹æœ‰å¾ˆå¤šç§ï¼š rabbit MQï¼šå†…éƒ¨å¯ç©æ€§ï¼ˆåŠŸèƒ½æ€§ï¼‰æ˜¯éå¸¸å¼ºçš„ rocket MQ :é˜¿é‡Œå†…éƒ¨å¤§ç¥æ ¹æ®Kafkaçš„å†…éƒ¨æ‰§è¡ŒåŸç†ï¼Œæ‰‹å†™çš„ä¸€ä¸ªæ¶ˆæ¯ä¸­é—´ä»¶ã€‚æ€§èƒ½æ¯”è‚©kafkaï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œåœ¨åŠŸèƒ½ä¸Šå°è£…äº†æ›´å¤šçš„åŠŸèƒ½ã€‚ï¼ˆæ¶ˆæ¯çš„é€†åºï¼‰ kafkaï¼šå…¨çƒæ¶ˆæ¯å¤„ç†æ€§èƒ½æœ€å¿«çš„ä¸€æ¬¾MQï¼ˆçº¯ç²¹ï¼‰ zeroMQ è¿™äº›æ¶ˆæ¯é˜Ÿåˆ—ä¸­é—´ä»¶æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ æˆ‘ä»¬æŠŠæ¶ˆæ¯é˜Ÿåˆ—åˆ†ä¸ºä¸¤ç§ MQï¼Œåˆ†ä¸ºæœ‰Brokerçš„MQï¼Œå’Œæ²¡æœ‰Brokerçš„MQã€‚ Brokerï¼Œä»£ç†ï¼Œç»çºªäººçš„æ„æ€ã€‚ 2.1æœ‰broker æœ‰brokerçš„MQ è¿™ä¸ªæµæ´¾é€šå¸¸æœ‰ä¸€å°æœåŠ¡å™¨ä½œä¸ºBrokerï¼Œæ‰€æœ‰çš„æ¶ˆæ¯éƒ½é€šè¿‡å®ƒä¸­è½¬ã€‚ç”Ÿäº§è€…æŠŠæ¶ˆæ¯å‘é€ç»™å®ƒå°±ç»“æŸè‡ªå·±çš„ä»»åŠ¡äº†ï¼ŒBrokeråˆ™æŠŠæ¶ˆæ¯ä¸»åŠ¨æ¨é€ç»™æ¶ˆè´¹è€…ï¼ˆæˆ–è€…æ¶ˆè´¹è€…ä¸»åŠ¨è½®è¯¢ï¼‰ã€‚ é‡topicï¼šKafka ã€RocketMQ ã€ ActiveMQ æ•´ä¸ªbrokerï¼Œä¾æ®topicæ¥è¿›è¡Œæ¶ˆæ¯çš„ä¸­è½¬ï¼Œåœ¨é‡topicçš„æ¶ˆæ¯é˜Ÿåˆ—é‡Œå¿…ç„¶éœ€è¦topicçš„å­˜åœ¨ è½»topicï¼šRabbitMQ topicåªæ˜¯å…¶ä¸€ç§ä¸­è½¬æ¨¡å¼ã€‚ 2.2æ— broker åœ¨ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ä¹‹é—´æ²¡æœ‰ä½¿ç”¨brokerï¼Œä¾‹å¦‚zeroMQï¼Œç›´æ¥ä½¿ç”¨socketè¿›è¡Œé€šä¿¡ æ— brokerçš„MQä»£è¡¨æ˜¯ZeroMQï¼Œè¯¥ä½œè€…éå¸¸ç¿æ™ºï¼Œä»–éå¸¸æ•é”çš„æ„è¯†åˆ°â€“MQæ˜¯æ›´é«˜çº§çš„Socket å®ƒæ˜¯è§£å†³é€šä¿¡é—®é¢˜çš„ã€‚æ‰€ä»¥ZeroMQè¢«è®¾è®¡æˆäº†ä¸€ä¸ªâ€œåº“â€è€Œä¸æ˜¯ä¸€ä¸ªä¸­é—´ä»¶ï¼Œè¿™ç§å®ç°ä¹Ÿå¯ä»¥è¾¾åˆ°â€“æ²¡æœ‰Brokerçš„ç›®çš„ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:2:2","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"ä¸‰ã€Kafkaçš„åŸºæœ¬çŸ¥è¯† Kafkaæ˜¯æœ€åˆç”±Linkedinå…¬å¸å¼€å‘ï¼Œæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ã€æ”¯æŒåˆ†åŒºçš„ï¼ˆpartitionï¼‰ã€å¤šå‰¯æœ¬çš„ï¼ˆreplicaï¼‰ï¼ŒåŸºäºzookeeperåè°ƒçš„åˆ†å¸ƒå¼æ¶ˆæ¯ç³»ç»Ÿ. å®ƒçš„æœ€å¤§çš„ç‰¹æ€§å°±æ˜¯å¯ä»¥å®æ—¶çš„å¤„ç†å¤§é‡æ•°æ®ä»¥æ»¡è¶³å„ç§éœ€æ±‚åœºæ™¯ï¼š æ¯”å¦‚åŸºäºhadoopçš„æ‰¹å¤„ç†ç³»ç»Ÿã€ä½å»¶è¿Ÿçš„å®æ—¶ç³»ç»Ÿã€storm/Sparkæµå¼å¤„ç†å¼•æ“ï¼Œweb/nginxæ—¥å¿—ã€è®¿é—®æ—¥å¿—ï¼Œæ¶ˆæ¯æœåŠ¡ç­‰ç­‰ï¼Œç”¨scalaè¯­è¨€ç¼–å†™ï¼ŒLinkedinäº2010å¹´è´¡çŒ®ç»™äº†ApacheåŸºé‡‘ä¼šå¹¶æˆä¸ºé¡¶çº§å¼€æºé¡¹ç›®ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.1 Kafkaçš„ç‰¹æ€§: é«˜ååé‡ã€ä½å»¶è¿Ÿï¼škafkaæ¯ç§’å¯ä»¥å¤„ç†å‡ åä¸‡æ¡æ¶ˆæ¯ï¼Œå®ƒçš„å»¶è¿Ÿæœ€ä½åªæœ‰å‡ æ¯«ç§’ï¼Œæ¯ä¸ªtopicå¯ä»¥åˆ†å¤šä¸ªpartition, consumer group å¯¹partitionè¿›è¡Œconsumeæ“ä½œã€‚ å¯æ‰©å±•æ€§ï¼škafkaé›†ç¾¤æ”¯æŒçƒ­æ‰©å±• æŒä¹…æ€§ã€å¯é æ€§ï¼šæ¶ˆæ¯è¢«æŒä¹…åŒ–åˆ°æœ¬åœ°ç£ç›˜ï¼Œå¹¶ä¸”æ”¯æŒæ•°æ®å¤‡ä»½é˜²æ­¢æ•°æ®ä¸¢å¤± å®¹é”™æ€§ï¼šå…è®¸é›†ç¾¤ä¸­èŠ‚ç‚¹å¤±è´¥ï¼ˆè‹¥å‰¯æœ¬æ•°é‡ä¸ºn,åˆ™å…è®¸n-1ä¸ªèŠ‚ç‚¹å¤±è´¥ï¼‰ é«˜å¹¶å‘ï¼šæ”¯æŒæ•°åƒä¸ªå®¢æˆ·ç«¯åŒæ—¶è¯»å†™ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:1","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.2 Kafkaçš„ä½¿ç”¨åœºæ™¯ æ—¥å¿—æ”¶é›†ï¼šä¸€ä¸ªå…¬å¸å¯ä»¥ç”¨Kafkaå¯ä»¥æ”¶é›†å„ç§æœåŠ¡çš„logï¼Œé€šè¿‡kafkaä»¥ç»Ÿä¸€æ¥å£æœåŠ¡çš„æ–¹å¼å¼€æ”¾ç»™å„ç§consumerï¼Œä¾‹å¦‚hadoopã€Hbaseã€Solrç­‰ã€‚ æ¶ˆæ¯ç³»ç»Ÿï¼šè§£è€¦å’Œç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ã€ç¼“å­˜æ¶ˆæ¯ç­‰ã€‚ ç”¨æˆ·æ´»åŠ¨è·Ÿè¸ªï¼šKafkaç»å¸¸è¢«ç”¨æ¥è®°å½•webç”¨æˆ·æˆ–è€…appç”¨æˆ·çš„å„ç§æ´»åŠ¨ï¼Œå¦‚æµè§ˆç½‘é¡µã€æœç´¢ã€ç‚¹å‡»ç­‰æ´»åŠ¨ï¼Œè¿™äº›æ´»åŠ¨ä¿¡æ¯è¢«å„ä¸ªæœåŠ¡å™¨å‘å¸ƒåˆ°kafkaçš„topicä¸­ï¼Œç„¶åè®¢é˜…è€…é€šè¿‡è®¢é˜…è¿™äº›topicæ¥åšå®æ—¶çš„ç›‘æ§åˆ†æï¼Œæˆ–è€…è£…è½½åˆ°hadoopã€æ•°æ®ä»“åº“ä¸­åšç¦»çº¿åˆ†æå’ŒæŒ–æ˜ã€‚ è¿è¥æŒ‡æ ‡ï¼šKafkaä¹Ÿç»å¸¸ç”¨æ¥è®°å½•è¿è¥ç›‘æ§æ•°æ®ã€‚åŒ…æ‹¬æ”¶é›†å„ç§åˆ†å¸ƒå¼åº”ç”¨çš„æ•°æ®ï¼Œç”Ÿäº§å„ç§æ“ä½œçš„é›†ä¸­åé¦ˆï¼Œæ¯”å¦‚æŠ¥è­¦å’ŒæŠ¥å‘Šã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:2","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.2 åŸºæœ¬æ¦‚å¿µ kafkaæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼çš„ï¼Œåˆ†åŒºçš„æ¶ˆæ¯(å®˜æ–¹ç§°ä¹‹ä¸ºcommit log)æœåŠ¡ã€‚å®ƒæä¾›ä¸€ä¸ªæ¶ˆæ¯ç³»ç»Ÿåº”è¯¥å…·å¤‡çš„åŠŸèƒ½ï¼Œä½†æ˜¯ç¡®æœ‰ç€ç‹¬ç‰¹çš„è®¾è®¡ã€‚ é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹åŸºç¡€çš„æ¶ˆæ¯(Message)ç›¸å…³æœ¯è¯­ï¼š kafka ä¸­æœ‰è¿™ä¹ˆäº›å¤æ‚çš„æ¦‚å¿µ åç§° è§£é‡Š Broker æ¶ˆæ¯ä¸­é—´ä»¶å¤„ç†èŠ‚ç‚¹ï¼Œä¸€ä¸ªkafkaèŠ‚ç‚¹å°±æ˜¯ä¸€ä¸ªbrokerï¼Œä¸€ä¸ªæˆ–å¤šä¸ªBrokerå¯ä»¥ç»„æˆä¸€ä¸ªkafkaé›†ç¾¤ã€‚ Topic kafkaæ ¹æ®Topicå¯¹æ¶ˆæ¯è¿›è¡Œåˆ†ç±»ï¼Œå‘å¸ƒåˆ°kafkaé›†ç¾¤çš„æ¯æ¡æ¶ˆæ¯éƒ½éœ€è¦æŒ‡å®šä¸€ä¸ªTopic Producer æ¶ˆæ¯ç”Ÿäº§è€…ï¼Œå‘Brokerå‘é€æ¶ˆæ¯çš„å®¢æˆ·ç«¯ Consumer æ¶ˆæ¯æ¶ˆè´¹è€…ï¼Œä»Brokerè¯»å–æ¶ˆæ¯çš„å®¢æˆ·ç«¯ ConsumerGroup æ¯ä¸ªconsumerå±äºä¸€ä¸ªç‰¹å®šçš„Consumer Groupï¼Œä¸€æ¡æ¶ˆæ¯å¯ä»¥è¢«å¤šä¸ªä¸åŒçš„Consumeræ¶ˆè´¹ï¼Œä½†æ˜¯ä¸€ä¸ªConsumer Groupä¸­åªèƒ½æœ‰ä¸€ä¸ªconsumerèƒ½æ¶ˆè´¹è¯¥æ¶ˆæ¯ Partition ç‰©ç†ä¸Šçš„æ¦‚å¿µï¼Œä¸€ä¸ªtopicå¯ä»¥åˆ†ä¸ºå¤šä¸ªpartitionï¼Œæ¯ä¸ªpartitionå†…éƒ¨æ¶ˆæ¯æ˜¯æœ‰åºçš„ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:3","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.3 åˆ›å»ºä¸»é¢˜topic topic kafkaæ¶ˆæ¯é€»è¾‘çš„åˆ’åˆ† topicæ˜¯ä»€ä¹ˆæ¦‚å¿µ? topicå¯ä»¥å®ç°æ¶ˆæ¯çš„åˆ†ç±»ï¼Œä¸åŒæ¶ˆè´¹è€…è®¢é˜…ä¸åŒçš„topicã€‚ æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åˆ›å»ºåä¸º\"test\"çš„topicï¼Œè¿™ä¸ªtopicåªæœ‰ä¸€ä¸ªpartitionï¼Œå¹¶ä¸”å¤‡ä»½å› å­ä¹Ÿè®¾ç½®ä¸º1; ./kafka-topics.sh --create --zookeeper 172.16.253.35:2181 --replication-factor 1 --partitions 1 --topic testæŸ¥çœ‹å½“å‰kafkaå†…æœ‰å“ªäº›topic ./ kafka-topics.sh --list --zookeeper 172.16.253.35:2181 ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:4","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.4 å‘é€æ¶ˆæ¯ kafkaè‡ªå¸¦äº†ä¸€ä¸ªproducerå‘½ä»¤å®¢æˆ·ç«¯ï¼Œå¯ä»¥ä»æœ¬åœ°æ–‡ä»¶ä¸­è¯»å–å†…å®¹ï¼Œæˆ–è€…æˆ‘ä»¬ä¹Ÿå¯ä»¥ä»¥å‘½ä»¤è¡Œä¸­ç›´æ¥è¾“å…¥å†…å®¹ï¼Œå¹¶å°†è¿™äº›å†…å®¹ä»¥æ¶ˆæ¯çš„å½¢å¼å‘é€åˆ°kafkaé›†ç¾¤ä¸­ã€‚åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¯ä¸€ä¸ªè¡Œä¼šè¢«å½“åšæˆä¸€ä¸ªç‹¬ç«‹çš„æ¶ˆæ¯ã€‚ ä½¿ç”¨kafkaçš„å‘é€æ¶ˆæ¯çš„å®¢æˆ·ç«¯ï¼ŒæŒ‡å®šå‘é€åˆ°çš„kafkaæœåŠ¡å™¨åœ°å€å’Œtopic ./kafka-console-producer.sh --broker-list 10.31.167.10:9092 --topic test","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:5","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.5 æ¶ˆè´¹æ¶ˆæ¯ å¯¹äºconsumer, kafkaåŒæ ·ä¹Ÿæºå¸¦äº†ä¸€ä¸ªå‘½ä»¤è¡Œå®¢æˆ·ç«¯ï¼Œä¼šå°†è·å–åˆ°å†…å®¹åœ¨å‘½ä»¤ä¸­è¿›è¡Œè¾“å‡ºï¼Œé»˜è®¤æ˜¯æ¶ˆè´¹æœ€æ–°çš„æ¶ˆæ¯ã€‚ä½¿ç”¨kafkaçš„æ¶ˆè´¹è€…æ¶ˆæ¯çš„å®¢æˆ·ç«¯ï¼Œä»æŒ‡å®škafkaæœåŠ¡å™¨çš„æŒ‡å®štopicä¸­æ¶ˆè´¹æ¶ˆæ¯ æ–¹å¼ä¸€:ä»å½“å‰ä¸»é¢˜ä¸­æœ€åä¸€æ¡æ¶ˆæ¯çš„offsetï¼ˆåç§»é‡ï¼‰+1å¼€å§‹æ¶ˆè´¹ ./kafka-console-consumer.sh --bootstrap-server 10.31.167.10:9092 --topic test æ–¹å¼äºŒâˆ¶ä»å½“å‰ä¸»é¢˜ä¸­çš„ç¬¬ä¸€æ¡æ¶ˆæ¯å¼€å§‹æ¶ˆè´¹ ./kafxa-console-consumer.sh --bootstrap-server 10.31.167.10:9092 --from-beginning --topic test","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:6","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.6 å…³äºæ¶ˆæ¯çš„ç»†èŠ‚ ç”Ÿäº§è€…å°†æ¶ˆæ¯å‘é€ç»™brokerï¼Œbrokerä¼šå°†æ¶ˆæ¯ä¿å­˜åœ¨æœ¬åœ°çš„æ—¥å¿—æ–‡ä»¶ä¸­ /usr/ local/kafka/data/kafka-logs/ä¸»é¢˜-åˆ†åŒº/0000000o.log æ¶ˆæ¯çš„ä¿å­˜æ˜¯æœ‰åºçš„ï¼Œé€šè¿‡offsetåç§»é‡æ¥æè¿°æ¶ˆæ¯çš„æœ‰åºæ€§ æ¶ˆè´¹è€…æ¶ˆè´¹æ¶ˆæ¯æ—¶ä¹Ÿæ˜¯é€šè¿‡offsetæ¥æè¿°å½“å‰è¦æ¶ˆè´¹çš„é‚£æ¡æ¶ˆæ¯çš„ä½ç½® ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:7","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.7å•æ’­æ¶ˆæ¯ åœ¨ä¸€ä¸ªkafkaçš„topicä¸­ï¼Œå¯åŠ¨ä¸¤ä¸ªæ¶ˆè´¹è€…ï¼Œä¸€ä¸ªç”Ÿäº§è€…ï¼Œé—®:ç”Ÿäº§è€…å‘é€æ¶ˆæ¯ï¼Œè¿™æ¡æ¶ˆæ¯æ˜¯å¦åŒæ—¶ä¼šè¢«ä¸¤ä¸ªæ¶ˆè´¹è€…æ¶ˆè´¹? å¦‚æœå¤šä¸ªæ¶ˆè´¹è€…åœ¨åŒä¸€ä¸ªæ¶ˆè´¹ç»„ï¼Œé‚£ä¹ˆåªæœ‰ä¸€ä¸ªæ¶ˆè´¹è€…å¯ä»¥æ”¶åˆ°è®¢é˜…çš„topicä¸­çš„æ¶ˆæ¯ã€‚æ¢è¨€ä¹‹ï¼ŒåŒä¸€ä¸ªæ¶ˆè´¹ç»„ä¸­åªèƒ½æœ‰ä¸€ä¸ªæ¶ˆè´¹è€…æ”¶åˆ°ä¸€ä¸ªtopicä¸­çš„æ¶ˆæ¯ã€‚ ./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092--consumer-property group.id=testGroup --topic test ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:8","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.8 å¤šæ’­æ¶ˆæ¯ ä¸åŒçš„æ¶ˆè´¹ç»„è®¢é˜…åŒä¸€ä¸ªtopicï¼Œé‚£ä¹ˆä¸åŒçš„æ¶ˆè´¹ç»„ä¸­åªæœ‰ä¸€ä¸ªæ¶ˆè´¹è€…èƒ½æ”¶åˆ°æ¶ˆæ¯ã€‚å®é™…ä¸Šä¹Ÿæ˜¯å¤šä¸ªæ¶ˆè´¹ç»„ä¸­çš„å¤šä¸ªæ¶ˆè´¹è€…æ”¶åˆ°äº†åŒä¸€ä¸ªæ¶ˆæ¯ã€‚ ./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092--consumer-property group.id=testGroupl --topic test./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092--consumer-property group.id=testGroup2 --topic testä¸‹å›¾å°±æ˜¯æè¿°å¤šæ’­å’Œå•æ’­æ¶ˆæ¯çš„åŒºåˆ«: ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:9","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.9 æŸ¥çœ‹æ¶ˆè´¹ç»„çš„è¯¦ç»†ä¿¡æ¯ é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯ä»¥æŸ¥çœ‹åˆ°æ¶ˆè´¹ç»„çš„ç›¸ä¿¡ä¿¡æ¯ï¸° ./kafka-consumer-groups.sh --bootstrap-server 172.16.253.38:9092 --describe --group testGroup é‡ç‚¹å…³æ³¨ä»¥ä¸‹å‡ ä¸ªä¿¡æ¯âˆ¶ current-offset:æœ€åè¢«æ¶ˆè´¹çš„æ¶ˆæ¯çš„åç§»é‡ Log-end-offset:æ¶ˆæ¯æ€»é‡(æœ€åä¸€æ¡æ¶ˆæ¯çš„åç§»é‡) Lag:ç§¯å‹äº†å¤šå°‘æ¡æ¶ˆæ¯ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:3:10","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"å››ã€Kafka ä¸­ä¸»é¢˜å’Œåˆ†åŒºçš„æ¦‚å¿µ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:4:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"4.1 ä¸»é¢˜Topic ä¸»é¢˜-topicåœ¨kafkaä¸­æ˜¯ä¸€ä¸ªé€»è¾‘çš„æ¦‚å¿µï¼Œkafkaé€šè¿‡topicå°†æ¶ˆæ¯è¿›è¡Œåˆ†ç±»ã€‚ä¸åŒçš„topicä¼šè¢«è®¢é˜…è¯¥topicçš„æ¶ˆè´¹è€…æ¶ˆè´¹ã€‚ ä½†æ˜¯æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœè¯´è¿™ä¸ªtopicä¸­çš„æ¶ˆæ¯éå¸¸éå¸¸å¤šï¼Œå¤šåˆ°éœ€è¦å‡ Tæ¥å­˜ï¼Œå› ä¸ºæ¶ˆæ¯æ˜¯ä¼šè¢«ä¿å­˜åˆ°logæ—¥å¿—æ–‡ä»¶ä¸­çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªæ–‡ä»¶è¿‡å¤§çš„é—®é¢˜, kafkaæå‡ºäº†Partitionåˆ†åŒºçš„æ¦‚å¿µ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:4:1","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"4.2 partition åˆ†åŒº 1)åˆ†åŒºçš„æ¦‚å¿µ é€šè¿‡partitionå°†ä¸€ä¸ªtopicä¸­çš„æ¶ˆæ¯åˆ†åŒºæ¥å­˜å‚¨ã€‚ è¿™æ ·çš„å¥½å¤„æœ‰å¤šä¸ª: åˆ†åŒºå­˜å‚¨ï¼Œå¯ä»¥è§£å†³ç»Ÿä¸€å­˜å‚¨æ–‡ä»¶è¿‡å¤§çš„é—®é¢˜ æä¾›äº†è¯»å†™çš„ååé‡:è¯»å’Œå†™å¯ä»¥åŒæ—¶åœ¨å¤šä¸ªåˆ†åŒºä¸­è¿›è¡Œ 2)åˆ›å»ºå¤šåˆ†åŒºçš„ä¸»é¢˜ ./kafka-topics.sh --create --zokeeper 172.16.253.35:2181 --replication-factor l --partitions 2 --topic test1 ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:4:2","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"4.3 kafka ä¸­æ¶ˆæ¯æ—¥å¿—æ–‡ä»¶ä¸­ä¿å­˜çš„å†…å®¹ . 00000.log:è¿™ä¸ªæ–‡ä»¶ä¸­ä¿å­˜çš„å°±æ˜¯æ¶ˆæ¯ _consumer_offsets-49 kafkaå†…éƒ¨è‡ªå·±åˆ›å»ºäº†_consumer_offsetsä¸»é¢˜åŒ…å«äº†50ä¸ªåˆ†åŒºã€‚è¿™ä¸ªä¸»é¢˜ç”¨æ¥å­˜æ”¾æ¶ˆè´¹è€…æ¶ˆè´¹æŸä¸ªä¸»é¢˜çš„åç§»é‡ã€‚ å› ä¸ºæ¯ä¸ªæ¶ˆè´¹è€…éƒ½ä¼šè‡ªå·±ç»´æŠ¤ç€æ¶ˆè´¹çš„ä¸»é¢˜çš„åç§»é‡ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸ªæ¶ˆè´¹è€…ä¼šæŠŠæ¶ˆè´¹çš„ä¸»é¢˜çš„åç§»é‡è‡ªä¸»ä¸ŠæŠ¥ç»™kafkaä¸­çš„é»˜è®¤ä¸»é¢˜consumer_offsetsã€‚å› æ­¤kafkaä¸ºäº†æå‡è¿™ä¸ªä¸»é¢˜çš„å¹¶å‘æ€§ï¼Œé»˜è®¤è®¾ç½®äº†50ä¸ªåˆ†åŒºã€‚(å¯ä»¥é€šè¿‡offsets.topic.num.paritionsè®¾ç½®)ï¼Œè¿™æ ·å¯ä»¥é€šè¿‡åŠ æœºå™¨çš„æ–¹å¼æŠ—å¤§å¹¶å‘ã€‚ æäº¤åˆ°å“ªä¸ªåˆ†åŒºï¸°é€šè¿‡hashå‡½æ•°: hash(consumerGroupld) %_consumer_offsetsä¸»é¢˜çš„åˆ†åŒºæ•° æäº¤åˆ°è¯¥ä¸»é¢˜ä¸­çš„å†…å®¹æ˜¯: keyæ˜¯consumerGroupld+topic+åˆ†åŒºå·ï¼Œvalueå°±æ˜¯å½“å‰offsetçš„å€¼ æ–‡ä»¶ä¸­ä¿å­˜çš„æ¶ˆæ¯ï¼Œkafkaä¼šå®šæœŸæ¸…ç†topicé‡Œçš„æ¶ˆæ¯ï¼Œæœ€åå°±ä¿ç•™æœ€æ–°çš„é‚£æ¡æ•°æ®é»˜è®¤ä¿å­˜7å¤©ã€‚ä¸ƒå¤©åˆ°åæ¶ˆæ¯ä¼šè¢«åˆ é™¤ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:4:3","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"äº”ã€Kafkaé›†ç¾¤æ“ä½œ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:5:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"5.1 æ­å»ºkafkaé›†ç¾¤ï¼ˆä¸‰ä¸ªbrokerï¼‰ åˆ›å»ºä¸‰ä¸ªserver.propertiesæ–‡ä»¶ #0 1 2 broker.id=2 #9092 9093 9094 listeners=PLAINTEXT ://192.168.65.60:9094 #kafka-logs kafka-logs-1 kafka-logs-2 log.dir=/usr/ local/ data/ kafka-logs-2 ./ kafka-server-start.sh -daemon ../config/server.properties ./ kafka-server-start.sh -daemon ../config/server1.properties ./ kafka-server-start.sh -daemon ../config/server2.properties æ ¡éªŒæ˜¯å¦å¯åŠ¨æˆåŠŸ è¿›å…¥åˆ°zkä¸­æŸ¥çœ‹/brokers/idsä¸­è¿‡æ˜¯å¦æœ‰ä¸‰ä¸ªznode (0,1,2) ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:5:1","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"5.2 å‰¯æœ¬çš„æ¦‚å¿µ åœ¨åˆ›å»ºä¸»é¢˜æ—¶ï¼Œé™¤äº†æŒ‡æ˜äº†ä¸»é¢˜çš„åˆ†åŒºæ•°ä»¥å¤–ï¼Œè¿˜æŒ‡æ˜äº†å‰¯æœ¬æ•°ï¼Œé‚£ä¹ˆå‰¯æœ¬æ˜¯ä¸€ä¸ªä»€ä¹ˆæ¦‚å¿µå‘¢? å‰¯æœ¬æ˜¯ä¸ºäº†ä¸ºä¸»é¢˜ä¸­çš„åˆ†åŒºåˆ›å»ºå¤šä¸ªå¤‡ä»½ï¼Œå¤šä¸ªå‰¯æœ¬åœ¨kafkaé›†ç¾¤çš„å¤šä¸ªbrokerä¸­ï¼Œä¼šæœ‰ä¸€ä¸ªå‰¯æœ¬ä½œä¸ºleaderï¼Œå…¶ä»–æ˜¯followerã€‚ ç”Ÿäº§è€…ä¸æ¶ˆè´¹è€…åªä¼šä¸leaderäº¤äº’æ¶ˆæ¯ï¼Œè€Œfolloweråªä¼šä¸leaderä¿æŒåŒæ­¥ä»¥å¤‡ä¸æ—¶ä¹‹éœ€ã€‚ leader: kafkaçš„å†™å’Œè¯»çš„æ“ä½œï¼Œéƒ½å‘ç”Ÿåœ¨leaderä¸Šã€‚leaderè´Ÿè´£æŠŠæ•°æ®åŒæ­¥ç»™followerã€‚å½“leaderæŒ‚äº†ï¼Œç»è¿‡ä¸»ä»é€‰ä¸¾ï¼Œä»å¤šä¸ªfollowerä¸­é€‰ä¸¾äº§ç”Ÿä¸€ä¸ªæ–°çš„leader followerï¼š æ¥æ”¶leaderçš„åŒæ­¥çš„æ•°æ® isr: å¯ä»¥åŒæ­¥å’Œå·²åŒæ­¥çš„èŠ‚ç‚¹ä¼šè¢«å­˜å…¥åˆ°isré›†åˆä¸­ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªç»†èŠ‚ï¸°å¦‚æœisrä¸­çš„èŠ‚ç‚¹æ€§èƒ½è¾ƒå·®ï¼Œä¼šè¢«æå‡ºisré›†åˆã€‚) ç†è§£: é›†ç¾¤ä¸­æœ‰å¤šä¸ªbrokerï¼Œåˆ›å»ºä¸»é¢˜æ—¶å¯ä»¥æŒ‡æ˜ä¸»é¢˜æœ‰å¤šä¸ªåˆ†åŒº(æŠŠæ¶ˆæ¯æ‹†åˆ†åˆ°ä¸åŒçš„åˆ†åŒºä¸­å­˜å‚¨)ï¼Œå¯ä»¥ä¸ºåˆ†åŒºåˆ›å»ºå¤šä¸ªå‰¯æœ¬ï¼Œä¸åŒçš„å‰¯æœ¬å­˜æ”¾åœ¨ä¸åŒçš„brokeré‡Œã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:5:2","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"5.3 å…³äºé›†ç¾¤æ¶ˆè´¹ å‘é›†ç¾¤å‘é€æ¶ˆæ¯âˆ¶ ./kafka-console-consumer . sh --bootstrap-server 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --from-beginning --consumer-property group.id=testGroupl --topic my-replicated-topic ä»é›†ç¾¤ä¸­æ¶ˆè´¹æ¶ˆæ¯ ./kafka-console-producer .sh --broker-list 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --topicmy-replicated-topic æŒ‡å®šæ¶ˆè´¹ç»„æ¥æ¶ˆè´¹æ¶ˆæ¯ ./kafka-console-consumer .sh --bootstrap-server 172.16.253.38âˆ¶9092,172.16.253.38:9093,172.16.253.38:9094 --from-beginning --consumer-property group.id=testGroupl --topic my-replicated-topic ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:5:3","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"5.4 åˆ†åŒºåˆ†æ¶ˆè´¹ç»„çš„é›†ç¾¤æ¶ˆè´¹ä¸­çš„ç»†èŠ‚ ä¸€ä¸ªpartitionåªèƒ½è¢«ä¸€ä¸ªæ¶ˆè´¹ç»„ä¸­çš„ä¸€ä¸ªæ¶ˆè´¹è€…æ¶ˆè´¹ï¼Œç›®çš„æ˜¯ä¸ºäº†ä¿è¯æ¶ˆè´¹çš„é¡ºåºæ€§ï¼Œä½†æ˜¯å¤šä¸ªpartionçš„å¤šä¸ªæ¶ˆè´¹è€…æ¶ˆè´¹çš„æ€»çš„é¡ºåºæ€§æ˜¯å¾—ä¸åˆ°ä¿è¯çš„ï¼Œé‚£æ€ä¹ˆåšåˆ°æ¶ˆè´¹çš„æ€»é¡ºåºæ€§å‘¢? partitionçš„æ•°é‡å†³å®šäº†æ¶ˆè´¹ç»„ä¸­æ¶ˆè´¹è€…çš„æ•°é‡ï¼Œå»ºè®®åŒä¸€ä¸ªæ¶ˆè´¹ç»„ä¸­æ¶ˆè´¹è€…çš„æ•°é‡ä¸è¦è¶…è¿‡partitionçš„æ•°é‡ï¼Œå¦åˆ™å¤šçš„æ¶ˆè´¹è€…æ¶ˆè´¹ä¸åˆ°æ¶ˆæ¯ å¦‚æœæ¶ˆè´¹è€…æŒ‚äº†ï¼Œé‚£ä¹ˆä¼šè§¦å‘rebalanceæœºåˆ¶ï¼ˆåé¢ä»‹ç»)ï¼Œä¼šè®©å…¶ä»–æ¶ˆè´¹è€…æ¥æ¶ˆè´¹è¯¥åˆ†åŒº ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:5:4","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"å…­ã€ä¸“é¢˜1 Kafka é›†ç¾¤Controller ã€Rebalance å’ŒHW ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:6:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"1.controller é›†ç¾¤ä¸­è°æ¥å……å½“controller æ¯ä¸ªbrokerå¯åŠ¨æ—¶ä¼šå‘zkåˆ›å»ºä¸€ä¸ªä¸´æ—¶åºå·èŠ‚ç‚¹ï¼Œè·å¾—çš„åºå·æœ€å°çš„é‚£ä¸ªbrokerå°†ä¼šä½œä¸ºé›†ç¾¤ä¸­çš„controllerï¼Œè´Ÿè´£è¿™ä¹ˆå‡ ä»¶äº‹: å½“é›†ç¾¤ä¸­æœ‰ä¸€ä¸ªå‰¯æœ¬çš„leaderæŒ‚æ‰ï¼Œéœ€è¦åœ¨é›†ç¾¤ä¸­é€‰ä¸¾å‡ºä¸€ä¸ªæ–°çš„leaderï¼Œé€‰ä¸¾çš„è§„åˆ™æ˜¯ä»isré›†åˆä¸­æœ€å·¦è¾¹è·å¾—ã€‚ å½“é›†ç¾¤ä¸­æœ‰brokeræ–°å¢æˆ–å‡å°‘ï¼Œcontrollerä¼šåŒæ­¥ä¿¡æ¯ç»™å…¶ä»–broker å½“é›†ç¾¤ä¸­æœ‰åˆ†åŒºæ–°å¢æˆ–å‡å°‘ï¼Œcontrollerä¼šåŒæ­¥ä¿¡æ¯ç»™å…¶ä»–broker ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:6:1","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"2.rebalanceæœºåˆ¶ å‰æ:æ¶ˆè´¹ç»„ä¸­çš„æ¶ˆè´¹è€…æ²¡æœ‰æŒ‡æ˜åˆ†åŒºæ¥æ¶ˆè´¹ è§¦å‘çš„æ¡ä»¶:å½“æ¶ˆè´¹ç»„ä¸­çš„æ¶ˆè´¹è€…å’Œåˆ†åŒºçš„å…³ç³»å‘ç”Ÿå˜åŒ–çš„æ—¶å€™ åˆ†åŒºåˆ†é…çš„ç­–ç•¥:åœ¨rebalanceä¹‹å‰ï¼Œ åˆ†åŒºæ€ä¹ˆåˆ†é…ä¼šæœ‰è¿™ä¹ˆä¸‰ç§ç­–ç•¥ range: æ ¹æ®å…¬ç¤ºè®¡ç®—å¾—åˆ°æ¯ä¸ªæ¶ˆè´¹æ¶ˆè´¹å“ªå‡ ä¸ªåˆ†åŒº:å‰é¢çš„æ¶ˆè´¹è€…æ˜¯åˆ†åŒºæ€»æ•°/æ¶ˆè´¹ è€…æ•°é‡+1,ä¹‹åçš„æ¶ˆè´¹è€…æ˜¯åˆ†åŒºæ€»æ•°/æ¶ˆè´¹è€…æ•°é‡. è½®è¯¢:å¤§å®¶è½®ç€æ¥ sticky: ç²˜åˆç­–ç•¥ï¼Œå¦‚æœéœ€è¦rebalance, ä¼šåœ¨ä¹‹å‰å·²åˆ†é…çš„åŸºç¡€ä¸Šè°ƒæ•´ï¼Œä¸ä¼šæ”¹å˜ä¹‹å‰çš„åˆ†é…æƒ…å†µã€‚å¦‚æœè¿™ä¸ªç­–ç•¥æ²¡æœ‰å¼€ï¼Œé‚£ä¹ˆå°±è¦è¿›è¡Œå…¨éƒ¨çš„é‡æ–°åˆ†é…ã€‚å»ºè®®å¼€å¯ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:6:2","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"ä¸ƒã€ä¸“é¢˜2 Kafkaä¸­çš„ä¼˜åŒ–é—®é¢˜(é¢è¯•é—®é¢˜) ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:7:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"1.å¦‚ä½•é˜²æ­¢æ¶ˆæ¯ä¸¢å¤± â½£äº§è€…ï¼š ä½¿â½¤åŒæ­¥å‘é€ æŠŠackè®¾æˆ1ï¼ˆleader æˆåŠŸå†™å…¥ï¼‰æˆ–è€…all(æ‰€æœ‰brokerå®ŒæˆåŒæ­¥)ï¼Œå¹¶ä¸”è®¾ç½®åŒæ­¥çš„åˆ†åŒºæ•°\u003e=2 æ¶ˆè´¹è€…ï¼šæŠŠâ¾ƒåŠ¨æäº¤æ”¹æˆâ¼¿åŠ¨æäº¤ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:7:1","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"2.å¦‚ä½•é˜²â½Œé‡å¤æ¶ˆè´¹ åœ¨é˜²â½Œæ¶ˆæ¯ä¸¢å¤±çš„â½…æ¡ˆä¸­ï¼Œå¦‚æœâ½£äº§è€…å‘é€å®Œæ¶ˆæ¯åï¼Œå› ä¸ºâ½¹ç»œæŠ–åŠ¨ï¼Œæ²¡æœ‰æ”¶åˆ°ackï¼Œä½†å®é™… ä¸Šbrokerå·²ç»æ”¶åˆ°äº†ã€‚ æ­¤æ—¶â½£äº§è€…ä¼šè¿›â¾é‡è¯•ï¼Œäºæ˜¯brokerå°±ä¼šæ”¶åˆ°å¤šæ¡ç›¸åŒçš„æ¶ˆæ¯ï¼Œâ½½é€ æˆæ¶ˆè´¹è€…çš„é‡å¤æ¶ˆè´¹ã€‚ æ€ä¹ˆè§£å†³ï¼š â½£äº§è€…å…³é—­é‡è¯•ï¼šä¼šé€ æˆä¸¢æ¶ˆæ¯ï¼ˆä¸å»ºè®®ï¼‰ æ¶ˆè´¹è€…è§£å†³â¾®å¹‚ç­‰æ€§æ¶ˆè´¹é—®é¢˜ï¼š æ‰€è°“çš„å¹‚ç­‰æ€§ï¼šå¤šæ¬¡è®¿é—®çš„ç»“æœæ˜¯â¼€æ ·çš„ã€‚ å¯¹äºrestçš„è¯·æ±‚ï¼ˆgetï¼ˆå¹‚ç­‰ï¼‰ã€postï¼ˆâ¾®å¹‚ ç­‰ï¼‰ã€putï¼ˆå¹‚ç­‰ï¼‰ã€deleteï¼ˆå¹‚ç­‰ï¼‰ï¼‰ å¹‚ç­‰ï¼šå¤šæ¬¡è®¿é—®çš„ç»“æœæ˜¯ä¸€æ ·çš„ è§£å†³â½…æ¡ˆï¼š åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè”åˆä¸»é”®ï¼Œé˜²â½Œç›¸åŒçš„ä¸»é”® åˆ›å»ºå‡ºå¤šæ¡è®°å½• ä½¿â½¤åˆ†å¸ƒå¼é”ï¼Œä»¥ä¸šåŠ¡idä¸ºé”ã€‚ä¿è¯åªæœ‰â¼€æ¡è®°å½•èƒ½å¤Ÿåˆ›å»ºæˆåŠŸ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:7:2","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"3.å¦‚ä½•åšåˆ°æ¶ˆæ¯çš„é¡ºåºæ¶ˆè´¹ â½£äº§è€…ï¼šä¿è¯æ¶ˆæ¯æŒ‰é¡ºåºæ¶ˆè´¹ï¼Œä¸”æ¶ˆæ¯ä¸ä¸¢å¤±â€”â€”ä½¿â½¤åŒæ­¥çš„å‘é€ï¼Œackè®¾ç½®æˆâ¾®0çš„ å€¼ã€‚ æ¶ˆè´¹è€…ï¼šä¸»é¢˜åªèƒ½è®¾ç½®â¼€ä¸ªåˆ†åŒºï¼Œæ¶ˆè´¹ç»„ä¸­åªèƒ½æœ‰â¼€ä¸ªæ¶ˆè´¹è€… kafkaçš„é¡ºåºæ¶ˆè´¹ä½¿â½¤åœºæ™¯ä¸å¤šï¼Œå› ä¸ºç‰ºç‰²æ‰äº†æ€§èƒ½ï¼Œä½†æ˜¯â½å¦‚rocketmqåœ¨è¿™â¼€å—æœ‰ä¸“â»”çš„åŠŸèƒ½å·²è®¾è®¡å¥½ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:7:3","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"4.å¦‚ä½•è§£å†³æ¶ˆæ¯ç§¯å‹é—®é¢˜ 1ï¼‰æ¶ˆæ¯ç§¯å‹é—®é¢˜çš„å‡ºç° æ¶ˆæ¯çš„æ¶ˆè´¹è€…çš„æ¶ˆè´¹é€Ÿåº¦è¿œèµ¶ä¸ä¸Šâ½£äº§è€…çš„â½£äº§æ¶ˆæ¯çš„é€Ÿåº¦ï¼Œå¯¼è‡´kafkaä¸­æœ‰â¼¤é‡çš„æ•°æ®æ²¡æœ‰è¢«æ¶ˆè´¹ã€‚ éšç€æ²¡æœ‰è¢«æ¶ˆè´¹çš„æ•°æ®å †ç§¯è¶Šå¤šï¼Œæ¶ˆè´¹è€…å¯»å€çš„æ€§èƒ½ä¼šè¶Šæ¥è¶Šå·®ï¼Œæœ€åå¯¼è‡´æ•´ä¸ª kafkaå¯¹å¤–æä¾›çš„æœåŠ¡çš„æ€§èƒ½å¾ˆå·®ï¼Œä»â½½é€ æˆå…¶ä»–æœåŠ¡ä¹Ÿè®¿é—®é€Ÿåº¦å˜æ…¢ï¼Œé€ æˆæœåŠ¡é›ªå´©ã€‚ 2ï¼‰æ¶ˆæ¯ç§¯å‹çš„è§£å†³â½…æ¡ˆ åœ¨è¿™ä¸ªæ¶ˆè´¹è€…ä¸­ï¼Œä½¿â½¤å¤šçº¿ç¨‹ï¼Œå……åˆ†åˆ©â½¤æœºå™¨çš„æ€§èƒ½è¿›â¾æ¶ˆè´¹æ¶ˆæ¯ã€‚ é€šè¿‡ä¸šåŠ¡çš„æ¶æ„è®¾è®¡ï¼Œæå‡ä¸šåŠ¡å±‚â¾¯æ¶ˆè´¹çš„æ€§èƒ½ã€‚ åˆ›å»ºå¤šä¸ªæ¶ˆè´¹ç»„ï¼Œå¤šä¸ªæ¶ˆè´¹è€…ï¼Œéƒ¨ç½²åˆ°å…¶ä»–æœºå™¨ä¸Šï¼Œâ¼€èµ·æ¶ˆè´¹ï¼Œæâ¾¼æ¶ˆè´¹è€…çš„æ¶ˆè´¹é€Ÿåº¦ åˆ›å»ºâ¼€ä¸ªæ¶ˆè´¹è€…ï¼Œè¯¥æ¶ˆè´¹è€…åœ¨kafkaå¦å»ºâ¼€ä¸ªä¸»é¢˜ï¼Œé…ä¸Šå¤šä¸ªåˆ†åŒºï¼Œå¤šä¸ªåˆ†åŒºå†é…ä¸Šå¤šä¸ª æ¶ˆè´¹è€…ã€‚è¯¥æ¶ˆè´¹è€…å°†pollä¸‹æ¥çš„æ¶ˆæ¯ï¼Œä¸è¿›â¾æ¶ˆè´¹ï¼Œç›´æ¥è½¬å‘åˆ°æ–°å»ºçš„ä¸»é¢˜ä¸Šã€‚æ­¤æ—¶ï¼Œæ–° çš„ä¸»é¢˜çš„å¤šä¸ªåˆ†åŒºçš„å¤šä¸ªæ¶ˆè´¹è€…å°±å¼€å§‹â¼€èµ·æ¶ˆè´¹äº†ã€‚â€”â€”ä¸å¸¸â½¤ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:7:4","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"5.å®ç°å»¶æ—¶é˜Ÿåˆ—çš„æ•ˆæœ 1ï¼‰åº”â½¤åœºæ™¯ è®¢å•åˆ›å»ºåï¼Œè¶…è¿‡30åˆ†é’Ÿæ²¡æœ‰â½€ä»˜ï¼Œåˆ™éœ€è¦å–æ¶ˆè®¢å•ï¼Œè¿™ç§åœºæ™¯å¯ä»¥é€šè¿‡å»¶æ—¶é˜Ÿåˆ—æ¥å®ç° 2ï¼‰å…·ä½“â½…æ¡ˆ kafkaä¸­åˆ›å»ºåˆ›å»ºç›¸åº”çš„ä¸»é¢˜ æ¶ˆè´¹è€…æ¶ˆè´¹è¯¥ä¸»é¢˜çš„æ¶ˆæ¯(è½®è¯¢) æ¶ˆè´¹è€…æ¶ˆè´¹æ¶ˆæ¯æ—¶åˆ¤æ–­æ¶ˆæ¯çš„åˆ›å»ºæ—¶é—´å’Œå½“å‰æ—¶é—´æ˜¯å¦è¶…è¿‡30åˆ†é’Ÿ(å‰ææ˜¯è®¢å•æ²¡æ”¯ä»˜) å¦‚æœæ˜¯:å»æ•°æ®åº“ä¸­ä¿®æ”¹è®¢å•çŠ¶æ€ä¸ºå·²å–æ¶ˆ å¦‚æœå¦:è®°å½•å½“å‰æ¶ˆæ¯çš„offset,å¹¶ä¸å†ç»§ç»­æ¶ˆè´¹ä¹‹åçš„æ¶ˆæ¯ã€‚ç­‰å¾…1åˆ†é’Ÿåï¼Œå†æ¬¡å‘kafkaæ‹‰å–è¯¥offsetåŠä¹‹åçš„æ¶ˆ æ¯ï¼Œç»§ç»­è¿›è¡Œåˆ¤æ–­ï¼Œä»¥æ­¤åå¤ã€‚ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:7:5","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"å…«ã€Kafka-eagleç›‘æ§å¹³å° ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:8:0","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"1.æ­å»º å»kafka-eagleå®˜â½¹ä¸‹è½½å‹ç¼©åŒ… http://download.kafka-eagle.org/ åˆ†é…â¼€å°è™šæ‹Ÿæœº è™šæ‹Ÿæœºä¸­å®‰è£…jdk è§£å‹ç¼©kafka-eagleçš„å‹ç¼©åŒ… ç»™kafka-eagleé…ç½®ç¯å¢ƒå˜é‡ export KE_HOME=/usr/local/kafka-eagle export PATH=$PATH:$KE_HOME/bin éœ€è¦ä¿®æ”¹kafka-eagleå†…éƒ¨çš„é…ç½®â½‚ä»¶ï¼š vim system-config.properties ä¿®æ”¹â¾¥â¾¯çš„zkçš„åœ°å€å’Œmysqlçš„åœ°å€ è¿›â¼Šåˆ°binä¸­ï¼Œé€šè¿‡å‘½ä»¤æ¥å¯åŠ¨ ./ke.sh start ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:8:1","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["Kafka"],"content":"1.ä½¿ç”¨ kafka-eagle ç›‘æ§é¢æ¿ kafka-ç›‘æ§æŸ¥çœ‹èŠ‚ç‚¹ä¿¡æ¯ kafka-eagleæŸ¥çœ‹æ¶ˆè´¹ç»„ä¸æ¶ˆè´¹ä¸»é¢˜ä¿¡æ¯ kafka-eagleæŸ¥çœ‹æ¶ˆæ¯ç§¯å‹æƒ…å†µ ","date":"2021-12-04","objectID":"/posts/zookeeper/kafka01/:8:2","tags":["Kafka","Zookeeper","ä¸­é—´ä»¶"],"title":"Kafka é›†ç¾¤å®æˆ˜ä¸åŸç†åˆ†æçº¿ä¸Šé—®é¢˜ä¼˜åŒ–","uri":"/posts/zookeeper/kafka01/"},{"categories":["ElasticStack"],"content":"åœ¨ç­‰ä¿2.0 æµ‹è¯„å•ä½å¯¹ä¸šåŠ¡ç³»ç»Ÿè¿›è¡Œè¯„æµ‹åï¼Œç»™å‡ºæ•´æ”¹æ„è§ä¸­æå‡ºï¼š åº”å¯ç”¨å®‰å…¨å®¡è®¡åŠŸèƒ½ï¼Œå®¡è®¡è¦†ç›–åˆ°æ¯ä¸ªç”¨æˆ·ï¼Œå¯¹é‡è¦çš„ç”¨æˆ·è¡Œä¸ºå’Œé‡è¦å®‰å…¨äº‹ä»¶è¿›è¡Œå®¡è®¡ï¼›å»ºè®®å¯¹å¯ç”¨å®‰å…¨å®¡è®¡åŠŸèƒ½ï¼Œå¯¹æ‰€æœ‰ç”¨æˆ·æ“ä½œè¡Œä¸ºåŠç³»ç»Ÿå®‰å…¨äº‹ä»¶è¿›è¡Œå®¡è®¡è®°å½•ã€‚ åº”å¯¹å®¡è®¡è®°å½•è¿›è¡Œä¿æŠ¤ï¼Œå®šæœŸå¤‡ä»½ï¼Œé¿å…å—åˆ°æœªé¢„æœŸçš„åˆ é™¤ã€ä¿®æ”¹æˆ–è¦†ç›–ç­‰ã€‚å»ºè®®å®šæœŸå¯¹å®¡è®¡è®°å½•è¿›è¡Œå¤‡ä»½ï¼Œä¿è¯å®¡è®¡è®°å½•ä¸ä¼šå—åˆ°æœªé¢„æœŸçš„åˆ é™¤ã€ä¿®æ”¹æˆ–è¦†ç›–ã€‚ æ­å»ºELKå¹³å°æ”¶é›†å„ç³»ç»Ÿæ—¥å¿— ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:0:0","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"åº”ç”¨åœºæ™¯ è¦æ”¶é›†çš„è®¾å¤‡æ¸…å•å¦‚ä¸‹ï¼š æ·±ä¿¡æœé˜²ç«å¢™è®¾å¤‡ H3C æ ¸å¿ƒäº¤æ¢æœº æ·±ä¿¡æœSSL VPN è®¾å¤‡ ä¸šåŠ¡é€šç”¨æœåŠ¡å™¨ ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:1:0","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"æ€è·¯ å› ä¸ºæ—¥å¿—é‡ä¸å¤§æ‰€ä»¥ä½¿ç”¨å››å°æœåŠ¡å™¨æ­å»ºELKï¼Œéƒ¨ç½²æƒ…å†µå¦‚ä¸‹ï¼š 192.168.10.106 éƒ¨ç½²ES + head æ’ä»¶ ç”¨æ¥å¤„ç†æ—¥å¿—æ•°æ®\r192.168.10.107 éƒ¨ç½²Logstash æ”¶é›†filebeatæ•°æ®å¹¶å°†æ•°æ®ä¼ é€ç»™ES 192.168.10.108 éƒ¨ç½²Kibana å°†æ•°æ®ä»ESä¸­è¯»å–å‡ºè¿›è¡Œå¯è§†åŒ–å±•ç¤º\r192.168.10.109 éƒ¨ç½²rsyslog + filebeat æ”¶é›†æ±‡æ€»å„ç³»ç»Ÿæ—¥å¿—æ–‡ä»¶å¹¶å°†æ—¥å¿—æ–‡ä»¶ä¼ é€ç»™logstash\rç³»ç»Ÿç‰ˆæœ¬ä¸ºï¼šUbuntu 20.04.3 LTS ELKç»„ä»¶ç‰ˆæœ¬ï¼š7.14.x ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:1:1","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"Rsyslog éƒ¨ç½² rsyslogç”¨äºæ”¶é›†å¯¹ç«¯ç³»ç»Ÿçš„æ—¥å¿—æ¨é€ #æ›¿æ¢æº vim /etc/apt/sources.list deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse #å®‰è£…rsyslog sudo apt-get install rsyslog #ç¼–è¾‘é…ç½®æ–‡ä»¶ vim /etc/rsyslog.conf #è®¾ç½®æ—¥å¿—æ”¶é›†ç›®å½•ï¼Œä»¥ä¸»æœºå+IP+æ—¶é—´çš„æ ¼å¼ å¹¶æ’é™¤æœ¬æœºçš„æ—¥å¿— $template Remote,\"/var/log/attack-syslog/%hostname%_%fromhost-ip%/log_%$YEAR%-%$MONTH%-%$DAY%.log\" #å®šä¹‰æ¨¡æ¿ï¼Œæ¥å—æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ŒåŒºåˆ†äº†ä¸åŒä¸»æœºçš„æ—¥å¿— :fromhost-ip, !isequal, \"127.0.0.1\" ?Remote # è¿‡æ»¤server æœ¬æœºçš„æ—¥å¿— #å¼€å¯udp tcp ä¼ è¾“ $ModLoad imudp $UDPServerRun 514 $ModLoad imtcp $InputTCPServerRun 514 #ç„¶å,ä»¥rootèº«ä»½ä¿®æ”¹rsyslogå¯åŠ¨é…ç½®æ–‡ä»¶(Ubuntuåœ¨/etc/default/rsyslogä¸‹) # Options to syslogd # -m 0 disables 'MARK' messages. # -r enables logging from remote machines # -x disables DNS lookups on messages recieved with -r //ç¦ç”¨æ‰dnsè®°å½•é¡¹ä¸å¤Ÿé½å…¨æˆ–å…¶ä»–çš„æ—¥å¿—ä¸­å¿ƒçš„æ—¥å¿— # See syslogd(8) for more details # SYSLOGD_OPTIONS=\"-r\" #SYSLOGD_OPTIONS=\"-r -x -m 180\" # åŠ  -r é€‰é¡¹ä»¥å…è®¸æ¥å—å¤–æ¥æ—¥å¿—æ¶ˆæ¯ # åŠ  -x ç¦ç”¨æ‰dnsè®°å½•é¡¹ä¸å¤Ÿé½å…¨æˆ–å…¶ä»–çš„æ—¥å¿—ä¸­å¿ƒçš„æ—¥å¿—# # åŠ  -m ä¿®æ”¹syslogçš„å†…éƒ¨markæ¶ˆæ¯å†™å…¥é—´éš”æ—¶é—´ï¼ˆ0ä¸ºå…³é—­ï¼‰ã€‚ä¾‹å¦‚-m 180ï¼Œè¡¨ç¤ºæ¯éš”180åˆ†é’Ÿï¼ˆæ¯å¤©8æ¬¡ï¼‰åœ¨æ—¥å¿—æ–‡ä»¶é‡Œå¢åŠ ä¸€è¡Œæ—¶é—´æˆ³æ¶ˆæ¯ # åŠ  -h é»˜è®¤æƒ…å†µä¸‹ï¼Œsyslogä¸ä¼šå‘é€ä»è¿œç«¯æ¥å—è¿‡æ¥çš„æ¶ˆæ¯åˆ°å…¶ä»–ä¸»æœºï¼Œè€Œä½¿ç”¨è¯¥é€‰é¡¹ï¼Œåˆ™æŠŠè¯¥å¼€å…³æ‰“å¼€ï¼Œæ‰€æœ‰æ¥å—åˆ°çš„ä¿¡æ¯éƒ½å¯æ ¹æ®syslog.confä¸­å®šä¹‰çš„@ä¸»æœºè½¬å‘è¿‡å»ã€‚ # Options to klogd # -2 prints all kernel oops messages twice; once for klogd to decode, and # once for processing with 'ksymoops' # -x disables all klogd processing of oops messages entirely # See klogd(8) for more detailsKLOGD_OPTIONS=\"-x\" #SYSLOG_UMASK=077# set this to a umask value to use for all log files as in umask(1). # By default, all permissions are removed for \"group\" and \"other\". #é‡å¯rsyslog service rsyslog restart #æŸ¥çœ‹å…¶æ˜¯å¦å¯åŠ¨ netstat -nultp | grep 514 #éªŒè¯ #åœ¨rsyslog serverç«¯,ç”¨tailåŠ¨æ€æŸ¥çœ‹ tail -f /var/log/host/'hostname'_'ip'/log_'y'_'m'_'d'.log ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:2:0","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"å¯¹ç«¯æ·±ä¿¡æœé˜²ç«å¢™é…ç½® ç‰ˆæœ¬å·ï¼šAF 8.0.45 åœ¨ç›‘æ§â€”\u003e æ—¥å¿—â€”\u003eè®¾ç½® ä¸­å¼€å¯è¡Œä¸ºå®¡è®¡æ—¥å¿—é€‰é¡¹ï¼Œé…ç½®å¯¹ç«¯syslogæœåŠ¡å™¨åœ°å€å’Œç«¯å£å·ã€‚ ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:2:1","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"å¯¹ç«¯æ·±ä¿¡æœSSL VPNé…ç½® ç‰ˆæœ¬å·ï¼š SSL 7.6.9R1 åœ¨ç³»ç»Ÿè®¾ç½®â€”\u003e ç³»ç»Ÿé…ç½®â€”\u003e æ•°æ®ä¸­å¿ƒä¸­å¯ç”¨Syslog è®¾ç½®æ·»åŠ å¯¹ç«¯æœåŠ¡å™¨åœ°å€ ç‚¹å‡»æµ‹è¯•è¿é€šæ€§æµ‹è¯•å¯¹ç«¯æœåŠ¡å™¨è¿æ¥çŠ¶å†µ è®¾ç½®æ—¥å¿—è¾“å‡ºç±»å‹ï¼Œæ³¨æ„æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©ç›¸åº”æ—¥å¿—ç­‰çº§ï¼Œé¿å…ä¸å¿…è¦çš„èµ„æºæµªè´¹ã€‚ ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:2:2","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"å¯¹ç«¯H3Cæ ¸å¿ƒäº¤æ¢æœºé…ç½® è®¾å¤‡å‹å·ï¼šH3C S7503E-M è¯¦æƒ…è§äº¤æ¢æœºé…ç½®æ‰‹å†Œ-15-ä¿¡æ¯ä¸­å¿ƒé…ç½®-æ–°åä¸‰é›†å›¢-H3C [Intranet-CSW-S7503E]info-center enable #å¼€å¯ä¿¡æ¯ä¸­å¿ƒ\r[Intranet-CSW-S7503E]info-center loghost 192.168.10.109 port 514 facility local5\r#é…ç½®å‘é€æ—¥å¿—ä¿¡æ¯åˆ°IPåœ°å€ä¸º192.168.10.109ç«¯å£ä¸º514çš„æ—¥å¿—ä¸»æœºï¼Œæ—¥å¿—ä¸»æœºè®°å½•å·¥å…·ä¸ºlocal5ã€‚\r[Intranet-CSW-S7503E]info-center source default loghost deny\r# å…³é—­loghostæ–¹å‘æ‰€æœ‰æ¨¡å—æ—¥å¿—ä¿¡æ¯çš„è¾“å‡ºå¼€å…³ã€‚\r[Intranet-CSW-S7503E]info-center source ftp loghost level notification\r# é…ç½®è¾“å‡ºè§„åˆ™ï¼šå…è®¸FTPæ¨¡å—çš„ã€ç­‰çº§é«˜äºç­‰äºnotificationçš„æ—¥å¿—ä¿¡æ¯è¾“å‡ºåˆ°æ—¥å¿—ä¸»æœºï¼ˆæ³¨æ„ï¼šå…è®¸è¾“å‡ºä¿¡æ¯çš„æ¨¡å—ç”±äº§å“å†³å®šï¼‰ã€‚ ç”±äºç³»ç»Ÿå¯¹å„æ–¹å‘å…è®¸è¾“å‡ºçš„æ—¥å¿—ä¿¡æ¯çš„ç¼ºçœæƒ…å†µä¸ä¸€æ ·ï¼Œæ‰€ä»¥é…ç½®å‰å¿…é¡»å°†æ‰€æœ‰æ¨¡å—çš„éœ€æ±‚æ–¹å‘ï¼ˆæœ¬ä¾‹ä¸ºloghostï¼‰ä¸Šæ—¥å¿—ä¿¡æ¯çš„è¾“å‡ºå¼€å…³å…³é—­ï¼Œå†æ ¹æ®å½“å‰çš„éœ€æ±‚é…ç½®è¾“å‡ºè§„åˆ™ï¼Œä»¥å…è¾“å‡ºå¤ªå¤šä¸éœ€è¦çš„ä¿¡æ¯ã€‚ å®Œæˆå¯¹ç«¯è®¾å¤‡æ—¥å¿—çš„æ¨é€è®¾ç½®åï¼Œç›¸å…³æ—¥å¿—ä¿å­˜åœ¨109æœ¬åœ°æœåŠ¡å™¨å¯¹åº”ç›®å½•ä¸‹çš„ã€‚ å¯è§ é˜²ç«å¢™æ—¥å¿—ä¸­è®°å½•äº†ä¹‹å‰åœ¨æœåŠ¡å™¨ä¸­æŒ‡å®šæ”¶é›†çš„æ—¥å¿—ç±»å‹ è‡³æ­¤rsyslogæ”¶é›†å·¥ä½œç»“æŸ ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:2:3","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"Filebeat ç»„ä»¶é…ç½® ç¯å¢ƒå˜é‡é…ç½® vim /etc/profile.d/filebeat.sh #/bin/bash export PATH=/usr/share/filebeat/bin:$PATHç»è¿‡é…ç½®rsyslogæœåŠ¡ï¼Œå·²ç»æ”¶é›†åˆ°äº†å„ä¸šåŠ¡ç³»ç»Ÿçš„æ—¥å¿—æ–‡ä»¶ï¼Œä¸‹ä¸€æ­¥å·¥ä½œå°±æ˜¯æ”¶é›†åˆ°çš„æ–‡ä»¶é€šè¿‡ELKä¸­çš„Filebeatç»„ä»¶å¯¹æ—¥å¿—è¿›è¡Œåˆæ­¥åŠ å·¥ã€‚ #ç¼–è¾‘é…ç½®æ–‡ä»¶ vim /etc/filebeat/filebeat.yml #filebeat inputs éƒ¨åˆ† è®¾ç½®æ—¥å¿—çš„æ‰€åœ¨ç›®å½•ä½ç½® #ä¸€å®šè¦æ³¨æ„æ ¼å¼ ç‰¹åˆ«æ˜¯æ’ä»¶å‰åé¡ºåºå’Œ-çš„ä½ç½®ã€‚ #ç»è¿‡å®è·µè¸©å‘å¤§éƒ¨åˆ†é—®é¢˜éƒ½æ˜¯å› ä¸ºæ ¼å¼å¯¼è‡´çš„ã€‚ filebeat.inputs: - type: log # Change to true to enable this input configuration. enabled: true # Paths that should be crawled and fetched. Glob based paths. paths: - /var/log/attack-syslog/localhost_10.123.0.2/*.log fields: logtype1: \"sangfor-af\" #- c:\\programdata\\elasticsearch\\logs\\* - type: log enabled: true paths: - /var/log/attack-syslog/sslvpn_10.123.0.27/*.log fields: logtype1: \"sangfor-sslvpn\" - type: log enabled: true paths: - /var/log/attack-syslog/sslvpn_10.123.0.28/*.log fields: logtype1: \"sangfor-sslvpn\" - type: log enabled: true paths: - /var/log/attack-syslog/2021_192.168.10.254/*.log fields: logtype1: \"hc-nwhx\" #æŠ“å–æ•°æ®å¹¶å¯¹æ—¥å¿—è¿›è¡Œæ‰“æ ‡ç­¾ï¼Œåç»­é€šè¿‡æ ‡ç­¾å»ºç«‹ç‹¬è‡ªçš„ç´¢å¼• #Outputséƒ¨åˆ† #æ³¨é‡Š Elasticsearch Output é…ç½®Logstash Output output.logstash: # The Logstash hosts hosts: [\"192.168.10.107:5044\"] #å¯é€‰é¡¹ # Optional SSL. By default is off. # List of root certificates for HTTPS server verifications #ssl.certificate_authorities: [\"/etc/pki/root/ca.pem\"] # Certificate for SSL client authentication #ssl.certificate: \"/etc/pki/client/cert.pem\" # Client Certificate Key #ssl.key: \"/etc/pki/client/cert.key\" #å¯åŠ¨ systemctl start filebeat ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:3:0","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"Filebeat ç»„ä»¶æ’é”™æ–¹æ³• åœ¨å‘ç”Ÿé”™è¯¯æ—¶ï¼ŒæœåŠ¡ä»åœ¨è¿è¡ŒçŠ¶æ€æ—¶ä½¿ç”¨systemctl status filebeat èƒ½çœ‹åˆ°çš„é”™è¯¯ä¿¡æ¯å¾ˆå°‘ï¼Œé€šè¿‡å‰ç«¯æ‰‹åŠ¨æŒ‡å®šè¿è¡Œæ—¥å¿—çš„æ–¹å¼æ›´æ˜“äºé—®é¢˜çš„å®šä½ã€‚ filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:3:1","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"Logstash ç»„ä»¶é…ç½® ç¯å¢ƒå˜é‡å®šåˆ¶ echo 'export PATH=/usr/share/logstash/bin:$PATH' \u003e /etc/profile.d/logstash.sh source /etc/profile.d/logstash.shç”Ÿæˆé…ç½®æ–‡ä»¶ ä»¥å‘½ä»¤è¡Œçš„æ–¹å¼æ¥è¿›è¡Œå¯åŠ¨å¤ªç¹çï¼Œæˆ‘ä»¬æœ€å¥½è¿˜æ˜¯ä»¥é…ç½®æ–‡ä»¶çš„æ–¹å¼æ¥è¿›è¡ŒæœåŠ¡çš„å¯åŠ¨ç®¡ç†ï¼Œå¯¹äº logstashæ¥è¯´ï¼Œå®ƒæä¾›å¥½äº†ä¸€ä¸ªä¸“é—¨ç”¨äºç”Ÿæˆé…ç½®æ–‡ä»¶çš„å‘½ä»¤ system-installï¼Œæˆ‘ä»¬åªéœ€è¦æŒ‰ç…§æ—¢å®šçš„ é…ç½®æ–‡ä»¶è§„åˆ™ï¼Œå®šåˆ¶åº”ç”¨é…ç½®ï¼Œæœ€åæ‰§è¡Œè¯¥å‘½ä»¤ï¼Œå³å¯å®ç°æœåŠ¡è„šæœ¬çš„é…ç½®ã€‚ #è¿›å…¥åº”ç”¨ç›®å½• cd /etc/logstash #ç¼–è¾‘å¯åŠ¨å‚æ•°æ–‡ä»¶ # vim startup.options ... # Arguments to pass to logstash LS_OPTS=\"--path.settings ${LS_SETTINGS_DIR} -f /etc/logstash/conf.d\" #æ³¨æ„ï¼š -f æŒ‡å®šçš„æ˜¯ logstashçš„åº”ç”¨é…ç½®æ–‡ä»¶(æ¯”å¦‚ logstash.conf)å­˜æ”¾åˆ°çš„ç›®å½•#ä»¥rootç”¨æˆ·æ‰§è¡Œä¸‹é¢çš„å‘½ä»¤ system-install #æŸ¥çœ‹ç”Ÿæˆçš„æœåŠ¡é…ç½®æ–‡ä»¶ # ls /etc/systemd/system/logstash.service /etc/systemd/system/logstash.service #æŸ¥çœ‹æœåŠ¡é…ç½®æ–‡ä»¶å†…å®¹ # cat /etc/systemd/system/logstash.service [Unit] Description=logstash [Service] Type=simple User=logstash Group=logstash # Load env vars from /etc/default/ and /etc/sysconfig/ if they exist. # Prefixing the path with '-' makes it try to load, but if the file doesn't # exist, it continues onward. EnvironmentFile=-/etc/default/logstash EnvironmentFile=-/etc/sysconfig/logstash ExecStart=/usr/share/logstash/bin/logstash \"--path.settings\" \"/etc/logstash\" \"- f\" \"/etc/logstash/conf.d\" Restart=always WorkingDirectory=/ Nice=19 LimitNOFILE=16384 # When stopping, how long to wait before giving up and sending SIGKILL? # Keep in mind that SIGKILL on a process can cause data loss. TimeoutStopSec=infinity [Install] WantedBy=multi-user.target #æ³¨æ„ï¼š # ç”±äºæœåŠ¡å¯åŠ¨çš„æ—¶å€™ï¼Œç”¨æˆ·åå’Œç”¨æˆ·ç»„éƒ½æ˜¯ logstash ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬é‡‡é›†æ•°æ®çš„æ–‡ä»¶å¿…é¡»æ˜¯å…·å¤‡æŸ¥çœ‹çš„ #æƒé™æ—¥å¿—åœ¨ç»è¿‡filebeatç»„ä»¶çš„åˆæ­¥æ”¹é€ ï¼Œå°†å„ç³»ç»Ÿæ”¶é›†åˆ°çš„æ—¥å¿—æ‰“ä¸Šäº†typeç±»å‹ï¼ŒLogstashæ ¹æ®ç±»å‹åˆ›å»ºä¸åŒçš„ç´¢å¼•æ–‡ä»¶ã€‚è¿™é‡Œé€šè¿‡grokæ’ä»¶å¯¹æ—¥å¿—è¿›è¡Œäº†å­—æ®µè‡ªå®šä¹‰æ”¹é€ ã€‚ä»¥ä¾¿åç»­åœ¨kibanaä¸­æ›´å¥½çš„ç»˜å›¾å±•ç¤ºã€‚è¯¦æƒ…è§ grokæ’ä»¶ç”¨æ³• vim /etc/logstash/conf.d/logstash.conf #input éƒ¨åˆ† #è¯»å–filebeatä¸»æœºæ¨é€åˆ°5044ç«¯å£çš„æ•°æ® input { beats { port =\u003e 5044 } } filter { grok { match =\u003e { \"message\" =\u003e \"%{TIMESTAMP_ISO8601:times} %{HOSTNAME:hosts} %{USERNAME:logtype}: message repeated %{INT:repetition_times} times: \\[ æ—¥å¿—ç±»å‹:(?\u003cOperation_type\u003e(?\u003c=)(.{4})), (?\u003cOperation_typ1e\u003e(?\u003c=)(.{2})):%{USER:user}\\(%{HOSTNAME:connection_method}\\)\\(%{HOSTNAME:connection_method}\\), IPåœ°å€:%{IPV4:connection_ip}, æ“ä½œå¯¹è±¡:%{GREEDYDATA:Action_log}, æ“ä½œç±»å‹:(?\u003cbehaviour_t\u003e(?\u003c=)(.{4})), æè¿°:(?\u003cBehavior_performance\u003e(?\u003c=)(.{4}))\\]\" } } } #output éƒ¨åˆ† #æ³¨æ„ifåéœ€è¦åŠ  [fields]å¹¶æ·»åŠ ä¹‹å‰filebeatä¸­å®šåˆ¶çš„å­—æ®µ[logtype1]ï¼Œç»æµ‹è¯•ç›´æ¥åŠ logtype1ä¸å¥½ä½¿ã€‚ output { if [fields][logtype1] == \"sangfor-af\" { elasticsearch { hosts =\u003e [\"http://localhost:9200\"] index =\u003e \"sangfor-af01-%{+YYYY.MM.dd}\" } } if [fields][logtype1] == \"hc-nwhx\" { elasticsearch { hosts =\u003e [\"http://localhost:9200\"] index =\u003e \"hc-nwhx-%{+YYYY.MM.dd}\" } } if [fields][logtype1] == \"sangfor-sslvpn\" { elasticsearch { hosts =\u003e [\"http://localhost:9200\"] index =\u003e \"sangfor-sslvpn-%{+YYYY.MM.dd}\" } } } å¯åŠ¨æœåŠ¡ é‡è½½æœåŠ¡ systemctl daemon-reload å¯åŠ¨æœåŠ¡ systemctl start logstash.service systemctl status logstash.service æŸ¥çœ‹æ•ˆæœ # netstat -tnulp | egrep 'Add|java' Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 127.0.0.1:9600 :::* LISTEN 88794/java tcp6 0 0 :::9200 :::* LISTEN 87210/java tcp6 0 0 :::9300 :::* LISTEN 87210/java ç»“æœæ˜¾ç¤ºï¼š logstashçš„é»˜è®¤ç«¯å£æ˜¯ 9600 ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:3:2","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"logstash æ’é”™ #æŸ¥çœ‹æ—¥å¿—ï¼š tail -f /var/log/logstash/logstash-plain.log #å¯ä»¥çœ‹åˆ°é»˜è®¤æŠ¥é”™ï¼š [2021-08-15T18:44:08,643][WARN ] [filewatch.tailmode.handlers.createinitial][main] [cc34021140e2525e95d5755b6135b9801f3595239bcda82a1cca03a1d0f857d6] failed to open file {:path=\u003e\"/var/log/syslog\", :exception=\u003eErrno::EACCES, :message=\u003e\"Permission denied - /var/log/syslog\"} #ä¸´æ—¶å¢åŠ ä¸€ä¸ª logstash å…è®¸è®¿é—®çš„æƒé™ chown logstash.logstash /var/log/syslogé€šè¿‡headæ’ä»¶æŸ¥çœ‹æ•°æ®ä¼ é€’æ•ˆæœ ","date":"2021-10-21","objectID":"/posts/elk/elk-practice/:3:3","tags":["æ—¥å¿—æ”¶é›†","ç­‰ä¿2.0","è¿ç»´å®æˆ˜"],"title":"ç­‰ä¿2.0é¡¹ç›®-æ—¥å¿—æ”¶é›†å®è·µ","uri":"/posts/elk/elk-practice/"},{"categories":["ElasticStack"],"content":"ä¸€èˆ¬ç³»ç»Ÿæˆ–æœåŠ¡ç”Ÿæˆçš„æ—¥å¿—éƒ½æ˜¯ä¸€å¤§é•¿ä¸²ã€‚æ¯ä¸ªå­—æ®µä¹‹é—´ç”¨ç©ºæ ¼éš”å¼€ã€‚logstashåœ¨è·å–æ—¥å¿—æ˜¯æ•´ä¸ªä¸€ä¸²è·å–ï¼Œå¦‚æœæŠŠæ—¥å¿—ä¸­æ¯ä¸ªå­—æ®µä»£è¡¨çš„æ„æ€åˆ†å‰²å¼€æ¥åœ¨ä¼ ç»™elasticsearchã€‚è¿™æ ·å‘ˆç°å‡ºæ¥çš„æ•°æ®æ›´åŠ æ¸…æ™°ï¼Œè€Œä¸”ä¹Ÿèƒ½è®©kibanaæ›´æ–¹ä¾¿çš„ç»˜åˆ¶å›¾å½¢ã€‚ Grok æ˜¯ Logstash æœ€é‡è¦çš„æ’ä»¶ã€‚å®ƒçš„ä¸»è¦ä½œç”¨å°±æ˜¯å°†æ–‡æœ¬æ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œè½¬æ¢æˆä¸ºå…·ä½“çš„ç»“æ„åŒ–çš„æ•°æ®ï¼Œé…åˆæ­£åˆ™è¡¨è¾¾å¼ä½¿ç”¨ã€‚ Grok æ­£åˆ™æ•è· Grok æ”¯æŒæŠŠé¢„å®šä¹‰çš„ grok è¡¨è¾¾å¼ å†™å…¥åˆ°æ–‡ä»¶ä¸­ï¼Œå®˜æ–¹æä¾›çš„é¢„å®šä¹‰ grok è¡¨è¾¾å¼è§ï¼šhttps://github.com/logstash/logstash/tree/v1.4.2/patternsã€‚ %{syntax:semantic} syntaxä»£è¡¨çš„æ˜¯æ­£åˆ™è¡¨è¾¾å¼æ›¿ä»£å­—æ®µï¼Œsemanticæ˜¯ä»£è¡¨è¿™ä¸ªè¡¨è¾¾å¼å¯¹åº”çš„å­—æ®µåï¼Œä½ å¯ä»¥è‡ªç”±å‘½åã€‚è¿™ä¸ªå‘½åå°½é‡èƒ½ç®€å•æ˜“æ‡‚çš„è¡¨è¾¾å‡ºè¿™ä¸ªå­—æ®µä»£è¡¨çš„æ„æ€ã€‚ logstashå®‰è£…æ—¶å°±å¸¦æœ‰å·²ç»å†™å¥½çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚è·¯å¾„å¦‚ä¸‹ï¼š /usr/local/logstash-2.3.4/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-2.0.5/patterns æˆ–è€…ç›´æ¥è®¿é—®logstash-plugins/logstash-patterns-core Â· GitHub ä¸Šé¢IPORHOSTï¼ŒUSERç­‰éƒ½æ˜¯åœ¨é‡Œé¢å·²ç»å®šä¹‰å¥½çš„ï¼å½“ç„¶è¿˜æœ‰å…¶ä»–çš„ï¼ŒåŸºæœ¬èƒ½æ»¡è¶³æˆ‘ä»¬çš„éœ€æ±‚ã€‚ ","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:0:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"grok-patterns USERNAME [a-zA-Z0-9._-]+ USER %{USERNAME} EMAILLOCALPART [a-zA-Z0-9!#$%\u0026'*+\\-/=?^_`{|}~]{1,64}(?:\\.[a-zA-Z0-9!#$%\u0026'*+\\-/=?^_`{|}~]{1,62}){0,63} EMAILADDRESS %{EMAILLOCALPART}@%{HOSTNAME} INT (?:[+-]?(?:[0-9]+)) BASE10NUM (?\u003c![0-9.+-])(?\u003e[+-]?(?:(?:[0-9]+(?:\\.[0-9]+)?)|(?:\\.[0-9]+))) NUMBER (?:%{BASE10NUM}) BASE16NUM (?\u003c![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+)) BASE16FLOAT \\b(?\u003c![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\\.[0-9A-Fa-f]*)?)|(?:\\.[0-9A-Fa-f]+)))\\b POSINT \\b(?:[1-9][0-9]*)\\b NONNEGINT \\b(?:[0-9]+)\\b WORD \\b\\w+\\b NOTSPACE \\S+ SPACE \\s* DATA .*? GREEDYDATA .* QUOTEDSTRING (?\u003e(?\u003c!\\\\)(?\u003e\"(?\u003e\\\\.|[^\\\\\"]+)+\"|\"\"|(?\u003e'(?\u003e\\\\.|[^\\\\']+)+')|''|(?\u003e`(?\u003e\\\\.|[^\\\\`]+)+`)|``)) UUID [A-Fa-f0-9]{8}-(?:[A-Fa-f0-9]{4}-){3}[A-Fa-f0-9]{12} # URN, allowing use of RFC 2141 section 2.3 reserved characters URN urn:[0-9A-Za-z][0-9A-Za-z-]{0,31}:(?:%[0-9a-fA-F]{2}|[0-9A-Za-z()+,.:=@;$_!*'/?#-])+ # Networking MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC}) CISCOMAC (?:(?:[A-Fa-f0-9]{4}\\.){2}[A-Fa-f0-9]{4}) WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2}) COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2}) IPV6 ((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))(%.+)? IPV4 (?\u003c![0-9])(?:(?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5]))(?![0-9]) IP (?:%{IPV6}|%{IPV4}) HOSTNAME \\b(?:[0-9A-Za-z][0-9A-Za-z-]{0,62})(?:\\.(?:[0-9A-Za-z][0-9A-Za-z-]{0,62}))*(\\.?|\\b) IPORHOST (?:%{IP}|%{HOSTNAME}) HOSTPORT %{IPORHOST}:%{POSINT} # paths (only absolute paths are matched) PATH (?:%{UNIXPATH}|%{WINPATH}) UNIXPATH (/[[[:alnum:]]_%!$@:.,+~-]*)+ TTY (?:/dev/(pts|tty([pq])?)(\\w+)?/?(?:[0-9]+)) WINPATH (?\u003e[A-Za-z]+:|\\\\)(?:\\\\[^\\\\?*]*)+ URIPROTO [A-Za-z]([A-Za-z0-9+\\-.]+)+ URIHOST %{IPORHOST}(?::%{POSINT})? # uripath comes loosely from RFC1738, but mostly from what Firefox doesn't turn into %XX URIPATH (?:/[A-Za-z0-9$.+!*'(){},~:;=@#%\u0026_\\-]*)+ URIQUERY [A-Za-z0-9$.+!*'|(){},~@#%\u0026/=:;_?\\-\\[\\]\u003c\u003e]* # deprecated (kept due compatibility): URIPARAM \\?%{URIQUERY} URIPATHPARAM %{URIPATH}(?:\\?%{URIQUERY})? URI %{URIPROTO}://(?:%{USER}(?::[^@]*)?@)?(?:%{URIHOST})?(?:%{URIPATH}(?:\\?%{URIQUERY})?)? # Months: January, Feb, 3, 03, 12, December MONTH \\b(?:[Jj]an(?:uary|uar)?|[Ff]eb(?:ruary|ruar)?|[Mm](?:a|Ã¤)?r(?:ch|z)?|[Aa]pr(?:il)?|[Mm]a(?:y|i)?|[Jj]un(?:e|i)?|[Jj]ul(?:y|i)?|[Aa]ug(?:ust)?|[Ss]ep(?:tember)?|[Oo](?:c|k)?t(?:ober)?|[Nn]ov(?:ember)?|[Dd]e(?:c|z)(?:ember)?)\\b MONTHNUM (?:0?[1-9]|1[0-2]) MONTHNUM2 (?:0[1-9]|1[0-2]) MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]) # Days: Monday, Tue, Thu, etc... DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?) # Years? YEAR (?\u003e\\d\\d){1,2} HOUR (?:2[0123]|[01]?[0-9]) MINUTE (?:[0-5][0-9]) # '60' is a leap second in most time standards and thus is valid. SECOND (?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?) TIME (?!\u003c[0-9])%{HOUR}:%{MINUTE}(?::%{SECOND})(?![","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:1:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"æ¡ˆä¾‹å®è·µ ä¾‹1ï¼šå°†ä¸‹é¢çš„æ—¥å¿—æ–‡ä»¶æ ¼å¼æ‹†åˆ†ä¸º5æ®µ 2016-09-19T18:19:00 [8.8.8.8:prd] DEBUG this is an example log message æ—¶é—´ IPåœ°å€ ç¯å¢ƒ ç­‰çº§ ä¿¡æ¯ ä½¿ç”¨Grok é»˜è®¤æä¾›çš„æ­£åˆ™åŒ¹é…å %{TIMESTAMP_ISO8601:timestamp} \\[%{IPV4:ip};%{WORD:environment}\\] %{LOGLEVEL:log_level} %{GREEDYDATA:message} è¿™æ ·å°±ä¼šç”Ÿæˆç»“æ„åŒ–ç»“æœï¼š { \"timestamp\": \"2016-09-19T18:19:00\", \"ip\": \"8.8.8.8\", \"environment\": \"prd\", \"log_level\": \"DEBUG\", \"message\": \"this is an example log message\" }TIMESTAMP_ISO8601ç”¨æ¥åŒ¹é…æ—¶é—´ IPV4åŒ¹é…IPV4 IPåœ°å€ WORDåŒ¹é…ç¯å¢ƒ LOGLEVELåŒ¹é…äº†æ—¥å¿—ç­‰çº§ GREEDYDATAåŒ¹é…åé¢çš„æ‰€æœ‰å†…å®¹ ä¾‹2ï¼š 220.181.108.96 - - [13/Jun/2015:21:14:28 +0000] \"GET /blog/geekery/xvfb-firefox.html HTTP/1.1\" 200 10975 \"-\" \"Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)\"è½¬æ¢åï¼š %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"%{WORD:verb} %{DATA:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{QS:referrer} %{QS:agent}ä¾‹3ï¼š 220.181.108.96 - - [13/Jun/2015:21:14:28 +0000] \"GET /blog/geekery/xvfb-firefox.html HTTP/1.1\" 200 10975 \"-\" \"Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)\"è½¬æ¢åï¼š %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"%{WORD:verb} %{DATA:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{QS:referrer} %{QS:agent}ä¾‹4ï¼šå‡è®¾æˆ‘ä»¬æœ‰ä¸‰ä¸ªä½¿ç”¨â€œcommon_headerï¼špayloadâ€æ ¼å¼çš„åº”ç”¨ç¨‹åº Application 1: '8.8.8.8 process-name[666]: a b 1 2 a lot of text at the end' Application 2: '8.8.8.8 process-name[667]: a 1 2 3 a lot of text near the end;4' Application 3: '8.8.8.8 process-name[421]: a completely different format | 1111'è½¬æ¢åï¼š grok { \"match\" =\u003e { \"message =\u003e [\r'%{IPORHOST:clientip} %{DATA:process_name}\\[%{NUMBER:process_id}\\]: %{WORD:word_1} %{WORD:word_2} %{NUMBER:number_1} %{NUMBER:number_2} %{DATA:data}',\r'%{IPORHOST:clientip} %{DATA:process_name}\\[%{NUMBER:process_id}\\]: %{WORD:word_1} %{NUMBER:number_1} %{NUMBER:number_2} %{NUMBER:number_3} %{DATA:data};%{NUMBER:number_4}',\r'%{IPORHOST:clientip} %{DATA:process_name}\\[%{NUMBER:process_id}\\]: %{DATA:data} | %{NUMBER:number}'\r] }\r}","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:2:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"ä¸‹é¢é’ˆå¯¹Apacheæ—¥å¿—æ¥åˆ†å‰²å¤„ç† 192.168.10.97 - - [19/Jul/2016:16:28:52 +0800] \"GET / HTTP/1.1\" 200 23 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36\"æ—¥å¿—ä¸­æ¯ä¸ªå­—æ®µä¹‹é—´ç©ºæ ¼éš”å¼€ï¼Œåˆ†åˆ«å¯¹åº”messageä¸­çš„å­—æ®µã€‚ å¦‚ï¼š%{IPORHOST:addre} â€“\u003e 192.168.10.97 ä½†é—®é¢˜æ˜¯IPORHOSTåˆä¸æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ€ä¹ˆèƒ½åŒ¹é…IPåœ°å€å‘¢ï¼Ÿ å› ä¸ºIPPRHOSTæ˜¯grokè¡¨è¾¾å¼ï¼Œå®ƒä»£è¡¨çš„æ­£åˆ™è¡¨è¾¾å¼å¦‚ä¸‹ï¼š IPV6 ((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))(%.+)? IPV4 (?\u003c![0-9])(?:(?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5]))(?![0-9]) IP (?:%{IPV6}|%{IPV4}) HOSTNAME \\b(?:[0-9A-Za-z][0-9A-Za-z-]{0,62})(?:\\.(?:[0-9A-Za-z][0-9A-Za-z-]{0,62}))*(\\.?|\\b) IPORHOST (?:%{IP}|%{HOSTNAME})IPORHOSTä»£è¡¨çš„æ˜¯ipv4æˆ–è€…ipv6æˆ–è€…HOSTNAMEæ‰€åŒ¹é…çš„grokè¡¨è¾¾å¼ã€‚\rä¸Šé¢çš„IPORHOSTæœ‰ç‚¹å¤æ‚ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹ç®€å•ç‚¹çš„ï¼Œå¦‚USER\rUSERNAME [a-zA-Z0-9._-]+ #USERNAMEæ˜¯åŒ¹é…ç”±å­—æ¯ï¼Œæ•°å­—ï¼Œâ€œ.â€, \"_\", \"-\"ç»„æˆçš„ä»»æ„å­—ç¬¦\rUSER %{USERNAME}\r#USERä»£è¡¨USERNAMEçš„æ­£åˆ™è¡¨è¾¾å¼\rç¬¬ä¸€è¡Œï¼Œç”¨æ™®é€šçš„æ­£åˆ™è¡¨è¾¾å¼æ¥å®šä¹‰ä¸€ä¸ª grok è¡¨è¾¾å¼ï¼›\rç¬¬äºŒè¡Œï¼Œé€šè¿‡æ‰“å°èµ‹å€¼æ ¼å¼ï¼Œç”¨å‰é¢å®šä¹‰å¥½çš„ grok è¡¨è¾¾å¼æ¥å®šä¹‰å¦ä¸€ä¸ª grok è¡¨è¾¾å¼ã€‚ filter { if [type] == \"apache\" { grok { match =\u003e [\"message\" =\u003e \"%{IPORHOST:addre} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \\\"%{WORD:http_method} %{NOTSPACE:request} HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:status} (?:%{NUMBER:bytes}|-) \\\"(?:%{URI:http_referer}|-)\\\" \\\"%{GREEDYDATA:User_Agent}\\\"\"] remove_field =\u003e [\"message\"] } date { match =\u003e [ \"timestamp\", \"dd/MMM/YYYY:HH:mm:ss Z\" ] } } } ","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:2:1","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"Httpd HTTPDUSER %{EMAILADDRESS}|%{USER} HTTPDERROR_DATE %{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{YEAR} # Log formats HTTPD_COMMONLOG %{IPORHOST:clientip} %{HTTPDUSER:ident} %{HTTPDUSER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) HTTPD_COMBINEDLOG %{HTTPD_COMMONLOG} %{QS:referrer} %{QS:agent} # Error logs HTTPD20_ERRORLOG \\[%{HTTPDERROR_DATE:timestamp}\\] \\[%{LOGLEVEL:loglevel}\\] (?:\\[client %{IPORHOST:clientip}\\] ){0,1}%{GREEDYDATA:message} HTTPD24_ERRORLOG \\[%{HTTPDERROR_DATE:timestamp}\\] \\[%{WORD:module}:%{LOGLEVEL:loglevel}\\] \\[pid %{POSINT:pid}(:tid %{NUMBER:tid})?\\]( \\(%{POSINT:proxy_errorcode}\\)%{DATA:proxy_message}:)?( \\[client %{IPORHOST:clientip}:%{POSINT:clientport}\\])?( %{DATA:errorcode}:)? %{GREEDYDATA:message} HTTPD_ERRORLOG %{HTTPD20_ERRORLOG}|%{HTTPD24_ERRORLOG} # Deprecated COMMONAPACHELOG %{HTTPD_COMMONLOG} COMBINEDAPACHELOG %{HTTPD_COMBINEDLOG} ","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:2:2","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"java JAVACLASS (?:[a-zA-Z$_][a-zA-Z$_0-9]*\\.)*[a-zA-Z$_][a-zA-Z$_0-9]* #Space is an allowed character to match special cases like 'Native Method' or 'Unknown Source' JAVAFILE (?:[A-Za-z0-9_. -]+) #Allow special \u003cinit\u003e, \u003cclinit\u003e methods JAVAMETHOD (?:(\u003c(?:cl)?init\u003e)|[a-zA-Z$_][a-zA-Z$_0-9]*) #Line number is optional in special cases 'Native method' or 'Unknown source' JAVASTACKTRACEPART %{SPACE}at %{JAVACLASS:class}\\.%{JAVAMETHOD:method}\\(%{JAVAFILE:file}(?::%{NUMBER:line})?\\) # Java Logs JAVATHREAD (?:[A-Z]{2}-Processor[\\d]+) JAVACLASS (?:[a-zA-Z0-9-]+\\.)+[A-Za-z0-9$]+ JAVAFILE (?:[A-Za-z0-9_.-]+) JAVALOGMESSAGE (.*) # MMM dd, yyyy HH:mm:ss eg: Jan 9, 2014 7:13:13 AM CATALINA_DATESTAMP %{MONTH} %{MONTHDAY}, 20%{YEAR} %{HOUR}:?%{MINUTE}(?::?%{SECOND}) (?:AM|PM) # yyyy-MM-dd HH:mm:ss,SSS ZZZ eg: 2014-01-09 17:32:25,527 -0800 TOMCAT_DATESTAMP 20%{YEAR}-%{MONTHNUM}-%{MONTHDAY} %{HOUR}:?%{MINUTE}(?::?%{SECOND}) %{ISO8601_TIMEZONE} CATALINALOG %{CATALINA_DATESTAMP:timestamp} %{JAVACLASS:class} %{JAVALOGMESSAGE:logmessage} # 2014-01-09 20:03:28,269 -0800 | ERROR | com.example.service.ExampleService - something compeletely unexpected happened... TOMCATLOG %{TOMCAT_DATESTAMP:timestamp} \\| %{LOGLEVEL:level} \\| %{JAVACLASS:class} - %{JAVALOGMESSAGE:logmessage} ","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:2:3","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"Grok Debugger å½“æˆ‘ä»¬æ‹¿åˆ°ä¸€æ®µæ—¥å¿—ï¼ŒæŒ‰ç…§ä¸Šé¢çš„grokè¡¨è¾¾å¼ä¸€ä¸ªä¸ªå»åŒ¹é…æ—¶ï¼Œæˆ‘ä»¬å¦‚ä½•ç¡®å®šæˆ‘ä»¬åŒ¹é…çš„æ˜¯å¦æ­£ç¡®å‘¢ï¼Ÿ http://grokdebug.herokuapp.com/ è¿™ä¸ªåœ°å€å¯ä»¥æ»¡è¶³æˆ‘ä»¬çš„æµ‹è¯•éœ€æ±‚ã€‚å°±æ‹¿ä¸Šé¢apacheçš„æ—¥å¿—æµ‹è¯•ã€‚ ç‚¹å‡»åå°±å‡ºç°å¦‚ä¸‹æ•°æ®ï¼Œä½ å†™çš„æ¯ä¸ªgrokè¡¨è¾¾å¼éƒ½è·å–åˆ°å€¼äº†ã€‚ä¸ºäº†æµ‹è¯•å‡†ç¡®ï¼Œå¯ä»¥å¤šæµ‹è¯•å‡ æ¡æ—¥å¿—ã€‚ æ•ˆæœï¼š kibanaå­—æ®µå±•ç¤ºï¼š é…ç½®æ–‡ä»¶ï¼š # ---------------input è¾“å…¥æ¨¡å—----------------------- input { beats { port =\u003e 5044 } } # ---------------filter è¿‡æ»¤æ¨¡å—----------------------- filter { grok { match =\u003e { \"message\" =\u003e \"%{TIMESTAMP_ISO8601:times} %{HOSTNAME:hosts} %{USERNAME:logtype}: message repeated %{INT:repetition_times} times: \\[ æ—¥å¿—ç±»å‹:(?\u003cOperation_type\u003e(?\u003c=)(.{4})), (?\u003cOperation_typ1e\u003e(?\u003c=)(.{2})):%{USER:user}\\(%{HOSTNAME:connection_method}\\)\\(%{HOSTNAME:connection_method}\\), IPåœ°å€:%{IPV4:connection_ip}, æ“ä½œå¯¹è±¡:%{GREEDYDATA:Action_log}, æ“ä½œç±»å‹:(?\u003cbehaviour_t\u003e(?\u003c=)(.{4})), æè¿°:(?\u003cBehavior_performance\u003e(?\u003c=)(.{4}))\\]\" } } } # ---------------output è¾“å‡ºæ¨¡å—----------------------- output { elasticsearch { hosts =\u003e [\"http://localhost:9200\"] index =\u003e \"sangfor-af-%{+YYYY.MM.dd}\" #user =\u003e \"elastic\" #password =\u003e \"changeme\" } } ","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:2:4","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"è‡ªå®šä¹‰grokè¡¨è¾¾å¼ grokä¸»è¦æœ‰ä¸¤éƒ¨åˆ†ï¼šè‡ªå®šä¹‰æ­£åˆ™è¡¨è¾¾å¼å’Œç³»ç»Ÿé¢„å®šä¹‰çš„æ¨¡å¼è¡¨è¾¾å¼ã€‚ å¦‚æœä½ æ„Ÿè§‰logstashè‡ªå¸¦çš„grokè¡¨è¾¾å¼ä¸èƒ½æ»¡è¶³éœ€è¦ï¼Œä½ ä¹Ÿå¯ä»¥è‡ªå·±å®šä¹‰ å¦‚ï¼š filter { if [type] == \"apache\" { grok { patterns_dir =\u003e \"/usr/local/logstash-2.3.4/ownpatterns/patterns\" match =\u003e { \"message\" =\u003e \"%{APACHE_LOG}\" } remove_field =\u003e [\"message\"] } date { match =\u003e [ \"timestamp\", \"dd/MMM/YYYY:HH:mm:ss Z\" ] } } } #patterns_dirä¸ºè‡ªå®šä¹‰çš„grokè¡¨è¾¾å¼çš„è·¯å¾„ã€‚ #è‡ªå®šä¹‰çš„patternsä¸­æŒ‰ç…§logstashè‡ªå¸¦çš„æ ¼å¼ä¹¦å†™ã€‚ APACHE_LOG %{IPORHOST:addre} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \\\"%{WORD:http_method} %{NOTSPACE:request} HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:status} (?:%{NUMBER:bytes}|-) \\\"(?:%{URI:http_referer}|-)\\\" \\\"%{GREEDYDATA:User_Agent}\\\" #æˆ‘åªæ˜¯æŠŠapacheæ—¥å¿—åŒ¹é…çš„grokè¡¨è¾¾å¼å†™å…¥è‡ªå®šä¹‰æ–‡ä»¶ä¸­ï¼Œç®€åŒ–confæ–‡ä»¶ã€‚å•ä¸ªå­—æ®µçš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä½ å¯ä»¥è‡ªå·±ä¹¦å†™æµ‹è¯•ã€‚ ","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:3:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"å¸¸ç”¨æ­£åˆ™ (?\u003ctemMsg\u003e(.*)(?=Report)/?) è·å–Reportä¹‹å‰çš„å­—ç¬¦\r(?\u003ctemMsg\u003e(?=Report)(.*)/?) è·å–Reportä¹‹åçš„å­—ç¬¦\r(?\u003ctemMsg\u003e(?\u003c=report).*?(?=msg)) æˆªå–reportå’Œmsgä¹‹é—´çš„å€¼ ä¸åŒ…å«reportå’Œmsgæœ¬èº«\r(?\u003ctemMsg\u003e(report).*?(?=msg)) æˆªå–åŒ…å«reportä½†ä¸åŒ…å«msg\r(?\u003ctemMsg\u003e(?\u003c=report).*?(msg)) æˆªå–ä¸åŒ…å«reportä½†åŒ…å«msg\r(?\u003ctemMsg\u003e(report).*?(msg|request)) è¾“å‡ºä»¥reportå¼€å¤´,ä»¥msgæˆ–è€…ä»¥requestç»“å°¾çš„æ‰€æœ‰åŒ…å«å¤´å°¾ä¿¡æ¯\r(?\u003ctemMsg\u003e(report).*?(?=(msg|request))) è¾“å‡ºä»¥reportå¼€å¤´,ä»¥msgæˆ–è€…ä»¥requestç»“å°¾çš„ä¸åŒ…å«å¤´å°¾ä¿¡æ¯ ","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:3:1","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["ElasticStack"],"content":"grokæˆªå–å­—ç¬¦ä¸­æŒ‡å®šé•¿åº¦çš„å†…å®¹ è¦æ±‚åˆ©ç”¨grokæˆªå–æ—¥å¿—æ¶ˆæ¯ä¸­æŸä¸€æŒ‡å®šé•¿åº¦çš„å†…å®¹ã€‚ Logstatshéœ€è¦ä¸¤ä¸ªå¿…éœ€å‚æ•°inputã€outputï¼Œä»¥åŠä¸€ä¸ªå¯é€‰å‚æ•°filterã€‚inputç”¨äºè¾“å…¥æ•°æ®çš„è®¾ç½®ï¼Œoutputç”¨äºè¾“å‡ºæ•°æ®çš„è®¾ç½®ã€‚filteræ˜¯å®ç°æ•°æ®è¿‡æ»¤çš„è®¾ç½®ã€‚grokæ˜¯åœ¨filteré‡Œé¢å®ç°æ•°æ®æˆªå–ã€‚ é¡¹ç›®æœ‰ä¸€ä¸²åè®®æ¶ˆæ¯å¦‚ 7e8900000c040116432693324af0010180010005e98e0706000a7eï¼Œè¦æ±‚åˆ©ç”¨grokæˆªå–7eåé¢çš„å››ä¸ªå­—ç¬¦ï¼Œåˆ©ç”¨grokæ­£åˆ™è¡¨è¾¾å¼å³å¯å®ç°ã€‚ å®ç°ä»£ç å¦‚ä¸‹ï¼š filter{ grok{ match =\u003e { \"message\" =\u003e \"(?\u003cmid\u003e(?\u003c=7e)(.{4}))\" } } }ä»£ç è§£é‡Šï¼š messageï¼šå³è¾“å…¥çš„æ•°æ®ä¿¡æ¯ã€‚ midï¼šå³è¾“å‡ºç»“æœçš„åç§° (?\u003c=7e)ï¼šå³è¡¨ç¤ºè·å–7eåé¢çš„å­—ç¬¦ï¼Œä½†ä¸åŒ…æ‹¬7e (.{4})ï¼šå³è¡¨ç¤ºè·å–çš„å­—ç¬¦é•¿åº¦ä¸º4ä¸ª å¼•ç”¨æ–‡ç« ï¼š Grok æ­£åˆ™æ•è· | Logstash æœ€ä½³å®è·µ (yonyoucloud.com) logstash-patterns-core (github.com) Logstash å¸¸ç”¨æ­£åˆ™ï¼ˆgrok-patternsï¼‰qianghong000_51CTOåšå®¢ https://blog.51cto.com/irow10/1828077 Logstash Grokè¯¦è§£_å±å’¤å°‘å¸…çš„åšå®¢-CSDNåšå®¢ è½»æ¾æŒæ¡Logstashçš„grokåŒ¹é…_å…¨èœå·¥ç¨‹å¸ˆå°è¾‰çš„åšå®¢-CSDNåšå®¢ logstashæˆªå–æŒ‡å®šå­—ç¬¦å’Œgrokçš„ä½¿ç”¨_cai750415222çš„åšå®¢-CSDNåšå®¢ ","date":"2021-10-21","objectID":"/posts/elk/grok-patterns/:3:2","tags":["æ—¥å¿—æ”¶é›†"],"title":"æ—¥å¿—å¤„ç†-Grokæ­£åˆ™æ•è·","uri":"/posts/elk/grok-patterns/"},{"categories":["Zookeeper"],"content":"ä¼ä¸šé¢è¯•çœŸé¢˜ï¼ˆé¢è¯•é‡ç‚¹ï¼‰ ","date":"2021-10-09","objectID":"/posts/zookeeper/zookeeper-05/:0:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper ä¼ä¸šé¢è¯•çœŸé¢˜ï¼ˆé¢è¯•é‡ç‚¹ï¼‰","uri":"/posts/zookeeper/zookeeper-05/"},{"categories":["Zookeeper"],"content":"é€‰ä¸¾æœºåˆ¶ åŠæ•°æœºåˆ¶ï¼Œè¶…è¿‡åŠæ•°çš„æŠ•ç¥¨é€šè¿‡ï¼Œå³é€šè¿‡ã€‚ ï¼ˆ1ï¼‰ç¬¬ä¸€æ¬¡å¯åŠ¨é€‰ä¸¾è§„åˆ™ï¼š æŠ•ç¥¨è¿‡åŠæ•°æ—¶ï¼ŒæœåŠ¡å™¨ id å¤§çš„èƒœå‡º ï¼ˆ2ï¼‰ç¬¬äºŒæ¬¡å¯åŠ¨é€‰ä¸¾è§„åˆ™ï¼š â‘ EPOCH å¤§çš„ç›´æ¥èƒœå‡º â‘¡EPOCH ç›¸åŒï¼Œäº‹åŠ¡ id å¤§çš„èƒœå‡º â‘¢äº‹åŠ¡ id ç›¸åŒï¼ŒæœåŠ¡å™¨ id å¤§çš„èƒœå‡º ","date":"2021-10-09","objectID":"/posts/zookeeper/zookeeper-05/:1:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper ä¼ä¸šé¢è¯•çœŸé¢˜ï¼ˆé¢è¯•é‡ç‚¹ï¼‰","uri":"/posts/zookeeper/zookeeper-05/"},{"categories":["Zookeeper"],"content":"ç”Ÿäº§é›†ç¾¤å®‰è£…å¤šå°‘ zk åˆé€‚ï¼Ÿ å®‰è£…å¥‡æ•°å°ã€‚ ç”Ÿäº§ç»éªŒï¼š âš« 10 å°æœåŠ¡å™¨ï¼š3 å° zkï¼› âš« 20 å°æœåŠ¡å™¨ï¼š5 å° zkï¼› âš« 100 å°æœåŠ¡å™¨ï¼š11 å° zkï¼› âš« 200 å°æœåŠ¡å™¨ï¼š11 å° zk æœåŠ¡å™¨å°æ•°å¤šï¼šå¥½å¤„ï¼Œæé«˜å¯é æ€§ï¼›åå¤„ï¼šæé«˜é€šä¿¡å»¶æ—¶ ","date":"2021-10-09","objectID":"/posts/zookeeper/zookeeper-05/:2:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper ä¼ä¸šé¢è¯•çœŸé¢˜ï¼ˆé¢è¯•é‡ç‚¹ï¼‰","uri":"/posts/zookeeper/zookeeper-05/"},{"categories":["Zookeeper"],"content":"å¸¸ç”¨å‘½ä»¤ lsã€getã€createã€delete ","date":"2021-10-09","objectID":"/posts/zookeeper/zookeeper-05/:3:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper ä¼ä¸šé¢è¯•çœŸé¢˜ï¼ˆé¢è¯•é‡ç‚¹ï¼‰","uri":"/posts/zookeeper/zookeeper-05/"},{"categories":["Zookeeper"],"content":"ZooKeeper åˆ†å¸ƒå¼é”æ¡ˆä¾‹ ä»€ä¹ˆå«åšåˆ†å¸ƒå¼é”å‘¢ï¼Ÿ æ¯”å¦‚è¯´\"è¿›ç¨‹ 1\"åœ¨ä½¿ç”¨è¯¥èµ„æºçš„æ—¶å€™ï¼Œä¼šå…ˆå»è·å¾—é”ï¼Œâ€œè¿›ç¨‹ 1\"è·å¾—é”ä»¥åä¼šå¯¹è¯¥èµ„æºä¿æŒç‹¬å ï¼Œè¿™æ ·å…¶ä»–è¿›ç¨‹å°±æ— æ³•è®¿é—®è¯¥èµ„æºï¼Œâ€œè¿›ç¨‹ 1\"ç”¨å®Œè¯¥èµ„æºä»¥åå°±å°†é”é‡Šæ”¾æ‰ï¼Œè®©å…¶ ä»–è¿›ç¨‹æ¥è·å¾—é”ï¼Œé‚£ä¹ˆé€šè¿‡è¿™ä¸ªé”æœºåˆ¶ï¼Œæˆ‘ä»¬å°±èƒ½ä¿è¯äº†åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å¤šä¸ªè¿›ç¨‹èƒ½å¤Ÿæœ‰åºçš„ è®¿é—®è¯¥ä¸´ç•Œèµ„æºã€‚é‚£ä¹ˆæˆ‘ä»¬æŠŠè¿™ä¸ªåˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„è¿™ä¸ªé”å«ä½œåˆ†å¸ƒå¼é”ã€‚ ","date":"2021-10-08","objectID":"/posts/zookeeper/zookeeper-04/:0:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åˆ†å¸ƒå¼é”æ¡ˆä¾‹ ï¼ˆå››ï¼‰","uri":"/posts/zookeeper/zookeeper-04/"},{"categories":["Zookeeper"],"content":"Curator æ¡†æ¶å®ç°åˆ†å¸ƒå¼é”æ¡ˆä¾‹ ","date":"2021-10-08","objectID":"/posts/zookeeper/zookeeper-04/:1:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åˆ†å¸ƒå¼é”æ¡ˆä¾‹ ï¼ˆå››ï¼‰","uri":"/posts/zookeeper/zookeeper-04/"},{"categories":["Zookeeper"],"content":"åŸç”Ÿçš„ Java API å¼€å‘å­˜åœ¨çš„é—®é¢˜ ä¼šè¯è¿æ¥æ˜¯å¼‚æ­¥çš„ï¼Œéœ€è¦è‡ªå·±å»å¤„ç†ã€‚æ¯”å¦‚ä½¿ç”¨ CountDownLatch Watch éœ€è¦é‡å¤æ³¨å†Œï¼Œä¸ç„¶å°±ä¸èƒ½ç”Ÿæ•ˆ å¼€å‘çš„å¤æ‚æ€§è¿˜æ˜¯æ¯”è¾ƒé«˜çš„ ä¸æ”¯æŒå¤šèŠ‚ç‚¹åˆ é™¤å’Œåˆ›å»ºã€‚éœ€è¦è‡ªå·±å»é€’å½’ Curator æ˜¯ä¸€ä¸ªä¸“é—¨è§£å†³åˆ†å¸ƒå¼é”çš„æ¡†æ¶ï¼Œè§£å†³äº†åŸç”Ÿ JavaAPI å¼€å‘åˆ†å¸ƒå¼é‡åˆ°çš„é—®é¢˜ã€‚ è¯¦æƒ…è¯·æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£ï¼šhttps://curator.apache.org/index.html ","date":"2021-10-08","objectID":"/posts/zookeeper/zookeeper-04/:1:1","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åˆ†å¸ƒå¼é”æ¡ˆä¾‹ ï¼ˆå››ï¼‰","uri":"/posts/zookeeper/zookeeper-04/"},{"categories":["Zookeeper"],"content":"Curator æ¡ˆä¾‹å®æ“ 1.æ·»åŠ ä¾èµ– \u003cdependency\u003e \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e \u003cartifactId\u003ecurator-framework\u003c/artifactId\u003e \u003cversion\u003e4.3.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e \u003cartifactId\u003ecurator-recipes\u003c/artifactId\u003e \u003cversion\u003e4.3.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e \u003cartifactId\u003ecurator-client\u003c/artifactId\u003e \u003cversion\u003e4.3.0\u003c/version\u003e \u003c/dependency\u003e2.ä»£ç å®ç° package com.atguigu.lock; import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.framework.recipes.locks.InterProcessLock; import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.retry.ExponentialBackoffRetry; public class CuratorLockTest { private String rootNode = \"/locks\"; // zookeeper server åˆ—è¡¨ private String connectString = \"hadoop102:2181,hadoop103:2181,hadoop104:2181\"; // connection è¶…æ—¶æ—¶é—´ private int connectionTimeout = 2000; // session è¶…æ—¶æ—¶é—´ private int sessionTimeout = 2000; public static void main(String[] args) { new CuratorLockTest().test(); } // æµ‹è¯• private void test() { // åˆ›å»ºåˆ†å¸ƒå¼é” 1 final InterProcessLock lock1 = new InterProcessMutex(getCuratorFramework(), rootNode); // åˆ›å»ºåˆ†å¸ƒå¼é” 2 final InterProcessLock lock2 = new InterProcessMutex(getCuratorFramework(), rootNode); new Thread(new Runnable() { @Override public void run() { // è·å–é”å¯¹è±¡ try { lock1.acquire(); System.out.println(\"çº¿ç¨‹ 1 è·å–é”\"); // æµ‹è¯•é”é‡å…¥ lock1.acquire(); System.out.println(\"çº¿ç¨‹ 1 å†æ¬¡è·å–é”\"); Thread.sleep(5 * 1000); lock1.release(); System.out.println(\"çº¿ç¨‹ 1 é‡Šæ”¾é”\"); lock1.release(); System.out.println(\"çº¿ç¨‹ 1 å†æ¬¡é‡Šæ”¾é”\"); } catch (Exception e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable() { @Override public void run() { // è·å–é”å¯¹è±¡ try { lock2.acquire(); System.out.println(\"çº¿ç¨‹ 2 è·å–é”\"); // æµ‹è¯•é”é‡å…¥ lock2.acquire(); System.out.println(\"çº¿ç¨‹ 2 å†æ¬¡è·å–é”\"); Thread.sleep(5 * 1000); lock2.release(); System.out.println(\"çº¿ç¨‹ 2 é‡Šæ”¾é”\"); lock2.release(); System.out.println(\"çº¿ç¨‹ 2 å†æ¬¡é‡Šæ”¾é”\"); } catch (Exception e) { e.printStackTrace(); } } }).start(); } // åˆ†å¸ƒå¼é”åˆå§‹åŒ– public CuratorFramework getCuratorFramework (){ //é‡è¯•ç­–ç•¥ï¼Œåˆè¯•æ—¶é—´ 3 ç§’ï¼Œé‡è¯• 3 æ¬¡ RetryPolicy policy = new ExponentialBackoffRetry(3000, 3); //é€šè¿‡å·¥å‚åˆ›å»º Curator CuratorFramework client = CuratorFrameworkFactory.builder() .connectString(connectString) .connectionTimeoutMs(connectionTimeout) .sessionTimeoutMs(sessionTimeout) .retryPolicy(policy).build(); //å¼€å¯è¿æ¥ client.start(); System.out.println(\"zookeeper åˆå§‹åŒ–å®Œæˆ...\"); return client; } }","date":"2021-10-08","objectID":"/posts/zookeeper/zookeeper-04/:1:2","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åˆ†å¸ƒå¼é”æ¡ˆä¾‹ ï¼ˆå››ï¼‰","uri":"/posts/zookeeper/zookeeper-04/"},{"categories":["Zookeeper"],"content":"æœåŠ¡å™¨åŠ¨æ€ä¸Šä¸‹çº¿ç›‘å¬æ¡ˆä¾‹ æŸåˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä¸»èŠ‚ç‚¹å¯ä»¥æœ‰å¤šå°ï¼Œå¯ä»¥åŠ¨æ€ä¸Šä¸‹çº¿ï¼Œä»»æ„ä¸€å°å®¢æˆ·ç«¯éƒ½èƒ½å®æ—¶æ„ŸçŸ¥ åˆ°ä¸»èŠ‚ç‚¹æœåŠ¡å™¨çš„ä¸Šä¸‹çº¿ã€‚ ","date":"2021-10-07","objectID":"/posts/zookeeper/zookeeper-03/:0:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper æœåŠ¡å™¨åŠ¨æ€ä¸Šä¸‹çº¿ç›‘å¬æ¡ˆä¾‹ ï¼ˆä¸‰ï¼‰","uri":"/posts/zookeeper/zookeeper-03/"},{"categories":["Zookeeper"],"content":"ä»£ç å®ç° ","date":"2021-10-07","objectID":"/posts/zookeeper/zookeeper-03/:1:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper æœåŠ¡å™¨åŠ¨æ€ä¸Šä¸‹çº¿ç›‘å¬æ¡ˆä¾‹ ï¼ˆä¸‰ï¼‰","uri":"/posts/zookeeper/zookeeper-03/"},{"categories":["Zookeeper"],"content":"æœåŠ¡ç«¯ä»£ç  package com.atguigu.zkcase1; import java.io.IOException; import org.apache.zookeeper.CreateMode; import org.apache.zookeeper.WatchedEvent; import org.apache.zookeeper.Watcher; import org.apache.zookeeper.ZooKeeper; import org.apache.zookeeper.ZooDefs.Ids; public class DistributeServer { private static String connectString = \"hadoop102:2181,hadoop103:2181,hadoop104:2181\"; private static int sessionTimeout = 2000; private ZooKeeper zk = null; private String parentNode = \"/servers\"; // åˆ›å»ºåˆ° zk çš„å®¢æˆ·ç«¯è¿æ¥ public void getConnect() throws IOException{ zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() { @Override public void process(WatchedEvent event) { } }); } // æ³¨å†ŒæœåŠ¡å™¨ public void registServer(String hostname) throws Exception{ String create = zk.create(parentNode + \"/server\", hostname.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); System.out.println(hostname +\" is online \"+ create); } // ä¸šåŠ¡åŠŸèƒ½ public void business(String hostname) throws Exception{ System.out.println(hostname + \" is working ...\"); Thread.sleep(Long.MAX_VALUE); } public static void main(String[] args) throws Exception { // 1 è·å– zk è¿æ¥ DistributeServer server = new DistributeServer(); server.getConnect(); // 2 åˆ©ç”¨ zk è¿æ¥æ³¨å†ŒæœåŠ¡å™¨ä¿¡æ¯ server.registServer(args[0]); // 3 å¯åŠ¨ä¸šåŠ¡åŠŸèƒ½ server.business(args[0]); } }","date":"2021-10-07","objectID":"/posts/zookeeper/zookeeper-03/:1:1","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper æœåŠ¡å™¨åŠ¨æ€ä¸Šä¸‹çº¿ç›‘å¬æ¡ˆä¾‹ ï¼ˆä¸‰ï¼‰","uri":"/posts/zookeeper/zookeeper-03/"},{"categories":["Zookeeper"],"content":"å®¢æˆ·ç«¯ä»£ç  package com.atguigu.zkcase1; import java.io.IOException; import java.util.ArrayList; import java.util.List; import org.apache.zookeeper.WatchedEvent; import org.apache.zookeeper.Watcher; import org.apache.zookeeper.ZooKeeper; public class DistributeClient { private static String connectString = \"hadoop102:2181,hadoop103:2181,hadoop104:2181\"; private static int sessionTimeout = 2000; private ZooKeeper zk = null; private String parentNode = \"/servers\"; // åˆ›å»ºåˆ° zk çš„å®¢æˆ·ç«¯è¿æ¥ public void getConnect() throws IOException { zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() { @Override public void process(WatchedEvent event) { // å†æ¬¡å¯åŠ¨ç›‘å¬ try { getServerList(); } catch (Exception e) { e.printStackTrace(); } } }); } // è·å–æœåŠ¡å™¨åˆ—è¡¨ä¿¡æ¯ public void getServerList() throws Exception { // 1 è·å–æœåŠ¡å™¨å­èŠ‚ç‚¹ä¿¡æ¯ï¼Œå¹¶ä¸”å¯¹çˆ¶èŠ‚ç‚¹è¿›è¡Œç›‘å¬ List\u003cString\u003e children = zk.getChildren(parentNode, true); // 2 å­˜å‚¨æœåŠ¡å™¨ä¿¡æ¯åˆ—è¡¨ ArrayList\u003cString\u003e servers = new ArrayList\u003c\u003e(); // 3 éå†æ‰€æœ‰èŠ‚ç‚¹ï¼Œè·å–èŠ‚ç‚¹ä¸­çš„ä¸»æœºåç§°ä¿¡æ¯ for (String child : children) { byte[] data = zk.getData(parentNode + \"/\" + child, false, null); servers.add(new String(data)); } // 4 æ‰“å°æœåŠ¡å™¨åˆ—è¡¨ä¿¡æ¯ System.out.println(servers); } // ä¸šåŠ¡åŠŸèƒ½ public void business() throws Exception{ System.out.println(\"client is working ...\"); Thread.sleep(Long.MAX_VALUE); } public static void main(String[] args) throws Exception { // 1 è·å– zk è¿æ¥ DistributeClient client = new DistributeClient(); client.getConnect(); // 2 è·å– servers çš„å­èŠ‚ç‚¹ä¿¡æ¯ï¼Œä»ä¸­è·å–æœåŠ¡å™¨ä¿¡æ¯åˆ—è¡¨ client.getServerList(); //3 ä¸šåŠ¡è¿›ç¨‹å¯åŠ¨ client.business(); } }","date":"2021-10-07","objectID":"/posts/zookeeper/zookeeper-03/:1:2","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper æœåŠ¡å™¨åŠ¨æ€ä¸Šä¸‹çº¿ç›‘å¬æ¡ˆä¾‹ ï¼ˆä¸‰ï¼‰","uri":"/posts/zookeeper/zookeeper-03/"},{"categories":["ElasticStack"],"content":"ELK ç»¼åˆå®è·µ ","date":"2021-10-06","objectID":"/posts/elk/elk-experiment/:0:0","tags":["æ—¥å¿—æ”¶é›†","è¿ç»´å®æˆ˜"],"title":"ELK ç»¼åˆå®è·µ-æ”¶é›†Nignxçš„æ—¥å¿—æ•°æ® ï¼ˆäº”ï¼‰","uri":"/posts/elk/elk-experiment/"},{"categories":["ElasticStack"],"content":"å®è·µæ¡ˆä¾‹ é¡¹ç›®å®ç°æ•ˆæœå›¾ ","date":"2021-10-06","objectID":"/posts/elk/elk-experiment/:1:0","tags":["æ—¥å¿—æ”¶é›†","è¿ç»´å®æˆ˜"],"title":"ELK ç»¼åˆå®è·µ-æ”¶é›†Nignxçš„æ—¥å¿—æ•°æ® ï¼ˆäº”ï¼‰","uri":"/posts/elk/elk-experiment/"},{"categories":["ElasticStack"],"content":"éœ€æ±‚ç®€ä»‹ åœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­ï¼Œæ—¥å¿—ä¿¡æ¯ä¼šè¾“å‡ºåˆ°å®šåˆ¶çš„ç›®å½•é‡Œé¢äº†ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±ä»¥nignxçš„æ—¥å¿—æ•°æ®ä¸ºå¯¹è±¡ï¼Œä½¿ç”¨filebeatæ¥è·å–è¿™äº›æ—¥å¿—ï¼Œå°†å…¶è¾“å…¥åˆ°logstashä¸­ï¼Œlogstashæ¥æ”¶åˆ°æ•°æ®åï¼Œå®šåˆ¶æ˜¾ç¤ºæ ¼å¼ï¼Œå°†å…¶è¾“å…¥åˆ°elasticsearchä¸­ï¼Œkibanaä»elasticsearchä¸­è·å–æ•°æ®ï¼Œå¹¶å±•ç¤ºåˆ°å½“å‰ç•Œé¢ã€‚ ","date":"2021-10-06","objectID":"/posts/elk/elk-experiment/:1:1","tags":["æ—¥å¿—æ”¶é›†","è¿ç»´å®æˆ˜"],"title":"ELK ç»¼åˆå®è·µ-æ”¶é›†Nignxçš„æ—¥å¿—æ•°æ® ï¼ˆäº”ï¼‰","uri":"/posts/elk/elk-experiment/"},{"categories":["ElasticStack"],"content":"æµç¨‹åˆ†æ ç¡®å®šnginxçš„æ—¥å¿—æ–‡ä»¶ filebeat è¯»å–æœ¬æœºçš„nginxæ—¥å¿—ï¼Œå¹¶ä¼ è¾“åˆ° logstash logstash æ¥æ”¶åˆ°æ•°æ®åï¼Œå®šåˆ¶è¾“å‡ºæ ¼å¼ï¼Œå°†æ•°æ®è½¬äº¤ç»™ elasticsearch kibana æ ¹æ®å®šåˆ¶çš„ç´¢å¼•åç§°ï¼Œä» elasticsearchä¸­è·å–æ•°æ®ã€‚ å…³é”®ç‚¹åˆ†æ å‡†å¤‡å·¥ä½œï¼š nginx æ—¥å¿—æ–‡ä»¶å¾„åœ¨/var/log/nginx/access.logï¼Œæˆ‘ä»¬æ¥è·å–.logæ ¼å¼æ–‡ä»¶æ•°æ® filebeatæ•°æ®æ”¶é›† åŸºäºé»˜è®¤çš„ input æ–¹å¼ç¡®å®šæ•°æ®æ–‡ä»¶ï¼Œoutput æ–¹å¼é€‰æ‹© logstash æ³¨æ„ï¼š input å†…éƒ¨çš„ nabled å¿…é¡»å¼€å¯ logstashä¼ è¾“ åŸºäº input å±æ€§è·å– filebeat çš„å†…å®¹ï¼ŒåŸºäºoutputå±æ€§å°†æ•°æ®å‘é€ç»™es kibanaå±•ç¤º åŸºäºç´¢å¼•åç§°åˆ° elasticsearch è·å–æ•°æ®ï¼Œç„¶ååœ¨discoverä¸­ç¡®è®¤æ•°æ® å®è·µæ­¥éª¤ ç¯å¢ƒè¿˜åŸ æ¸…ç©ºfilebeatç¨‹åº å…³é—­kibanaç¨‹åº æ¸…ç©ºelasticsearchç´¢å¼• å®šåˆ¶filebeat ç¼–å†™é…ç½®æ–‡ä»¶ å¯åŠ¨filebeat å®šåˆ¶logstash å®šåˆ¶logstashæ–‡ä»¶ å¯åŠ¨logstash å®šåˆ¶kibana é…ç½®æŸ¥è¯¢ç´¢å¼• éªŒè¯æ•ˆæœ ","date":"2021-10-06","objectID":"/posts/elk/elk-experiment/:1:2","tags":["æ—¥å¿—æ”¶é›†","è¿ç»´å®æˆ˜"],"title":"ELK ç»¼åˆå®è·µ-æ”¶é›†Nignxçš„æ—¥å¿—æ•°æ® ï¼ˆäº”ï¼‰","uri":"/posts/elk/elk-experiment/"},{"categories":["ElasticStack"],"content":"é¡¹ç›®å®è·µ ç¯å¢ƒè¿˜åŸ æ¸…é™¤æ‰€æœ‰çš„index for index in $(curl -s http://192.168.8.12:9200/_cat/indices | awk '{print $3}') do curl -XDELETE 192.168.8.12:9200/$index done filebeatä¸»æœºå®‰è£…nginx apt install -y nginx å…³é—­æ‰€æœ‰æœåŠ¡ systemctl stop logstash systemctl stop filebeat systemctl stop kibana ç¼–å†™ filebeat é…ç½®æ–‡ä»¶ å®šåˆ¶é…ç½®æ–‡ä»¶ # cd /etc/filebeat/ # cat filebeat.yaml filebeat.inputs: - type: log paths: - /var/log/nginx/*.log output.logstash: hosts: [\"192.168.8.13:5044\"] å¯åŠ¨filebeat systemctl start filebeat ç¼–å†™ logstash é…ç½®æ–‡ä»¶ # cd /etc/logstash/conf.d # vim logstash.conf input { beats { port =\u003e 5044 } } output{ elasticsearch { hosts =\u003e [\"192.168.8.12:9200\"] index =\u003e \"nginx-%{+YYYY.MM.dd}\" } } é‡å¯logstash systemctl start logstash æ£€æŸ¥æ•ˆæœ curl 192.168.8.12:9200/_cat/indices æŸ¥çœ‹æ—¥å¿— tail -f /var/log/logstash/logstash-plain.log å¯åŠ¨ kibana systemctl start kibana netstat -tnulp æµè§ˆå™¨ç™»å½•åˆ° 192.168.8.14:5601ï¼Œç‚¹å‡»å·¦ä¸Šè§’çš„logoå›¾æ ‡ï¼Œè¿›å…¥åˆ°homeé¡µé¢ é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿›å…¥ï¼š é€‰æ‹© å·¦è¾¹æ çš„ Stack Management ç‚¹å‡» kibana æ çš„ ç´¢å¼•æ¨¡å¼ ç‚¹å‡» åˆ›å»ºç´¢å¼•æ¨¡å¼ åœ¨ç´¢å¼•æ¨¡å¼ä¸­ï¼Œè¾“å…¥æ­£åˆ™è¡¨è¾¾å¼ï¼Œçœ‹æ˜¯å¦èƒ½å¤ŸåŒ¹é…ç°æœ‰çš„æ—¥å¿—ï¼ŒåŒ¹é…åˆ°çš„è¯ï¼Œç‚¹å‡»ä¸‹ä¸€æ­¥ æ—¶é—´å­—æ®µé€‰æ‹© é»˜è®¤çš„ @timestamp å­—æ®µï¼Œç„¶åç‚¹å‡»å³ä¸‹è§’çš„ åˆ›å»ºç´¢å¼•æ¨¡å¼ æˆ‘ä»¬æ”¶é›†åˆ°çš„æ•°æ®ä¸­ï¼ŒåŒ…å«58ä¸ªå­—æ®µï¼Œå½“æˆ‘ä»¬ç‚¹å‡»æŸäº›å±æ€§çš„æ—¶å€™ï¼Œè¿˜ä¼šæ˜¾ç¤ºç®€å•çš„æ’åºï¼Œåˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬çš„kibanaä»elasticsearchä¸­è·å–æ•°æ®å°±é…ç½®å®Œæ¯•äº† ç‚¹å‡»å·¦è¾¹æ çš„ç¬¬ä¸€ä¸ª\"Discover\"æŒ‰é’®,ç‚¹å‡»\"Add ï¬lter\"çš„ä¸‹æ‹‰æ¡†ï¼Œé€‰æ‹©nginx-*ç´¢å¼•åï¼Œåœ¨\"Refresh\"å³ä¾§é€‰æ‹©æ—¥å¿—çš„æ—¶é—´èŒƒå›´ï¼Œå°±å¯ä»¥å®æ—¶çš„æŸ¥çœ‹åˆ°è¯´æœ‰æ•°æ®çš„è·å–æ•ˆæœ ç•Œé¢è§£æ Filters éƒ¨åˆ†çš„è§„åˆ™ï¼Œå…¶å®å°±æ˜¯æ—¥å¿—ä¸­çš„é”®åæ˜¯å¦åŒ…å«æŸäº›å…³é”®ä¿¡æ¯ï¼Œç­‰åŒäº KQLçš„ç¤ºä¾‹ message is 200ã€‚ ç‚¹å¼€æ¯æ¡è®°å½•æ—è¾¹çš„\"\u003eâ€œè¡¨ç¤ºæŸ¥çœ‹è¯¥æ¡æ—¥å¿—çš„å…·ä½“ä¿¡æ¯ ","date":"2021-10-06","objectID":"/posts/elk/elk-experiment/:1:3","tags":["æ—¥å¿—æ”¶é›†","è¿ç»´å®æˆ˜"],"title":"ELK ç»¼åˆå®è·µ-æ”¶é›†Nignxçš„æ—¥å¿—æ•°æ® ï¼ˆäº”ï¼‰","uri":"/posts/elk/elk-experiment/"},{"categories":["Zookeeper"],"content":"é›†ç¾¤éƒ¨ç½² Zookeeperä¸ºäº†æ›´å¥½çš„å®ç°ç”Ÿäº§çš„ä¸šåŠ¡åœºæ™¯ï¼Œä¸€èˆ¬éƒ½ä¼šé‡‡ç”¨åˆ†å¸ƒå¼çš„é›†ç¾¤æ¶æ„ã€‚é›†ç¾¤é€šå¸¸ç”±2n+1å°ServerèŠ‚ç‚¹ç»„æˆï¼Œæ¯ä¸ªServeréƒ½çŸ¥é“å½¼æ­¤çš„å­˜åœ¨ã€‚æ¯ä¸ªserveréƒ½ç»´æŠ¤çš„å†…å­˜çŠ¶æ€é•œåƒä»¥åŠæŒä¹…åŒ–å­˜å‚¨çš„äº‹åŠ¡æ—¥å¿—å’Œå¿«ç…§ã€‚ å¯¹äº2n+1å°serverï¼Œåªè¦æœ‰\u003e=(n+1)å°serverèŠ‚ç‚¹å¯ç”¨ï¼Œæ•´ä¸ªZookeeperç³»ç»Ÿä¿æŒå¯ç”¨ã€‚ ä¸ºäº†ç»´æŠ¤é›†ç¾¤å†…éƒ¨æ‰€æœ‰ä¸»æœºä¿¡æ¯çš„ä¸€è‡´æ€§ï¼Œä»–ä»¬è‡ªå·±å‚è€ƒPaxosåè®®è‡ªå·±è®¾è®¡äº†ä¸€ä¸ªæ›´åŠ è½»é‡çº§çš„åè®®:Zab(Zookeeper Atomic Broadcast)æ¥è§£å†³é›†ç¾¤æ•°æ®ä¸€è‡´æ€§çš„é—®é¢˜ã€‚ ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:0:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"é›†ç¾¤æµç¨‹ Leaderæ¢å¤ï¼šå½“é›†ç¾¤Leaderä¸»æœºæœåŠ¡é‡å¯æˆ–è€…å´©æºƒåï¼Œå½“Zookeeperé›†ç¾¤ä¸­æ‰€æœ‰Serverä¸»æœºåŸºäº Zabåè®®é€‰ä¸¾æ–°çš„Leaderè€…ï¼Œæ¥ç€å°±è¿›å…¥æ—¥å¸¸æ“ä½œé˜¶æ®µã€‚ç„¶åå…¶ä»–Serverä¸»æœºå’Œæ–°çš„Leaderä¸»æœºè¿›è¡Œæ•°æ® ä¿¡æ¯åŒæ­¥ï¼Œå½“çŠ¶æ€åŒæ­¥å®Œæˆä»¥åï¼Œ æ—¥å¸¸æ“ä½œé˜¶æ®µï¼š æ—¥å¸¸æ“ä½œé˜¶æ®µä¸»è¦æœ‰ä¸¤ç§åœºæ™¯ï¼šä¸»æœºé—´å¿ƒè·³ç›‘æµ‹å’Œæ•°æ®æ“ä½œã€‚ ä¸»æœºé—´å¿ƒè·³ç›‘æµ‹ï¼š å½“Leaderé€‰ä¸¾å®Œæ¯•åï¼Œå°±è¿›å…¥æ—¥å¸¸æ“ä½œé˜¶æ®µï¼Œç¬¬ä¸€æ­¥å°±æ˜¯æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹éƒ½äº’ç›¸ä¿æŒé€šä¿¡ï¼Œ ç„¶åLeaderå’ŒFollowerèŠ‚ç‚¹é—´è¿›è¡Œæ•°æ®åŒæ­¥ï¼Œç¡®ä¿æ‰€æœ‰ä¸»æœºèŠ‚ç‚¹éƒ½æ˜¯ç›¸åŒçš„çŠ¶æ€ï¼Œ å½“æ‰€æœ‰FollowerèŠ‚ç‚¹å’Œæ–°çš„Leaderä¸»æœºå®Œæˆæ•°æ®ä¿¡æ¯åŒæ­¥ä»¥åï¼Œå°±å¼€å§‹è¿›è¡Œæ—¥å¸¸çš„æ•°æ®æ“ä½œã€‚ ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:1:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"é€šä¿¡æœºåˆ¶ å¯¹äºZookeeperé›†ç¾¤æ¥è¯´ï¼Œæˆ‘ä»¬è¦è€ƒè™‘çš„å†…å®¹ä¸»è¦æœ‰ä¸‰å¤§å—ï¼šå®¢æˆ·ç«¯è¿æ¥ã€ä¸»æœºé€šä¿¡ã€é€‰ä¸¾Leaderã€‚ å®¢æˆ·ç«¯è¿æ¥ï¼š å®¢æˆ·ç«¯è¿æ¥æœåŠ¡ç«¯åŠŸèƒ½ï¼Œè¿›è¡Œç›¸å…³è¯·æ±‚æ“ä½œ ä¸»æœºé€šä¿¡ï¼š é›†ç¾¤å„æœåŠ¡èŠ‚ç‚¹è¿›è¡Œä¿¡æ¯äº¤æµçš„åŠŸèƒ½ é€‰ä¸¾Leaderï¼š é›†ç¾¤ä¸­å„æœåŠ¡èŠ‚ç‚¹å…±åŒé€‰ä¸¾ä¸»èŠ‚ç‚¹çš„åŠŸèƒ½ æ ¼å¼ï¼š server.\u003cmyid\u003e=\u003cserver_ip\u003e:\u003cLF_Port\u003e:\u003cL_Port\u003e å®¢æˆ·ç«¯æ“ä½œï¼š 2181 ä¸»æœºé€šä¿¡ï¼š 2182 é€‰ä¸¾Leaderï¼š 2183 æ³¨æ„ï¼š è¿™ä¸‰ç«¯å£éƒ½æ˜¯è‡ªå®šä¹‰çš„ï¼Œåœ¨ç”Ÿäº§ä¸­ï¼Œå› ä¸ºæ¯å°ä¸»æœºéƒ½æœ‰ç‹¬ç«‹çš„ipï¼Œæ‰€ä»¥ä¸‰ä¸ªç«¯å£ä¸€èˆ¬éƒ½è®¾ç½®ä¸€æ ·ã€‚ ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:2:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"é›†ç¾¤éƒ¨ç½² Zookeeperé›†ç¾¤ä½¿ç”¨å¤šä¸ªç‹¬ç«‹çš„ä¸»æœºï¼Œæ¯ä¸ªä¸»æœºä¸Šéƒ½éƒ¨ç½²åŒæ ·ç¯å¢ƒçš„Zookeeperç¯å¢ƒï¼ŒåŸºäºå†…éƒ¨çš„Zabåè®®è¾¾åˆ°æ•°æ®çš„ä¸€è‡´æ€§ï¼Œç„¶åç»Ÿä¸€å¯¹å¤–æä¾›æœåŠ¡ã€‚å®¢æˆ·ç«¯è¿æ¥ä»»æ„ä¸€èŠ‚ç‚¹ï¼Œæ•ˆæœéƒ½ä¸€æ ·ã€‚ èŠ‚ç‚¹ ä¸»æœºIP é€šä¿¡ç«¯å£ å¿ƒè·³ç«¯å£ é€‰ä¸¾ç«¯å£ è½¯ä»¶å­˜æ”¾ç›®å½• myid zk1 192.168.10.126 2181 2182 2183 /data/server/zk1/{data,logs} 1 zk2 192.168.10.127 2181 2182 2183 /data/server/zk2/{data,logs} 2 zk3 192.168.10.128 2181 2182 2183 /data/server/zk3/{data,logs} 3 ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:3:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"è½¯ä»¶å®‰è£… åˆ†åˆ«åœ¨ä¸‰ä¸ªä¸åŒçš„Zookeeperç›®å½•ä¸­æ‰§è¡Œè½¯ä»¶å®‰è£… å®‰è£…ä¸‰ä¸ªèŠ‚ç‚¹ tar xf /data/softs/apache-zookeeper-3.7.0.tar.gz -C /data/server/ mv /data/server/apache-zookeeper-3.7.0 /data/server/zk1 mkdir /data/softs/zk/{data,log} -pæ³¨æ„ï¼š ä¸‰ä¸ªèŠ‚ç‚¹æ‰§è¡ŒåŒæ ·çš„æ“ä½œï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯æ•°å­—ä¸ä¸€è‡´ï¼Œåˆ†åˆ«æ˜¯1-2-3 ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:3:1","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"é…ç½®ç®¡ç† å‡†å¤‡é…ç½®æ–‡ä»¶ cd /data/server/ mv zk1/conf/zoo_sample.cfg zk1/conf/zoo.cfg ä¿®æ”¹é…ç½®æ–‡ä»¶ # grep -ni '^[a-Z]' zk1/conf/zoo.cfg 2:tickTime=2000 5:initLimit=10 8:syncLimit=5 12:dataDir=/data/server/zk1/data 13:dataLogDir=/data/server/zk1/log 15:clientPort=2181 30:server.1=192.168.10.126:2182:2183 31:server.2=192.168.10.127:2282:2283 32:server.3=192.168.10.128:2382:2383 è®¾ç½®myidæ–‡ä»¶ echo 1 \u003e zk1/data/myid æ³¨æ„ï¼š ä¸‰ä¸ªèŠ‚ç‚¹æ‰§è¡ŒåŒæ ·çš„æ“ä½œï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯ç»¿è‰²èƒŒæ™¯çš„å­—ä½“ä¸ä¸€è‡´ï¼Œåˆ†åˆ«æ˜¯1-2-3 ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:3:2","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"å¯åŠ¨æœåŠ¡ ä»¥ä¸Šä¸‰ä¸ªèŠ‚ç‚¹å†…å®¹éƒ½é…ç½®å®Œæ¯•åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯åŠ¨é›†ç¾¤äº†ã€‚ ä¸å•æœºæ¨¡å¼çš„å¯åŠ¨æ–¹æ³•ä¸€è‡´ï¼Œåªéœ€ä¸€æ¬¡å¯åŠ¨æ‰€æœ‰ZookeeperèŠ‚ç‚¹å³å¯å¯åŠ¨æ•´ä¸ªé›†ç¾¤ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä¸€ä¸ªä¸€\rä¸ªçš„æ‰‹å·¥å¯åŠ¨ï¼Œå½“ç„¶äº†æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨è„šæœ¬æ–¹å¼ä¸€æ¬¡å¯åŠ¨æ‰€æœ‰Zookeeperä¸»æœºæœåŠ¡ã€‚\rå¯åŠ¨æœåŠ¡\r/data/server/zk1/bin/zkServer.sh start\r/data/server/zk2/bin/zkServer.sh start\r/data/server/zk3/bin/zkServer.sh startæœåŠ¡å¯åŠ¨åœæ­¢è„šæœ¬ #!/bin/bash case $1 in \"start\"){ for i in zk1 zk2 zk3\rdo echo ---------- zookeeper $i å¯åŠ¨ ------------\rssh $i \"/opt/module/zookeeper-3.5.7/bin/zkServer.sh start\" done };; \"stop\"){ for i in zk1 zk2 zk3\rdo echo ---------- zookeeper $i åœæ­¢ ------------\rssh $i \"/opt/module/zookeeper-3.5.7/bin/zkServer.sh stop\" done };; \"status\"){ for i in zk1 zk2 zk3\rdo echo ---------- zookeeper $i çŠ¶æ€ ------------\rssh $i \"/opt/module/zookeeper-3.5.7/bin/zkServer.sh status\" done };; esac #å¢åŠ è„šæœ¬æ‰§è¡Œæƒé™\r$ chmod u+x zk.sh\r#æ‰§è¡Œ Zookeeper é›†ç¾¤å¯åŠ¨è„šæœ¬\r$ zk.sh start\rZookeeper é›†ç¾¤åœæ­¢è„šæœ¬\r$ zk.sh stop ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:3:3","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"æœåŠ¡æ£€æŸ¥ æ£€æŸ¥é›†ç¾¤æœåŠ¡ä¸€èˆ¬æœ‰ä¸¤ç±»æ–¹æ³•ï¼šæ£€æŸ¥ç«¯å£å’Œæ£€æŸ¥é›†ç¾¤æœåŠ¡çŠ¶æ€ æ£€æŸ¥ç«¯å£\rnetstat -tnulp | grep 218\ræŸ¥çœ‹é›†ç¾¤æœåŠ¡çŠ¶æ€\r[root@controller ~]# /data/server/zk1/bin/zkServer.sh status\rZooKeeper JMX enabled by default\rUsing config: /data/server/zk1/bin/../conf/zoo.cfg\rMode: follower\r[root@controller ~]# /data/server/zk2/bin/zkServer.sh status\rZooKeeper JMX enabled by default\rUsing config: /data/server/zk2/bin/../conf/zoo.cfg\rMode: leader\r[root@controller ~]# /data/server/zk3/bin/zkServer.sh status\rZooKeeper JMX enabled by default\rUsing config: /data/server/zk3/bin/../conf/zoo.cfg\rMode: follower\rç»“æœæ˜¾ç¤ºï¼š\ræŸ¥çœ‹é›†ç¾¤çŠ¶æ€ï¼Œå…³é”®å°±æ˜¯çœ‹Mode:çš„å€¼ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç›®å‰Zookeeperä¸‰èŠ‚ç‚¹é›†ç¾¤ä¸­ï¼Œå¤„äºleaderçš„\ræ˜¯zk2èŠ‚ç‚¹ï¼Œå…¶ä»–ä¸¤ä¸ªèŠ‚ç‚¹æ˜¯followerè§’è‰²ã€‚\råŒæ—¶è¿æ¥å¤šä¸ªserverçš„æ–¹æ³•\rbin/zkCli -server \u003czk1_ip\u003e:\u003czk1_port\u003e,\u003czk2_ip\u003e:\u003czk2_port\u003e,\u003czk3_ip\u003e:\u003czk3_port\u003e\ræ³¨æ„ï¼š\råŒæ—¶è¿æ¥å¤šä¸ªserverèŠ‚ç‚¹çš„æ—¶å€™ï¼Œå½¼æ­¤é—´ä½¿ç”¨é€—å·éš”å¼€\rä½¿ç”¨ä»»æ„ä¸€ä¸ªzkCli.shè¿æ¥ä¸‰ä¸ªZookeeperèŠ‚ç‚¹\rcd /data/server/zk2/bin/\r./zkCli.sh -server 192.168.10.126:2181,192.168.10.127:2281,192.168.10.128:2381 ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:3:4","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"ä¸“ç”¨æ£€æµ‹ å› ä¸ºä½¿ç”¨telnetæ–¹æ³•æ¥æ£€æŸ¥é›†ç¾¤çš„èŠ‚ç‚¹çŠ¶æ€ä¿¡æ¯æ¯”è¾ƒç¹çï¼Œè€Œä¸”ç»å¸¸ä¸­æ–­ï¼Œæ‰€ä»¥ç”Ÿäº§ä¸­æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ncè½¯ä»¶ æ¥æ£€æŸ¥Zookeeperé›†ç¾¤çŠ¶æ€. ncå…¨ç§°NetCatï¼Œåœ¨ç½‘ç»œå·¥å…·ä¸­æœ‰â€œç‘å£«å†›åˆ€â€ç¾èª‰ï¼Œæ”¯æŒWindowså’ŒLinuxã€‚å› ä¸ºå®ƒçŸ­å°ç²¾æ‚(ä¸è¿‡25k)ã€åŠŸ èƒ½å®ç”¨ï¼Œè¢«è®¾è®¡ä¸ºä¸€ä¸ªç®€å•ã€å¯é çš„ç½‘ç»œå·¥å…·ï¼Œå¯é€šè¿‡TCPæˆ–UDPåè®®ä¼ è¾“è¯»å†™æ•°æ®ã€‚åŒæ—¶ï¼Œå®ƒè¿˜æ˜¯ä¸€ä¸ªç½‘ç»œåº”ç”¨Debugåˆ†æå™¨ï¼Œå› ä¸ºå®ƒå¯ä»¥æ ¹æ®éœ€è¦åˆ›å»ºå„ç§ä¸åŒç±»å‹çš„ç½‘ç»œè¿æ¥ã€‚ å®‰è£…è½¯ä»¶\rapt-get -y install netcat-traditional\rä½¿ç”¨æ–¹å¼\recho \"å‘½ä»¤\" | nc \u003cserver_ip\u003e \u003cserver_port\u003e\ræ£€æŸ¥é›†ç¾¤çŠ¶æ€\recho stat | nc 192.168.10.126 2181\recho stat | nc 192.168.10.127 2281\recho stat | nc 192.168.10.128 2381 ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:3:5","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"é›†ç¾¤æ“ä½œå‘½ä»¤ ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:4:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"å¸¸è§å‘½ä»¤ å‘½ä»¤ å†…å®¹ conf è¾“å‡ºç›¸å…³æœåŠ¡é…ç½®çš„è¯¦ç»†ä¿¡æ¯ cons åˆ—å‡ºæ‰€æœ‰è¿æ¥åˆ°æœåŠ¡å™¨çš„å®¢æˆ·ç«¯çš„å®Œå…¨çš„è¿æ¥/ä¼šè¯çš„è¯¦ç»†ä¿¡æ¯ envi è¾“å‡ºå…³äºæœåŠ¡ç¯å¢ƒçš„è¯¦ç»†ä¿¡æ¯ dump åˆ—å‡ºæœªç»å¤„ç†çš„ä¼šè¯å’Œä¸´æ—¶èŠ‚ç‚¹ stat æŸ¥çœ‹å“ªä¸ªèŠ‚ç‚¹è¢«é€‰æ‹©ä½œä¸º Follower æˆ–è€… Leader ruok æµ‹è¯•æ˜¯å¦å¯åŠ¨äº†è¯¥ Serverï¼Œè‹¥å›å¤ imok è¡¨ç¤ºå·²ç»å¯åŠ¨ mntr è¾“å‡ºä¸€äº›è¿è¡Œæ—¶ä¿¡æ¯ reqs åˆ—å‡ºæœªç»å¤„ç†çš„è¯·æ±‚ wchs åˆ—å‡ºæœåŠ¡å™¨ watch çš„ç®€è¦ä¿¡æ¯ wchc é€šè¿‡ session åˆ—å‡ºæœåŠ¡å™¨ watch çš„è¯¦ç»†ä¿¡æ¯ wchp é€šè¿‡è·¯å¾„åˆ—å‡ºæœåŠ¡å™¨ watch çš„è¯¦ç»†ä¿¡æ¯ srvr è¾“å‡ºæœåŠ¡çš„æ‰€æœ‰ä¿¡æ¯ srst é‡ç½®æœåŠ¡å™¨ç»Ÿè®¡ä¿¡æ¯ kill å…³æ‰ Server isro æŸ¥çœ‹è¯¥æœåŠ¡çš„èŠ‚ç‚¹æƒé™ä¿¡æ¯ ZooKeeper æ”¯æŒæŸäº›ç‰¹å®šçš„å››å­—å‘½ä»¤å­—æ¯ä¸å…¶çš„äº¤äº’ã€‚å®ƒä»¬å¤§å¤šæ˜¯æŸ¥è¯¢å‘½ä»¤ï¼Œç”¨æ¥è·å– ZooKeeper æœåŠ¡çš„å½“å‰çŠ¶æ€åŠç›¸å…³ä¿¡æ¯ã€‚ç”¨æˆ·åœ¨å®¢æˆ·ç«¯å¯ä»¥é€šè¿‡ telnet æˆ– nc å‘ ZooKeeper æäº¤ç›¸åº”çš„å‘½ä»¤ã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™äº›4å­—å‘½ä»¤æœ‰å¯èƒ½ä¼šè¢«æ‹’ç»ï¼Œå‘é€å¦‚ä¸‹æŠ¥é”™ xxx is not executed because it is not in the whitelist. è§£å†³åŠæ³•ï¼šå‘ zoo.cfg æ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹é…ç½® 4lw.commands.whitelist=* ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:4:1","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"å‘½ä»¤å®è·µ æŸ¥çœ‹èŠ‚ç‚¹æœåŠ¡çŠ¶æ€\recho stat | nc 127.0.0.1 2281\ræŸ¥çœ‹èŠ‚ç‚¹æœåŠ¡é…ç½®\recho conf | nc 127.0.0.1 2281\ræŸ¥çœ‹èŠ‚ç‚¹æœåŠ¡ç¯å¢ƒ\recho envi | nc 127.0.0.1 2281\ræŸ¥çœ‹èŠ‚ç‚¹æœåŠ¡ä¼šè¯\recho cons | nc 127.0.0.1 2281\recho dump | nc 127.0.0.1 2281åŸºæœ¬å®‰å…¨ åœ¨è¿™ä¹ˆå¤šçš„æœåŠ¡çŠ¶æ€æŸ¥çœ‹å‘½ä»¤ä¸­æœ‰å¾ˆå¤šå­˜åœ¨éšæ‚£çš„å‘½ä»¤ï¼Œæ‰€ä»¥ä¸ºäº†é¿å…ç”Ÿäº§ä¸­å› ä¸ºè¿™äº›å‘½ä»¤çš„å®‰å…¨éšæ‚£ï¼Œæ‰€ä»¥\ræˆ‘ä»¬è¦å¯¹è¿™äº›å‘½ä»¤è¿›è¡Œä¸€äº›å®‰å…¨é™åˆ¶ï¼Œåªéœ€è¦ç¼–è¾‘æœåŠ¡çš„zoo.cfgæ–‡ä»¶å³å¯\r# vim /data/server/zk1/conf/zoo.cfg\r4lw.commands.whitelist=stat, ruok, conf, isro\ré‡å¯æœåŠ¡å\r/data/server/zk1/bin/zkServer.sh restart\ræŸ¥çœ‹å…è®¸é€šè¿‡çš„å‘½ä»¤æ•ˆæœ\recho isro | nc 127.0.0.1 2181\recho conf | nc 127.0.0.1 2181\recho stat | nc 127.0.0.1 2181\ræ£€æŸ¥ä¸å…è®¸é€šè¿‡çš„å‘½ä»¤\r[root@controller bin]# echo dump | nc 127.0.0.1 2181\rdump is not executed because it is not in the whitelist.\ræµ‹è¯•æ²¡æœ‰è®¾ç½®å‘½ä»¤è¿‡æ»¤çš„èŠ‚ç‚¹\r[root@controller bin]# echo dump | nc 127.0.0.1 2281\rSessionTracker dump:\rSession Sets (0):\rephemeral nodes dump:\rSessions with Ephemerals (0):\ræ‰€ä»¥ç”Ÿäº§ä¸­ï¼Œæˆ‘ä»¬ä¸€å®šè¦æŠŠä¸çŸ¥é“æˆ–è€…ä¸æƒ³ç”¨çš„å‘½ä»¤å…¨éƒ¨è¿‡æ»¤æ‰ï¼Œè¿™æ ·æ‰èƒ½ä¿è¯åŸºæœ¬çš„å®‰å…¨ã€‚ ","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:4:2","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["Zookeeper"],"content":"é›†ç¾¤ç®¡ç† çŠ¶æ€ç›‘æ§ åœ¨ZookeeperæœåŠ¡ç«¯çš„æ“ä½œä¸­ï¼Œæœ‰ä¸€ä¸ªå‘½ä»¤éå¸¸æœ‰ç”¨å°±æ˜¯mntrï¼Œå¯ä»¥æŸ¥çœ‹èŠ‚ç‚¹æœåŠ¡çš„æ‰€æœ‰è¿è¡Œæ—¶ä¿¡æ¯ï¼Œè¿™äº› ä¿¡æ¯å°±æ˜¯æˆ‘ä»¬å¹³å¸¸è¦ç›‘æ§åˆ°çš„å†…å®¹ã€‚ å‘½ä»¤æ•ˆæœ # echo mntr | nc 127.0.0.1 2281 zk_version 3.7.0-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2021 10:13 GMT zk_avg_latency 0 zk_max_latency 0 zk_min_latency 0 zk_packets_received 8 zk_packets_sent 7 zk_num_alive_connections 1 zk_outstanding_requests 0 zk_server_state leader zk_znode_count 4 zk_watch_count 0 zk_ephemerals_count 0 zk_approximate_data_size 27 zk_open_file_descriptor_count 36 zk_max_file_descriptor_count 4096 zk_followers 2 zk_synced_followers 2 zk_pending_syncs 0æŒ‡æ ‡åˆ†ç±» ç½‘ç»œå“åº”å»¶è¿Ÿä¿¡æ¯ zk_avg_latencyã€zk_max_latencyã€zk_min_latency ç½‘ç»œè¯·æ±‚(æ•°æ®åŒ…å’Œè¿æ¥çŠ¶æ€æ•°é‡) æ•°æ®åŒ…ç›¸å…³ï¼šzk_packets_receivedã€zk_packets_sent è¿æ¥çŠ¶æ€ç›¸å…³ï¼šzk_num_alive_connections(æ´»è·ƒè¿æ¥)ã€zk_outstanding_requests èŠ‚ç‚¹æ•°é‡ä¿¡æ¯ï¼š zk_znode_countã€zk_watch_countã€zk_ephemerals_count(ä¸´æ—¶èŠ‚ç‚¹æ•°) æœåŠ¡çŠ¶æ€ zk_server_stateã€zk_open_file_descriptor_countã€zk_max_file_descriptor_count Leaderç‰¹æœ‰ï¼š zk_followersã€zk_synced_followers(åŒæ­¥æ•°é‡)ã€zk_pending_syncs(é˜»å¡æ•°é‡)é›†ç¾¤ä¼˜åŒ– æ–‡ä»¶éš”ç¦» ç”Ÿäº§ä¸­Zookeeperçš„dataDir å’Œ dataLogDir åº”è¯¥åˆ†å¼€éƒ¨ç½²ï¼Œå› ä¸ºäº‹åŠ¡æ—¥å¿—éå¸¸é‡è¦è€Œä¸”å†…å®¹æ¯”è¾ƒå¤šï¼Œ\ræ‰€ä»¥åœ¨é…ç½®çš„æ—¶å€™ï¼ŒdataLogDiræ‰€åœ¨çš„ç›®å½•ï¼Œè¦ä¿è¯ç›®å½•ç©ºé—´è¶³å¤Ÿå¤§ï¼Œå¹¶æŒ‚è½½åˆ°å•ç‹¬çš„ç£ç›˜ä¸Šï¼Œå¦‚æœå¯ä»¥çš„\rè¯ï¼Œç£ç›˜åº”è¯¥å¼€å¯å®æ—¶åˆ·æ–°åŠŸèƒ½ã€‚æ—¥å¿—æ»šåŠ¨ é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸€èˆ¬æ—¥å¿—æ˜¯æ”¾åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œä¸ºäº†æ›´å¥½çš„æŸ¥çœ‹æ—¥å¿—æ•ˆæœï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šå°†æ—¥å¿—è¿›è¡Œåˆ‡å‰²ï¼Œæ¥ä¸‹æ¥æˆ‘\rä»¬é…ç½®ä¸€ä¸‹æ—¥å¿—çš„åˆ‡å‰²åŠŸèƒ½ã€‚\rZookeeperçš„é»˜è®¤æ—¥å¿—åˆ‡å‰²é…ç½®æ–‡ä»¶æ˜¯ é¡¹ç›®ç›®å½•çš„conf/log4j.properties,å’Œåˆ‡å‰²é…ç½®ä¸»è¦ç›¸å…³çš„æ˜¯ï¼š\rlog4j.appender.ROLLINGFILE=org.apache.log4j.RollingFileAppender\rå¦‚æœæƒ³æŒ‰å¤©è¿›è¡Œæ—¥å¿—åˆ‡å‰²çš„è¯ï¼Œå¯ä»¥ä¿®æ”¹ä¸º DaliyRollingFileAppender\rZookeeperä½¿ç”¨æ—¥å¿—åˆ‡å‰²åŠŸèƒ½\r# vim /data/server/zk1/bin/zkServer.sh\r...\r30 # å¢åŠ  ZOO_LOG_DIR é…ç½®\r31 ZOO_LOG_DIR=\"$ZOOBINDIR/../log4j\"\r...\r# vim /data/server/zk1/bin/zkEnv.sh\r59 if [ \"x${ZOO_LOG4J_PROP}\" = \"x\" ]\r60 then\r61 ZOO_LOG4J_PROP=\"INFO,ROLLINGFILE\" # æ³¨æ„ï¼šåŸCONSOLE ä¿®æ”¹ä¸º\rROLLINGFILE\r62 fiæ—¥å¿—æ¸…ç† è‡ªåŠ¨æ¸…ç†ï¼šè‡ªä»Zookeeper 3.4.0ç‰ˆæœ¬ä¹‹åï¼Œé…ç½®æ–‡ä»¶ä¸­å¤šäº†ä¸¤ä¸ªå’Œæ—¥å¿—è‡ªåŠ¨æ¸…ç†ç›¸å…³çš„é…ç½®\rautopurge.purgeIntervalï¼šæŒ‡å®šæ¸…ç†é¢‘ç‡ï¼Œå•ä½ä¸ºå°æ—¶(é»˜è®¤æ˜¯0ï¼Œè¡¨ç¤ºä¸å¼€å¯è‡ªåŠ¨æ¸…ç†)\rautopurge.snapRetainCountï¼šå’ŒpurgeIntervalé…åˆä½¿ç”¨ï¼ŒæŒ‡å®šéœ€è¦ä¿ç•™çš„æ–‡ä»¶æ•°ç›®\ræ³¨æ„ï¼š\rZookeeper é‡å¯ä¼šè‡ªåŠ¨æ¸…é™¤ zookeeper-root-server-python-auto.out æ—¥å¿—ï¼Œå¦‚æœæœ‰æ’é”™éœ€è¦ï¼Œåˆ™åº”å…ˆå¤‡ä»½å¥½æ—¥å¿—æ–‡ä»¶\ré…ç½®æ•ˆæœï¼š\r# vim /data/server/zk1/conf/zoo.cfg\r...\rautopurge.purgeInterval=1\rautopurge.snapRetainCount=3\ræ‰‹å·¥æ¸…ç†ï¼š\rå¦‚æœå‘ç°å•äº‹åŠ¡æ—¥å¿—é‡è¿‡å¤§ï¼Œå¯¼è‡´å®šæ—¶æ¸…ç†æ— æ³•åŠæ—¶å¤„ç†ï¼Œæˆ‘ä»¬å¯ä»¥åŸºäºè‡ªå®šä¹‰è„šæœ¬æˆ–è€… zookeeperæä¾›çš„ zkCleanup.sh è¿›è¡Œ ç»“åˆ å®šæ—¶ä»»åŠ¡æ¥å®ç°è‡ªåŠ¨æ¸…ç†çš„ä»»åŠ¡ã€‚\r#!/bin/bash\r# å®šåˆ¶æ—¥å¿—ç›®å½•\rzookeeperDir='/data/server/zookeeper'\rdataDir=\"$zookeeperDir/data/version-2\"\rdataLogDir=$zookeeperDir/logs/version-2\r# ä¿ç•™æ–‡ä»¶60\rcount=60\rcount=$[$count+1] # ä»61è¡Œå¼€å§‹åˆ é™¤\rls -t $dataLogDir/log.* | tail -n +$count | xargs rm -f\rls -t $dataDir/snapshot.* | tail -n +$count | xargs rm -f\ræ³¨æ„ï¼š\rls -t æ˜¯é¡ºåºæ’åˆ—ï¼Œ\rtail -n +5 æ˜¯ä»ç¬¬ 5 ä¸ªè‡³æœ€æ–°æ–‡ä»¶èŠ‚ç‚¹æ‰©å±• åœ¨Zookeeperé›†ç¾¤ä¸­æœ‰ä¸€ä¸ªè§’è‰²æ˜¯observerï¼Œå®ƒä¸»è¦çš„ä½œç”¨ä»…ä»…æ˜¯å¢åŠ é¢å¤–çš„æ¥æ”¶å®¢æˆ·ç«¯è¯·æ±‚çš„æ‰©å±• èŠ‚ç‚¹ï¼Œå°†æ¥æ”¶åˆ°çš„è¯·æ±‚ï¼Œè½¬äº¤ç»™Leaderå¤„ç†ï¼Œä¸ä¼šå½±å“é›†ç¾¤çš„å…¶ä»–ä»»ä½•æ“ä½œã€‚ æˆ‘ä»¬åªéœ€è¦åœ¨ObserveèŠ‚ç‚¹çš„zoo.cfgé…ç½®æ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®å³å¯ peerType=observer server.n:localhost:2181:3181:observer ä¿®æ”¹é…ç½®æ–‡ä»¶ Zk1èŠ‚ç‚¹ï¼š vim /data/server/zk1/conf/zoo.cfg # ä¿®æ”¹å¦‚ä¸‹é…ç½® server.3=192.168.8.14:2382:2383:observer Zk2èŠ‚ç‚¹ï¼š vim /data/server/zk2/conf/zoo.cfg # ä¿®æ”¹å¦‚ä¸‹é…ç½® server.3=192.168.8.14:2382:2383:observer Zk3èŠ‚ç‚¹ï¼š vim /data/server/zk3/conf/zoo.cfg # å¢åŠ å¦‚ä¸‹é…ç½® peerType=observer # ä¿®æ”¹å¦‚ä¸‹é…ç½® server.3=192.168.8.14:2382:2383:observer é‡å¯ç›¸å…³æœåŠ¡ /data/server/zk1/bin/zkServer.sh restart /data/server/zk2/bin/zkServer.sh restart /data/server/zk3/bin/zkServer.sh restart å†æ¬¡æŸ¥çœ‹é›†ç¾¤çŠ¶æ€ /data/server/zk3/bin/zkServer.sh status /data/server/zk2/bin/zkServer.sh status /data/server/zk1/bin/zkServer.sh status å¯ä»¥çœ‹åˆ°ï¼š zk3çš„é›†ç¾¤è§’è‰²å°±å˜æˆäº†è§‚å¯Ÿè€… éªŒè¯observeræ˜¯å¦å‚ä¸é€‰ä¸¾ /data/server/zk2/bin/zkServer.sh stop æŸ¥çœ‹é›†ç¾¤çŠ¶æ€ /data/server/zk1/bin/zkServer.sh status å¯ä»¥çœ‹åˆ°ï¼š é›†ç¾¤èŠ‚ç‚¹æœ‰ä¸‰ä¸ªï¼Œzk3æ˜¯è§‚å¯Ÿè€…ï¼ŒçœŸæ­£æä¾›æœåŠ¡çš„æ˜¯ä¸¤ä¸ªï¼Œæˆ‘ä»¬å…³é—­äº†ä¸€ä¸ªï¼Œé›†ç¾¤æœåŠ¡å°±å´©æºƒäº†ï¼Œæ‰€ä»¥ observeræ²¡ æœ‰å‚ä¸é›†ç¾¤çš„é€‰ä¸¾å·¥ä½œã€‚","date":"2021-10-06","objectID":"/posts/zookeeper/zookeeper-02/:5:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper é›†ç¾¤éƒ¨ç½² ï¼ˆäºŒï¼‰","uri":"/posts/zookeeper/zookeeper-02/"},{"categories":["ElasticStack"],"content":"ä¸€å¼ å›¾ç‰‡èƒœè¿‡åƒä¸‡è¡Œæ—¥å¿—ï¼ŒKibana è®©æ‚¨èƒ½å¤Ÿè‡ªç”±åœ°é€‰æ‹©å¦‚ä½•å‘ˆç°è‡ªå·±çš„æ•°æ®ã€‚Kibana æ˜¯ä¸€ä¸ªå…è´¹ä¸”å¼€æ”¾çš„ç”¨æˆ·ç•Œé¢ï¼Œèƒ½å¤Ÿè®©æ‚¨å¯¹ Elasticsearch æ•°æ®è¿›è¡Œå¯è§†åŒ–ï¼Œå¹¶è®©æ‚¨åœ¨ Elastic Stack ä¸­è¿›è¡Œå¯¼èˆªã€‚æ‚¨å¯ä»¥è¿›è¡Œå„ç§æ“ä½œï¼Œä»è·Ÿè¸ªæŸ¥è¯¢è´Ÿè½½ï¼Œåˆ°ç†è§£è¯·æ±‚å¦‚ä½•æµç»æ‚¨çš„æ•´ä¸ªåº”ç”¨ï¼Œéƒ½èƒ½è½»æ¾å®Œæˆã€‚ ","date":"2021-10-05","objectID":"/posts/elk/elk-kibana/:0:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Kibana ï¼ˆå››ï¼‰","uri":"/posts/elk/elk-kibana/"},{"categories":["ElasticStack"],"content":"åŸºç¡€çŸ¥è¯† ","date":"2021-10-05","objectID":"/posts/elk/elk-kibana/:1:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Kibana ï¼ˆå››ï¼‰","uri":"/posts/elk/elk-kibana/"},{"categories":["ElasticStack"],"content":"åŠŸèƒ½ç®€ä»‹ Kibana æ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†æå’Œå¯è§†åŒ–å¹³å°ï¼Œè®¾è®¡ç”¨äºå’ŒElasticsearchä¸€èµ·å·¥ä½œã€‚Kibanaæ¥æœç´¢ï¼ŒæŸ¥çœ‹ï¼Œå¹¶å’Œå­˜å‚¨åœ¨Elasticsearchç´¢å¼•ä¸­çš„æ•°æ®è¿›è¡Œäº¤äº’ã€‚å¯ä»¥è½»æ¾åœ°æ‰§è¡Œé«˜çº§æ•°æ®åˆ†æï¼Œå¹¶ä¸”ä»¥å„ç§å›¾æ ‡ã€è¡¨æ ¼å’Œåœ°å›¾çš„å½¢å¼å¯è§†åŒ–æ•°æ®ã€‚Kibanaä½¿å¾—ç†è§£å¤§é‡æ•°æ®å˜å¾—å¾ˆå®¹æ˜“ã€‚å®ƒç®€å•çš„ã€åŸºäºæµè§ˆå™¨çš„ç•Œé¢ä½¿ä½ èƒ½å¤Ÿå¿«é€Ÿåˆ›å»ºå’Œå…±äº«åŠ¨æ€ä»ªè¡¨æ¿ï¼Œå®æ—¶æ˜¾ç¤ºElasticsearchæŸ¥è¯¢çš„å˜åŒ–ã€‚ è¿è¡Œç¯å¢ƒ å®‰è£…java8ç¯å¢ƒ\rapt install openjdk-8-jdk\ræ£€æŸ¥æ•ˆæœ\rjava -version ","date":"2021-10-05","objectID":"/posts/elk/elk-kibana/:1:1","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Kibana ï¼ˆå››ï¼‰","uri":"/posts/elk/elk-kibana/"},{"categories":["ElasticStack"],"content":"è½¯ä»¶å®‰è£… aptæºç æ–¹å¼ è·å–è½¯ä»¶æº wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - apt install apt-transport-https echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee â€“a /etc/apt/sources.list.d/elastic-7.x.list apt update å®‰è£…è½¯ä»¶ apt install kibana è½¯ä»¶åŒ…å®‰è£… wget https://artifacts.elastic.co/downloads/kibana/kibana-7.14.0-amd64.deb wget https://artifacts.elastic.co/downloads/kibana/kibana-7.14.0- amd64.deb.sha512 shasum -a 512 -c kibana-7.14.0-amd64.deb.sha512 dpkg -i kibana-7.14.0-amd64.deb é…ç½®æŸ¥çœ‹ # dpkg -L kibana /. /etc /etc/default /etc/default/kibana /etc/init.d /etc/init.d/kibana /etc/kibana kibanaå®¶ç›®å½• /etc/kibana/kibana.yml /etc/kibana/node.options /etc/systemd /etc/systemd/system /etc/systemd/system/kibana.service æœåŠ¡å¯åŠ¨æ–‡ä»¶ /usr /usr/share /usr/share/kibana ... /usr/share/kibana/bin æ‰§è¡Œå‘½ä»¤ç›®å½•æ–‡ä»¶ /usr/share/kibana/bin/kibana-encryption-keys /usr/share/kibana/bin/kibana-plugin /usr/share/kibana/bin/kibana /usr/share/kibana/bin/kibana-keystore å®šåˆ¶ç¯å¢ƒå˜é‡ echo 'export PATH=/usr/share/kibana/bin:$PATH' \u003e /etc/profile.d/kibana.sh source /etc/profile.d/kibana.sh ","date":"2021-10-05","objectID":"/posts/elk/elk-kibana/:1:2","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Kibana ï¼ˆå››ï¼‰","uri":"/posts/elk/elk-kibana/"},{"categories":["ElasticStack"],"content":"ç®€å•å®è·µ å‘½ä»¤æ ¼å¼ ä¿®æ”¹é…ç½®æ–‡ä»¶ # vim /etc/kibana/kibana.yml # è®¾å®škibanaå¯¹å¤–å¼€æ”¾çš„é€šä¿¡ç«¯å£ server.port: 5601 # è®¾å®šå¯ä»¥è®¿é—®kibanaçš„ä¸»æœºåœ°å€ server.host: \"0.0.0.0\" # è®¾å®šelasticsearchçš„ä¸»æœºåœ°å€ elasticsearch.hosts: [\"http://192.168.8.12:9200\"] # è®¾å®škibanaçš„æ•°æ®ç´¢å¼• kibana.index: \".kibana\" # è®¾å®šä¸­æ–‡æ˜¾ç¤ºæ ¼å¼ i18n.locale: \"zh-CN\" å¯åŠ¨æœåŠ¡ å¯åŠ¨æœåŠ¡ systemctl start kibana.service systemctl status kibana.service æŸ¥çœ‹ç«¯å£ # netstat -tnulp | egrep 'Add|node' Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:5601 0.0.0.0:* LISTEN 31992/node ç»“æœæ˜¾ç¤ºï¼š kibanaé»˜è®¤ç«¯å£æ˜¯ 5601 æµè§ˆå™¨æŸ¥çœ‹æ•ˆæœ http://192.168.10.108:5601 kibanaé»˜è®¤å¸®æˆ‘ä»¬æä¾›äº†éå¸¸å¤šçš„ç¤ºä¾‹æ•°æ® å°ç»“ï¼š å®šä½ æ•°æ®çš„å¯è§†åŒ–å¹³å° éƒ¨ç½² å®‰è£…è½¯ä»¶ é…ç½®æ–‡ä»¶ å¯åŠ¨æŸ¥çœ‹æ•ˆæœ æ³¨æ„ï¼š é»˜è®¤çš„åœ°å›¾è™½ç„¶æ”¯æŒä¸­æ–‡ï¼Œä½†æ˜¯å›½å®¶åœ°å›¾æœ‰é—®é¢˜ï¼Œ æ ¸å¿ƒç‚¹ï¼š 1 æ•°æ®é‡‡é›† 2 æ•°æ®å¯è§†åŒ– ","date":"2021-10-05","objectID":"/posts/elk/elk-kibana/:1:3","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Kibana ï¼ˆå››ï¼‰","uri":"/posts/elk/elk-kibana/"},{"categories":["Zookeeper"],"content":"ZooKeeper åŸºç¡€ä¸å®‰è£… ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:0:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"åŸºç¡€çŸ¥è¯† ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:1:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"å¼€å‘æ¡†æ¶ ORM - ä¸€å°ä¸»æœºæ‰¿è½½æ‰€æœ‰çš„ä¸šåŠ¡åº”ç”¨ MVC - å¤šå°ä¸»æœºåˆ†åˆ«æ‰¿è½½ä¸šåŠ¡åº”ç”¨çš„ä¸åŒåŠŸèƒ½ï¼Œé€šè¿‡ç®€å•çš„ç½‘ç»œé€šä¿¡å®ç°ä¸šåŠ¡çš„æ­£å¸¸è®¿é—® RPC - åº”ç”¨ä¸šåŠ¡æ‹†åˆ†ã€å¤šåº”ç”¨å…±ç”¨åŠŸèƒ½ã€æ ¸å¿ƒä¸šåŠ¡åŠŸèƒ½ ç‹¬ç«‹éƒ¨ç½²ï¼ŒåŸºäºè¿œç¨‹è¿‡ç¨‹è°ƒç”¨æŠ€æœ¯(RPC)çš„åˆ†å¸ƒå¼æœ åŠ¡æ¡†æ¶ æé«˜ä¸šåŠ¡åŠŸèƒ½å¤ç”¨åŠé¡¹ç›®çš„æ•´åˆ SOA - ç²—æ”¾å‹çš„RPCåˆ†å¸ƒå¼å®ç°äº†å¤§é‡çš„èµ„æºæµªè´¹ï¼Œæé«˜æœºå™¨åˆ©ç”¨ç‡çš„ èµ„æºè°ƒåº¦å’Œæ²»ç†ä¸­å¿ƒ(SOA) ï¼ŒåŸºäº ç°æœ‰èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ï¼Œè¿›ä¸€æ­¥æé«˜æœåŠ¡çš„èƒ½åŠ› å¾®æœåŠ¡ - éšç€äº’è”ç½‘çš„å‘å±•ã€å„ç§æŠ€æœ¯çš„å¹³å°å·¥å…·å‡ºç°ã€ç¼–ç¨‹è¯­è¨€çš„å‡çº§ã€å¼€å‘è§„èŒƒçš„æ ‡å‡†åŒ–ç­‰å› ç´ ï¼Œä¸­å° å‹ä¼ä¸šä¹Ÿæœ‰äº†ç›¸åº”çš„èƒ½åŠ›æ¥å‘å±•æ›´è½»é‡çº§çš„SOAæ¨¡å¼ã€‚ åœ¨å¾®æœåŠ¡æ¶æ„çš„åœºæ™¯ä¸­ï¼Œæœ‰ä¸€ä¸ªç»„ä»¶æœåŠ¡Service Registry,å®ƒæ˜¯æ•´ä¸ª\"å¾®æœåŠ¡æ¶æ„\"ä¸­çš„æ ¸å¿ƒï¼Œä¸»è¦æä¾›äº† å››ä¸ªåŠŸèƒ½ï¼šæœåŠ¡æ³¨å†Œå’ŒæœåŠ¡å‘ç°ã€ä¸‹çº¿å¤„ç†ã€å¥åº·æ£€æµ‹ç­‰ã€‚ æœåŠ¡æ³¨å†Œï¼šå½“æœåŠ¡å¯åŠ¨åï¼Œå°†å½“å‰æœåŠ¡çš„ç›¸å…³é…ç½®ä¿¡æ¯éƒ½æ³¨å†Œåˆ°ä¸€ä¸ªå…¬å…±çš„ç»„ä»¶ â€“ Service Registryä¸­ã€‚ æœåŠ¡å‘ç°ï¼šå½“å®¢æˆ·ç«¯è°ƒç”¨æ“ä½œæŸäº›å·²æ³¨å†ŒæœåŠ¡ æˆ–è€… æœåŠ¡çš„æ–°å¢æˆ–åˆ é™¤ç­‰ï¼Œé€šè¿‡ä»Service Registryä¸­è¯»å–è¿™äº› æœåŠ¡é…ç½®çš„è¿‡ç¨‹ã€‚ ç›®å‰ï¼ŒService Registryçš„æœ€ä½³è§£å†³æ–¹æ¡ˆå°±æ˜¯Zookeeperã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¦å­¦ä¹ Zookeeperçš„ç›®çš„ä¹‹ä¸€ã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:1:1","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"åˆ†å¸ƒå¼ç‰¹æ€§ ç›®å‰æ¥è¯´ï¼Œéšç€äº’è”ç½‘çš„å‘å±•ï¼Œå„ç§è½¯ä»¶æŠ€æœ¯ï¼Œå°¤å…¶æ˜¯è®¾å¤‡è®¡ç®—èƒ½åŠ›çš„æå‡ï¼Œæ‰€ä»¥å¾ˆå¤šä¼ä¸šåœ¨é¡¹ç›®çš„å¼€å¯å°±åº” ç”¨äº† åˆ†å¸ƒå¼æ¶æ„ã€‚åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å„ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„åä½œæ˜¯é€šè¿‡é«˜æ•ˆç½‘ç»œè¿›è¡Œæ¶ˆæ¯æ•°æ®ä¼ é€’ï¼Œå®ç°ä¸šåŠ¡å†…éƒ¨å¤š ä¸ªæœåŠ¡çš„é€šä¿¡å’Œåè°ƒï¼ŒåŸºäºæœåŠ¡æœ¬åœ°è®¾å¤‡çš„æ€§èƒ½å®ç°èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ã€‚ åˆ†å¸ƒå¼ç³»ç»Ÿçš„è®¾è®¡ç›®æ ‡é€šå¸¸åŒ…æ‹¬å‡ ä¸ªæ–¹é¢ï¼š å¯ç”¨æ€§ï¼šå¯ç”¨æ€§æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿçš„æ ¸å¿ƒéœ€æ±‚ï¼Œè¡¡é‡äº†ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»ŸæŒç»­å¯¹å¤–æä¾›æœåŠ¡çš„èƒ½åŠ›ã€‚ å¯æ‰©å±•æ€§ï¼šå¢åŠ åŠå…¶åä¸ä¼šæ”¹å˜æˆ–è€…æå°‘æ”¹å˜ç³»ç»Ÿè¡Œä¸ºï¼Œå¹¶ä¸”è·å¾—ç›¸ä¼¼çš„çº¿æ€§çš„æ€§èƒ½æå‡ å®¹é”™æ€§ï¼šç³»ç»Ÿå‘ç”Ÿé”™è¯¯æ—¶ï¼Œå…·æœ‰å¯¹é”™è¯¯è¿›è¡Œè§„é¿ä»¥åŠä»é”™è¯¯ä¸­æ¢å¤çš„èƒ½åŠ› æ€§èƒ½ï¼šå¯¹å¤–æœåŠ¡çš„å“åº”å»¶æ—¶å’Œååç‡è¦æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:1:2","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"ä¸€è‡´æ€§åè®® æˆ‘ä»¬ä¸ºäº†æ»¡è¶³åˆ†å¸ƒå¼çš„å„ç§åœºæ™¯éœ€æ±‚ï¼Œå…ˆåæå‡ºäº† ACIDã€CAPã€BASEç­‰ç†è®ºï¼Œå…¶ç›®çš„å°±æ˜¯ åœ¨é¡¹ç›®æ¶æ„æ­£å¸¸çš„è¿è¡Œè¿‡ç¨‹ä¸­ï¼Œå³æ—¶å‡ºç°å„ç§é—®é¢˜ï¼Œä¹Ÿèƒ½å¤Ÿä¿è¯ä¸šåŠ¡ä¿æŒåŸºæœ¬å¯ç”¨çš„ç›®æ ‡ã€‚ é‚£ä¹ˆï¼Œæˆ‘ä»¬åœ¨ é¡¹ç›®æ¶æ„åœ¨è¿è¡Œè¿‡ç¨‹ä¸­ ä¸ºäº†ä¿è¯ ä¸šåŠ¡ä¿æŒåŸºæœ¬å¯ç”¨ è¿‡ç¨‹ä¸­å®šåˆ¶çš„å„ç§è§„çº¦æˆ–è€…é€šä¿¡æ ¼ å¼ï¼Œéƒ½å¯ä»¥å°†å…¶ç§°ä¸º ä¸€è‡´æ€§åè®®ã€‚ ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šåŸºäº é›†ç¾¤çš„æ–¹å¼å®ç°åˆ†å¸ƒå¼çš„ å¯ç”¨æ€§ã€å¯æ‰©å±•æ€§ã€å®¹é”™æ€§ç­‰çš„ç›®æ ‡ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¦‚ ä½•ä¿è¯é›†ç¾¤ä¸­çš„æ•°æ®çš„ä¸€è‡´æ€§å‘¢ï¼Ÿ ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šåŸºäº é›†ç¾¤çš„æ–¹å¼å®ç°åˆ†å¸ƒå¼çš„ å¯ç”¨æ€§ã€å¯æ‰©å±•æ€§ã€å®¹é”™æ€§ç­‰çš„ç›®æ ‡ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œ é›†ç¾¤ä¸­å„ä¸ªä¸»æœºä¹‹é—´çš„é€šä¿¡ä¿¡æ¯æ˜¯å¦ä¸€è‡´çš„å°±éå¸¸é‡è¦äº†ã€‚æ‰€è°“çš„ä¸€è‡´æ€§æ˜¯é›†ç¾¤å†…éƒ¨å„ä¸ªä¸»æœºç³»ç»Ÿå¯¹å¤–å‘ˆç°çš„çŠ¶æ€æ˜¯å¦ä¸€è‡´ï¼Œå³æ—¶ä¸šåŠ¡å‡ºç°é—®é¢˜çš„æ—¶å€™ï¼Œè¿™æ˜¯æ‰€æœ‰çš„èŠ‚ç‚¹ä¹Ÿè¦è¾¾æˆä¸€ä¸ªé”™è¯¯çš„å…±è¯†ã€‚å¦‚æœå„ä¸ªä¸»æœºä¹‹é—´é€šä¿¡çš„æ•°æ®ä¸ä¸€è‡´ï¼Œå°±ä¼šå¯¼è‡´å„ç§åˆ†å¸ƒå¼çš„åœºæ™¯é—®é¢˜ã€‚ åœ¨ä¸€ä¸ªé›†ç¾¤ç³»ç»Ÿä¸­ï¼Œä¸ºäº†ä¿è¯æ‰€æœ‰çš„ä¸»æœºç³»ç»Ÿèƒ½å¤Ÿå¤„äºä¸€ç§ç›¸å¯¹çš„å¹³è¡¡çŠ¶æ€ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šåŸºäºä¼ é€’æ•°æ®æœ¬ èº«å’Œä¸»æœºè§’è‰²çš„æ–¹å¼æ¥å®ç°ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä»ä¸¤ä¸ªæ–¹é¢æ¥è¿›è¡Œåˆ†æï¼š æ•°æ®æœ¬èº«ï¼šå°†æ‰€æœ‰çš„æ›´æ–°æ•°æ®ï¼ŒåŒæ­¥åˆ°æ•´ä¸ªé›†ç¾¤ç³»ç»Ÿï¼Œä¿è¯æ•°æ®çš„æœ€ç»ˆä¸€è‡´æ€§ã€‚ ä¸»æœºè§’è‰²ï¼šclientå‘å¤šä¸ªserverä¸»æœºç³»ç»Ÿå‘èµ·è®¿é—®(åŒ…æ‹¬å¹¶è¡Œè®¿é—®)è¯·æ±‚æ—¶ï¼Œå¦‚ä½•è·å–ç›¸åŒçš„æ›´æ–°åæ•°æ®ã€‚ åˆ†ç±» è§£æ çŠ¶æ€å¤åˆ¶æœº(StateMachineReplication) ä¸€ä¸ªæœåŠ¡ç«¯é›†ç¾¤ï¼Œæœ‰å¤šä¸ªserverä¸»æœºç»„æˆï¼Œæ¯ä¸ªserverä¸»æœºçš„æ›´æ–°éƒ½åœ¨æœ¬åœ°å®ç°ã€‚æ¯ä¸ªæœåŠ¡ç«¯éƒ½æœ‰ä¸€ä¸ªä¸€è‡´æ€§æ¨¡å—æ¥æ¥æ”¶å®¢æˆ·ç«¯è¯·æ±‚ï¼Œæ²¡æ¥æ”¶ä¸€æ¬¡ç”¨æˆ·è¯·æ±‚ï¼Œä¸€è‡´æ€§æ¨¡å—çš„çŠ¶æ€å°±å‘ç”Ÿæ”¹å˜ï¼Œé€šè¿‡ çŠ¶æ€æœºç³»ç»Ÿ å¯¹æ‰€æœ‰çš„ä¸€è‡´æ€§æ¨¡å—çš„çŠ¶æ€è¿›è¡Œç®¡æ§ï¼Œåªè¦æ‰€æœ‰çš„æ¨¡å—çŠ¶æ€æ˜¯ä¸€æ ·çš„ï¼Œé‚£ä¹ˆserverä¸»æœºæœ¬åœ°æ‰§è¡Œåçš„æœ€ç»ˆæ•°æ®å€¼å°±æ˜¯ä¸€æ ·çš„ï¼Œä»è€Œå®ç°æœåŠ¡çš„å®¹é”™æ•ˆæœã€‚GFSã€HDFSã€Chubbyã€ZooKeeperå’Œetcdç­‰åˆ†å¸ƒå¼ç³»ç»Ÿéƒ½æ˜¯åŸºäºå¤åˆ¶çŠ¶æ€æœºæ¨¡å‹å®ç°çš„ã€‚ æ‹œå åº­å°†å†›é—®é¢˜(Byzantine Failures) ä¸€ä¸ªæœåŠ¡ç«¯é›†ç¾¤ï¼Œæœ‰å¤šä¸ªserverä¸»æœºç»„æˆ,æ¯ä¸ªserverä¸»æœºæ¥æ”¶åˆ°clientè¯·æ±‚åï¼Œæ ¹æ®è‡ªå·±æœ¬èº«çš„ç‰¹æ€§è¿›è¡Œåˆ†æå¹¶ç»™å‡ºæ‰§è¡Œçš„ç­–ç•¥ï¼Œå¤šä¸ªserverä¸»æœºé€šè¿‡ä¸“ç”¨çš„é€šè®¯æ–¹å¼æ¥è¿›è¡Œåå•†ï¼Œå¹¶è¾¾æˆæœ€ç»ˆçš„å…±è¯†ç»“æœ(å°‘æ•°æœä»å¤šæ•°)ï¼Œç„¶åæŒ‰ç…§æœ€ç»ˆçš„ç»“æœè¿›è¡Œæ“ä½œæ‰§è¡Œï¼Œä»è€Œå®ç°æœåŠ¡çš„å®¹é”™æ•ˆæœã€‚ FLPå®šç†(Fischer,Lynch ,Patterson) ä¸‰ä½ç§‘å­¦å®¶åœ¨1985å¹´å‘è¡¨çš„åˆ†å¸ƒå¼ç†è®ºï¼Œæœ€å°åŒ–å¼‚æ­¥ç½‘ç»œé€šä¿¡åœºæ™¯ä¸‹ï¼Œå› ä¸ºæ¶ˆæ¯é€šä¿¡æ˜¯å»¶è¿Ÿçš„ï¼Œæ‰€ä»¥å¯èƒ½ä¼šå‡ºç° åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹æ•…éšœ(æ²¡è¢«å…¶ä»–èŠ‚ç‚¹å‘ç°)æ—¶ï¼Œå…¶ä»–èŠ‚ç‚¹ä¸èƒ½è¾¾æˆä¸€è‡´ã€‚è¿™è¯æ˜äº†åœ¨å¼‚æ­¥åœºæ™¯ä¸­æ°¸è¿œæ— æ³•é¿å…çš„ä¸€ç§ç°è±¡ã€‚æ¯”å¦‚ï¼šä¸‰å°ä¸»æœºABCå¼‚æ­¥æ–¹å¼é€šä¿¡ï¼Œåœ¨æ­£å¸¸åå•†ä¹‹é—´ï¼Œå› ä¸ºCä¸»æœºçªç„¶ç½‘ç»œæ•…éšœï¼Œå¯¼è‡´æ— æ³•å®ç°å‰©ä½™ä¸¤å°çš„å°‘æ•°æœä»å¤šæ•°ï¼Œä»è€Œå¯¼è‡´ä¸šåŠ¡ç»ˆæ­¢æ‰§è¡Œã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:1:3","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"ZooKeeper ç®€ä»‹ Zookeeperï¼Œè‹±æ–‡å­—é¢æ„æ€å°±æ˜¯\"åŠ¨ç‰©ç®¡ç†å‘˜\"ï¼Œå› ä¸ºåŠ¨ç‰©å›­é‡Œé¢çš„æ‰€æœ‰åŠ¨ç‰©çš„ç‰¹æ®Šæ€§ï¼Œéœ€è¦ç®¡ç†å‘˜å¿…é¡»å…·å¤‡ è§‚å¯ŸåŠ¨ç‰©çŠ¶æ€å’Œç®¡ç†åŠ¨ç‰©è¡Œä¸ºç­‰æ–¹é¢çš„åè°ƒçš„èƒ½åŠ›ï¼Œä¸ºåŠ¨ç‰©ä»¬å»ºç«‹å‹å¥½ç”Ÿå­˜çš„ç”Ÿæ´»ç¯å¢ƒã€‚Zookeeperå°±æ˜¯çº·ä¹± çš„è½¯ä»¶æœåŠ¡ä¸–ç•Œä¸­çš„ä¸€åç®¡ç†è€…ï¼Œä¸ºç¹æ‚çš„è½¯ä»¶æœåŠ¡ç¯å¢ƒæä¾›ç»Ÿä¸€çš„åè°ƒç®¡ç†æœåŠ¡ã€‚ å¯ä»¥æƒ³è±¡ä¸º Pig hive hadoop HAMA ç­‰æ¡†æ¶çš„logoéƒ½æ˜¯åŠ¨ç‰©çš„è±¡å½¢,zookeeper ç›¸å½“äºé“²å±å®˜ï¼Œå¸®ä»–ä»¬è§£å†³å¤§å°ä¾¿ Zookeeperæ˜¯YahooåŸºäº Googleçš„ Chubby è®ºæ–‡å®ç°çš„ä¸€æ¬¾è§£å†³åˆ†å¸ƒå¼æ•°æ®ä¸€è‡´æ€§é—®é¢˜çš„å¼€æºå®ç°ï¼Œå®ƒ æ˜¯ä½¿ç”¨Javaè¯­è¨€å¼€å‘çš„ï¼Œç›®å‰æ˜¯Hadoopé¡¹ç›®ä¸­çš„ä¸€ä¸ªå­é¡¹ç›®ã€‚å®ƒåœ¨Hadoopã€HBaseã€Kafkaã€Dubboç­‰æŠ€ æœ¯ä¸­å……å½“äº†éå¸¸é‡è¦çš„æ ¸å¿ƒç»„ä»¶è§’è‰²ã€‚ å®˜æ–¹ç½‘ç«™ï¼šhttps://zookeeper.apache.org/ æœ€æ–°ç‰ˆæœ¬ï¼š3.7.0 ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:0","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"ç¯å¢ƒå®‰è£… æ­å»ºjavaç¯å¢ƒ zookeeper æ˜¯ä¾èµ–äºjavaç¯å¢ƒçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æå‰å®šåˆ¶javaç¯å¢ƒ åˆ›å»ºç›®å½• mkdir /data/{softs,server} -p cd /data/softs ä¸‹è½½javaæˆ–è€…ä¸Šä¼ java ls /data/softs å®‰è£…java tar xf jdk-8u121-linux-x64.tar.gz -C /data/server cd /data/server/ ln -s jdk1.8.0_121 java é…ç½®javaç¯å¢ƒå˜é‡ echo 'export JAVA_HOME=/data/server/java' \u003e\u003e /etc/profile echo 'export JRE_HOME=$JAVA_HOME/jre' \u003e\u003e /etc/profile echo 'export CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar' \u003e\u003e /etc/profile echo 'export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH' \u003e\u003e /etc/profile source /etc/profile æ£€æŸ¥æ•ˆæœ java -version æ£€æŸ¥javaç›®å½•æ•ˆæœ tree -L 1 /data/server/java/å®‰è£…è½¯ä»¶ è½¯ä»¶å‡†å¤‡\rcd /data/softs\rwget http://archive.apache.org/dist/zookeeper/zookeeper-3.7.0/apache-zookeeper-3.7.0-bin.tar.gz\rwget http://archive.apache.org/dist/zookeeper/zookeeper-3.7.0/apache-zookeeper-3.7.0-bin.tar.gz.asc\ræ ¡éªŒè½¯ä»¶\rgpg --verify apache-zookeeper-3.7.0-bin.tar.gz.asc\rå¯¹æ¯” MD5 ç ä¸€è‡´åè¿›è¡Œè§£å‹å®‰è£…\rtar zxvf apache-zookeeper-3.7.0-bin.tar.gz -C /data/server\rcd /data/server\rln -s apache-zookeeper-3.7.0-bin zookeeper\recho 'export PATH=/data/server/zookeeper/bin:$PATH' \u003e /etc/profile.d/zk.sh\rsource /etc/profile.d/zk.shä¿®æ”¹é…ç½®æ–‡ä»¶ æŸ¥çœ‹é…ç½®æ¨¡æ¿æ–‡ä»¶\rcat zookeeper/conf/zoo_sample.cfg\rgrep -ni '^[a-Z]' zookeeper/conf/zoo_sample.cfg\rè®¾ç½®é…ç½®æ–‡ä»¶\rcp conf/zoo_sample.cfg conf/zoo.cfg\ré»˜è®¤è¯»å–é…ç½®æ–‡ä»¶å zoo.cfgé…ç½®æ–‡ä»¶å¸¸ç”¨å‚æ•° tickTime ï¼šâ€œæ»´ç­”æ—¶é—´â€ï¼Œç”¨äºé…ç½® Zookeeperä¸­æœ€å°çš„æ—¶é—´å•å…ƒé•¿åº¦ï¼Œå•ä½æ¯«ç§’ï¼Œæ˜¯å…¶ä»–æ—¶é—´é…ç½®çš„åŸºç¡€ initLimitï¼šåˆå§‹åŒ–æ—¶é—´ï¼ŒåŒ…å«å¯åŠ¨å’Œæ•°æ®åŒæ­¥ï¼Œå…¶å€¼æ˜¯tickTimeçš„å€æ•° syncLimit ï¼šæ­£å¸¸å·¥ä½œï¼Œå¿ƒè·³ç›‘æµ‹çš„æ—¶é—´é—´éš”ï¼Œå…¶å€¼æ˜¯tickTimeçš„å€æ•° dataDir ï¼šé…ç½®ZookeeperæœåŠ¡å­˜å‚¨æ•°æ®çš„ç›®å½• clientPortï¼šé…ç½®å½“å‰ZookeeperæœåŠ¡å¯¹å¤–æš´éœ²çš„ç«¯å£ï¼Œç”¨æˆ·å®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯å»ºç«‹è¿æ¥ä¼šè¯ å¯åŠ¨æœåŠ¡ åœ¨Zookeeperçš„binç›®å½•ä¸‹æœ‰å¾ˆå¤šæ‰§è¡Œæ–‡ä»¶ï¼Œå…¶ä¸­zkServer.shæ˜¯å¯åŠ¨æœåŠ¡çš„è„šæœ¬æ–‡ä»¶ ls bin/ æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯ bin/zkServer.sh å‘½ä»¤å‚æ•°åŠŸèƒ½è¯¦è§£ startï¼šç”¨äºåå°å¯åŠ¨ZookeeperæœåŠ¡å™¨ start-foregroundï¼šç”¨äºå‰å°å¯åŠ¨ZookeeperæœåŠ¡å™¨ï¼Œå¸¸ç”¨æ¥æ’æŸ¥å¤±è´¥åŸå›  stopï¼šç”¨äºå…³é—­ZookeeperæœåŠ¡å™¨ restartï¼šç”¨äºé‡å¯ZookeeperæœåŠ¡å™¨ statusï¼šç”¨äºæŸ¥çœ‹ZookeeperæœåŠ¡å™¨çŠ¶æ€ upgradeï¼šç”¨äºå‡çº§ZookeeperæœåŠ¡å™¨ print-cmdï¼šç”¨äºæ‰“å°Zookeeperç¨‹åºå‘½ä»¤è¡ŒåŠå…¶ç›¸å…³å¯åŠ¨å‚æ•° å¯åŠ¨æœåŠ¡ bin/zkServer.sh startæ£€æŸ¥æœåŠ¡çŠ¶æ€ Zookeeperçš„æ£€æŸ¥æœ‰å¾ˆå¤šç§æ–¹å¼ï¼Œä¸»è¦æœ‰ä»¥ä¸‹å››ç§ï¼šç«¯å£ã€æœåŠ¡ã€è¿›ç¨‹ã€è¿æ¥\rç«¯å£æ£€æŸ¥\rnetstat -tnulp | grep 2181\ræœåŠ¡æ£€æŸ¥\rbin/zkServer.sh status\rè¿›ç¨‹æ£€æŸ¥\rps aux | grep zoo\rè¿æ¥æ£€æŸ¥\rbin/zkCli.shè¿›é˜¶å®è·µ åœ¨ç”Ÿäº§ä¸­ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šè®²Zookeeperçš„æ•°æ®ç›®å½•å’Œæ—¥å¿—ç›®å½•éƒ½æ”¾åœ¨ä¸€ä¸ªä¸“ç”¨çš„è·¯å¾„ä¸‹ï¼Œè€Œæˆ‘ä»¬åˆšæ‰å®è·µ çš„æ•ˆæœæ˜¯æ•°æ®ç›®å½•åœ¨ä¸´æ—¶æ–‡ä»¶å¤¹/tmpä¸‹ï¼Œè€Œä¸”æ²¡æœ‰è®¾ç½®æ—¥å¿—æ–‡ä»¶é…ç½®ä¿¡æ¯ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘ä»¬å°±æŒ‰ç…§ç”Ÿäº§ç¯å¢ƒçš„ éƒ¨ç½²æ–¹æ³•å…ˆæ¥åšä¸€ä¸ªå•æœºç‰ˆçš„Zookeeperç¯å¢ƒã€‚ å…³é—­åˆšæ‰çš„æœåŠ¡ bin/zkServer.sh stop åˆ›å»ºä¸“ç”¨çš„æ•°æ®å’Œæ—¥å¿—ç›®å½• cd /data/server/zookeeper mkdir {data,logs} åœ¨é»˜è®¤çš„é…ç½®æ–‡ä»¶ä¸­ï¼Œæ²¡æœ‰æ—¥å¿—çš„é…ç½®é¡¹ï¼Œæ—¥å¿—çš„é…ç½®é¡¹æ˜¯dataLogDir # vim conf/zoo.cfg # grep -ni '^[a-Z]' conf/zoo.cfg 2:tickTime=2000 5:initLimit=10 8:syncLimit=5 12:dataDir=/data/server/zookeeper/data 13:dataLogDir=/data/server/zookeeper/logs 15:clientPort=2181 å¯åŠ¨ä¹‹å‰æ³¨æ„æƒé™ ll chown 1000.1000 -R /data/server/zookeeper* å¯åŠ¨å½“å‰Zookeeperçš„æœåŠ¡ bin/zkServer.sh start ä¸‰ç§æ–¹å¼æŸ¥çœ‹ä¸åŒçš„å…³æ³¨ç‚¹ bin/zkServer.sh status ps aux | grep zoo bin/zkCli.sh æŸ¥çœ‹äº§ç”Ÿçš„æ•°æ® ls /data/server/zookeeper/data/ ls /data/server/zookeeper/logs/æœ¬åœ°è¿æ¥æœåŠ¡ å½“ZookeeperæœåŠ¡å™¨æ­£å¸¸å¯åŠ¨åï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨Zookeeperè‡ªå¸¦çš„zkCli.shè„šæœ¬ï¼Œä»¥å‘½ä»¤è¡Œçš„æ–¹å¼ è¿æ¥åˆ°Zookeeperã€‚ä½¿ç”¨æ–¹æ³•éå¸¸ç®€å•ï¼š bin/zkCli.sh å¦‚æœå‡ºç°ä¸‹é¢ä¿¡æ¯ï¼Œå°±è¡¨ç¤ºå‘½ä»¤è¡Œå®¢æˆ·ç«¯å·²ç»æˆåŠŸè¿å…¥åˆ°Zookeeper WATCHER:: WatchedEvent state:SyncConnected type:None path:null [zk: localhost:2181(CONNECTED) 0]è¿œç¨‹è¿æ¥æœåŠ¡ zkCli.sh è„šæœ¬è¿˜æä¾›äº†è¿œç¨‹è¿æ¥éæœ¬åœ°çš„ZookeeperæœåŠ¡å™¨çš„å‚æ•° -serverï¼Œä½¿ç”¨è¿™ä¸ªå‚æ•°å°±å¯ä»¥è¿æ¥ åˆ°è¿œç¨‹çš„ZookeeperæœåŠ¡ä¸»æœº zkCli.sh è„šæœ¬è¿˜æä¾›äº†è¿œç¨‹è¿æ¥éæœ¬åœ°çš„ZookeeperæœåŠ¡å™¨çš„å‚æ•° -serverï¼Œä½¿ç”¨è¿™ä¸ªå‚æ•°å°±å¯ä»¥è¿æ¥\råˆ°è¿œç¨‹çš„ZookeeperæœåŠ¡ä¸»æœº\rå‘½ä»¤æ ¼å¼ï¼š\rbin/zkCli.sh -server \u003czk_ip\u003e:\u003czk_port\u003e\rè¿œç¨‹è¿æ¥\rbin/zkCli.sh -server 192.168.8.14:2181å‘½ä»¤å¸®åŠ© å½“å®¢æˆ·ç«¯æˆåŠŸçš„è¿æ¥åˆ°ZookeeperæœåŠ¡åï¼Œæˆ‘ä»¬å¯ä»¥è¾“å…¥ä»»æ„éæ³•çš„å‘½ä»¤éƒ½å¯ä»¥è·å–Zookeeperå®¢æˆ·ç«¯ ç›¸å…³çš„å‘½ä»¤ä½¿ç”¨æ–¹æ³•ã€‚ è¿æ¥åˆ°ZookeeperæœåŠ¡åï¼Œè¾“å…¥helpæŸ¥çœ‹ç›¸å…³å‘½ä»¤\rZooKeeper -server host:port cmd args å®¿ä¸»æœºå‘½ä»¤è¡Œæ‰§è¡ŒZookeeperå®¢æˆ·ç«¯å‘½ä»¤\rstat path [watch] æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€æˆ–è€…åˆ¤æ–­ç»“ç‚¹æ˜¯å¦å­˜åœ¨\rset path data [version] è®¾ç½®èŠ‚ç‚¹æ•°æ®\rls path [watch] åˆ—å‡ºèŠ‚ç‚¹ä¿¡æ¯\rdelquota [-n|-b] path åˆ é™¤èŠ‚ç‚¹ä¸ªæ•°(-n)æˆ–æ•°æ®é•¿åº¦(-b)é…é¢\rls2 path [watch] lså‘½ä»¤çš„åŠ å¼ºç‰ˆï¼Œåˆ—å‡ºæ›´å¤šä¿¡æ¯\rsetAcl path acl è®¾ç½®èŠ‚ç‚¹çš„æƒé™ä¿¡æ¯\rsetquota -n|-b val path è®¾ç½®èŠ‚ç‚¹ä¸ªæ•°(-n)æˆ–æ•°æ®é•¿åº¦(-b)çš„é…é¢\rhistory åˆ—å‡ºæœ€è¿‘çš„å‘½ä»¤å†å²ï¼Œå¯ä»¥å’Œredoé…åˆä½¿ç”¨\rredo cmdid å†æ¬¡æ‰§è¡ŒæŸä¸ªå‘½ä»¤ï¼Œç»“åˆhistoryä½¿ç”¨\rprintwatches on|off è®¾ç½®å’Œæ˜¾ç¤ºç›‘è§†çŠ¶æ€\rdelete path [version] åˆ é™¤èŠ‚ç‚¹ï¼Œä¸å¯åˆ é™¤æœ‰å­èŠ‚ç‚¹çš„èŠ‚ç‚¹\rsync path å¼ºåˆ¶æ•°æ®åŒæ­¥\rlistquota path æ˜¾ç¤ºèŠ‚ç‚¹èµ„æºé…é¢ä¿¡æ¯\rrmr path å¼ºåˆ¶åˆ é™¤èŠ‚ç‚¹\rget path [watch] è·å–èŠ‚ç‚¹æ•°æ®\rcreate [-s] [-e] path data acl åˆ›å»ºé¡ºåº(-s)æˆ–ä¸´æ—¶(-e)ç»“ç‚¹\raddauth scheme auth é…ç½®èŠ‚ç‚¹è®¤è¯ä¿¡æ¯\rquit é€€å‡ºè¿æ¥\rgetAcl path è·å–èŠ‚ç‚¹çš„æƒé™ä¿¡æ¯\rclose æ–­å¼€å½“å‰Zookeeperè¿æ¥\rconnect host:port è¿æ¥ZookeeperæœåŠ¡ç«¯\rä½¿ç”¨closeå‘½ä»¤å¯ä»¥å…³é—­å½“å‰çš„è¿æ¥\rä½¿ç”¨quitå‘½ä»¤å¯ä»¥é€€å‡ºZookeeperæœåŠ¡\rä½¿ç”¨connect host:portå‘½ä»¤å¯ä»¥é‡æ–°è¿æ¥ZookeeperæœåŠ¡ connect 192.16","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:1","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"Zookeeper å·¥ä½œæœºåˆ¶ Zookeeper ä»è®¾è®¡æ¨¡å¼çš„è§’åº¦ç†è§£ï¼šæ˜¯ä¸€ä¸ªåŸºäºè§‚å¯Ÿè€…æ¨¡å¼è®¾è®¡çš„åˆ†å¸ƒå¼æœåŠ¡ç®¡ç†æ¡†æ¶ï¼ˆç›‘å·¥ï¼‰ï¼Œå®ƒè´Ÿè´£å­˜å‚¨å’Œç®¡ç†å¤§å®¶éƒ½å…³å¿ƒçš„æ•°æ®ï¼Œç„¶åæ¥å—è§‚å¯Ÿè€…çš„æ³¨å†Œï¼Œä¸€æ—¦è¿™äº›æ•°æ®çš„çŠ¶æ€å‘ç”Ÿå˜åŒ–ï¼ŒZookeeperå°±å°†è´Ÿè´£é€šçŸ¥å·²ç»åœ¨Zookeeperä¸Šæ³¨å†Œçš„å“ªäº›è§‚å¯Ÿè€…åšå‡ºç›¸åº”çš„ååº”ã€‚ Zookeeperä½œä¸ºä¸€ä¸ªå…¸å‹çš„åˆ†å¸ƒå¼æ•°æ®ä¸€è‡´æ€§è§£å†³æ–¹æ¡ˆï¼Œä¾èµ–Zookeeperçš„åˆ†å¸ƒå¼åº”ç”¨ç¨‹åºï¼Œå¯ä»¥åŸºäºZookeeperå®ç°æ•°æ®å‘å¸ƒ/è®¢é˜…ã€è´Ÿè½½å‡è¡¡ã€å‘½åæœåŠ¡ã€æœåŠ¡æ³¨å†Œä¸å‘ç°ã€åˆ†å¸ƒå¼åè°ƒ/äº‹ä»¶é€šçŸ¥ã€é›†ç¾¤ç®¡ç†ã€Leader é€‰ä¸¾ã€ åˆ†å¸ƒå¼é”å’Œé˜Ÿåˆ— ç­‰åŠŸèƒ½ã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:2","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"ç‰¹ç‚¹ Zookeeperï¼šä¸€ä¸ªé¢†å¯¼è€…ï¼ˆLeaderï¼‰ï¼Œå¤šä¸ªè·Ÿéšè€…ï¼ˆFollowerï¼‰ç»„æˆçš„é›†ç¾¤ã€‚ é›†ç¾¤ä¸­åªè¦æœ‰åŠæ•°ä»¥ä¸ŠèŠ‚ç‚¹å­˜æ´»ï¼ŒZookeeperé›†ç¾¤å°±èƒ½æ­£å¸¸æœåŠ¡ã€‚æ‰€ ä»¥Zookeeperé€‚åˆå®‰è£…å¥‡æ•°å°æœåŠ¡å™¨ã€‚ å…¨å±€æ•°æ®ä¸€è‡´ï¼šæ¯ä¸ªServerä¿å­˜ä¸€ä»½ç›¸åŒçš„æ•°æ®å‰¯æœ¬ï¼ŒClientæ— è®ºè¿æ¥åˆ°å“ªä¸ªServerï¼Œæ•°æ®éƒ½æ˜¯ä¸€è‡´çš„ã€‚ æ›´æ–°è¯·æ±‚é¡ºåºæ‰§è¡Œï¼Œæ¥è‡ªåŒä¸€ä¸ªClientçš„æ›´æ–°è¯·æ±‚æŒ‰å…¶å‘é€é¡ºåºä¾æ¬¡æ‰§è¡Œã€‚ æ•°æ®æ›´æ–°åŸå­æ€§ï¼Œä¸€æ¬¡æ•°æ®æ›´æ–°è¦ä¹ˆæˆåŠŸï¼Œè¦ä¹ˆå¤±è´¥ã€‚ å®æ—¶æ€§ï¼Œåœ¨ä¸€å®šæ—¶é—´èŒƒå›´å†…ï¼ŒClientèƒ½è¯»åˆ°æœ€æ–°æ•°æ®ã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:3","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"è§’è‰² åŸºæœ¬ä¸Šæ‰€æœ‰çš„é›†ç¾¤æ¨¡å¼ä¸­çš„ä¸»æœºéƒ½æœ‰è‡ªå·±çš„è§’è‰²ï¼Œæœ€ä¸ºå…¸å‹çš„é›†ç¾¤æ¨¡å¼å°±æ˜¯ M/S ä¸»å¤‡æ¨¡å¼ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œ æˆ‘ä»¬æŠŠå¤„äºä¸»è¦åœ°ä½(å¤„ç†å†™æ“ä½œ)çš„ä¸»æœºç§°ä¸º Master èŠ‚ç‚¹ï¼Œå¤„äºæ¬¡è¦åœ°ä½(å¤„ç†è¯»æ“ä½œ)çš„ä¸»æœºç§°ä¸º Slave èŠ‚ç‚¹ï¼Œç”Ÿäº§ä¸­è¯»å–çš„æ–¹å¼ä¸€èˆ¬æ˜¯ä»¥å¼‚æ­¥å¤åˆ¶æ–¹å¼æ¥å®ç°çš„ã€‚ Zookeeperé›†ç¾¤å°±æ˜¯è¿™ç§M/Sçš„æ¨¡å‹ï¼Œé›†ç¾¤é€šå¸¸ç”±2n+1å°ServerèŠ‚ç‚¹ç»„æˆï¼Œæ¯ä¸ªServeréƒ½çŸ¥é“å½¼æ­¤çš„å­˜ åœ¨ã€‚å¯¹äº2n+1å°serverï¼Œåªè¦æœ‰\u003e=(n+1)å°serverèŠ‚ç‚¹å¯ç”¨ï¼Œæ•´ä¸ªZookeeperç³»ç»Ÿä¿æŒå¯ç”¨ã€‚ è§’è‰² æè¿° é¢†å¯¼è€… (Leader) é¢†å¯¼è€…ä¸æ¥å—clientè¯»è¯·æ±‚ï¼Œè´Ÿè´£è¿›è¡ŒæŠ•ç¥¨å‘èµ·å’Œå†³è®®ï¼Œæ›´æ–°ç³»ç»ŸçŠ¶æ€ è·Ÿéšè€… (Follower) æ¥æ”¶å®¢æˆ·è¯·æ±‚å¹¶å‘å®¢æˆ·ç«¯è¿”å›ç»“æœï¼Œåœ¨é€‰Leaderè¿‡ç¨‹ä¸­å‚ä¸æŠ•ç¥¨ è§‚å¯Ÿè€… (Observer) è½¬äº¤å®¢æˆ·ç«¯å†™è¯·æ±‚ç»™leaderèŠ‚ç‚¹ï¼Œå’ŒåŒæ­¥leaderçŠ¶æ€ï¼Œä¸å‚ä¸é€‰ä¸»æŠ•ç¥¨ å­¦ä¹ è€…(Learner) å’Œleaderè¿›è¡ŒçŠ¶æ€åŒæ­¥çš„èŠ‚ç‚¹ç»Ÿç§°Learnerï¼ŒFollowerå’ŒObserver éƒ½æ˜¯ å®¢æˆ·ç«¯(client) è¯·æ±‚å‘èµ·æ–¹ Zookeeperé›†ç¾¤ç³»ç»Ÿå¯åŠ¨æ—¶ï¼Œé›†ç¾¤ä¸­çš„ä¸»æœºä¼šé€‰ä¸¾å‡ºä¸€å°ä¸»æœºä¸ºLeaderï¼Œå…¶å®ƒçš„å°±ä½œä¸ºLearner(åŒ…æ‹¬ Followerå’ŒObserver)ã€‚æ¥ç€ç”±followeræ¥æœåŠ¡clientçš„è¯·æ±‚ï¼Œå¯¹äºä¸æ”¹å˜ç³»ç»Ÿä¸€è‡´æ€§çŠ¶æ€çš„è¯»æ“ä½œï¼Œ ç”±followerçš„æœ¬åœ°å†…å­˜æ•°æ®åº“ç›´æ¥ç»™clientè¿”å›ç»“æœï¼›å¯¹äºä¼šæ”¹å˜Zookeeperç³»ç»ŸçŠ¶æ€çš„æ›´æ–°æ“ä½œï¼Œåˆ™äº¤ ç”±Leaderè¿›è¡Œæè®®æŠ•ç¥¨ï¼Œè¶…è¿‡åŠæ•°é€šè¿‡åè¿”å›å°†ç»“æœç»™clientã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:4","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"ZABåè®® ï¼ˆZookeeper Atomic Broadcastï¼ŒZookeeperåŸå­å¹¿æ’­åè®®ï¼‰æ¥ä¿è¯ä¸»ä»èŠ‚ç‚¹æ•°æ®ä¸€è‡´æ€§çš„ï¼ŒZABåè®®æ”¯æŒã€Œå´©æºƒæ¢å¤å’Œæ¶ˆæ¯å¹¿æ’­ã€ä¸¤ç§æ¨¡å¼ï¼Œå¾ˆå¥½è§£å†³äº†è¿™ä¸¤ä¸ªé—®é¢˜ï¼š å´©æºƒæ¢å¤ï¼š LeaderæŒ‚äº†ï¼Œè¿›å…¥è¯¥æ¨¡å¼ï¼Œé€‰ä¸€ä¸ªæ–°çš„leaderå‡ºæ¥,æ¥ç€ï¼Œæ–°çš„LeaderæœåŠ¡å™¨ä¸é›†ç¾¤ä¸­FolloweræœåŠ¡è¿›è¡Œæ•°æ®åŒæ­¥ï¼Œå½“é›†ç¾¤ä¸­è¶…è¿‡åŠæ•°æœºå™¨ä¸è¯¥ LeaderæœåŠ¡å™¨å®Œæˆæ•°æ®åŒæ­¥ä¹‹åï¼Œé€€å‡ºæ¢å¤æ¨¡å¼è¿›å…¥æ¶ˆæ¯å¹¿æ’­æ¨¡å¼ã€‚ æ¶ˆæ¯å¹¿æ’­ï¼š æŠŠæ›´æ–°çš„æ•°æ®ï¼Œä»LeaderåŒæ­¥åˆ°æ‰€æœ‰Follower Leader æœåŠ¡å™¨å¼€å§‹æ¥æ”¶å®¢æˆ·ç«¯çš„äº‹åŠ¡è¯·æ±‚ç”Ÿæˆäº‹åŠ¡Proposalè¿›è¡Œäº‹åŠ¡è¯·æ±‚å¤„ç†ã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:5","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"äº‹åŠ¡id æ‰€è°“çš„äº‹åŠ¡id â€“ zxidã€‚ZooKeeperçš„åœ¨é€‰ä¸¾æ—¶é€šè¿‡æ¯”è¾ƒå„ç»“ç‚¹çš„zxidå’Œæœºå™¨IDé€‰å‡ºæ–°çš„ä¸»ç»“ç‚¹çš„ã€‚ zxidç”±LeaderèŠ‚ç‚¹ç”Ÿæˆï¼Œæœ‰æ–°å†™å…¥äº‹ä»¶æ—¶ï¼ŒLeaderç”Ÿæˆæ–°zxidå¹¶éšææ¡ˆä¸€èµ·å¹¿æ’­ï¼Œæ¯ä¸ªç»“ç‚¹æœ¬åœ°éƒ½ä¿å­˜äº† å½“å‰æœ€è¿‘ä¸€æ¬¡äº‹åŠ¡çš„zxidï¼Œzxidæ˜¯é€’å¢çš„ï¼Œæ‰€ä»¥è°çš„zxidè¶Šå¤§ï¼Œå°±è¡¨ç¤ºè°çš„æ•°æ®æ˜¯æœ€æ–°çš„ã€‚ ZXIDæœ‰ä¸¤éƒ¨åˆ†ç»„æˆï¼š ä»»æœŸï¼šå®Œæˆæœ¬æ¬¡é€‰ä¸¾åï¼Œç›´åˆ°ä¸‹æ¬¡é€‰ä¸¾å‰ï¼Œç”±åŒä¸€Leaderè´Ÿè´£åè°ƒå†™å…¥ï¼› äº‹åŠ¡è®¡æ•°å™¨ï¼šå•è°ƒé€’å¢ï¼Œæ¯ç”Ÿæ•ˆä¸€æ¬¡å†™å…¥ï¼Œè®¡æ•°å™¨åŠ ä¸€ã€‚ â€“åŒä¸€ä»»æœŸå†…ï¼ŒZXIDæ˜¯è¿ç»­çš„ï¼Œæ¯ä¸ªç»“ç‚¹åˆéƒ½ä¿å­˜ç€è‡ªèº«æœ€æ–°ç”Ÿæ•ˆçš„ZXIDï¼Œé€šè¿‡å¯¹æ¯”æ–°ææ¡ˆçš„ZXIDä¸ è‡ªèº«æœ€æ–°ZXIDæ˜¯å¦ç›¸å·®â€œ1â€ï¼Œæ¥ä¿è¯äº‹åŠ¡ä¸¥æ ¼æŒ‰ç…§é¡ºåºç”Ÿæ•ˆçš„ã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:6","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"æ•°æ®ç»“æ„ ZooKeeper æ•°æ®æ¨¡å‹çš„ç»“æ„ä¸ Unix æ–‡ä»¶ç³»ç»Ÿå¾ˆç±»ä¼¼ï¼Œæ•´ä½“ä¸Šå¯ä»¥çœ‹ä½œæ˜¯ä¸€æ£µæ ‘ï¼Œæ¯ä¸ª èŠ‚ç‚¹ç§°åšä¸€ä¸ª ZNodeã€‚æ¯ä¸€ä¸ª ZNode é»˜è®¤èƒ½å¤Ÿå­˜å‚¨ 1MB çš„æ•°æ®ï¼Œæ¯ä¸ª ZNode éƒ½å¯ä»¥é€šè¿‡ å…¶è·¯å¾„å”¯ä¸€æ ‡è¯†ã€‚ Zookeeperä½¿ç”¨è¿™ä¸ªåŸºäºå†…å­˜çš„æ ‘çŠ¶æ¨¡å‹æ¥å­˜å‚¨åˆ†å¸ƒå¼æ•°æ®ï¼Œæ­£å› ä¸ºæ‰€æœ‰æ•°æ®éƒ½å­˜æ”¾åœ¨å†…å­˜ä¸­ï¼Œæ‰€ä»¥ æ‰èƒ½å®ç°é«˜æ€§èƒ½çš„ç›®çš„ï¼Œæé«˜æ•°æ®çš„ååç‡ã€‚ç‰¹åˆ«æ˜¯åœ¨é›†ç¾¤ä¸»æœºèŠ‚ç‚¹é—´çš„æ•°æ®åŒæ­¥ã€‚ ZnodeåŒ…å«äº† å­˜å‚¨æ•°æ®(data)ã€è®¿é—®æƒé™(acl)ã€å­èŠ‚ç‚¹å¼•ç”¨(child)ã€èŠ‚ç‚¹çŠ¶æ€(stat)ä¿¡æ¯ç­‰ä¿¡æ¯ æ³¨æ„ï¼š ä¸ºäº†ä¿è¯é«˜ååå’Œä½å»¶è¿Ÿï¼Œä»¥åŠæ•°æ®çš„ä¸€è‡´æ€§ï¼Œznodeåªé€‚åˆå­˜å‚¨éå¸¸å°çš„æ•°æ®ï¼Œä¸èƒ½è¶…è¿‡1Mï¼Œæœ€å¥½éƒ½ å°äº1K ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:7","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"èŠ‚ç‚¹ç±»å‹è§£æ è™½ç„¶ZNodeçš„æ ·å¼è·ŸLinuxæ–‡ä»¶ç³»ç»Ÿç±»ä¼¼ï¼Œæ ¹æ®èŠ‚ç‚¹çš„ç”Ÿå‘½å‘¨æœŸï¼Œåœ¨Zookeeperä¸­çš„ZNodeæœ‰å››ç§ç‹¬æœ‰çš„ç‰¹ æ€§,æœ‰æ—¶å€™é¡µç§°ä¸ºå››ç§ç±»å‹ï¼š åŸºæœ¬èŠ‚ç‚¹ï¼š Persistent(æŒä¹…èŠ‚ç‚¹)ï¼šä¼šè¯æ–­å¼€åï¼Œé™¤éä¸»åŠ¨è¿›è¡Œç§»é™¤æ“ä½œï¼Œå¦åˆ™è¯¥èŠ‚ç‚¹ä¸€ç›´å­˜åœ¨ Ephemeral(ä¸´æ—¶èŠ‚ç‚¹)ï¼šä¼šè¯æ–­å¼€åï¼Œè¯¥èŠ‚ç‚¹è¢«åˆ é™¤ åºåˆ—èŠ‚ç‚¹ï¼š Persistent Sequential:æŒ‰é¡ºåºç¼–å·çš„æŒä¹…èŠ‚ç‚¹è¯¥èŠ‚ç‚¹è¢«åˆ›å»ºçš„æ—¶å€™ï¼ŒZookeeper ä¼šè‡ªåŠ¨åœ¨å…¶å­èŠ‚ç‚¹åä¸Šï¼ŒåŠ ä¸€ä¸ªç”±çˆ¶èŠ‚ç‚¹ç»´æŠ¤çš„ã€è‡ªå¢æ•´æ•°çš„åç¼€ã€‚ Ephemeral Sequentialï¼šæŒ‰é¡ºåºç¼–å·çš„ä¸´æ—¶èŠ‚ç‚¹è¯¥èŠ‚ç‚¹è¢«åˆ›å»ºçš„æ—¶å€™ï¼ŒZookeeper ä¼šè‡ªåŠ¨åœ¨å…¶å­èŠ‚ç‚¹åä¸Šï¼ŒåŠ ä¸€ä¸ªç”±çˆ¶èŠ‚ç‚¹ç»´æŠ¤çš„ã€è‡ªå¢æ•´æ•°çš„åç¼€ æ³¨æ„ï¼š åªæœ‰æŒä¹…æ€§èŠ‚ç‚¹(æŒä¹…èŠ‚ç‚¹å’Œé¡ºåºæŒä¹…èŠ‚ç‚¹)æ‰æœ‰èµ„æ ¼åˆ›å»ºå­èŠ‚ç‚¹ è‡ªå¢åç¼€æ ¼å¼ï¼š 10ä½10è¿›åˆ¶æ•°çš„åºå· æœ‰åºå’Œæ— åºåŒºåˆ«ï¼š å¤šä¸ªå®¢æˆ·ç«¯åŒæ—¶åˆ›å»ºåŒä¸€æ— åºZNodeèŠ‚ç‚¹æ—¶ï¼Œåªæœ‰ä¸€ä¸ªå¯åˆ›å»ºæˆåŠŸï¼Œå…¶å®ƒåŒ€å¤±è´¥ã€‚å¹¶ä¸”åˆ›å»ºå‡ºçš„èŠ‚ç‚¹åç§° ä¸åˆ›å»ºæ—¶æŒ‡å®šçš„èŠ‚ç‚¹åå®Œå…¨ä¸€æ ·ã€‚ å¤šä¸ªå®¢æˆ·ç«¯åŒæ—¶åˆ›å»ºåŒä¸€æœ‰åºZNodeèŠ‚ç‚¹æ—¶ï¼Œéƒ½èƒ½åˆ›å»ºæˆåŠŸï¼Œåªæ˜¯åºå·ä¸åŒã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:8","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"Stat æ•°æ®ç»“æ„ Zookeeper çš„ ZNode ä¸Šéƒ½ä¼šå­˜å‚¨æ•°æ®ï¼Œå¯¹åº”äºæ¯ä¸ª ZNodeï¼ŒZookeeper éƒ½ä¼šä¸ºå…¶ç»´æŠ¤ä¸€ä¸ªå«åš Stat çš„æ•°æ®ç»“æ„ã€‚ Stat ä¸­è®°å½•äº†è¿™ä¸ª ZNode çš„ä¸‰ä¸ªæ•°æ®ç‰ˆæœ¬ï¼š dataversion å½“å‰ ZNode æ•°æ®å†…å®¹çš„ç‰ˆæœ¬ cversion å½“å‰ ZNode å­èŠ‚ç‚¹çš„ç‰ˆæœ¬ aversion å½“å‰ ZNode çš„ ACL å˜æ›´ç‰ˆæœ¬ã€‚ è¿™é‡Œçš„ç‰ˆæœ¬èµ·åˆ°äº†æ§åˆ¶ Zookeeper æ“ä½œåŸå­æ€§çš„ä½œç”¨ï¼ŒåŸºäºè¿™äº›åŠŸèƒ½ï¼Œæ‰èƒ½æ›´å¥½å®ç°äº†åˆ†å¸ƒå¼é”çš„åŠŸèƒ½ã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:9","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"èŠ‚ç‚¹å®è·µ èŠ‚ç‚¹åˆ›å»º ä½¿ç”¨createå‘½ä»¤å¯ä»¥æ¥åˆ›å»ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œå‘½ä»¤æ ¼å¼å¦‚ä¸‹ï¼š\rcreate [-s] [-e] [-c] [-t ttl] path [data] [acl]\ræ³¨æ„ï¼š\r-s è¡¨ç¤ºåˆ›å»ºçš„èŠ‚ç‚¹æ˜¯é¡ºåºèŠ‚ç‚¹ã€‚\r-e è¡¨ç¤ºåˆ›å»ºçš„èŠ‚ç‚¹æ˜¯ä¸´æ—¶èŠ‚ç‚¹ï¼Œè¿™ä¸ªæ˜¯createçš„é»˜è®¤å‚æ•°ã€‚\racl ç”¨äºæƒé™æ§åˆ¶ï¼ŒZookeeperçš„æƒé™æ§åˆ¶å¾ˆå¼ºå¤§ï¼Œé»˜è®¤ä¸ä½¿ç”¨ã€‚åˆ†åˆ«åˆ›å»º2ä¸ªæ™®é€šèŠ‚ç‚¹ï¼ˆæ°¸ä¹…èŠ‚ç‚¹ + ä¸å¸¦åºå·ï¼‰ [zk: localhost:2181(CONNECTED) 3] create /sanguo \"diaochan\"\rCreated /sanguo\r[zk: localhost:2181(CONNECTED) 4] create /sanguo/shuguo\r\"liubei\"\rCreated /sanguo/shuguo\ræ³¨æ„ï¼šåˆ›å»ºèŠ‚ç‚¹æ—¶ï¼Œè¦èµ‹å€¼è·å¾—èŠ‚ç‚¹çš„å€¼ [zk: localhost:2181(CONNECTED) 5] get -s /sanguo diaochan cZxid = 0x100000003 ctime = Wed Aug 29 00:03:23 CST 2018 mZxid = 0x100000003 mtime = Wed Aug 29 00:03:23 CST 2018 pZxid = 0x100000004 cversion = 1 dataVersion = 0 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 7 numChildren = 1 [zk: localhost:2181(CONNECTED) 6] get -s /sanguo/shuguo liubei cZxid = 0x100000004 ctime = Wed Aug 29 00:04:35 CST 2018 mZxid = 0x100000004 mtime = Wed Aug 29 00:04:35 CST 2018 pZxid = 0x100000004 cversion = 0 dataVersion = 0 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6 numChildren = 0 åˆ›å»ºå¸¦åºå·çš„èŠ‚ç‚¹ï¼ˆæ°¸ä¹…èŠ‚ç‚¹ + å¸¦åºå·ï¼‰ ï¼ˆ1ï¼‰å…ˆåˆ›å»ºä¸€ä¸ªæ™®é€šçš„æ ¹èŠ‚ç‚¹/sanguo/weiguo\r[zk: localhost:2181(CONNECTED) 1] create/sanguo/weiguo \"caocao\" Created /sanguo/weiguo ï¼ˆ2ï¼‰åˆ›å»ºå¸¦åºå·çš„èŠ‚ç‚¹ [zk: localhost:2181(CONNECTED) 2] create -s /sanguo/weiguo/zhangliao \"zhangliao\" Created /sanguo/weiguo/zhangliao0000000000 [zk: localhost:2181(CONNECTED) 3] create -s /sanguo/weiguo/zhangliao \"zhangliao\" Created /sanguo/weiguo/zhangliao0000000001 [zk: localhost:2181(CONNECTED) 4] create -s /sanguo/weiguo/xuchu \"xuchu\" Created /sanguo/weiguo/xuchu0000000002 å¦‚æœåŸæ¥æ²¡æœ‰åºå·èŠ‚ç‚¹ï¼Œåºå·ä»0 å¼€å§‹ä¾æ¬¡é€’å¢ã€‚å¦‚æœåŸèŠ‚ç‚¹ä¸‹å·²æœ‰2 ä¸ªèŠ‚ç‚¹ï¼Œåˆ™å†æ’åºæ—¶ä»2 å¼€å§‹ï¼Œä»¥æ­¤ç±»æ¨ã€‚ åˆ›å»ºçŸ­æš‚èŠ‚ç‚¹ï¼ˆçŸ­æš‚èŠ‚ç‚¹ + ä¸å¸¦åºå· or å¸¦åºå·ï¼‰ ï¼ˆ1ï¼‰åˆ›å»ºçŸ­æš‚çš„ä¸å¸¦åºå·çš„èŠ‚ç‚¹ [zk: localhost:2181(CONNECTED) 7] create -e /sanguo/wuguo \"zhouyu\" Created /sanguo/wuguo ï¼ˆ2ï¼‰åˆ›å»ºçŸ­æš‚çš„å¸¦åºå·çš„èŠ‚ç‚¹ [zk: localhost:2181(CONNECTED) 2] create -e -s /sanguo/wuguo \"zhouyu\" Created /sanguo/wuguo0000000001 ï¼ˆ3ï¼‰åœ¨å½“å‰å®¢æˆ·ç«¯æ˜¯èƒ½æŸ¥çœ‹åˆ°çš„ [zk: localhost:2181(CONNECTED) 3] ls /sanguo [wuguo, wuguo0000000001, shuguo] é€€å‡ºå½“å‰å®¢æˆ·ç«¯ç„¶åå†é‡å¯å®¢æˆ·ç«¯ [zk: localhost:2181(CONNECTED) 12] quit [atguigu@hadoop104 zookeeper-3.5.7]$ bin/zkCli.sh ï¼ˆ5ï¼‰å†æ¬¡æŸ¥çœ‹æ ¹ç›®å½•ä¸‹çŸ­æš‚èŠ‚ç‚¹å·²ç»åˆ é™¤ [zk: localhost:2181(CONNECTED) 0] ls /sanguo [shuguo] ä¿®æ”¹èŠ‚ç‚¹æ•°æ®å€¼ [zk: localhost:2181(CONNECTED) 6] set /sanguo/weiguo \"simayi\"æŸ¥çœ‹çŠ¶æ€ æŸ¥çœ‹ä¸‰è€…çš„çŠ¶æ€ä¿¡æ¯ [zk: 127.0.0.1:2181(CONNECTED) 19] stat /sswang ... ephemeralOwner = 0x0 ... [zk: 127.0.0.1:2181(CONNECTED) 20] stat /sswang2 ... ephemeralOwner = 0x16454e2c6580007 # è¿™æ˜¯ä¸´æ—¶èŠ‚ç‚¹çš„ç‰¹ç‚¹ ... [zk: 127.0.0.1:2181(CONNECTED) 21] stat /sswang10000000001 ... ephemeralOwner = 0x0 ...èŠ‚ç‚¹åˆ é™¤ä¸æŸ¥çœ‹ 1ï¼‰ åˆ é™¤èŠ‚ç‚¹\r[zk: localhost:2181(CONNECTED) 4] delete /sanguo/jin\r2ï¼‰ é€’å½’åˆ é™¤èŠ‚ç‚¹\r[zk: localhost:2181(CONNECTED) 15] deleteall /sanguo/shuguo\r3ï¼‰ æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€\r[zk: localhost:2181(CONNECTED) 17] stat /sanguo\rcZxid = 0x100000003\rctime = Wed Aug 29 00:03:23 CST 2018 mZxid = 0x100000011 èµ„æºé…é¢ æŸ¥çœ‹èµ„æºé…é¢ ä½¿ç”¨listquotatå‘½ä»¤å¯ä»¥è·å–èŠ‚ç‚¹æ•°æ®ï¼Œå‘½ä»¤æ ¼å¼å¦‚ä¸‹ï¼š listquota path æ³¨æ„ï¼š æ³¨æ„äº‹é¡¹åŒls æŸ¥çœ‹æŒ‡å®šç»“ç‚¹çš„èµ„æº [zk: localhost:2181(CONNECTED) 28] create /sswang sswang Created /sswang [zk: localhost:2181(CONNECTED) 29] listquota /sswang absolute path is /zookeeper/quota/sswang/zookeeper_limits quota for /sswang does not exist. å¯ä»¥çœ‹åˆ°ï¼š é»˜è®¤æ–°åˆ›å»ºçš„ç»“ç‚¹èµ„æºï¼Œæ˜¯æ²¡æœ‰èµ„æºé…é¢çš„ã€‚è®¾ç½®èµ„æºé…é¢ ä½¿ç”¨listquotatå‘½ä»¤å¯ä»¥è·å–èŠ‚ç‚¹èµ„æºé…é¢æ•°æ®ï¼Œå‘½ä»¤æ ¼å¼å¦‚ä¸‹ï¼š\rsetquota -n|-b|-N|-B val path\ræ³¨æ„ï¼š\r-n è®¾ç½®èŠ‚ç‚¹çš„èŠ‚ç‚¹ä¸ªæ•°\r-b è®¾ç½®èŠ‚ç‚¹çš„æ•°æ®é•¿åº¦\rå¦‚æœè¶…å‡ºäº†é…ç½®é™åˆ¶ï¼Œä¸ä¼šåœæ­¢è¡Œä¸ºæ“ä½œï¼Œåªæ˜¯ZooKeeperå°†ä¼šåœ¨logæ—¥å¿—ä¸­æ‰“å°WARNæ—¥å¿—ã€‚\rå…¶ä»–æ³¨æ„äº‹é¡¹åŒls\rè®¾ç½®èŠ‚ç‚¹çš„æ•°é‡èµ„æº\r[zk: localhost:2181(CONNECTED) 34] setquota -n 2 /sswang\rComment: the parts are option -n val 2 path /sswang\r[zk: localhost:2181(CONNECTED) 35] listquota /sswang\rabsolute path is /zookeeper/quota/sswang/zookeeper_limits\rOutput quota for /sswang count=2,bytes=-1\rOutput stat for /sswang count=1,bytes=6\rå¯ä»¥çœ‹åˆ°ï¼š\rOutput stat åé¢çš„ count è¡¨ç¤ºçš„æ˜¯æ€»æ•°é‡ï¼ŒbytesæŒ‡å®šçš„æ˜¯æ•°æ®æ€»é•¿åº¦ï¼ŒåŒ…æ‹¬çš„å­èŠ‚ç‚¹çš„æ•°æ®é•¿åº¦\ræŒ‡å®šæ•°é‡çš„è¯ï¼Œæ•°æ®é•¿åº¦é»˜è®¤æ²¡æœ‰é™åˆ¶\ræµ‹è¯•æ•ˆæœï¼š\råœ¨/sswangèŠ‚ç‚¹ä¸‹åˆ›å»ºå¤šä¸ªå­èŠ‚ç‚¹\rcreate /sswang/child1 1\rcreate /sswang/child2 1\rcreate /sswang/child3 1\rcreate /sswang/child4 1\ræŸ¥çœ‹zookeeper-root-server-python-auto.outæ–‡ä»¶ä¿¡æ¯ï¼Œä¼šæœ‰WARNæç¤ºä¿¡æ¯\r2021-07-01 20:07:30,649 [myid:] - WARN [SyncThread:0:DataTree@301] - Quota\rexceeded: /sswang count=3 limit=2\r2021-07-01 20:08:06,715 [myid:] - WARN [SyncThread:0:DataTree@301] - Quota\rexceeded: /sswang count=4 limit=2\rè®¾ç½®èŠ‚ç‚¹çš„æ•°æ®é•¿åº¦èµ„æº\r[zk: localhost:2181(CONNECTED) 54] create","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:10","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"åº”ç”¨åœºæ™¯ Zookeeper æä¾›çš„æœåŠ¡åŒ…æ‹¬ï¼šç»Ÿä¸€å‘½åæœåŠ¡ã€ç»Ÿä¸€é…ç½®ç®¡ç†ã€ç»Ÿä¸€é›†ç¾¤ç®¡ç†ã€æœåŠ¡å™¨èŠ‚ç‚¹åŠ¨æ€ä¸Šä¸‹ çº¿ã€è½¯è´Ÿè½½å‡è¡¡ç­‰ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:11","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"Watcher äº‹ä»¶ç›‘å¬å™¨ Watcher(äº‹ä»¶ç›‘å¬å™¨)æ˜¯ Zookeeper æä¾›çš„ä¸€ç§ å‘å¸ƒ/è®¢é˜…çš„æœºåˆ¶ã€‚ Zookeeper å…è®¸å®¢æˆ·ç«¯åœ¨æŒ‡å®šçš„é›†ç¾¤æ•°æ®èŠ‚ç‚¹ä¸Šæ³¨å†Œä¸€äº› Watcherï¼Œå½“å‘ç”ŸZNodeå­˜å‚¨æ•°æ®çš„ä¿®æ”¹ï¼Œ å­èŠ‚ç‚¹ç›®å½•çš„å˜åŒ–ç­‰æƒ…å†µçš„æ—¶å€™ï¼ŒZookeeper æœåŠ¡ç«¯ä¼šå°†äº‹ä»¶é€šçŸ¥ç»™ç›‘å¬çš„å®¢æˆ·ç«¯ï¼Œç„¶åå®¢æˆ·ç«¯æ ¹æ® Watcheré€šçŸ¥çŠ¶æ€å’Œäº‹ä»¶ç±»å‹åšå‡ºä¸šåŠ¡ä¸Šçš„æ”¹å˜ã€‚ å®¢æˆ·ç«¯æ³¨å†Œç›‘å¬å®ƒå…³å¿ƒçš„ç›®å½•èŠ‚ç‚¹ï¼Œå½“ç›®å½•èŠ‚ç‚¹å‘ç”Ÿå˜åŒ–ï¼ˆæ•°æ®æ”¹å˜ã€èŠ‚ç‚¹åˆ é™¤ã€å­ç›® å½•èŠ‚ç‚¹å¢åŠ åˆ é™¤ï¼‰æ—¶ï¼ŒZooKeeper ä¼šé€šçŸ¥å®¢æˆ·ç«¯ã€‚ç›‘å¬æœºåˆ¶ä¿è¯ ZooKeeper ä¿å­˜çš„ä»»ä½•çš„æ•° æ®çš„ä»»ä½•æ”¹å˜éƒ½èƒ½å¿«é€Ÿçš„å“åº”åˆ°ç›‘å¬äº†è¯¥èŠ‚ç‚¹çš„åº”ç”¨ç¨‹åºã€‚ è¯¥æœºåˆ¶æ˜¯ Zookeeper å®ç°åˆ†å¸ƒå¼åè°ƒçš„é‡è¦ç‰¹æ€§ï¼Œä¹Ÿæ˜¯Zookeeperçš„æ ¸å¿ƒç‰¹æ€§,Zookeeperçš„å¾ˆå¤š åŠŸèƒ½éƒ½æ˜¯åŸºäºè¿™ä¸ªç‰¹æ€§å®ç°çš„ã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯å¼‚æ­¥çš„ã€‚ Zookeeperçš„ç›‘å¬æœºåˆ¶ä¸»è¦æœ‰ä¸‰ä¸ªå…³é”®ç‚¹ï¼šæ•´ä½“è§¦å‘ã€å‘é€æ–¹å¼ã€å±€éƒ¨è§¦å‘ã€‚ æ•´ä½“è§¦å‘: å½“è®¾ç½®ç›‘è§†çš„æ•°æ®å‘ç”Ÿæ”¹å˜æ—¶ï¼Œè¯¥ç›‘è§†äº‹ä»¶ä¼šè¢«å‘é€åˆ°å®¢æˆ·ç«¯ï¼Œå¸¸è§çš„å°±æ˜¯ç›‘æ§ZNodeä¸­çš„æ•°æ®æˆ–å­ç›®å½•å‘ç”Ÿå˜åŒ–ã€‚ å‘é€æ–¹å¼ï¼š ZookeeperæœåŠ¡ç«¯è¢«è§¦å‘çš„æ—¶å€™ï¼Œä¼šåŸºäºä¼šè¯ç»™å®¢æˆ·ç«¯å‘é€ä¿¡æ¯ï¼Œä½†æ˜¯ç”±äºç½‘ç»œçš„åŸå› ï¼Œç»å¸¸ä¼šå‡ºç°ç½‘ç»œå»¶è¿Ÿçš„å› ç´ ï¼Œé€ æˆå®¢æˆ·ç«¯æ¥æ”¶çš„ç»“æ„ä¸ä¸€è‡´ï¼Œè€ŒZookeeperæœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„ç‰¹ç‚¹å°±æ˜¯:ä¸€è‡´æ€§ï¼Œä¸ºäº†è¾¾åˆ°è¿™ä¸ªç›®æ ‡ï¼ŒZookeeperçš„ç›‘å¬æœºåˆ¶åœ¨ä¿¡æ¯å‘é€çš„æ–¹å¼ä¸Šï¼Œå°±æœ‰äº†ä¸€ä¸ªå‘é€ç‰¹ç‚¹ï¼šæ‰€æœ‰çš„ç›‘è§†äº‹ä»¶è¢«è§¦å‘åï¼Œä¸ä¼šç«‹å³å‘é€è‡³å®¢æˆ·ç«¯ï¼Œè€Œæ˜¯ä»¥å¼‚æ­¥çš„æ–¹å¼å‘é€è‡³ç›‘è§†è€…çš„ï¼Œè€Œä¸”Zookeeper æœ¬èº«æä¾›äº†é¡ºåºä¿è¯ã€‚æ•ˆæœå°±æ˜¯ï¼šå®¢æˆ·ç«¯é¦–å…ˆçœ‹åˆ°ç›‘è§†äº‹ä»¶ï¼Œç„¶åæ‰ä¼šæ„ŸçŸ¥åˆ°å®ƒæ‰€è®¾ç½®ç›‘è§†çš„znodeå‘ç”Ÿäº†å˜åŒ–ã€‚è¿™æ ·å°±è¾¾åˆ°äº†ï¼Œè™½ç„¶ä¸åŒçš„å®¢æˆ·ç«¯åœ¨ä¸åŒçš„æ—¶åˆ»æ„ŸçŸ¥åˆ°äº†ç›‘è§†äº‹ä»¶ï¼Œä½†æ˜¯å®¢æˆ·ç«¯æ‰€çœ‹åˆ°çš„æ•ˆæœéƒ½æ˜¯çœŸå®ä¸€è‡´çš„ã€‚ å±€éƒ¨è§¦å‘ å½“å®¢æˆ·ç«¯ç›‘è§†çš„ZookeeperèŠ‚ç‚¹ZNodeå†…éƒ¨æœ‰æ¯”è¾ƒå¤šçš„å­ç›®å½•æ•°æ®çš„æ—¶å€™ï¼Œè¿™ç§åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬åªéœ€è¦ç›‘è§†å…¶ä¸­çš„ä¸€ä¸ªå°éƒ¨åˆ†é‡è¦çš„æ•°æ®ï¼Œå…¶ä»–çš„æ•°æ®æ˜¯ä¸€äº›æ— å…³ç´§è¦çš„ï¼Œæ‰€ä»¥å°±æ²¡æœ‰å¿…è¦ç›‘è§†å…¨éƒ¨çš„ZNodeæ•°æ®å˜åŒ–ï¼Œè¿™æ„å‘³ç€znodeèŠ‚ç‚¹æœ¬èº«å°±åº”è¯¥å…·æœ‰ä¸åŒçš„è§¦å‘äº‹ä»¶æ–¹å¼ï¼šå³æ”¯æŒå¯¹ZNodeæ•°æ®äº‹ä»¶çš„å±€éƒ¨è§¦å‘ã€‚ ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:12","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"ç›‘å¬å™¨å®è·µ 1.èŠ‚ç‚¹çš„å€¼å˜åŒ–ç›‘å¬ åœ¨hadoop104 ä¸»æœºä¸Šæ³¨å†Œç›‘å¬/sanguo èŠ‚ç‚¹æ•°æ®å˜åŒ– [zk: localhost:2181(CONNECTED) 26] get -w /sanguoåœ¨hadoop103 ä¸»æœºä¸Šä¿®æ”¹/sanguo èŠ‚ç‚¹çš„æ•°æ® [zk: localhost:2181(CONNECTED) 1] set /sanguo \"xisi\"è§‚å¯Ÿhadoop104 ä¸»æœºæ”¶åˆ°æ•°æ®å˜åŒ–çš„ç›‘å¬ WATCHER:: WatchedEvent state:SyncConnected type:NodeDataChanged path:/sanguoæ³¨æ„ï¼šåœ¨hadoop103å†å¤šæ¬¡ä¿®æ”¹/sanguoçš„å€¼ï¼Œhadoop104ä¸Šä¸ä¼šå†æ”¶åˆ°ç›‘å¬ã€‚å› ä¸ºæ³¨å†Œ ä¸€æ¬¡ï¼Œåªèƒ½ç›‘å¬ä¸€æ¬¡ã€‚æƒ³å†æ¬¡ç›‘å¬ï¼Œéœ€è¦å†æ¬¡æ³¨å†Œã€‚ 2.èŠ‚ç‚¹çš„å­èŠ‚ç‚¹å˜åŒ–ç›‘å¬ï¼ˆè·¯å¾„å˜åŒ–ï¼‰ åœ¨hadoop104 ä¸»æœºä¸Šæ³¨å†Œç›‘å¬/sanguo èŠ‚ç‚¹çš„å­èŠ‚ç‚¹å˜åŒ– [zk: localhost:2181(CONNECTED) 1] ls -w /sanguo [shuguo, weiguo]åœ¨hadoop103 ä¸»æœº/sanguo èŠ‚ç‚¹ä¸Šåˆ›å»ºå­èŠ‚ç‚¹ [zk: localhost:2181(CONNECTED) 2] create /sanguo/jin \"simayi\" Created /sanguo/jin è§‚å¯Ÿhadoop104 ä¸»æœºæ”¶åˆ°å­èŠ‚ç‚¹å˜åŒ–çš„ç›‘å¬ WATCHER:: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/sanguo æ³¨æ„ï¼šèŠ‚ç‚¹çš„è·¯å¾„å˜åŒ–ï¼Œä¹Ÿæ˜¯æ³¨å†Œä¸€æ¬¡ï¼Œç”Ÿæ•ˆä¸€æ¬¡ã€‚æƒ³å¤šæ¬¡ç”Ÿæ•ˆï¼Œå°±éœ€è¦å¤šæ¬¡æ³¨å†Œã€‚ æ—¥å¿—å®è·µ zookeeperæœåŠ¡å™¨ä¼šäº§ç”Ÿä¸‰ç±»æ—¥å¿—ï¼šäº‹åŠ¡æ—¥å¿—ã€å¿«ç…§æ—¥å¿—å’Œç³»ç»Ÿæ—¥å¿—ã€‚\ræˆ‘ä»¬å¯ä»¥åœ¨zookeeperçš„é…ç½®æ–‡ä»¶zoo.cfgä¸­ é€šè¿‡\rdataDir è®¾å®šæ•°æ®å¿«ç…§æ—¥å¿—çš„å­˜å‚¨ä½ç½®\rdataLogDir è®¾å®šäº‹åŠ¡æ—¥å¿—çš„å­˜å‚¨ä½ç½®ï¼Œå¦‚æœä¸è®¾ç½®è¯¥é¡¹ï¼Œè¿™é»˜è®¤ä¿å­˜åœ¨ dataDirç›®å½•ä¸‹\ræ³¨æ„ï¼š\räº‹åŠ¡æ—¥å¿—å’Œå¿«ç…§æ—¥å¿—éƒ½ä¼šä¿å­˜åœ¨ æŒ‡å®šç›®å½•çš„ version-2 å­ç›®å½•ä¸‹ã€‚\ræˆ‘ä»¬å€¾å‘äº dataLogDir å’Œ dataLog å•ç‹¬é…ç½®ï¼Œå› ä¸ºzookeeperé›†ç¾¤é¢‘ç¹è¯»å†™æ“ä½œï¼Œ\rå¯èƒ½ä¼šäº§ç”Ÿå¤§é¾„æ—¥å¿—ï¼Œæœ‰å¯èƒ½å½±å“ç³»ç»Ÿæ€§èƒ½ï¼Œå¯ä»¥æ ¹æ®æ—¥å¿—çš„ç‰¹æ€§ï¼Œä½¿ç”¨ä¸åŒçš„å­˜å‚¨ä»‹è´¨\rzookeeperçš„ç³»ç»Ÿè¿è¡Œæ—¥å¿—æ˜¯å¯ä»¥é€šè¿‡ä¸‰ä¸ªä½ç½®æ¥è¿›è¡Œè®¾ç½®\r1 åœ¨log4j.propertiesæ–‡ä»¶ä¸­ é€šè¿‡\rzookeeper.log.dir=. æ¥è®¾ç½®ï¼Œè¿™é‡Œçš„'.'æŒ‡çš„æ˜¯zkServer.shååœ¨çš„ç›®å½•\r2 åœ¨ zkEnv.sh æ–‡ä»¶ä¸­é€šè¿‡\rZOO_LOG_DIR=\"$ZOOKEEPER_PREFIX/logs\" æ¥è®¾ç½®\r3 åœ¨ zkServer.sh æ–‡ä»¶ä¸­ é€šè¿‡\rZOO_LOG_FILE=zookeeper-$USER-server-$HOSTNAME.log\r_ZOO_DAEMON_OUT=\"$ZOO_LOG_DIR/zookeeper-$USER-server-$HOSTNAME.out\"\ræ¥æŒ‡å®šäº‹åŠ¡æ—¥å¿— æ—¥å¿—ç®€ä»‹ äº‹åŠ¡æ—¥å¿—æ˜¯æŒ‡ Zookeeper ç³»ç»Ÿåœ¨æ­£å¸¸è¿è¡Œè¿‡ç¨‹ä¸­ï¼Œé’ˆå¯¹æ‰€æœ‰çš„æ›´æ–°æ“ä½œï¼Œåœ¨è¿”å›å®¢æˆ·ç«¯ æ›´æ–°æˆåŠŸ çš„ å“åº”å‰ï¼ŒZookeeper ä¼šä¿è¯å·²ç»å°†æœ¬æ¬¡æ›´æ–°æ“ä½œçš„äº‹åŠ¡æ—¥å¿—å†™åˆ°ç£ç›˜ä¸Šï¼Œåªæœ‰è¿™æ ·ï¼Œæ•´ä¸ªæ›´æ–°æ“ä½œæ‰ä¼šç”Ÿ æ•ˆã€‚ æ—¥å¿—æŸ¥çœ‹ zookeeperçš„äº‹åŠ¡æ—¥å¿—ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œä¸èƒ½é€šè¿‡vimç­‰å·¥å…·ç›´æ¥è®¿é—®,å¯ä»¥é€šè¿‡zookeeperè‡ªå¸¦çš„åŠŸèƒ½ æ–‡ä»¶è¯»å–äº‹åŠ¡æ—¥å¿—æ–‡ä»¶ã€‚ å¯¹äº3.5.5 ä¹‹å‰çš„zookeeperéœ€è¦å€ŸåŠ©äºå¤§é‡çš„jaråŒ…æ¥å®ç°æ—¥å¿—çš„æŸ¥çœ‹ï¼Œæ¯”å¦‚ java -cp .:zookeeper-3.7.0.jar:slf4j-api-1.7.30.jar org.apache.zookeeper.server.LogFormatter log.1 zookeeper ä» 3.5.5 ç‰ˆæœ¬ä¹‹åï¼Œå°±å–æ¶ˆçš„LogFormatter ï¼Œä½¿ç”¨äº†ä¸€ä¸ªæ›´å¥½çš„ TxnLogToolkit å·¥å…·,è¿™ä¸ªå·¥å…·æ”¾ç½®åœ¨äº† bin/ ç›®å½•ä¸‹ï¼Œæ–‡ä»¶åæ˜¯ zkTxnLogToolkit.sh ä½¿ç”¨æ–¹å¼ï¼š zkTxnLogToolkit.sh log_fileå¿«ç…§æ—¥å¿— æ—¥å¿—ç®€ä»‹\rzookeeperçš„æ•°æ®åœ¨å†…å­˜ä¸­æ˜¯ä»¥æ ‘å½¢ç»“æ„è¿›è¡Œå­˜å‚¨çš„ï¼Œè€Œå¿«ç…§å°±æ˜¯æ¯éš”ä¸€æ®µæ—¶é—´å°±ä¼šæŠŠæ•´ä¸ªDataTree\rçš„æ•°æ®åºåˆ—åŒ–åå­˜å‚¨åœ¨ç£ç›˜ä¸­ã€‚\ræ—¥å¿—æŸ¥çœ‹\råŒæ ·åœ¨ 3.5.5 ç‰ˆæœ¬ä¹‹å, æˆ‘ä»¬å¯ä»¥åŸºäº zkSnapShotToolkit.sh å‘½ä»¤æ¥è¿›è¡Œå¿«ç…§æ—¥å¿—çš„æŸ¥çœ‹æŸ¥çœ‹æ—¥å¿—å®è·µ æ—¥å¿—æ–‡ä»¶æŸ¥çœ‹ # ls logs/version-2/ -lh\ræ€»ç”¨é‡ 24K\r-rw-r--r-- 1 root root 65M 8æœˆ 10 16:38 log.100000005\r-rw-r--r-- 1 root root 65M 8æœˆ 10 16:06 log.800000001\r-rw-r--r-- 1 root root 65M 8æœˆ 10 16:23 log.b00000001\rç»“æœæ˜¾ç¤ºï¼š\ræ¯ä¸ªæ—¥å¿—æ–‡ä»¶å¤§å°æ˜¯ 65Mï¼Œæ–‡ä»¶åè§„åˆ™ 'log.9ä¸ªå­—ç¬¦',è¿™9ä¸ªå­—ç¬¦æŒ‡çš„æ˜¯äº‹åŠ¡id\ræ—¥å¿—å†…å®¹æŸ¥çœ‹\r# ./bin/zkTxnLogToolkit.sh logs/version-2/log.b00000001\rZooKeeper Transactional Log File with dbid 0 txnlog format version 2\r# è¿™æ˜¯æ¯ä¸ªäº‹åŠ¡æ—¥å¿—æ–‡ä»¶éƒ½æœ‰çš„æ—¥å¿—å¤´ï¼Œè¾“å‡ºäº† dbid è¿˜æœ‰ versionç­‰ä¿¡æ¯\r2021-08-10 17:07:23,272 [myid:] - INFO [main:ZookeeperBanner@42] -\r...\r2021-08-10 17:07:23,289 [myid:] - INFO [main:ZooKeeperServer@260] -\rzookeeper.intBufferStartingSizeBytes = 1024\r21-8-10 ä¸‹åˆ04æ—¶23åˆ†21ç§’ session 0x100009bc0f50000 cxid 0x0 zxid 0xb00000001\rcloseSession v{}\r# è¿™æ˜¯xxæ—¶å€™ï¼Œsessionid è¯·æ±‚ç±»å‹ä¸º closeSessionï¼Œè¡¨ç¤ºå…³é—­äº†ä¼šè¯\rEOF reached after 1 txns.å¿«ç…§æ—¥å¿—æŸ¥çœ‹ æ—¥å¿—æ–‡ä»¶æŸ¥çœ‹\r# ls data/version-2/ -lh\ræ€»ç”¨é‡ 20K\r-rw-r--r-- 1 root root 2 8æœˆ 10 16:45 acceptedEpoch\r-rw-r--r-- 1 root root 2 8æœˆ 10 16:45 currentEpoch\r-rw-r--r-- 1 root root 2.1K 8æœˆ 10 16:05 snapshot.600000000\r-rw-r--r-- 1 root root 2.1K 8æœˆ 10 16:06 snapshot.700000000\r-rw-r--r-- 1 root root 2.0K 8æœˆ 10 16:15 snapshot.800000001\rç»“æœæ˜¾ç¤ºï¼š\rå¿«ç…§æ—¥å¿—çš„å‘½åè§„åˆ™ä¸º'snapshot.9ä¸ªå­—ç¬¦',\rè¿™9ä¸ªå­—ç¬¦è¡¨ç¤ºzookeeperè§¦å‘å¿«ç…§çš„é‚£ä¸ªç¬é—´ï¼Œæäº¤çš„æœ€åä¸€ä¸ªäº‹åŠ¡çš„IDã€‚\ræ—¥å¿—å†…å®¹æŸ¥çœ‹\r#\r./bin/zkSnapShotToolkit.sh data/version-2/snapshot.800000001\r2021-08-10 17:08:25,876 [myid:] - INFO [main:SnapStream@61] -\rzookeeper.snapshot.compression.method = CHECKED\r...\r----\r/zookeeper/quota/sswang2/zookeeper_stats è·¯å¾„\rcZxid = 0x00000000000051 åˆ›å»ºèŠ‚ç‚¹æ—¶çš„ Zxid\rctime = Tue Aug 10 14:44:11 CST 2021 åˆ›å»ºèŠ‚ç‚¹çš„æ—¶é—´\rmZxid = 0x00000000000051 èŠ‚ç‚¹æœ€è¿‘ä¸€æ¬¡æ›´æ–°å¯¹åº”çš„ Zxid\rmtime = Tue Aug 10 14:44:11 CST 2021 èŠ‚ç‚¹æœ€è¿‘ä¸€æ¬¡æ›´æ–°çš„æ—¶é—´\rpZxid = 0x00000000000051 çˆ¶èŠ‚ç‚¹çš„ Zxid\rcversion = 0 å­èŠ‚ç‚¹æ›´æ–°æ¬¡æ•°\rdataVersion = 0 æ•°æ®æ›´æ–°æ¬¡æ•°\raclVersion = 0 èŠ‚ç‚¹ acl æ›´æ–°æ¬¡æ•°\rephemeralOwner = 0x00000000000000 èŠ‚ç‚¹çš„ sessionidå€¼\rdataLength = 16 å­˜å‚¨çš„æ•°æ®é•¿åº¦\r----\rè¿™é‡Œè¡¨è¾¾çš„æ˜¯å½“å‰æŠ“å–å¿«ç…§æ—¥å¿—æ–‡ä»¶çš„æ—¶é—´è®°å½•\rSession Details (sid, timeout, ephemeralCount):\r0x1000048d7820002, 30000, 0\r0x100009bc0f50000, 30000, 0\r----\rLast zxid: 0x800000001ç³»ç»Ÿæ—¥å¿—æŸ¥çœ‹ æ—¥å¿—æŸ¥çœ‹\r# ls bin/zook*\rbin/zookeeper_audit.log\r# ls logs/zook*\rlogs/zookeeper_audit.log logs/zookeeper-root-server-python-auto.out\ræŸ¥çœ‹é›†ç¾¤è¿è¡Œæ—¥å¿—\r# cat logs/","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:13","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"åŸºç¡€é…ç½® é…ç½® è§£æ tickTimeï¼ˆSS / CSï¼‰ ç”¨æ¥æŒ‡ç¤º æœåŠ¡å™¨ä¹‹é—´æˆ–å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨ä¹‹é—´ç»´æŠ¤å¿ƒè·³æœºåˆ¶çš„ æœ€å°æ—¶é—´å•å…ƒï¼ŒSession æœ€å°è¿‡æœŸæ—¶é—´é»˜è®¤ä¸ºä¸¤å€çš„ tickTimeï¼ˆdefaultï¼š2000msï¼‰ initLimitï¼ˆLFï¼‰ é›†ç¾¤ä¸­çš„ Leader èŠ‚ç‚¹å’Œ Follower èŠ‚ç‚¹ä¹‹é—´åˆå§‹è¿æ¥æ—¶èƒ½å®¹å¿çš„æœ€å¤šå¿ƒè·³æ•°ï¼ˆdefaultï¼š10 tickTimeï¼‰ syncLimitï¼ˆLFï¼‰ é›†ç¾¤ä¸­çš„ Leader èŠ‚ç‚¹å’Œ Follower èŠ‚ç‚¹ä¹‹é—´è¯·æ±‚å’Œåº”ç­”æ—¶èƒ½å®¹å¿çš„æœ€å¤šå¿ƒè·³æ•°ï¼ˆdefaultï¼š5 tickTimeï¼‰ dataDir Zookeeper ä¿å­˜æœåŠ¡å™¨å­˜å‚¨å¿«ç…§æ–‡ä»¶çš„ç›®å½•ï¼Œé»˜è®¤æƒ…å†µï¼ŒZookeeperå°† å†™æ•°æ®çš„æ—¥å¿—æ–‡ä»¶ä¹Ÿä¿å­˜åœ¨è¿™ä¸ªç›®å½•é‡Œï¼ˆdefaultï¼š/tmp/zookeeperï¼‰ clientPort å®¢æˆ·ç«¯è¿æ¥ Zookeeper æœåŠ¡å™¨çš„ç«¯å£ï¼ŒZookeeper ä¼šç›‘å¬è¿™ä¸ªç«¯å£ï¼Œæ¥å—å®¢æˆ·ç«¯çš„è®¿é—®è¯·æ±‚ï¼ˆdefaultï¼š2181ï¼‰ dataLogDir ç”¨æ¥å­˜å‚¨æœåŠ¡å™¨äº‹åŠ¡æ—¥å¿— minSessionTimeout\u0026maxSessionTimeout é»˜è®¤åˆ†åˆ«æ˜¯ 2 * tickTime ~ 20 * tickTimeï¼Œæ¥ç”¨æ§åˆ¶ å®¢æˆ·ç«¯è®¾ç½®çš„Session è¶…æ—¶æ—¶é—´ã€‚å¦‚æœè¶…å‡ºæˆ–è€…å°äºï¼Œå°†è‡ªåŠ¨è¢«æœåŠ¡ç«¯å¼ºåˆ¶è®¾ç½®ä¸ºæœ€å¤§æˆ–è€…æœ€å° ","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:14","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["Zookeeper"],"content":"é›†ç¾¤é…ç½® ä¸ºäº†é…ç½® Zookeeper é›†ç¾¤ï¼Œä¼šåœ¨é…ç½®æ–‡ä»¶æœ«å°¾å¢åŠ å¦‚ä¸‹æ ¼å¼çš„æœåŠ¡å™¨èŠ‚ç‚¹é…ç½®\ræ ¼å¼ï¼šserver.\u003cmyid\u003e=\u003cserver_ip\u003e:\u003cLF_Port\u003e:\u003cL_Port\u003eæ ¼å¼è§£æ \u003cmyid\u003e\rè¡¨ç¤ºèŠ‚ç‚¹ç¼–å·ï¼Œæ˜¯è¯¥èŠ‚ç‚¹åœ¨é›†ç¾¤ä¸­å”¯ä¸€çš„ç¼–å·ï¼Œå–å€¼èŒƒå›´æ˜¯1~255ä¹‹é—´çš„æ•´æ•°ï¼Œè€Œä¸”æˆ‘ä»¬å¿…é¡»åœ¨\rdataDirç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªmyidçš„æ–‡ä»¶ï¼Œå°†èŠ‚ç‚¹å¯¹åº”çš„\u003cmyid\u003eå€¼è¾“å…¥åˆ°è¯¥èŠ‚ç‚¹çš„myidæ–‡ä»¶ã€‚\r\u003cserver_ip\u003e\rè¡¨ç¤ºé›†ç¾¤ä¸­çš„èŠ‚ç‚¹ipåœ°å€ï¼Œå¯ä»¥ä½¿ç”¨ä¸»æœºåæˆ–ipæ¥è¡¨ç¤ºï¼Œç”Ÿäº§ä¸­å¦‚æœé…ç½®å¥½å†…éƒ¨dnsçš„è¯ï¼Œæ¨èä½¿ç”¨ä¸»\ræœºåï¼Œæœ¬æœºåœ°å€çš„è¡¨ç¤ºæ–¹æ³•æ˜¯ï¼š127.0.0.1æˆ–è€…localhost\r\u003cLF_Port\u003e\rè¡¨ç¤ºLeaderèŠ‚ç‚¹å’ŒFollowerèŠ‚ç‚¹è¿›è¡Œå¿ƒè·³æ£€æµ‹ä¸æ•°æ®åŒæ­¥æ‰€ä½¿ç”¨çš„ç«¯å£ã€‚\r\u003cL_Port\u003e\rè¡¨ç¤ºè¿›è¡Œé¢†å¯¼é€‰ä¸¾è¿‡ç¨‹ä¸­ï¼Œç”¨äºæŠ•ç¥¨é€šä¿¡çš„ç«¯å£ã€‚\ræ³¨æ„ï¼š\rè¿™äº›ç«¯å£å¯ä»¥éšæœºè‡ªå·±å®šä¹‰ã€‚\rçœŸæ­£çš„ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä¸åŒä¸»æœºä¸Šçš„clientPortã€LF_Portã€L_Portä¸‰ä¸ªç«¯å£ä¸€èˆ¬å¯ä»¥é…ç½®æˆä¸€æ ·ï¼Œå› \rä¸ºç”Ÿäº§é›†ç¾¤ä¸­æ¯ä¸ªserverä¸»æœºéƒ½åˆ†å¸ƒåœ¨ä¸åŒçš„ä¸»æœºä¸Šï¼Œéƒ½æœ‰ç‹¬ç«‹çš„ipåœ°å€ï¼Œä¸ä¼šé€ æˆç«¯å£å†²çª","date":"2021-10-05","objectID":"/posts/zookeeper/zookeeper-01/:2:15","tags":["Zookeeper","ä¸­é—´ä»¶"],"title":"zookeeper åŸºç¡€ä¸å®‰è£… ï¼ˆä¸€ï¼‰","uri":"/posts/zookeeper/zookeeper-01/"},{"categories":["ElasticStack"],"content":"Logstash èƒ½å¤ŸåŠ¨æ€åœ°é‡‡é›†ã€è½¬æ¢å’Œä¼ è¾“æ•°æ®ï¼Œä¸å—æ ¼å¼æˆ–å¤æ‚åº¦çš„å½±å“ã€‚Logstash é‡‡ç”¨å¯æ’æ‹”æ¡†æ¶ï¼Œæ‹¥æœ‰ 200 å¤šä¸ªæ’ä»¶ã€‚æ‚¨å¯ä»¥å°†ä¸åŒçš„è¾“å…¥é€‰æ‹©ã€è¿‡æ»¤å™¨å’Œè¾“å‡ºé€‰æ‹©æ··åˆæ­é…ã€ç²¾å¿ƒå®‰æ’ï¼Œè®©å®ƒä»¬åœ¨ç®¡é“ä¸­å’Œè°åœ°è¿è¡Œã€‚åˆ©ç”¨ Grok ä»éç»“æ„åŒ–æ•°æ®ä¸­æ´¾ç”Ÿå‡ºç»“æ„ï¼Œä» IP åœ°å€è§£ç å‡ºåœ°ç†åæ ‡ï¼ŒåŒ¿ååŒ–æˆ–æ’é™¤æ•æ„Ÿå­—æ®µï¼Œå¹¶ç®€åŒ–æ•´ä½“å¤„ç†è¿‡ç¨‹ã€‚Logstash æä¾›ä¼—å¤šè¾“å‡ºé€‰æ‹©ï¼Œæ‚¨å¯ä»¥å°†æ•°æ®å‘é€åˆ°æ‚¨è¦æŒ‡å®šçš„åœ°æ–¹ï¼Œå¹¶ä¸”èƒ½å¤Ÿçµæ´»åœ°è§£é”ä¼—å¤šä¸‹æ¸¸ç”¨ä¾‹ã€‚ ","date":"2021-10-03","objectID":"/posts/elk/elk-logstash/:0:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Logstash ï¼ˆä¸‰ï¼‰","uri":"/posts/elk/elk-logstash/"},{"categories":["ElasticStack"],"content":"åŸºç¡€çŸ¥è¯† ","date":"2021-10-03","objectID":"/posts/elk/elk-logstash/:1:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Logstash ï¼ˆä¸‰ï¼‰","uri":"/posts/elk/elk-logstash/"},{"categories":["ElasticStack"],"content":"åŠŸèƒ½ç®€ä»‹ logstash å°±æ˜¯å€ŸåŠ©äºå¤§é‡çš„åŠŸèƒ½æ’ä»¶ï¼Œå®ç°ä»æ•°æ®æºè·å–æ•°æ®ï¼Œç„¶åå°†æ•°æ®ä¼ è¾“åˆ°elasticsearchã€‚ åœ¨å›¾ä¸­æˆ‘ä»¬å¯ä»¥æ˜æ˜¾çœ‹åˆ°ï¼Œlogstashç»„ä»¶è‡³å°‘åŒ…å«ä¸¤ä¸ªæ’ä»¶ï¼šinputå’Œoutputï¼Œè¿™ä¸¤ä¸ªä¸»è¦ç”¨äºä¿¡æ¯çš„æ¥å…¥å’Œè¾“å‡ºã€‚ æ³¨æ„ï¼š logstash è½¯ä»¶æœ¬èº«æ— åºå®‰è£…ï¼Œå®ƒä»…ä»…æ˜¯ä¸€ä¸ªè½¯ä»¶è¿è¡Œå‘½ä»¤ç¨‹åºï¼Œä½†æ˜¯è¯¥è½¯ä»¶çš„è¿è¡Œä¾èµ–äºjavaç¯å¢ƒ è¿è¡Œç¯å¢ƒ å®‰è£…java8ç¯å¢ƒ\rapt install openjdk-8-jdk\ræ£€æŸ¥æ•ˆæœ\rjava -version ","date":"2021-10-03","objectID":"/posts/elk/elk-logstash/:1:1","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Logstash ï¼ˆä¸‰ï¼‰","uri":"/posts/elk/elk-logstash/"},{"categories":["ElasticStack"],"content":"è½¯ä»¶å®‰è£… aptæºç æ–¹å¼ è·å–è½¯ä»¶æº wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - apt install apt-transport-https echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee â€“a /etc/apt/sources.list.d/elastic-7.x.list apt update å®‰è£…è½¯ä»¶ apt install logstash è½¯ä»¶åŒ…å®‰è£… wget https://artifacts.elastic.co/downloads/logstash/logstash-7.14.0-amd64.deb wget https://artifacts.elastic.co/downloads/logstash/logstash-7.14.0- amd64.deb.sha512 shasum -a 512 -c logstash-7.14.0-amd64.deb.sha512 dpkg -i logstash-7.14.0-amd64.deb é…ç½®æŸ¥çœ‹ dpkg -L logstash /. /usr /usr/share /usr/share/logstash ... /etc /etc/logstash /etc/logstash/conf.d /etc/logstash/log4j2.properties /etc/logstash/startup.options æœåŠ¡å¯åŠ¨ç¯å¢ƒå˜é‡æ–‡ä»¶ /etc/logstash/jvm.options jvmç›¸å…³é…ç½® /etc/logstash/logstash.yml æœåŠ¡é…ç½®æ–‡ä»¶ /etc/logstash/logstash-sample.conf åº”ç”¨é…ç½®æ–‡ä»¶æ¨¡æ¿ /etc/logstash/pipelines.yml ... /usr/share/logstash/bin /usr/share/logstash/bin/benchmark.bat /usr/share/logstash/bin/benchmark.sh /usr/share/logstash/bin/cpdump /usr/share/logstash/bin/dependencies-report /usr/share/logstash/bin/ingest-convert.bat /usr/share/logstash/bin/ingest-convert.sh /usr/share/logstash/bin/logstash /usr/share/logstash/bin/logstash-keystore /usr/share/logstash/bin/logstash-keystore.bat /usr/share/logstash/bin/logstash-plugin /usr/share/logstash/bin/logstash-plugin.bat /usr/share/logstash/bin/logstash.bat /usr/share/logstash/bin/logstash.lib.sh /usr/share/logstash/bin/pqcheck /usr/share/logstash/bin/pqcheck.bat /usr/share/logstash/bin/pqrepair /usr/share/logstash/bin/pqrepair.bat /usr/share/logstash/bin/ruby /usr/share/logstash/bin/setup.bat /usr/share/logstash/bin/system-install ç”Ÿæˆç³»ç»Ÿç®¡ç†é…ç½®æ–‡ä»¶ ... å®šåˆ¶ç¯å¢ƒå˜é‡ echo 'export PATH=/usr/share/logstash/bin:$PATH' \u003e /etc/profile.d/logstash.sh source /etc/profile.d/logstash.sh ","date":"2021-10-03","objectID":"/posts/elk/elk-logstash/:1:2","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Logstash ï¼ˆä¸‰ï¼‰","uri":"/posts/elk/elk-logstash/"},{"categories":["ElasticStack"],"content":"ç®€å•å®è·µ å‘½ä»¤æ ¼å¼ logstash -e 'å¯åŠ¨å‚æ•°' å¯åŠ¨å‚æ•°ï¼š input { stdin {} } output { stdout {} } å‚æ•°è§£æï¼š input {} ç”¨äºæ¥å—ä¿¡æ¯çš„è¾“å…¥ output {} ç”¨äºå¯¹å†…éƒ¨çš„æ•°æ®è¾“å‡º stdin {} è¡¨ç¤ºå±å¹•ä¸Šçš„æ ‡å‡†è¾“å…¥ stdout {} è¡¨ç¤ºå±å¹•çš„æ ‡å‡†è¾“å‡º å®è·µ1 - ç®€å•çš„è¾“å…¥è¾“å‡ºæµ‹è¯• # logstash -e 'input { stdin { } } output { stdout {} }' ... [INFO ] 2021-08-15 18:03:54.011 [Api Webserver] agent - Successfully started Logstash API endpoint {:port=\u003e9600} # çœ‹åˆ°ä¸Šé¢å‡†å¤‡å¥½çš„ä¿¡æ¯åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬åœ¨å±å¹•ä¸Šéšä¾¿è¾“å…¥ä¸€æ®µä¿¡æ¯ nihao logstash # ä¿¡æ¯è¾“å…¥å®Œæ¯•åï¼Œä»–ä¼šè‡ªåŠ¨æ ¼å¼åŒ–çš„è¾“å‡ºä¸€äº›å†…å®¹ { \"host\" =\u003e \"ubuntu\", # å½“å‰çš„ä¸»æœºä¿¡æ¯ \"@timestamp\" =\u003e 2021-08-15T10:04:32.873Z, # è¯¥æ¡ä¿¡æ¯çš„æ—¶é—´æˆ³ \"message\" =\u003e \"nihao logstash\", # æˆ‘ä»¬è¾“å…¥çš„å†…å®¹ \"@version\" =\u003e \"1\" # ç‰ˆæœ¬ä¿¡æ¯ } ç»“æœå±•ç¤ºï¼š ä¿¡æ¯å±•ç¤ºå‡ºæ¥çš„å†…å®¹ï¼Œå…¶å®åŒ…å«ä¸¤éƒ¨åˆ†ï¼š index(æœç´¢æ•°æ®æ—¶å€™çš„ç´¢å¼•)å’Œvalue(å…·ä½“çš„æ•°æ®å†…å®¹) å®è·µ2 - ä¿¡æ¯ä¼ é€’åˆ°es é…ç½®logstashå°†ä¿¡æ¯è¾“å‡ºåˆ°esä¸­\r# logstash -e 'input { stdin{} } output { elasticsearch { hosts =\u003e\r[\"192.168.10.106:9200\"] index =\u003e \"message\" } }'\r...\r[2021-08-15 18:07:51.678][INFO ][logstash.agent ] Successfully started\rLogstash API endpoint {:port=\u003e9600}\r# çœ‹åˆ°ä¸Šé¢å‡†å¤‡å¥½çš„ä¿¡æ¯åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬åœ¨å±å¹•ä¸Šéšä¾¿è¾“å…¥ä¸€æ®µä¿¡æ¯\rhello elasticsearch\rç»“æœå±•ç¤ºï¼š\rå› ä¸ºæˆ‘ä»¬å°†ä¿¡æ¯è¾“å…¥åˆ°esä¸­äº†ï¼Œæ‰€ä»¥è¿™é‡Œçœ‹ä¸åˆ°ä¿¡æ¯è¾“å…¥\resæ£€æŸ¥æŸ¥çœ‹æ•ˆæœ\r# curl 192.168.10.106:9200/_cat/indices\rgreen open message x3JlhXwBQsmGYITwOnlWEw 1 1 1 0 10.8kb 5.3kb\r# curl 192.168.10.106:9200/message?pretty\r{\r\"message\" : {\r...,\r\"number_of_shards\" : \"1\",\r\"provided_name\" : \"message\",\r\"creation_date\" : \"1629022162762\",\r\"number_of_replicas\" : \"1\",\r\"uuid\" : \"x3JlhXwBQsmGYITwOnlWEw\",\r\"version\" : {\r\"created\" : \"7140099\"\r}\r}\r}\r}\r}\ræŸ¥çœ‹å†…å®¹ä¿¡æ¯\r# curl 192.168.10.106:9200/message/_search?pretty\r{\r\"took\" : 88,\r\"timed_out\" : false,\r\"_shards\" : {\r\"total\" : 1,\r\"successful\" : 1,\r\"skipped\" : 0,\r\"failed\" : 0\r},\r\"hits\" : {\r\"total\" : {\r\"value\" : 1,\r\"relation\" : \"eq\"\r},\r\"max_score\" : 1.0,\r\"hits\" : [\r{\r\"_index\" : \"message\",\r\"_type\" : \"_doc\",\r\"_id\" : \"3UZJSXsBvfqpwa_-kJ8V\",\r\"_score\" : 1.0,\r\"_source\" : {\r\"host\" : \"python-auto\",\r\"@timestamp\" : \"2021-08-15T10:09:22.359Z\",\r\"message\" : \"hello elasticsearch\",\r\"@version\" : \"1\"\r}\r}\r]\r}\r} å®è·µ3 - è¯»å–æ—¥å¿—æ–‡ä»¶åˆ°es æ¨¡å—ç®€ä»‹\rlogstashçš„ä¿¡æ¯é‡‡é›†æ¨¡å—æ”¯æŒfileæ¨¡å—ï¼Œå¯ä»¥é€šè¿‡æŒ‡å®šæ—¥å¿—æ–‡ä»¶ï¼Œç›´æ¥ä»æ–‡ä»¶ä¸­è¯»å–ç›¸å…³ä¿¡æ¯ã€‚\rå‚è€ƒèµ„æ–™ï¼š\rhttps://www.elastic.co/guide/en/logstash/7.14/plugins-inputs-file.html\råŸºæœ¬å±æ€§ï¼š\rpath æŒ‡å®šæ–‡ä»¶è·¯å¾„\rstart_position è®¾å®šä»æ–‡ä»¶çš„é‚£ä¸ªä½ç½®å¼€å§‹è¯»å–ï¼Œå¯é€‰å€¼ -- beginning, end(é»˜è®¤)\rtype ä¼ é€’ä¿¡æ¯çš„æ—¶å€™ï¼Œå¢åŠ ä¸€ä¸ªé¢å¤–çš„å±æ€§å­—æ®µ\ré…ç½®ç¤ºä¾‹ï¼š\rfile {\rpath =\u003e \"/var/log/syslog\"\rstart_position =\u003e \"beginning\"\rtype =\u003e \"elasticsearch\"\r}\rä»ç³»ç»Ÿæ—¥å¿—æ–‡ä»¶ä¸­è¯»å–ä¿¡æ¯ï¼Œè¾“å‡ºåˆ°esä¸­\r# logstash -e 'input { file{path =\u003e \"/var/log/syslog\" start_position =\u003e\r\"beginning\" type =\u003e \"elasticsearch\"} } output { elasticsearch { hosts =\u003e\r[\"192.168.10.106\"] index =\u003e \"message\" } }'\r...\r[INFO ] 2021-08-15 18:32:50.789 [[main]-pipeline-manager] elasticsearch - New\rElasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e\r[\"//192.168.8.12:9200\"]}\r...\r[INFO ] 2021-08-15 18:32:54.992 [[main]-pipeline-manager] file - No sincedb_path\rset, generating one based on the \"path\" setting\r{:sincedb_path=\u003e\"/usr/share/logstash/data/plugins/inputs/file/.sincedb_f5fdf6ea0\rea92860c6a6b2b354bfcbbc\", :path=\u003e[\"/var/log/syslog\"]}\råœ¨headæ’ä»¶ä¸­æŸ¥çœ‹æ—¥å¿—æ•ˆæœ ","date":"2021-10-03","objectID":"/posts/elk/elk-logstash/:1:3","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Logstash ï¼ˆä¸‰ï¼‰","uri":"/posts/elk/elk-logstash/"},{"categories":["ElasticStack"],"content":"æœåŠ¡æ–‡ä»¶æ–¹å¼ ç”Ÿæˆé…ç½®æ–‡ä»¶ â€‹ ä»¥å‘½ä»¤è¡Œçš„æ–¹å¼æ¥è¿›è¡Œå¯åŠ¨å¤ªç¹çï¼Œæˆ‘ä»¬æœ€å¥½è¿˜æ˜¯ä»¥é…ç½®æ–‡ä»¶çš„æ–¹å¼æ¥è¿›è¡ŒæœåŠ¡çš„å¯åŠ¨ç®¡ç†ï¼Œå¯¹äº logstashæ¥è¯´ï¼Œå®ƒæä¾›å¥½äº†ä¸€ä¸ªä¸“é—¨ç”¨äºç”Ÿæˆé…ç½®æ–‡ä»¶çš„å‘½ä»¤ system-installï¼Œæˆ‘ä»¬åªéœ€è¦æŒ‰ç…§æ—¢å®šçš„ é…ç½®æ–‡ä»¶è§„åˆ™ï¼Œå®šåˆ¶åº”ç”¨é…ç½®ï¼Œæœ€åæ‰§è¡Œè¯¥å‘½ä»¤ï¼Œå³å¯å®ç°æœåŠ¡è„šæœ¬çš„é…ç½®ã€‚ æœåŠ¡å¯åŠ¨å‚æ•° è¿›å…¥åº”ç”¨ç›®å½•\rcd /etc/logstash\rç¼–è¾‘å¯åŠ¨å‚æ•°æ–‡ä»¶\r# vim startup.options\r...\r# Arguments to pass to logstash\rLS_OPTS=\"--path.settings ${LS_SETTINGS_DIR} -f /etc/logstash/conf.d\"\ræ³¨æ„ï¼š -f æŒ‡å®šçš„æ˜¯ logstashçš„åº”ç”¨é…ç½®æ–‡ä»¶(æ¯”å¦‚ logstash.conf)å­˜æ”¾åˆ°çš„ç›®å½• å®šåˆ¶é…ç½®æ–‡ä»¶ä¿¡æ¯è¾“å…¥åˆ°esçš„é…ç½®æ–‡ä»¶ ç”Ÿæˆé…ç½®æ–‡ä»¶ cp logstash-sample.conf conf.d/logstash.conf ä¿®æ”¹é…ç½®æ–‡ä»¶ conf.d/logstash.conf # Sample Logstash configuration for creating a simple # Beats -\u003e Logstash -\u003e Elasticsearch pipeline. #è¾“å…¥éƒ¨åˆ† input { # beats { # port =\u003e 5044 # } #æ’ä»¶ file { path =\u003e [\"/var/log/syslog\"] start_position =\u003e \"beginning\" type =\u003e \"elasticsearch\" } } #è¾“å‡ºéƒ¨åˆ† output { elasticsearch { hosts =\u003e [\"http://192.168.8.12:9200\"] index =\u003e \"logstash-test-%{+YYYY.MM.dd}\" } } ç”Ÿæˆé…ç½®æ–‡ä»¶ ä»¥rootç”¨æˆ·æ‰§è¡Œä¸‹é¢çš„å‘½ä»¤ system-install æŸ¥çœ‹ç”Ÿæˆçš„æœåŠ¡é…ç½®æ–‡ä»¶ # ls /etc/systemd/system/logstash.service /etc/systemd/system/logstash.service æŸ¥çœ‹æœåŠ¡é…ç½®æ–‡ä»¶å†…å®¹ # cat /etc/systemd/system/logstash.service [Unit] Description=logstash [Service] Type=simple User=logstash Group=logstash # Load env vars from /etc/default/ and /etc/sysconfig/ if they exist. # Prefixing the path with '-' makes it try to load, but if the file doesn't # exist, it continues onward. EnvironmentFile=-/etc/default/logstash EnvironmentFile=-/etc/sysconfig/logstash ExecStart=/usr/share/logstash/bin/logstash \"--path.settings\" \"/etc/logstash\" \"- f\" \"/etc/logstash/conf.d\" Restart=always WorkingDirectory=/ Nice=19 LimitNOFILE=16384 # When stopping, how long to wait before giving up and sending SIGKILL? # Keep in mind that SIGKILL on a process can cause data loss. TimeoutStopSec=infinity [Install] WantedBy=multi-user.target æ³¨æ„ï¼š ç”±äºæœåŠ¡å¯åŠ¨çš„æ—¶å€™ï¼Œç”¨æˆ·åå’Œç”¨æˆ·ç»„éƒ½æ˜¯ logstash ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬é‡‡é›†æ•°æ®çš„æ–‡ä»¶å¿…é¡»æ˜¯å…·å¤‡æŸ¥çœ‹çš„æƒé™ å¯åŠ¨æœåŠ¡ é‡è½½æœåŠ¡ systemctl daemon-reload å¯åŠ¨æœåŠ¡ systemctl start logstash.service systemctl status logstash.service æŸ¥çœ‹æ•ˆæœ # netstat -tnulp | egrep 'Add|java' Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 127.0.0.1:9600 :::* LISTEN 88794/java tcp6 0 0 :::9200 :::* LISTEN 87210/java tcp6 0 0 :::9300 :::* LISTEN 87210/java ç»“æœæ˜¾ç¤ºï¼š logstashçš„é»˜è®¤ç«¯å£æ˜¯ 9600 æŸ¥çœ‹æ—¥å¿— tail -f /var/log/logstash/logstash-plain.log å¯ä»¥çœ‹åˆ°é»˜è®¤æŠ¥é”™ï¼š [2021-08-15T18:44:08,643][WARN ] [filewatch.tailmode.handlers.createinitial][main] [cc34021140e2525e95d5755b6135b9801f3595239bcda82a1cca03a1d0f857d6] failed to open file {:path=\u003e\"/var/log/syslog\", :exception=\u003eErrno::EACCES, :message=\u003e\"Permission denied - /var/log/syslog\"} ä¸´æ—¶å¢åŠ ä¸€ä¸ª logstash å…è®¸è®¿é—®çš„æƒé™ chown logstash.logstash /var/log/syslog é€šè¿‡headæ’ä»¶æŸ¥çœ‹æ•°æ®ä¼ é€’æ•ˆæœ å°ç»“ï¼š å®šä½ æ•°æ®çš„é‡‡é›†å’Œä¼ é€’ ç»„æˆï¼š æ ¸å¿ƒï¼šinput - filter - output è¾…åŠ©ï¼šcodec ç‰¹ç‚¹ï¼š æ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰å¯¹åº”ä¸šåŠ¡åœºæ™¯çš„æ’ä»¶æ¥å®ç°åŠŸèƒ½ å®ˆæŠ¤è¿›ç¨‹æ–¹å¼è¿è¡Œlogstash å®šåˆ¶æœåŠ¡çš„å¯åŠ¨å‚æ•° system-install ç”ŸæˆæœåŠ¡å¯åŠ¨æ–‡ä»¶ åº”ç”¨æœåŠ¡å¯åŠ¨æ–‡ä»¶ ä¸´æ—¶æµ‹è¯•æ–‡ä»¶çš„æ–¹å¼ logstash -f xxx.conf ","date":"2021-10-03","objectID":"/posts/elk/elk-logstash/:1:4","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-Logstash ï¼ˆä¸‰ï¼‰","uri":"/posts/elk/elk-logstash/"},{"categories":["ElasticStack"],"content":"ä¸¤ä¸‰å¹´å‰ELKè¿˜æ˜¯ä¸€å¥—æ—¥å¿—åˆ†æå¹³å°çš„è§£å†³æ–¹æ¡ˆ ï¼Œå®ƒæ˜¯ç”±Elasticå…¬å¸å¼€å‘ï¼Œç®¡ç†å’Œç»´æŠ¤çš„ä¸‰æ¬¾å¼€æºäº§å“Elasticsearchï¼ŒLogstashå’ŒKibanaçš„é¦–å­—æ¯ç¼©å†™ï¼Œéšç€è¯¥å¥—è§£å†³æ–¹æ¡ˆçš„è½¯ä»¶ç”Ÿæ€é€æ¸å£®å¤§ï¼Œå…¶ç»„ä»¶å’ŒåŠŸèƒ½ä¹Ÿæ¸æ¸å¤šäº†èµ·æ¥ï¼Œå°¤å…¶æ˜¯Beatsç»„ä»¶çš„å¼•å…¥ï¼Œé€æ¸å½¢æˆäº†è¿™ä¸ªç³»åˆ—çš„å››å¤§æ”¯æŸ±ï¼Œç„¶åå…¬å¸å°†è¿™å¥—è§£å†³æ–¹æ¡ˆé‡æ–°å‘½åä¸ºï¼šElastic Stackï¼Œæœ€æ–°ç‰ˆæœ¬7.Xã€‚ ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:0:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"åŸºç¡€çŸ¥è¯† ç®€ä»‹ æ‰€è°“çš„ æœç´¢å¼•æ“(Search Engine)ï¼Œé€šå¸¸æŒ‡çš„æ˜¯æ”¶é›†äº† å‡ åƒä¸‡åˆ°å‡ åäº¿ä¸ªæ¡æ•°æ®ï¼Œä¸ºäº†æ–¹ä¾¿åç»­ç²¾\rç¡®æŸ¥è¯¢ï¼Œæˆ‘ä»¬ä¸ºè¿™äº›æ•°æ®çš„å¤šä¸ªè¯(å…³é”®è¯)è¿›è¡Œç´¢å¼•ï¼Œå»ºç«‹ç´¢å¼•æ•°æ®åº“çš„å…¨æ–‡æœç´¢å¼•æ“ã€‚\rè¿™æ ·ï¼Œå½“ç”¨æˆ·æŸ¥æ‰¾æŸä¸ªå…³é”®è¯çš„æ—¶å€™ï¼Œæ‰€æœ‰åœ¨é¡µé¢å†…å®¹ä¸­åŒ…å«äº†è¯¥å…³é”®è¯çš„ç½‘é¡µéƒ½å°†ä½œä¸ºæœç´¢ç»“æœè¢«æœå‡ºæ¥ã€‚å†ç»è¿‡å¤æ‚çš„ç®—æ³•è¿›è¡Œæ’åº(æˆ–è€…åŒ…å«å•†ä¸šåŒ–çš„ç«ä»·æ’åã€å•†ä¸šæ¨å¹¿æˆ–è€…å¹¿å‘Š)åï¼Œè¿™äº›ç»“æœå°†æŒ‰ç…§ä¸æœç´¢å…³é”®è¯çš„ç›¸å…³åº¦é«˜ä½ï¼ˆæˆ–ä¸ç›¸å…³åº¦æ¯«æ— å…³ç³»ï¼‰ï¼Œä¾æ¬¡æ’åˆ—ã€‚ åº”ç”¨åœºæ™¯ æœç´¢ä¸æ¨è:\ræœç´¢ - ç”¨æˆ·åœ¨ç½‘ä¸Šï¼Œä¸»åŠ¨æ ¹æ®å…³é”®å­—å»æœç´¢ç›¸å…³çš„æ•°æ®\ræ¨è - ç½‘ç«™ç¨‹åºï¼Œæ ¹æ®ç”¨æˆ·æ—¥å¸¸çš„æœç´¢ä¹ æƒ¯ï¼Œé€šè¿‡åˆ†æç”¨æˆ·çš„è¡Œä¸ºæ•°æ®ï¼Œä¸»åŠ¨æ¨é€ä¸€äº›ç”¨æˆ·æ„Ÿå…´è¶£çš„äº‹æƒ…ã€‚\ræœç´¢é¢†åŸŸï¼š\ré—¨æˆ·ç½‘ç«™ - æä¾›å„ç§ç”¨æˆ·æ„Ÿå…´è¶£çš„ç½‘ç«™å…¥å£ï¼Œä¾¿äºç”¨æˆ·å¿«é€Ÿè·å–ç›¸å…³ä¿¡æ¯ï¼Œä¸€èˆ¬æ˜¯çˆ¬è™«çˆ¬å–çš„æ•°æ®ã€‚\rå®šå‘æœç´¢ - æœç´¢ç‰¹å®šé¢†åŸŸçš„å†…å®¹ï¼Œä¸€èˆ¬æ˜¯ç½‘ç«™è‡ªèº«æ ¹æ®äº§å“è®¾è®¡çš„æ ·å¼ï¼Œç»“æ„åŒ–å­˜å‚¨çš„æ•°æ®ã€‚\ræœç´¢åŠŸèƒ½ï¼š\ræ™ºèƒ½æœç´¢ - æ ¹æ®ç”¨æˆ·æœç´¢çš„å†å²æˆ–è€…å…³é”®å­—ï¼Œè‡ªåŠ¨å¼¹å‡ºæˆ–è€…æ‰©å±•ç±»ä¼¼çš„å…³é”®å­—ï¼Œæé«˜ç”¨æˆ·æœç´¢çš„æ•ˆç‡ã€‚\ræ™®é€šæœç´¢ - ç”¨æˆ·è¾“å…¥æ•°æ®ç„¶åæ­£å¸¸çš„æœç´¢ã€‚\rç›¸å…³æœç´¢ - é»˜è®¤æä¾›çš„å…¶ä»–å…³è”ç½‘ç«™çš„å…¥å£ã€‚ ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:1:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"æ•°æ®æµç¨‹ æ•°æ®é‡‡é›† ç‰©ç†å±‚ï¼šæ–‡ä»¶ã€è®¾å¤‡ç­‰\rä»£ç†å±‚ï¼šnginxã€haproxyç­‰\rwebå±‚ï¼šnginxã€apacheã€tomcatç­‰\ræ•°æ®åº“å±‚ï¼šmysqlã€mongodbã€redisç­‰\rå­˜å‚¨å±‚ï¼šcephã€k8sã€dockerç­‰\r...","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:2:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"æµç¨‹è§£æ è¦å®Œæˆä¸€æ¬¡å®Œæ•´çš„æ•°æ®é‡‡é›†ä¸å¤„ç†è‡³å°‘éœ€è¦æœ‰ä»¥ä¸‹å‡ æ–¹é¢æ¥ç»„æˆï¼š â‘  æ•°æ®é‡‡é›†ï¼šæ ¹æ®ä¸šåŠ¡çš„ç‰¹æ€§ï¼Œé‡‡å–å¤šç§æ–¹å¼ï¼Œè¿›è¡Œå¯¹ä¸€äº›é’ˆå¯¹æ€§çš„æ•°æ®è¿›è¡Œé‡‡é›†\râ‘¡ æ•°æ®æ•´ç†ï¼šå¯¹ä¸ŠæŠ¥åçš„æ•°æ®æºè¿›è¡Œæ”¶é›†ã€æ¸…æ´—ã€æ•´ç†\râ‘¢ å®æ—¶åˆ†æï¼šå¯¹æŸäº›é‡è¦çš„æ ¸å¿ƒçš„ä¸šåŠ¡æ•°æ®ï¼Œè¿›è¡Œå®æ—¶åˆ†æ\râ‘£ ç¦»çº¿åˆ†æï¼šå¯¹æ™®é€šçš„æ•°æ®ã€éç´§æ€¥çš„ä¸šåŠ¡æ•°æ®è¿›è¡Œå­˜å‚¨ï¼Œåç»­è¿›è¡Œç›¸åº”çš„åˆ†æ\râ‘¤ ç»“æœè¾“å‡ºï¼šå°†å®æ—¶åˆ†æå’Œç¦»çº¿åˆ†æåçš„æ•°æ®ç»“æœå±•ç°å‡ºæ¥ï¼Œä¾›å†³ç­–å‚è€ƒ\râ‘¥ é—®é¢˜å†³ç­–ï¼šæ ¹æ®å½“å‰ä¸šåŠ¡æƒ…å†µï¼Œäººå·¥æˆ–è€…è‡ªåŠ¨æ–¹å¼å¯¹è¾“å‡ºçš„ç»“æ„è¿›è¡Œåˆ†æï¼Œå¹¶åˆ¤å®šä¸‹ä¸€æ­¥çš„è¡ŒåŠ¨(è­¦å‘Šæˆ–ä¿®\rå¤)ï¼Œ\råŒæ—¶å°†å…¶å†³ç­–è®°å½•ä¿å­˜ä¸‹æ¥ï¼Œä»¥ä¾¿ä¸ºååºå†³ç­–æä¾›ä¾æ®\rä¹Ÿå°±æ˜¯è¯´ï¼šé‡‡é›†ã€ä¼ è¾“ã€å­˜å‚¨ã€åˆ†æã€è­¦å‘Šè¿™å‡ éƒ¨åˆ†æ˜¯éå¸¸å¿…è¦çš„ã€‚ ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:2:1","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"æ–¹æ¡ˆæ¢³ç† åœ¨è¿™ä¸ªæµç¨‹å›¾ä¸­æ¶‰åŠåˆ°ä¸¤ç§åœºæ™¯ï¼šå®æ—¶åˆ†æä¸ç¦»çº¿åˆ†æï¼Œå¦‚æœéœ€è¦ä½¿ç”¨å¸‚é¢ ä¸Šçš„å¼€æºè§£å†³æ–¹æ¡ˆæ¥å®ç°çš„è¯ï¼Œæœ‰ä¸¤å¥—æ–¹æ¡ˆæ¯”è¾ƒæœ‰ä¼˜åŠ¿ï¼š æ–¹æ¡ˆä¸€ï¼šELK + Kafka + åˆ†å¸ƒå¼å­˜å‚¨ ä¸­æ•°æ®é‡åœºæ™¯ä¸‹ï¼Œå®æ—¶çš„æ•°æ®å¤šä¸€äº› æ–¹æ¡ˆäºŒï¼šSpark + Flume + Kafka + Hadoop(Hive + HBase) å¤§æ•°æ®é‡åœºæ™¯ä¸‹ï¼Œç¦»çº¿çš„æ•°æ®å¤šä¸€äº› ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:2:2","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"å¿«é€Ÿå…¥é—¨ ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:3:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"ELKç®€ä»‹ ä¸¤ä¸‰å¹´å‰ELKè¿˜æ˜¯ä¸€å¥—æ—¥å¿—åˆ†æå¹³å°çš„è§£å†³æ–¹æ¡ˆ ï¼Œå®ƒæ˜¯ç”±Elasticå…¬å¸å¼€å‘ï¼Œç®¡ç†å’Œç»´æŠ¤çš„ä¸‰æ¬¾å¼€æºäº§å“\rElasticsearchï¼ŒLogstashå’ŒKibanaçš„é¦–å­—æ¯ç¼©å†™ï¼Œéšç€è¯¥å¥—è§£å†³æ–¹æ¡ˆçš„è½¯ä»¶ç”Ÿæ€é€æ¸å£®å¤§ï¼Œå…¶ç»„ä»¶å’ŒåŠŸ\rèƒ½ä¹Ÿæ¸æ¸å¤šäº†èµ·æ¥ï¼Œå°¤å…¶æ˜¯Beatsç»„ä»¶çš„å¼•å…¥ï¼Œé€æ¸å½¢æˆäº†è¿™ä¸ªç³»åˆ—çš„å››å¤§æ”¯æŸ±ï¼Œç„¶åå…¬å¸å°†è¿™å¥—è§£å†³æ–¹æ¡ˆé‡\ræ–°å‘½åä¸ºï¼šElastic Stackï¼Œæœ€æ–°ç‰ˆæœ¬7.Xã€‚ å®˜æ–¹ä»‹ç» The products in the Elastic Stack are designed to be used together and releases\rare\rsynchronized to simplify the installation and upgrade process. The full stack\rconsists\rof:\rBeats 7.14 APM Server 7.14 Elasticsearch Hadoop 7.14\rKibana 7.14 Elasticsearch 7.14 Logstash 7.14 å¼€å‘è¯­è¨€ javaï¼šElasticsearchã€Logstashã€Kibana\rgoï¼šFileBeats ç»„ä»¶å‘å±• ç›¸å…³ç½‘ç«™ å®˜æ–¹ç½‘ç«™ï¼šhttps://www.elastic.co\rgithubï¼šhttps://github.com/elastic\rç¤ºä¾‹ç½‘ç«™ï¼šhttps://demo.elastic.co ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:3:1","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"æ¶æ„ç»„ä»¶ å››ä¸ªç»„ä»¶ï¼š\rBeatsæ˜¯å®‰è£…åœ¨è¾¹ç¼˜ä¸»æœºä¸Šçš„è½»å‹ä»£ç†ï¼Œå¯æ”¶é›†ä¸åŒç±»å‹çš„æ•°æ®ä»¥è½¬å‘åˆ°å †æ ˆä¸­\rLogstashæ˜¯ä¸€ä¸ªæ—¥å¿—èšåˆå™¨ï¼Œå¯ä»å„ç§è¾“å…¥æºæ”¶é›†æ•°æ®ï¼Œæ‰§è¡Œä¸åŒçš„è½¬æ¢å’Œå¢å¼ºåŠŸèƒ½ï¼Œç„¶åå°†æ•°æ®å‘é€\råˆ°å„ç§å—æ”¯æŒçš„è¾“å‡ºç›®æ ‡\rElasticsearchæ˜¯åŸºäºApache Luceneæœç´¢å¼•æ“çš„å¼€æºå…¨æ–‡æœç´¢å’Œåˆ†æå¼•æ“\rKibanaæ˜¯åœ¨Elasticsearchä¹‹ä¸Šå·¥ä½œçš„å¯è§†åŒ–å±‚ï¼Œä¸ºç”¨æˆ·æä¾›äº†åˆ†æå’Œå¯è§†åŒ–æ•°æ®çš„èƒ½åŠ›\rè¿™å››ä¸ªç»„ä»¶åœ¨å®˜æ–¹çš„ä»‹ç»ä¸»è¦åˆ†æˆäº†ä¸¤ç»„åŠ¿åŠ›ï¼šæ•°æ®æ”¶é›†å’Œå±•ç¤º\r- æ•°æ®æ”¶é›†å’Œå¤„ç†ï¼šBeatså’ŒLogstashè´Ÿè´£æ•°æ®æ”¶é›†å’Œå¤„ç†ã€‚\r- æ•°æ®æœç´¢å’Œå±•ç¤ºï¼šElasticsearchç´¢å¼•å¹¶å­˜å‚¨æ•°æ®ï¼ŒKibanaæä¾›äº†ç”¨äºæŸ¥è¯¢æ•°æ®å’Œå¯è§†åŒ–æ•°æ®çš„ç”¨æˆ·ç•Œé¢\rè¿™äº›ç»„ä»¶åœ¨è®¾è®¡çš„æ—¶å€™ï¼Œç»„ä»¶é—´çš„äº¤æµå°±éå¸¸ç®€å•ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€è¦ç®€å•çš„å‡ æ¡é…ç½®ï¼Œå°±å¯ä»¥å°†ä¸åŒçš„ç»„ä»¶ç»„\råˆèµ·æ¥å®ç°ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„è§£å†³æ–¹æ¡ˆã€‚è€Œä¸”è¿˜å¯ä»¥åŸºäºåº”ç”¨åœºæ™¯çš„ä¸åŒéšæ„ç»„åˆï¼Œæ¯”å¦‚æ—¥å¿—ç®¡ç†ã€æ—¥å¿—åˆ†\ræã€åº”ç”¨ç›‘æ§ã€æ•…éšœæ’é™¤å’Œä¿æŠ¤ITç¯å¢ƒç­‰ã€‚ å¯¹äºå°å‹çš„åº”ç”¨é¡¹ç›®å¼€å‘ç¯å¢ƒï¼ŒELKçš„å››ä¸ªç»„ä»¶å¯ä»¥å®ç°ä¸€ä¸ªéå¸¸ç»å…¸çš„ç»„åˆï¼š å¯¹äºä¸­å¤§å‹åœºæ™¯ï¼ŒELKåŸºäºä¸°å¯Œçµæ´»çš„ä¿¡æ¯æ¥å£å°†éå¸¸å¤šçš„åŠŸèƒ½æ•´åˆåˆ°ç»å…¸ç»„åˆä¸­ï¼Œä»¥æé«˜å…¶æ¶æ„å¼¹æ€§å’Œå®‰å…¨æ€§ï¼š ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:3:2","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"å®‰è£…éƒ¨ç½² è¦ç‚¹ 1 ç»„ä»¶é—´å¦‚ä½•è”é€š\r2 ç»„ä»¶å¦‚ä½•åœ¨ä¸åŒåœºæ™¯ä¸­ä½¿ç”¨å¯¹åº”æ’ä»¶\relasticsearch å®è·µæœ¯è¯­åŠåˆ†ç‰‡å®è·µ\rlogstash ç»„ä»¶(æ’ä»¶)å®ç°æ•°æ®çš„è½¬ç§»åŠè½¬ç§»è¿‡ç¨‹ä¸­å¯¹æ•°æ®çš„å°è£…\rfilebeat é‡‡é›†æ•°æ®é›†è½¬ç§»\rkibana å¯è§†åŒ–çš„æµç¨‹åŠå¤§é‡å¯è§†åŒ–å®è·µ\r","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:4:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"ç¯å¢ƒ å‰æï¼š\rjavaç¯å¢ƒå¾ˆé‡è¦ï¼Œä½†æ˜¯å¾ˆå¯æƒœï¼Œelasticsearchè½¯ä»¶å†…éƒ¨å·²ç»æœ‰äº†javaç¯å¢ƒï¼Œ\ré»˜è®¤æƒ…å†µä¸‹ï¼Œelasticsearch è½¯ä»¶åŒ…é‡Œé¢å·²ç»åŒ…å«äº†javaç¯å¢ƒï¼Œè€Œä¸”æ˜¯æœ€æ–°ç‰ˆçš„ JDK-16.0.1\rç¯å¢ƒå¸ƒå±€\r10.0.0.12 elasticsearch elasticsearch_head\r10.0.0.13 elasticsearch logstash\r10.0.0.14 kibana\r10.0.0.15 filebeat + é¡¹ç›®ä»£ç å®šä½ æ—¥å¿—åˆ†æå¹³å°è§£å†³æ–¹æ¡ˆ - å¤§é‡å°æ–¹æ¡ˆçš„æ•´åˆ\rStore, Search, and Analyze\rç»„æˆ\rElasticsearch - æ•°æ®çš„å­˜å‚¨å’Œåˆ†æ\rLogstash - æ•°æ®é‡‡é›†å’Œä¼ è¾“(*)\rKibana - æ•°æ®çš„å¯è§†åŒ–(äºŒæ¬¡å¤„ç†) KQL\rBeats - æ•°æ®é‡‡é›†(*)å’Œä¼ è¾“\rä¸­å°åœºæ™¯æ–¹æ¡ˆ\rBeats - Logstash - elasticsearch - kibana\rä¸­å¤§åœºæ™¯æ–¹æ¡ˆ\rBeats - æ¶ˆæ¯é˜Ÿåˆ— - Logstash - æ¶ˆæ¯é˜Ÿåˆ— - elasticsearch - kibana(Nginx) åŸºæœ¬ç¯å¢ƒ å®‰è£…java8ç¯å¢ƒ\rapt install openjdk-8-jdk\ræ£€æŸ¥æ•ˆæœ\rjava -version\ræ³¨æ„:\ré»˜è®¤æƒ…å†µä¸‹ï¼Œelasticsearch è½¯ä»¶åŒ…é‡Œé¢å·²ç»åŒ…å«äº†javaç¯å¢ƒï¼Œè€Œä¸”æ˜¯æœ€æ–°ç‰ˆçš„ JDK-16.0.1 ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:4:1","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"è½¯ä»¶å®‰è£… apt æºç å®‰è£…æ–¹å¼ è·å–è½¯ä»¶æº wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - apt install apt-transport-https echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee â€“a /etc/apt/sources.list.d/elastic-7.x.list apt update å®‰è£…è½¯ä»¶ apt install elasticsearch è½¯ä»¶å®‰è£…æ–¹æ³•2 - åŒ…å®‰è£… wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.0- amd64.deb wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.0- amd64.deb.sha512 shasum -a 512 -c elasticsearch-7.14.0-amd64.deb.sha512 dpkg -i elasticsearch-7.14.0-amd64.deb æ³¨æ„ï¼š è¿™é‡Œæ¨è ä¸¤å°æœåŠ¡å™¨æ¥éƒ¨ç½² elasticsearch åŸºæœ¬é…ç½® æŸ¥çœ‹é…ç½®ç»“æ„ #dpkg -L elasticsearch /usr /usr/share /usr/share/elasticsearch /usr/share/elasticsearch/bin /usr/share/elasticsearch/bin/elasticsearch-geoip ... /etc /etc/elasticsearch /etc/elasticsearch/elasticsearch.yml æ ¸å¿ƒé…ç½®æ–‡ä»¶ /etc/elasticsearch/log4j2.properties æ—¥å¿—ç›¸å…³çš„é…ç½® /etc/elasticsearch/roles.yml /etc/elasticsearch/jvm.options jvmç›¸å…³çš„é…ç½® /etc/elasticsearch/role_mapping.yml /etc/elasticsearch/users_roles /etc/elasticsearch/users /etc/default /etc/default/elasticsearch ç¯å¢ƒå˜é‡é…ç½®æ–‡ä»¶ /usr/lib /usr/lib/tmpfiles.d /usr/lib/tmpfiles.d/elasticsearch.conf /usr/lib/systemd /usr/lib/systemd/system /usr/lib/systemd/system/elasticsearch.service æœåŠ¡å¯åŠ¨æ–‡ä»¶ ... ç¯å¢ƒå˜é‡å®šåˆ¶ echo 'export PATH=/usr/share/elasticsearch/bin:$PATH' \u003e /etc/profile.d/elasticsearch.sh source /etc/profile.d/elasticsearch.sh ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:4:2","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"ç®€å•å®è·µ ä¿®æ”¹é…ç½®æ–‡ä»¶ vim /etc/elasticsearch/elasticsearch.yml # è®¾å®šelasticsearché›†ç¾¤çš„åç§° cluster.name: elastic.example.com # è®¾å®šé›†ç¾¤masterç•Œé¢çš„åç§° node.name: 192.168.8.12 # è®¾å®šelasticsearchçš„å­˜å‚¨ç›®å½•ï¼ŒåŒ…æ‹¬æ•°æ®ç›®å½•å’Œæ—¥å¿—ç›®å½• path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch # å…è®¸æ‰€æœ‰ä¸»æœºéƒ½èƒ½è®¿é—®æˆ‘ä»¬çš„elasticsearch network.host: 0.0.0.0 # è®¾ç½®elasticsearchå¯¹å¤–çš„è®¿é—®ç«¯å£ http.port:9200 # è®¾å®šä¸»æœºå‘ç° discovery.seed_hosts: [\"192.168.10.106\",\"192.168.10.107\"] cluster.initial_master_nodes: [\"192.168.10.106\"] # å¼€å¯è·¨åŸŸè®¿é—®æ”¯æŒï¼Œé»˜è®¤ä¸ºfalse http.cors.enabled: true # è·¨åŸŸè®¿é—®å…è®¸çš„åŸŸååœ°å€ï¼Œ(å…è®¸æ‰€æœ‰åŸŸå)ä»¥ä¸Šä½¿ç”¨æ­£åˆ™ http.cors.allow-origin: \"*\" æ³¨æ„ï¼š å¯¹äº node ä¸»æœºåªéœ€è¦æ›´æ”¹ä¸€å¤„ node.name å³å¯ å¦‚æœæ˜¯é‡æ–°è¿˜åŸesé›†ç¾¤ï¼Œå¯åŠ¨å‰å°† path.data å’Œ path.logs ç›®å½•ä¸‹çš„æ•°æ®æ¸…ç©ºï¼Œé¿å…æ•°æ®ä¸ä¸€è‡´ é‡å¯æœåŠ¡ é‡å¯esæœåŠ¡ systemctl start elasticsearch æ£€æŸ¥æ•ˆæœ # netstat -tnulp | egrep 'Add|java' Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 :::9300 :::* LISTEN 12004/java tcp6 0 0 :::9200 :::* LISTEN 12004/java ç»“æœæ˜¾ç¤º é»˜è®¤elasticsearchå¼€å¯äº†ä¸¤ä¸ªç«¯å£ï¼Œ 9200 elasticsearchå¯¹å¤–æä¾›æœåŠ¡çš„æ¥å£ 9300 é›†ç¾¤èŠ‚ç‚¹é—´çš„é€šä¿¡ç«¯å£ å…ˆå¯åŠ¨ 9300ï¼Œç„¶åå†å¼€å¯9200 å¸¸ç”¨åœ°å€ æŸ¥çœ‹é›†ç¾¤çŠ¶æ€\rcurl -XGET 192.168.10.106:9200/_cat/health\rcurl -XGET 192.168.10.107:9200/_cat/health?v\ræ³¨æ„ï¼šåœ¨æ‰€æœ‰çš„åœ°å€åé¢ï¼Œå¢åŠ  ? å’Œ ?v ï¼Œä¼šé€æ¸æ˜¾ç¤ºæ›´å¤šçš„è¯¦ç»†å†…å®¹\ræŸ¥çœ‹é›†ç¾¤èŠ‚ç‚¹\rcurl -XGET 192.168.10.106:9200/_cat/nodes\ræŸ¥çœ‹ç´¢å¼•\rcurl -XGET 192.168.10.106:9200/_cat/indices\råˆ›å»ºç´¢å¼•\rcurl -XPUT 192.168.10.106:9200/index_test\rcurl -XGET 192.168.10.106:9200/_cat/indices\ræ ¼å¼åŒ–å±•ç¤º\rcurl 192.168.8.12:9200/index_test?pretty\råˆ é™¤ç´¢å¼•\rcurl -XDELETE 192.168.10.106:9200/index_test\rcurl -XGET 192.168.10.106:9200/_cat/indices\ræ‰¹é‡åˆ é™¤\rcurl -s http://192.168.10.106:9200/_cat/indices | awk '{print $3}'\rfor index in $(curl -s http://192.168.10.106:9200/_cat/indices | awk '{print\r$3}')\rdo\rcurl -XDELETE 192.168.10.106:9200/$index\rdone\rä¿®æ”¹åˆ‡ç‰‡å±æ€§\rcurl -X PUT 192.168.10.106:9200/index_test -H 'Content-Type:application/json' -d'\r{\r\"settings\" : {\r\"number_of_shards\" : 3,\r\"number_of_replicas\" : 1\r}\r}'\rcurl 192.168.10.107:9200/index_test?pretty\ræ³¨æ„ï¼š\råœ¨è®¾ç½®åˆ‡ç‰‡å±æ€§çš„æ—¶å€™ï¼Œä¸€å®šè¦æ³¨æ„åœ¨å†å²æ•°æ®ä¸­ï¼Œæœ€å¥½ä¸è¦å­˜åœ¨åŒåçš„ç´¢å¼•ï¼Œå¦åˆ™æŠ¥é”™ ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:4:3","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"åŠŸèƒ½æ’ä»¶ æ’ä»¶ç®¡ç† elasticsearchæœ€æ“…é•¿çš„åœºæ™¯å°±æ˜¯ç´¢å¼•çš„æ“ä½œï¼Œè€Œç´¢å¼•çš„ä½¿ç”¨åœºæ™¯åœ¨ä¸åŒçš„å…¬å¸éå¸¸ä¸åŒï¼Œæ‰€ä»¥\relasticsearchçš„ç´¢å¼•åœºæ™¯å¯ä»¥åŸºäºä¸åŒçš„æ’ä»¶æ¥å®ç°å¯¹åº”çš„åŠŸèƒ½ï¼Œè€Œæ’ä»¶ä¹Ÿæ˜¯ELKéå¸¸é‡è¦çš„å±æ€§ã€‚\relasticsearchæä¾›äº†ä¸¤ç§æ’ä»¶çš„ç®¡ç†æ–¹å¼ï¼š\r- ä¸“ç”¨çš„æ’ä»¶ç®¡ç†å¯ä»¥ä½¿ç”¨å‘½ä»¤ elasticsearch-pluginï¼Œå®ƒå¯ä»¥å¯¹é»˜è®¤çš„æ’ä»¶è¿›è¡Œç®¡ç†ï¼›\r- å®šåˆ¶çš„æ’ä»¶ç®¡ç†å¯ä»¥åŸºäºç¦»çº¿æ–¹å¼å®‰è£…æ’ä»¶ã€‚\rå¸¸è§æ’ä»¶ï¼š\råˆ†è¯æ’ä»¶ï¼šanalysis-icuã€analysis-ikã€ç­‰\rç®¡ç†æ’ä»¶ï¼šheadã€kopfã€bigdestã€ç­‰\ræ³¨æ„ï¼š\réšç€elasticsearchçš„ç‰ˆæœ¬æ›´æ–°ï¼Œå¾ˆå¤šä¹‹å‰å¯ä»¥ç›´æ¥å®‰è£…çš„æ’ä»¶ï¼Œç›®å‰æ— æ³•ç›´æ¥å®‰è£…äº†ï¼Œ\réœ€è¦é‡‡å–è‡ªå®šä¹‰çš„æ–¹å¼æ¥å®‰è£…\ræ—§çš„æ’ä»¶åœ°å€\rhttps://www.elastic.co/guide/en/elasticsearch/plugins/2.4/management.html\rå®˜æ–¹åœ°å€\rhttps://www.elastic.co/guide/en/elasticsearch/plugins/current/index.html å®‰è£…æ’ä»¶å‘½ä»¤ åœ¨çº¿æ–¹å¼ï¼š\relasticsearch-plugin install plugin_name/version\rç¦»çº¿æ–¹å¼ï¼š\ræ–¹æ³•1ï¼šelasticsearch-plugin install file:///path/to/plugin.zip\ræ–¹æ³•2ï¼šå°†ä¸‹è½½çš„æ’ä»¶è§£å‹åˆ°elasticsearchçš„pluginsç›®å½•å³å¯\ræŸ¥çœ‹å·²å®‰è£…æ’ä»¶\relasticsearch-plugin list\råˆ é™¤æ’ä»¶\relasticsearch-plugin remove [plugin_name]\ræ³¨æ„ï¼š\råˆ é™¤æ’ä»¶çš„æ—¶å€™ï¼Œæ¨èå…ˆå…³é—­ç»“ç‚¹ï¼Œç„¶åå†å…³é—­ã€‚å®‰è£…é»˜è®¤çš„æ’ä»¶ å®‰è£…ä¸­æ–‡è¯­æ³•åˆ†æåé‡å¯æœåŠ¡\relasticsearch-plugin install analysis-smartcn\relasticsearch-plugin install analysis-icu\rsystemctl restart elasticsearch.service\ræ£€æŸ¥æ•ˆæœ\r# elasticsearch-plugin list\ranalysis-icu\ranalysis-smartcn\r# ls /usr/share/elasticsearch/\rbin jdk lib modules NOTICE.txt plugins README.asciidoc\r# ls /usr/share/elasticsearch/plugins/\ranalysis-icu analysis-smartcn\rç®€å•æµ‹è¯•\r# curl -X POST 'http://192.168.10.106_analyze?pretty=true' -H 'content-type:\rapplication/json' -d '{\r\"analyzer\": \"icu_analyzer\",\r\"text\": \"ä¸­åäººæ°‘å…±å’Œå›½å›½æ­Œ\"\r}'\r---- ä¸‹é¢æ˜¯æ˜¾ç¤ºçš„å†…å®¹\r{\r\"tokens\" : [\r{\r\"token\" : \"ä¸­å\",\r\"start_offset\" : 0,\r\"end_offset\" : 2,\r\"type\" : \"\u003cIDEOGRAPHIC\u003e\",\r\"position\" : 0\r},\r{\r\"token\" : \"äººæ°‘\",\r\"start_offset\" : 2,\r\"end_offset\" : 4,\r\"type\" : \"\u003cIDEOGRAPHIC\u003e\",\r\"position\" : 1\r},\r{\r\"token\" : \"å…±å’Œå›½\",\r\"start_offset\" : 4,\rheadæ’ä»¶å®‰è£…\r\"end_offset\" : 7,\r\"type\" : \"\u003cIDEOGRAPHIC\u003e\",\r\"position\" : 2\r},\r{\r\"token\" : \"å›½æ­Œ\",\r\"start_offset\" : 7,\r\"end_offset\" : 9,\r\"type\" : \"\u003cIDEOGRAPHIC\u003e\",\r\"position\" : 3\r}\r]\r}\r# curl -X POST 'http://192.168.10.106:9200/_analyze?pretty=true' -H 'content-type:\rapplication/json' -d '{\r\"analyzer\": \"smartcn\",\r\"text\": \"ä¸­åäººæ°‘å…±å’Œå›½å›½æ­Œ\"\r}'\r---- ä¸‹é¢æ˜¯æ˜¾ç¤ºçš„å†…å®¹\r{\r\"tokens\" : [\r{\r\"token\" : \"ä¸­åäººæ°‘å…±å’Œå›½\",\r\"start_offset\" : 0,\r\"end_offset\" : 7,\r\"type\" : \"word\",\r\"position\" : 0\r},\r{\r\"token\" : \"å›½æ­Œ\",\r\"start_offset\" : 7,\r\"end_offset\" : 9,\r\"type\" : \"word\",\r\"position\" : 1\r}\r]\r} ","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:4:4","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"headæ’ä»¶å®‰è£… ç®€ä»‹\rheadæ’ä»¶ï¼Œåœ¨elasticsearchä¸­ï¼Œåº”ç”¨çš„è¿˜ç®—å¯ä»¥ï¼Œä½†æ˜¯è‡ªåŠ¨2.xä¹‹åçš„ç‰ˆæœ¬ï¼Œå°±ä¸å†æ”¯æŒäº†ï¼Œéœ€è¦æˆ‘ä»¬è‡ªå·±æ¥è¿›è¡Œç‹¬ç«‹çš„éƒ¨ç½²ã€‚\rä»£ç èµ„æ–™ï¼šhttps://github.com/mobz/elasticsearch-head\rå‡†å¤‡å·¥ä½œ\rapt install npm git -y\rå®‰è£…æ’ä»¶\rmkdir /data/server/elasticsearch/plugins -p\rcd /data/server/elasticsearch/plugins\rgit clone git://github.com/mobz/elasticsearch-head.git\rcd elasticsearch-head\rnpm config set registry https://registry.npm.taobao.org\rnpm install --force\ré…ç½®è½¯ä»¶çš„è®¿é—®åœ°å€\r# vim Gruntfile.js\r...\rconnect: {\rserver: {\roptions: {\rhostname: '*', # å¢åŠ è¿™ä¸€è¡Œ\rport: 9100,\rbase: '.',\rkeepalive: true\r}\r}\r}\r...\ré…ç½®æ’ä»¶è®¿é—®es\r# vim _site/app.js\r...\r4372 this._super();\r4373 this.prefs = services.Preferences.instance();\r4374 this.base_uri = this.config.base_uri ||\rthis.prefs.get(\"app-base_uri\") || \" http://192.168.10.106:9200\"; # ä¿®æ”¹è¿æ¥esçš„è¿æ¥åœ°å€\r...\rå¯åŠ¨æœåŠ¡\rnpm run start \u003e\u003e/dev/null 2\u003e\u00261 \u0026\ræ£€æŸ¥æ•ˆæœ\r# netstat -tnulp | egrep 'Add|grunt'\rProto Recv-Q Send-Q Local Address Foreign Address State\rPID/Program name\rtcp6 0 0 :::9100 :::* LISTEN\r19818/grunt headæ’ä»¶å›¾ å±æ€§è§£æï¼š\rä¸€å®šè¦å…ˆä¿è¯è¿æ¥æŒ‰é’®å·¦ä¾§çš„esåœ°å€æ˜¯æ­£ç¡®çš„ï¼Œç„¶åå†æ¥ç‚¹å‡»\"è¿æ¥\"\r* ä»£è¡¨ç´¢å¼•esçš„ä¸»èŠ‚ç‚¹ï¼Œé»‘è‰²åŠ ç²—çš„æ–¹æ¡†0è¡¨ç¤ºï¼Œç´¢å¼•çš„ä¸»å‰¯æœ¬ã€‚\ré»„è‰²ä»£è¡¨æœ‰ä»åˆ†ç‰‡ä¸¢å¤±ï¼Œä½†æ˜¯æ²¡æœ‰ä¸»åˆ†ç‰‡æ•°æ®ä¸¢å¤±ï¼Œå³å½“å‰æ²¡æœ‰æ•°æ®ä¸¢å¤±ã€‚\rçº¢è‰²ä»£è¡¨ä¸»åˆ†é…ä¸¢å¤±ï¼Œå³æœ‰æ•°æ®ä¸¢å¤±ï¼›ç»¿è‰²ä»£è¡¨æ‰€æœ‰ä¸»åˆ†ç‰‡å’Œä»åˆ†ç‰‡çš„æ•°æ®æ­£å¸¸ æœåŠ¡å¯åŠ¨è„šæœ¬ å¯åŠ¨è„šæœ¬ # cat /data/scripts/elasticsearch_head.sh\r#!/bin/bash\r# å¯åŠ¨elasticsearch è„šæœ¬\rcd /data/server/elasticsearch/plugins/elasticsearch-head\rnpm run start \u003e\u003e/dev/null 2\u003e\u00261\r# vim /lib/systemd/system/elasticsearch_head.service\r[Unit]\rDescription= elasticsearch head server project\r[Service]\rUser=root\rExecStart=/bin/bash /data/scripts/elasticsearch_head.sh\rTimeoutStopSec=10\rRestart=on-failure\rRestartSec=5\r[Install]\rWantedBy=multi-user.target\rå¯åŠ¨æœåŠ¡\rsystemctl daemon-reload\rsystemctl start elasticsearch_head.service\rsystemctl status elasticsearch_head.service å°ç»“ elasticsearch å‡ ä¹æ‰€æœ‰çš„ç‰¹è‰²åŠŸèƒ½éƒ½æ˜¯ä»¥æ’ä»¶çš„æ ·å¼æ¥æ•´åˆçš„\relasticsearch-plugin install | remove | list\ré»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™äº›æ’ä»¶å®‰è£…åœ¨äº† /usr/share/elasticsearch/plugins\rè¿™äº›æ’ä»¶å®‰è£…å®Œæ¯•åï¼Œéœ€è¦é‡æ–°å¯åŠ¨ç¯å¢ƒï¼Œæ‰ä¼šç”Ÿæ•ˆ\rå…³é”®æ’ä»¶\rheadæ’ä»¶ï¼Œæ˜¯éœ€è¦ç‹¬ç«‹éƒ¨ç½²çš„ï¼Œå¯ä»¥ä¸å®‰è£…åˆ° plugins","date":"2021-10-02","objectID":"/posts/elk/elk-elasticsearch/:4:5","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKæ—¥å¿—æ”¶é›†ç³»ç»Ÿ ï¼ˆä¸€ï¼‰","uri":"/posts/elk/elk-elasticsearch/"},{"categories":["ElasticStack"],"content":"è½»é‡å‹æ•°æ®é‡‡é›†å™¨ Beats æ˜¯ä¸€ä¸ªå…è´¹ä¸”å¼€æ”¾çš„å¹³å°ï¼Œé›†åˆäº†å¤šç§å•ä¸€ç”¨é€”æ•°æ®é‡‡é›†å™¨ã€‚å®ƒä»¬ä»æˆç™¾ä¸Šåƒæˆ–æˆåƒä¸Šä¸‡å°æœºå™¨å’Œç³»ç»Ÿå‘ Logstash æˆ– Elasticsearch å‘é€æ•°æ®ã€‚Beats æ˜¯æ•°æ®é‡‡é›†çš„å¾—åŠ›å·¥å…·ã€‚å°† Beats å’Œæ‚¨çš„å®¹å™¨ä¸€èµ·ç½®äºæœåŠ¡å™¨ä¸Šï¼Œæˆ–è€…å°† Beats ä½œä¸ºåŠŸèƒ½åŠ ä»¥éƒ¨ç½²ï¼Œç„¶åä¾¿å¯åœ¨ Elasticsearch ä¸­é›†ä¸­å¤„ç†æ•°æ®ã€‚Beats èƒ½å¤Ÿé‡‡é›†ç¬¦åˆ Elastic Common Schema (ECS) è¦æ±‚çš„æ•°æ®ï¼Œå¦‚æœæ‚¨å¸Œæœ›æ‹¥æœ‰æ›´åŠ å¼ºå¤§çš„å¤„ç†èƒ½åŠ›ï¼ŒBeats èƒ½å¤Ÿå°†æ•°æ®è½¬å‘è‡³ Logstash è¿›è¡Œè½¬æ¢å’Œè§£æã€‚ ","date":"2021-10-02","objectID":"/posts/elk/elk-filebeat/:0:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-beats ï¼ˆäºŒï¼‰","uri":"/posts/elk/elk-filebeat/"},{"categories":["ElasticStack"],"content":"åŸºç¡€çŸ¥è¯† ","date":"2021-10-02","objectID":"/posts/elk/elk-filebeat/:1:0","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-beats ï¼ˆäºŒï¼‰","uri":"/posts/elk/elk-filebeat/"},{"categories":["ElasticStack"],"content":"åŠŸèƒ½ç®€ä»‹ æ ¹æ®æˆ‘ä»¬å¯¹ELKçš„ç»å…¸æ¶æ„çš„äº†è§£ï¼Œä»–çš„æ•°æ®æ”¶é›†å’Œå¤„ç†æµç¨‹æ˜¯ï¼šbeats - logstash - elasticsearch - kibanaã€‚Beats é»˜è®¤æä¾›äº†å¾ˆå¤šä¸­åœºæ™¯çš„ç»„ä»¶ï¼Œæœ€å¸¸è§çš„å°±æ˜¯FileBeat è¿è¡Œç¯å¢ƒ å®‰è£…java8ç¯å¢ƒ\rapt install openjdk-8-jdk\ræ£€æŸ¥æ•ˆæœ\rjava -version ","date":"2021-10-02","objectID":"/posts/elk/elk-filebeat/:1:1","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-beats ï¼ˆäºŒï¼‰","uri":"/posts/elk/elk-filebeat/"},{"categories":["ElasticStack"],"content":"è½¯ä»¶å®‰è£… aptæºç æ–¹å¼ è·å–è½¯ä»¶æº wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - apt install apt-transport-https echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee â€“a /etc/apt/sources.list.d/elastic-7.x.list apt update å®‰è£…è½¯ä»¶ apt install filebeat è½¯ä»¶åŒ…å®‰è£… wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.14.0- amd64.deb wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.14.0- amd64.deb.sha512 shasum -a 512 -c filebeat-7.14.0-amd64.deb.sha512 dpkg -i filebeat-7.14.0-amd64.deb é…ç½®æŸ¥çœ‹ æŸ¥çœ‹é…ç½®æ–‡ä»¶ # dpkg -L filebeat /. /etc /etc/init.d /etc/init.d/filebeat /etc/filebeat /etc/filebeat/filebeat.yml æ ¸å¿ƒé…ç½®æ–‡ä»¶ ... /etc/filebeat/filebeat.reference.yml /etc/filebeat/fields.yml ... /usr/share/filebeat/bin /usr/share/filebeat/bin/filebeat /usr/share/filebeat/bin/filebeat-god /usr/share/doc /usr/share/doc/filebeat /usr/share/doc/filebeat/changelog.gz /usr/bin /usr/bin/filebeat /lib /lib/systemd /lib/systemd/system /lib/systemd/system/filebeat.service æœåŠ¡å¯åŠ¨æ–‡ä»¶æŸ¥çœ‹é…ç½®æ–‡ä»¶ # grep -Env '#|^$' /etc/filebeat/filebeat.yml 15:filebeat.inputs: æ•°æ®çš„é‡‡é›† 21:- type: log 24: enabled: false é»˜è®¤è¯¥åŠŸèƒ½æ²¡æœ‰å¼€å¯ 27: paths: 28: - /var/log/*.log 66:- type: filestream 69: enabled: false 72: paths: 73: - /var/log/*.log 96:filebeat.config.modules: 98: path: ${path.config}/modules.d/*.yml 101: reload.enabled: false 108:setup.template.settings: 109: index.number_of_shards: 1 é»˜è®¤çš„æ•°æ®åˆ†ç‰‡ä¸ªæ•°æ˜¯ 1 145:setup.kibana: 176:output.elasticsearch: æ•°æ®çš„è¾“å‡º 178: hosts: [\"localhost:9200\"] 204:processors: 205: - add_host_metadata: 206: when.not.contains.tag: forwarded 207: - add_cloud_metadata: ~ 208: - add_docker_metadata: ~ 209: - add_kubernetes_metadata: ~ ç»“æœæ˜¾ç¤ºï¼š filebeat.yml è¿™å°±æ˜¯filebeatçš„é…ç½®æ–‡ä»¶ï¼Œé‡Œé¢æœ‰12éƒ¨åˆ†çš„é…ç½®ï¼Œè€Œæˆ‘ä»¬é‡ç‚¹å…³å¿ƒçš„å°± æ˜¯\"Filebeat inputs\" å’Œ \"Outputs\", å®šåˆ¶ç¯å¢ƒå˜é‡ echo 'export PATH=/usr/share/kibana/bin:$PATH' \u003e /etc/profile.d/kibana.sh source /etc/profile.d/kibana.sh ","date":"2021-10-02","objectID":"/posts/elk/elk-filebeat/:1:2","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-beats ï¼ˆäºŒï¼‰","uri":"/posts/elk/elk-filebeat/"},{"categories":["ElasticStack"],"content":"ç®€å•å®è·µ å®šåˆ¶é…ç½®æ–‡ä»¶ å¤‡ä»½é…ç½®æ–‡ä»¶ cd /etc/filebeat/ cp filebeat.yml filebeat.yml-bak å®šåˆ¶é…ç½®æ–‡ä»¶ filebeat.inputs: - type: log paths: - /var/log/syslog setup.template.settings: index.number_of_shards: 5 output.elasticsearch: hosts: [\"192.168.8.12:9200\"] template.name: \"filebeat\" å±æ€§è§£æï¼š enabled: true è¡¨ç¤ºå¯ç”¨è¿™æ¡é…ç½® template.name åœ¨å°†æ•°æ®ä¼ å…¥åˆ°elasticsearchçš„æ—¶å€™ï¼Œè‡ªåŠ¨æ·»åŠ ä¸€ä¸ªç´¢å¼•ï¼Œåç§°æ˜¯filebeat å¯åŠ¨æœåŠ¡ å¯åŠ¨æœåŠ¡ systemctl start filebeat.service systemctl status filebeat.service æŸ¥çœ‹æ•ˆæœ # curl 192.168.8.12:9200/_cat/indices green open filebeat-7.14.0-2021.08.15-000001 yTq8KQtGSpOyGohS4kcLhQ 5 1 730 0 348.5kb 587b ç»“æœæ˜¾ç¤ºï¼š åœ¨elasticsearchä¸­å¤šäº†å¥½å‡ æ¡ç´¢å¼•æ•°æ® ç´¢å¼•å‘½åæ ¼å¼ï¼š\"è‡ªå®šä¹‰ç´¢å¼•å-ç‰ˆæœ¬å·-æ—¥æœŸ-6ä½ç¼–å·\" å°ç»“ï¼š æ ¸å¿ƒçš„é…ç½® input output modules elasticsearch â€¦. å®è·µ åªè·å–æŒ‡å®šæ–‡ä»¶å†…éƒ¨åŒ…å« 404 çš„æ–‡ä»¶å†…å®¹ è¾“å‡ºçš„æ—¶å€™ï¼Œè®¾å®šç´¢å¼•åç§° è¦ç‚¹ å¦‚æœéœ€è¦filebeat å®šåˆ¶esçš„ç´¢å¼•åç§°çš„è¯ï¼Œéœ€è¦è‡ªå·±è®¾å®šæ¨¡æ¿ ","date":"2021-10-02","objectID":"/posts/elk/elk-filebeat/:1:3","tags":["æ—¥å¿—æ”¶é›†"],"title":"ELKç»„ä»¶-beats ï¼ˆäºŒï¼‰","uri":"/posts/elk/elk-filebeat/"},{"categories":["ElasticStack"],"content":"æ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:0","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"é•œåƒæº é•œåƒæºæ˜¯æŒ‡è¢«ç›‘æ§çš„å¯¹è±¡ï¼Œè¯¥å¯¹è±¡å¯ä»¥æ˜¯ç«¯å£æˆ–å•æ¿ä¸Šçš„ CPUï¼Œæˆ‘ä»¬å°†ä¹‹ä¾æ¬¡ç§°ä¸ºæºç«¯å£å’Œæº CPUã€‚ ç»ç”±è¢«ç›‘æ§çš„å¯¹è±¡æ”¶å‘çš„æŠ¥æ–‡ä¼šè¢«å¤åˆ¶ä¸€ä»½åˆ°ä¸æ•°æ®ç›‘æµ‹è®¾å¤‡ç›¸è¿çš„ç«¯å£ï¼Œç”¨æˆ·å°±å¯ä»¥å¯¹è¿™äº›æŠ¥æ–‡ ï¼ˆç§°ä¸ºé•œåƒæŠ¥æ–‡ï¼‰è¿›è¡Œç›‘æ§å’Œåˆ†æäº†ã€‚é•œåƒæºæ‰€åœ¨çš„è®¾å¤‡å°±ç§°ä¸ºæºè®¾å¤‡ã€‚ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:1","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"é•œåƒç›®çš„ é•œåƒç›®çš„æ˜¯æŒ‡é•œåƒæŠ¥æ–‡æ‰€è¦åˆ°è¾¾çš„ç›®çš„åœ°ï¼Œå³ä¸æ•°æ®ç›‘æµ‹è®¾å¤‡ç›¸è¿çš„é‚£ä¸ªç«¯å£ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºç›®çš„ç«¯å£ï¼Œç›®çš„ç«¯å£æ‰€åœ¨çš„è®¾å¤‡å°±ç§°ä¸ºç›®çš„è®¾å¤‡ã€‚ç›®çš„ç«¯å£ä¼šå°†é•œåƒæŠ¥æ–‡è½¬å‘ç»™ä¸ä¹‹ç›¸è¿çš„æ•°æ®ç›‘æµ‹è®¾å¤‡ã€‚ ç”±äºä¸€ä¸ªç›®çš„ç«¯å£å¯ä»¥åŒæ—¶ç›‘æ§å¤šä¸ªé•œåƒæºï¼Œå› æ­¤åœ¨æŸäº›ç»„ç½‘ç¯å¢ƒä¸‹ï¼Œç›®çš„ç«¯å£å¯èƒ½æ”¶åˆ°å¯¹åŒä¸€æŠ¥ æ–‡çš„å¤šä»½æ‹·è´ã€‚ä¾‹å¦‚ï¼Œç›®çš„ç«¯å£ Port 1 åŒæ—¶ç›‘æ§åŒä¸€å°è®¾å¤‡ä¸Šçš„æºç«¯å£ Port 2 å’Œ Port 3 æ”¶å‘çš„æŠ¥æ–‡ï¼Œ å¦‚æœæŸæŠ¥æ–‡ä» Port 2 è¿›å…¥è¯¥è®¾å¤‡ååˆä» Port 3 å‘é€å‡ºå»ï¼Œé‚£ä¹ˆè¯¥æŠ¥æ–‡å°†è¢«å¤åˆ¶ä¸¤æ¬¡ç»™ Port 1ã€‚ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:2","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"é•œåƒæ–¹å‘ é•œåƒæ–¹å‘æ˜¯æŒ‡åœ¨é•œåƒæºä¸Šå¯å¤åˆ¶å“ªäº›æ–¹å‘çš„æŠ¥æ–‡ï¼š å…¥æ–¹å‘ï¼šæ˜¯æŒ‡ä»…å¤åˆ¶é•œåƒæºæ”¶åˆ°çš„æŠ¥æ–‡ã€‚ å‡ºæ–¹å‘ï¼šæ˜¯æŒ‡ä»…å¤åˆ¶é•œåƒæºå‘å‡ºçš„æŠ¥æ–‡ã€‚ åŒå‘ï¼šæ˜¯æŒ‡å¯¹é•œåƒæºæ”¶åˆ°å’Œå‘å‡ºçš„æŠ¥æ–‡éƒ½è¿›è¡Œå¤åˆ¶ã€‚ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:3","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"é•œåƒç»„ é•œåƒç»„æ˜¯ä¸€ä¸ªé€»è¾‘ä¸Šçš„æ¦‚å¿µï¼Œé•œåƒæºå’Œé•œåƒç›®çš„éƒ½è¦å±äºæŸä¸€ä¸ªé•œåƒç»„ã€‚æ ¹æ®å…·ä½“çš„å®ç°æ–¹å¼ä¸åŒï¼Œ é•œåƒç»„å¯åˆ†ä¸ºæœ¬åœ°é•œåƒç»„ã€è¿œç¨‹æºé•œåƒç»„å’Œè¿œç¨‹ç›®çš„é•œåƒç»„ä¸‰ç±»ã€‚ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:4","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"åå°„ç«¯å£ã€å‡ºç«¯å£å’Œè¿œç¨‹é•œåƒVLAN åå°„ç«¯å£ã€å‡ºç«¯å£å’Œè¿œç¨‹é•œåƒVLANéƒ½æ˜¯åœ¨äºŒå±‚è¿œç¨‹ç«¯å£é•œåƒçš„å®ç°è¿‡ç¨‹ä¸­ç”¨åˆ°çš„æ¦‚å¿µã€‚è¿œç¨‹é•œåƒ VLANæ˜¯å°†é•œåƒæŠ¥æ–‡ä»æºè®¾å¤‡ä¼ é€è‡³ç›®çš„è®¾å¤‡çš„ä¸“ç”¨VLANï¼›åå°„ç«¯å£å’Œå‡ºç«¯å£éƒ½ä½äºæºè®¾å¤‡ä¸Šï¼Œéƒ½ ç”¨æ¥å°†é•œåƒæŠ¥æ–‡å‘é€åˆ°è¿œç¨‹é•œåƒVLANä¸­ã€‚ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:5","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"ç«¯å£é•œåƒçš„åˆ†ç±»å’Œå®ç°æ–¹å¼ æ ¹æ®é•œåƒæºä¸é•œåƒç›®çš„æ˜¯å¦ä½äºåŒä¸€å°è®¾å¤‡ä¸Šï¼Œå¯ä»¥å°†ç«¯å£é•œåƒåˆ†ä¸ºæœ¬åœ°ç«¯å£é•œåƒå’Œè¿œç¨‹ç«¯å£é•œåƒ ä¸¤å¤§ç±»ã€‚ æœ¬åœ°ç«¯å£é•œåƒ å½“æºè®¾å¤‡ä¸æ•°æ®ç›‘æµ‹è®¾å¤‡ç›´æ¥ç›¸è¿æ—¶ï¼Œæºè®¾å¤‡å¯ä»¥åŒæ—¶ä½œä¸ºç›®çš„è®¾å¤‡ï¼Œå³ç”±æœ¬è®¾å¤‡å°†é•œåƒæŠ¥æ–‡è½¬å‘ è‡³æ•°æ®æ£€æµ‹è®¾å¤‡ï¼Œè¿™ç§æ–¹å¼å®ç°çš„ç«¯å£é•œåƒç§°ä¸ºæœ¬åœ°ç«¯å£é•œåƒã€‚å¯¹äºæœ¬åœ°ç«¯å£é•œåƒï¼Œé•œåƒæºå’Œé•œåƒ ç›®çš„å±äºåŒä¸€å°è®¾å¤‡ä¸Šçš„åŒä¸€ä¸ªé•œåƒç»„ï¼Œè¯¥é•œåƒç»„ç§°ä¸ºæœ¬åœ°é•œåƒç»„ã€‚ è¿œç¨‹ç«¯å£é•œåƒ å½“æºè®¾å¤‡ä¸æ•°æ®ç›‘æµ‹è®¾å¤‡ä¸ç›´æ¥ç›¸è¿æ—¶ï¼Œä¸æ•°æ®ç›‘æµ‹è®¾å¤‡ç›´æ¥ç›¸è¿çš„è®¾å¤‡ä½œä¸ºç›®çš„è®¾å¤‡ï¼Œæºè®¾å¤‡éœ€ è¦å°†é•œåƒæŠ¥æ–‡å¤åˆ¶ä¸€ä»½è‡³ç›®çš„è®¾å¤‡ï¼Œç„¶åç”±ç›®çš„è®¾å¤‡å°†é•œåƒæŠ¥æ–‡è½¬å‘è‡³æ•°æ®ç›‘æµ‹è®¾å¤‡ï¼Œè¿™ç§æ–¹å¼å® ç°çš„ç«¯å£é•œåƒç§°ä¸ºè¿œç¨‹ç«¯å£é•œåƒã€‚å¯¹äºè¿œç¨‹ç«¯å£é•œåƒï¼Œé•œåƒæºå’Œé•œåƒç›®çš„åˆ†å±äºä¸åŒè®¾å¤‡ä¸Šçš„ä¸åŒ é•œåƒç»„ï¼šé•œåƒæºæ‰€åœ¨çš„é•œåƒç»„ç§°ä¸ºè¿œç¨‹æºé•œåƒç»„ï¼Œé•œåƒç›®çš„æ‰€åœ¨çš„é•œåƒç»„ç§°ä¸ºè¿œç¨‹ç›®çš„é•œåƒç»„ï¼Œè€Œ ä½äºæºè®¾å¤‡ä¸ç›®çš„è®¾å¤‡ä¹‹é—´çš„è®¾å¤‡åˆ™ç»Ÿç§°ä¸ºä¸­é—´è®¾å¤‡ã€‚ æ ¹æ®æºè®¾å¤‡ä¸ç›®çš„è®¾å¤‡ä¹‹é—´çš„è¿æ¥å…³ç³»ï¼Œåˆå¯å°†è¿œç¨‹ç«¯å£é•œåƒç»†åˆ†ä¸ºï¼š â€¢ äºŒå±‚è¿œç¨‹ç«¯å£é•œåƒï¼šæºè®¾å¤‡ä¸ç›®çš„è®¾å¤‡ä¹‹é—´é€šè¿‡äºŒå±‚ç½‘ç»œè¿›è¡Œè¿æ¥ã€‚ â€¢ ä¸‰å±‚è¿œç¨‹ç«¯å£é•œåƒï¼šæºè®¾å¤‡ä¸ç›®çš„è®¾å¤‡ä¹‹é—´é€šè¿‡ä¸‰å±‚ç½‘ç»œè¿›è¡Œè¿æ¥ã€‚ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:6","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"äºŒå±‚è¿œç¨‹ç«¯å£é•œåƒ äºŒå±‚è¿œç¨‹ç«¯å£é•œåƒçš„å®ç°æ–¹å¼åŒ…æ‹¬ï¼šåå°„ç«¯å£æ–¹å¼å’Œå‡ºç«¯å£æ–¹å¼ã€‚ â€¢ åå°„ç«¯å£æ–¹å¼ï¼š æºè®¾å¤‡å°†è¿›å…¥æºç«¯å£ï¼ˆæˆ–æº CPUï¼‰çš„æŠ¥æ–‡å¤åˆ¶ä¸€ä»½ç»™åå°„ç«¯å£ï¼Œå†ç”±è¯¥ç«¯å£ å°†é•œåƒæŠ¥æ–‡åœ¨è¿œç¨‹é•œåƒ VLAN ä¸­å¹¿æ’­ï¼Œæœ€ç»ˆé•œåƒæŠ¥æ–‡ç»ç”±ä¸­é—´è®¾å¤‡è½¬å‘è‡³ç›®çš„è®¾å¤‡ã€‚ç›®çš„è®¾ 1-3 å¤‡æ”¶åˆ°è¯¥æŠ¥æ–‡ååˆ¤åˆ«å…¶ VLAN IDï¼Œè‹¥ä¸è¿œç¨‹é•œåƒ VLAN çš„ VLAN ID ç›¸åŒï¼Œå°±å°†é•œåƒæŠ¥æ–‡é€šè¿‡ ç›®çš„ç«¯å£è½¬å‘ç»™æ•°æ®ç›‘æµ‹è®¾å¤‡ã€‚è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ å‡ºç«¯å£æ–¹å¼ï¼š æºè®¾å¤‡å°†è¿›å…¥æºç«¯å£ï¼ˆæˆ–æº CPUï¼‰çš„æŠ¥æ–‡å¤åˆ¶ä¸€ä»½ç»™å‡ºç«¯å£ï¼Œè¯¥ç«¯å£å°†é•œåƒæŠ¥ æ–‡è½¬å‘ç»™ä¸­é—´è®¾å¤‡ï¼Œå†ç”±ä¸­é—´è®¾å¤‡åœ¨è¿œç¨‹é•œåƒ VLAN ä¸­å¹¿æ’­ï¼Œæœ€ç»ˆåˆ°è¾¾ç›®çš„è®¾å¤‡ã€‚ç›®çš„è®¾å¤‡ æ”¶åˆ°è¯¥æŠ¥æ–‡ååˆ¤åˆ«å…¶ VLAN IDï¼Œè‹¥ä¸è¿œç¨‹é•œåƒ VLAN çš„ VLAN ID ç›¸åŒï¼Œå°±å°†é•œåƒæŠ¥æ–‡é€šè¿‡ç›® çš„ç«¯å£è½¬å‘ç»™æ•°æ®ç›‘æµ‹è®¾å¤‡ã€‚è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:7","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"é…ç½®å®æˆ˜ ç°æœ‰ä¸¤å¥—æ€åŠ¿æ„ŸçŸ¥è®¾å¤‡éœ€è¦æ¥å…¥å†…éƒ¨ç½‘ç»œï¼Œéœ€è¦å°†åŠå…¬ç½‘ã€å†…å¤–ç½‘ä¸šåŠ¡æµé‡è¿›è¡Œæ”¶é›†æ±‡æ€»åå°†æµé‡å¤åˆ¶ä¸€ä»½åˆ°ä¸æ€åŠ¿æ„ŸçŸ¥è®¾å¤‡ã€‚ å¯¹æ¥è®¾å¤‡ï¼š H3Cæ¡†å¼ æ ¸å¿ƒäº¤æ¢æœº å¥‡å®‰ä¿¡ å¤©çœ¼æ–°ä¸€ä»£å¨èƒæ„ŸçŸ¥ç³»ç»Ÿ æ·±ä¿¡æœ å®‰å…¨æ„ŸçŸ¥å¹³å°SIP æ ¸å¿ƒäº¤æ¢æœºé…ç½® æœ¬åœ°ç«¯å£é•œåƒæ–¹å¼ mirroring-group 1 local mirroring-group 1 mirroring-port g1/1/0/1 to g1/1/0/8 both mirroring-group 1 monitor-port g1/1/0/10 //å¼•g1/1/0/1åˆ°8å£çš„æµé‡åˆ° g1/1/0/10 dis mirroring-group all Mirroring group 1: Type: local Status: Active Mirroring port: GigabitEthernet1/1/0/1 Both GigabitEthernet1/1/0/2 Both GigabitEthernet1/1/0/3 Both GigabitEthernet1/1/0/4 Both GigabitEthernet1/1/0/5 Both GigabitEthernet1/1/0/6 Both GigabitEthernet1/1/0/7 Both GigabitEthernet1/1/0/8 Both Monitor-port: GigabitEthernet1/1/0/10 è¿œç¨‹ç«¯å£é•œåƒæ–¹å¼ mirroring-group 2 remote-source mirroring-group 2 mirroring-port g2/2/0/1 to g2/2/0/8 both mirroring-group 2 reflector-port g2/2/0/10 //åå°„ç«¯å£ vlan 130 //é•œåƒæ•°æ®å¹¿æ’­VLAN port g2/2/0/11 to g2/2/0/12 //å®¡è®¡è®¾å¤‡äº’è”æ¥å£ mirroring-group 2 remote-probe vlan 130 dis mirroring-group all Mirroring group 1: Type: Remote source Status: Active Mirroring port: GigabitEthernet2/2/0/1 Both GigabitEthernet2/2/0/2 Both GigabitEthernet2/2/0/3 Both GigabitEthernet2/2/0/4 Both GigabitEthernet2/2/0/5 Both GigabitEthernet2/2/0/6 Both GigabitEthernet2/2/0/7 Both GigabitEthernet2/2/0/8 Both Reflector port: GigabitEthernet1/4/0/10 Remote probe VLAN: 130 è®¾å¤‡æ¥å£è°ƒæ•´ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:8","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["ElasticStack"],"content":"æ•ˆæœéªŒè¯ æ•°æ®æˆåŠŸå¼•å…¥ ","date":"2021-09-29","objectID":"/posts/elk/h3c-mirroring-port/:0:9","tags":["æ—¥å¿—æ”¶é›†","H3C"],"title":"H3C-7506Eæ ¸å¿ƒäº¤æ¢æœºæ•°æ®å¼•æµ","uri":"/posts/elk/h3c-mirroring-port/"},{"categories":["å°è®°"],"content":"Linuxå‘½ä»¤è¡Œæç¤ºç¬¦é»˜è®¤æ˜¯ç™½è‰²ï¼Œå¾ˆå¤šæ—¶å€™ä¸å¤ªæ–¹ä¾¿æŸ¥çœ‹å‘½ä»¤å’Œè®°å½•ï¼Œè€Œä¸”é»˜è®¤æ˜¯æ˜¾ç¤ºçš„å®Œæ•´è·¯å¾„ï¼Œå¦‚æœè·¯å¾„è¿‡ é•¿ï¼Œå¼€å‘å’Œçœ‹èµ·æ¥éƒ½ä¸æ–¹ä¾¿ï¼Œæ‰€ä»¥æ”¹å˜ä¸€ä¸‹ç»ˆç«¯å‘½ä»¤è¡Œé¢œè‰²å’Œæ ¼å¼ã€‚ PSï¼ˆPrompt Signï¼‰å‘½ä»¤æç¤ºç¬¦ï¼ŒPS1æ˜¯Linuxç»ˆç«¯ç”¨æˆ·çš„ä¸€ä¸ªç¯å¢ƒå˜é‡ï¼Œç”¨æ¥å®šä¹‰å‘½ä»¤è¡Œæç¤ºç¬¦çš„å‚æ•°ã€‚ åœ¨è®¾å®šPS1ç¯å¢ƒå˜é‡æ—¶ï¼Œéœ€è¦ç”¨åˆ°é¢„è®¾çš„ä¸€äº›å‚æ•°æ¥è®¾å®šPS1ã€‚ ","date":"2020-10-04","objectID":"/posts/notes/beautify-terminal/:0:0","tags":["Terminal"],"title":"ç¾åŒ–ç»ˆç«¯å‘½ä»¤è¡Œæ˜¾ç¤º","uri":"/posts/notes/beautify-terminal/"},{"categories":["å°è®°"],"content":"PS1çš„å¸¸â½¤å‚æ•°ä»¥åŠå«ä¹‰ï¼š \\d ï¼šä»£è¡¨æ—¥æœŸï¼Œæ ¼å¼ä¸ºweekday month dateï¼Œä¾‹å¦‚ï¼šâ€œMon Aug 1â€ \\H ï¼šå®Œæ•´çš„ä¸»æœºåç§° \\h ï¼šä»…å–ä¸»æœºåä¸­çš„ç¬¬ä¸€ä¸ªåå­— \\t ï¼šæ˜¾ç¤ºæ—¶é—´ä¸º24å°æ—¶æ ¼å¼ï¼Œå¦‚ï¼šHHï¼šMMï¼šSS \\T ï¼šæ˜¾ç¤ºæ—¶é—´ä¸º12å°æ—¶æ ¼å¼ \\A ï¼šæ˜¾ç¤ºæ—¶é—´ä¸º24å°æ—¶æ ¼å¼ï¼šHHï¼šMM \\u ï¼šå½“å‰ç”¨æˆ·çš„è´¦å·åç§° \\v ï¼šBASHçš„ç‰ˆæœ¬ä¿¡æ¯ \\w ï¼šå®Œæ•´çš„å·¥ä½œç›®å½•åç§° \\W ï¼šåˆ©ç”¨basenameå–å¾—å·¥ä½œç›®å½•åç§°ï¼Œåªæ˜¾ç¤ºæœ€åä¸€ä¸ªç›®å½•å # ï¼šä¸‹è¾¾çš„ç¬¬å‡ ä¸ªå‘½ä»¤ $ ï¼šæç¤ºå­—ç¬¦ï¼Œå¦‚æœæ˜¯rootç”¨æˆ·ï¼Œæç¤ºç¬¦ä¸º # ï¼Œæ™®é€šç”¨æˆ·åˆ™ä¸º $ ","date":"2020-10-04","objectID":"/posts/notes/beautify-terminal/:1:0","tags":["Terminal"],"title":"ç¾åŒ–ç»ˆç«¯å‘½ä»¤è¡Œæ˜¾ç¤º","uri":"/posts/notes/beautify-terminal/"},{"categories":["å°è®°"],"content":"æŸ¥çœ‹å½“å‰PS1çš„è®¾ç½®ï¼š echo $PS1 '\\u@\\h:\\w\\$' #å«ä¹‰ï¼š #[å½“å‰ç”¨æˆ·å@ä¸»æœºå:å®Œæ•´å·¥ä½œç›®å½• ]$","date":"2020-10-04","objectID":"/posts/notes/beautify-terminal/:2:0","tags":["Terminal"],"title":"ç¾åŒ–ç»ˆç«¯å‘½ä»¤è¡Œæ˜¾ç¤º","uri":"/posts/notes/beautify-terminal/"},{"categories":["å°è®°"],"content":"è®¾ç½®PS1 æ ·å¼ å½“å‰ç”¨æˆ·çš„ .bashrc ç¯å¢ƒé…ç½®ä¸­ï¼Œåœ¨åº•éƒ¨æ·»åŠ PS1å¹¶èµ‹å€¼ï¼š vim ~/.bashrc PS1=\"\\u@\\h:\\W\\$\" export PS1 source ~/.bashrc","date":"2020-10-04","objectID":"/posts/notes/beautify-terminal/:3:0","tags":["Terminal"],"title":"ç¾åŒ–ç»ˆç«¯å‘½ä»¤è¡Œæ˜¾ç¤º","uri":"/posts/notes/beautify-terminal/"},{"categories":["å°è®°"],"content":"é¢œè‰²è®¾ç½®å‚æ•° \\[\\e[F;Bm\\].....\\[\\e[0m\\] æˆ–è€… \\[\\033[F;Bm\\].....\\[\\033[0m\\] å…¶ä¸­â€œFâ€ä¸ºå­—ä½“é¢œè‰²ï¼Œç¼–å·ä¸º30-37ï¼Œâ€œBâ€ä¸ºèƒŒæ™¯é¢œè‰²ï¼Œç¼–å·ä¸º40-47ï¼Œ\\[\\e[0m\\] ç»“æŸé¢œè‰²è®¾å®šã€‚ â€œBâ€è¿˜å¯ä»¥è®¾ç½®å…¶ä»–æ ¼å¼ï¼Œä¾‹å¦‚ä¸º1æ—¶ï¼Œå°†æ˜¾ç¤ºåŠ äº®åŠ ç²—çš„æ–‡å­—ï¼Œè¯¦è§ä¸‹è¡¨ F å­—ä½“é¢œâ¾Š BèƒŒæ™¯é¢œâ¾Š é¢œâ¾Š å…¶ä»–æ ¼å¼ 30 40 â¿Šâ¾Š ä»£ç  å«ä¹‰ 31 41 çº¢â¾Š 0 OFF 32 42 ç»¿â¾Š 1 â¾¼äº®æ˜¾â½° 33 43 é»„â¾Š 4 underline 34 44 è“â¾Š 5 é—ªçƒ 35 45 ç´«çº¢â¾Š 7 åâ½©æ˜¾â½° 36 46 é’è“â¾Š 8 ä¸å¯â»… 37 47 â½©â¾Š ","date":"2020-10-04","objectID":"/posts/notes/beautify-terminal/:4:0","tags":["Terminal"],"title":"ç¾åŒ–ç»ˆç«¯å‘½ä»¤è¡Œæ˜¾ç¤º","uri":"/posts/notes/beautify-terminal/"},{"categories":["å°è®°"],"content":"æ ·å¼1 export PS1='\\[\\033[01;31m\\]\\u\\[\\033[00m\\]@\\[\\033[01;32m\\]\\h\\[\\033[00m\\][\\[\\033[01;34m\\]\\t\\[\\033[00m\\]]\\[\\033[01;36m\\]\\w\\[\\033[00m\\] \\[\\033[01;33m\\]\\$\\[\\033[00m\\]:' ","date":"2020-10-04","objectID":"/posts/notes/beautify-terminal/:5:0","tags":["Terminal"],"title":"ç¾åŒ–ç»ˆç«¯å‘½ä»¤è¡Œæ˜¾ç¤º","uri":"/posts/notes/beautify-terminal/"},{"categories":["æ•°æ®åº“"],"content":"Redis Sentinelï¼ˆå“¨å…µï¼‰ ","date":"2020-08-07","objectID":"/posts/redis/redis-7/:0:0","tags":["Redis"],"title":"Redis Sentinelï¼ˆå“¨å…µï¼‰ ï¼ˆä¸ƒï¼‰","uri":"/posts/redis/redis-7/"},{"categories":["æ•°æ®åº“"],"content":"ç®€ä»‹ ä¸»ä»å¤åˆ¶å¥ å®šäº†Redisåˆ†å¸ƒå¼çš„åŸºç¡€ï¼Œä½†æ˜¯æ™®é€šçš„ä¸»ä»å¤åˆ¶å¹¶ä¸èƒ½è¾¾åˆ°é«˜å¯ç”¨çš„çŠ¶æ€ã€‚åœ¨æ™®é€šçš„ä¸»ä»å¤åˆ¶æ¨¡å¼ä¸‹ï¼Œå¦‚æœä¸»æœåŠ¡å™¨å®•æœºï¼Œå°±åªèƒ½é€šè¿‡è¿ç»´äººå‘˜æ‰‹åŠ¨åˆ‡æ¢ä¸»æœåŠ¡å™¨ï¼Œå¾ˆæ˜¾ç„¶è¿™ç§æ–¹æ¡ˆå¹¶ä¸å¯å–ã€‚ é’ˆå¯¹ä¸Šè¿°æƒ…å†µï¼ŒRediså®˜æ–¹æ¨å‡ºäº†å¯æŠµæŠ—èŠ‚ç‚¹æ•…éšœçš„é«˜å¯ç”¨æ–¹æ¡ˆâ€”â€”Redis Sentinelï¼ˆå“¨å…µï¼‰ã€‚Redis Sentinelï¼ˆå“¨å…µï¼‰ï¼šç”±ä¸€ä¸ªæˆ–å¤šä¸ªSentinelå®ä¾‹ç»„æˆçš„Sentinelç³»ç»Ÿï¼Œå®ƒå¯ä»¥ç›‘è§†ä»»æ„å¤šä¸ªä¸»ä»æœåŠ¡å™¨ï¼Œå½“ç›‘è§†çš„ä¸»æœåŠ¡å™¨å®•æœºæ—¶ï¼Œè‡ªåŠ¨ä¸‹çº¿ä¸»æœåŠ¡å™¨ï¼Œå¹¶ä¸”æ‹©ä¼˜é€‰å–ä»æœåŠ¡å™¨å‡çº§ä¸ºæ–°çš„ä¸»æœåŠ¡å™¨ã€‚ Sentinel è¿›ç¨‹æ˜¯ç”¨äºç›‘æ§redisé›†ç¾¤ä¸­Masterä¸»æœåŠ¡å™¨å·¥ä½œçš„çŠ¶æ€ï¼Œåœ¨Masterä¸»æœåŠ¡å™¨å‘ç”Ÿæ•…éšœçš„æ—¶å€™ï¼Œå¯ä»¥å®ç°Masterå’ŒSlaveæœåŠ¡å™¨çš„åˆ‡æ¢ï¼Œä¿è¯ç³»ç»Ÿçš„é«˜å¯ç”¨ï¼Œå…¶å·²ç»è¢«é›†æˆåœ¨redis2.6+çš„ç‰ˆæœ¬ä¸­ï¼ŒRedisçš„å“¨å…µæ¨¡å¼åˆ°äº†2.8ç‰ˆæœ¬ä¹‹åå°±ç¨³å®šäº†ä¸‹æ¥ã€‚ä¸€èˆ¬åœ¨ç”Ÿäº§ç¯å¢ƒä¹Ÿå»ºè®®ä½¿ç”¨Redisçš„2.8ç‰ˆæœ¬çš„ä»¥åç‰ˆæœ¬ã€‚ å“¨å…µ(Sentinel) æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿï¼Œå¯ä»¥åœ¨ä¸€ä¸ªæ¶æ„ä¸­è¿è¡Œå¤šä¸ªå“¨å…µ(sentinel) è¿›ç¨‹ï¼Œè¿™äº›è¿›ç¨‹ä½¿ç”¨æµè¨€åè®®(gossip protocols)æ¥æ¥æ”¶å…³äºMasterä¸»æœåŠ¡å™¨æ˜¯å¦ä¸‹çº¿çš„ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨æŠ•ç¥¨åè®®(Agreement Protocols)æ¥å†³å®šæ˜¯å¦æ‰§è¡Œè‡ªåŠ¨æ•…éšœè¿ç§»,ä»¥åŠé€‰æ‹©å“ªä¸ªSlaveä½œä¸ºæ–°çš„Masterã€‚æ¯ä¸ªå“¨å…µ(Sentinel)è¿›ç¨‹ä¼šå‘å…¶å®ƒå“¨å…µ(Sentinel)ã€Masterã€Slaveå®šæ—¶å‘é€æ¶ˆæ¯ï¼Œä»¥ç¡®è®¤å¯¹æ–¹æ˜¯å¦â€æ´»â€ç€ï¼Œå¦‚æœå‘ç°å¯¹æ–¹åœ¨æŒ‡å®šé…ç½®æ—¶é—´(å¯é…ç½®çš„)å†…æœªå¾—åˆ°å›åº”ï¼Œåˆ™æš‚æ—¶è®¤ä¸ºå¯¹æ–¹å·²æ‰çº¿ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„â€ä¸»è§‚è®¤ä¸ºå®•æœºâ€ ï¼Œä¸»è§‚æ˜¯æ¯ä¸ªæˆå‘˜éƒ½å…·æœ‰çš„ç‹¬è‡ªçš„è€Œä¸”å¯èƒ½ç›¸åŒä¹Ÿå¯èƒ½ä¸åŒçš„æ„è¯†ï¼Œè‹±æ–‡åç§°ï¼šSubjective Downï¼Œç®€ç§°SDOWNã€‚æœ‰ä¸»è§‚å®•æœºï¼Œè‚¯å®šå°±æœ‰å®¢è§‚å®•æœºã€‚ å½“â€œå“¨å…µç¾¤â€ä¸­çš„å¤šæ•°Sentinelè¿›ç¨‹åœ¨å¯¹Masterä¸»æœåŠ¡å™¨åšå‡ºSDOWN çš„åˆ¤æ–­ï¼Œå¹¶ä¸”é€šè¿‡ SENTINEL is-master-down-by-addr å‘½ä»¤äº’ç›¸äº¤æµä¹‹åï¼Œå¾—å‡ºçš„Master Serverä¸‹çº¿åˆ¤æ–­ï¼Œè¿™ç§æ–¹å¼å°±æ˜¯â€œå®¢è§‚å®•æœºâ€ï¼Œå®¢è§‚æ˜¯ä¸ä¾èµ–äºæŸç§æ„è¯†è€Œå·²ç»å®é™…å­˜åœ¨çš„ä¸€åˆ‡äº‹ç‰©ï¼Œè‹±æ–‡åç§°æ˜¯ï¼šObjectivelyDownï¼Œ ç®€ç§° ODOWNã€‚é€šè¿‡ä¸€å®šçš„voteç®—æ³•ï¼Œä»å‰©ä¸‹çš„slaveä»æœåŠ¡å™¨èŠ‚ç‚¹ä¸­ï¼Œé€‰ä¸€å°æå‡ä¸ºMasteræœåŠ¡å™¨èŠ‚ç‚¹ï¼Œç„¶åè‡ªåŠ¨ä¿®æ”¹ç›¸å…³é…ç½®ï¼Œå¹¶å¼€å¯æ•…éšœè½¬ç§»ï¼ˆfailoverï¼‰ã€‚ Sentinel æœºåˆ¶å¯ä»¥è§£å†³masterå’Œslaveè§’è‰²çš„åˆ‡æ¢é—®é¢˜ã€‚ Sentinel ç»„ä»¶ Monitoring : ç›‘æ§MasterèŠ‚ç‚¹ã€SlaveèŠ‚ç‚¹ä»¥åŠå…¶ä»–SentineèŠ‚ç‚¹æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚ Automatic failover: å½“Masteræ•…éšœæ—¶ï¼ŒSentinelä¼šé€‰æ‹©ä¸€ä¸ªSlaveèŠ‚ç‚¹æ¥æ›¿æ¢å½“å‰Masterï¼Œ å¹¶é…ç½®å…¶ä»–çš„SlaveèŠ‚ç‚¹æˆä¸ºæ–°çš„MasterèŠ‚ç‚¹çš„ä»èŠ‚ç‚¹ã€‚åŒæ—¶Sentinelä¼š é€šçŸ¥å®¢æˆ·ç«¯æ–°çš„Masterçš„åœ°å€ã€‚ Notification: å½“ç›‘æ§çš„é›†ç¾¤èŠ‚ç‚¹å‡ºæ•…éšœæ—¶ï¼ŒSentinelå¯é€šè¿‡æ‰§è¡Œç‰¹å®šè„šæœ¬æˆ–è€…è®¢é˜…æ¥ å‘ŠçŸ¥ç³»ç»Ÿç®¡ç†å‘˜æˆ–è€…å…¶ä»–åº”ç”¨ç¨‹åºæ¥é€šçŸ¥ç›¸åº”ä¿¡æ¯ã€‚ Configuration providerï¼šå¦‚æœ ä»redis ä»…ä»…æ˜¯æ–­å¼€äº† ä¸»redisï¼Œé‚£ä¹ˆä¸ä¼šåˆ é™¤å·²ç»åŒæ­¥è¿‡çš„æ•°æ®ã€‚ Sentinel æµç¨‹ï¼šå½“æ—§Masterä¸‹çº¿æ—¶é•¿è¶…è¿‡ç”¨æˆ·è®¾å®šçš„ä¸‹çº¿æ—¶é•¿ä¸Šé™ï¼ŒSentinelç³»ç»Ÿå°±ä¼šå¯¹æ—§Masteræ‰§è¡Œæ•…éšœè½¬ç§»æ“ä½œï¼Œæ•…éšœè½¬ç§»æ“ä½œåŒ…å«ä¸‰ä¸ªæ­¥éª¤ï¼š åœ¨Slaveä¸­é€‰æ‹©æ•°æ®æœ€æ–°çš„ä½œä¸ºæ–°çš„Master å‘å…¶ä»–Slaveå‘é€æ–°çš„å¤åˆ¶æŒ‡ä»¤ï¼Œè®©å…¶ä»–ä»æœåŠ¡å™¨æˆä¸ºæ–°çš„Masterçš„Slave ç»§ç»­ç›‘è§†æ—§Masterï¼Œå¦‚æœå…¶ä¸Šçº¿åˆ™å°†æ—§Masterè®¾ç½®ä¸ºæ–°Masterçš„Slave ","date":"2020-08-07","objectID":"/posts/redis/redis-7/:0:1","tags":["Redis"],"title":"Redis Sentinelï¼ˆå“¨å…µï¼‰ ï¼ˆä¸ƒï¼‰","uri":"/posts/redis/redis-7/"},{"categories":["æ•°æ®åº“"],"content":"å®è·µæ“ä½œ å®è·µè¦ç‚¹ï¼š å‡†å¤‡ä¸»ä»ç¯å¢ƒ å®šåˆ¶ sentinel é…ç½® é…ç½®ä¸»ä»ç¯å¢ƒ 1 bind å¼€æ”¾æœ¬æœºçš„ip\r2 replicaof æŒ‡å®šä¸»è§’è‰²\rä¿®æ”¹redis.conf æ–‡ä»¶ä¸­\rrelicaof \u003cmasterip\u003e \u003cmsterport\u003e\rrelicaof 192.168.10.110 6379 é…ç½®Sentinel èŠ‚ç‚¹ cp /data/softs/redis-6.2.5/sentinel.conf /data/server/redis/etc/ vim /data/server/redis/etc/sentinel.conf èŠ‚ç‚¹1 bind 192.168.10.110 #æ³¨æ„å»æ‰127çš„åœ°å€å‘ç”Ÿå†²çª port 26379 daemonize yes pidfile /data/server/redis/run/redis-sentinel.pid logfile \"/data/server/redis/log/redis-sentinel.log\" #å®šåˆ¶logè·¯å¾„ dir \"/data/server/redis/data\" #å®šåˆ¶æ•°æ®æ–‡ä»¶è·¯å¾„ sentinel monitor mymaster 192.168.10.110 6379 2 #æ³•å®šäººæ•°é™åˆ¶(quorum)ï¼Œå³æœ‰å‡ ä¸ªslaveè®¤ä¸ºmaster downäº†å°±è¿›è¡Œæ•…éšœè½¬ç§» sentinel down-after-milliseconds mymaster 3000 #(SDOWN)ä¸»è§‚ä¸‹çº¿çš„æ—¶é—´ acllog-max-len 128 sentinel parallel-syncs mymaster 1 #å‘ç”Ÿæ•…éšœè½¬ç§»æ—¶å€™åŒæ—¶å‘æ–°masteråŒæ­¥æ•°æ®çš„slaveæ•°é‡ï¼Œæ•°å­—è¶Šå°æ€»åŒæ­¥æ—¶é—´è¶Šé•¿ sentinel failover-timeout mymaster 3000 #æ‰€æœ‰slavesæŒ‡å‘æ–°çš„masteræ‰€éœ€çš„è¶…æ—¶æ—¶é—´ sentinel deny-scripts-reconfig yes #ç¦æ­¢ä¿®æ”¹è„šæœ¬ SENTINEL resolve-hostnames no SENTINEL announce-hostnames no èŠ‚ç‚¹2 bind 192.168.10.113 port 26379 daemonize yes pidfile \"/data/server/redis/run/redis-sentinel.pid\" logfile \"/data/server/redis/log/redis-sentinel.log\" dir \"/data/server/redis/data\" sentinel deny-scripts-reconfig yes sentinel monitor mymaster 192.168.10.110 6379 2 èŠ‚ç‚¹3 bind 192.168.10.114 port 26379 daemonize yes pidfile \"/data/server/redis/run/redis-sentinel.pid\" logfile \"/data/server/redis/log/redis-sentinel.log\" dir \"/data/server/redis/data\" sentinel deny-scripts-reconfig yes sentinel monitor mymaster 192.168.10.110 6379 2å¯åŠ¨èŠ‚ç‚¹ #å¯åŠ¨redis root@redis-master:redis-server /data/server/redis/etc/redis.conf root@redis-slave1ï¼šredis-server /data/server/redis/etc/redis.conf root@redis-slave2ï¼šredis-server /data/server/redis/etc/redis.conf #å¯åŠ¨å“¨å…µ root@redis-master:redis-sentinel /data/server/redis/etc/sentinel.conf root@redis-slave1ï¼šredis-sentinel /data/server/redis/etc/sentinel.conf root@redis-slave2ï¼šredis-sentinel /data/server/redis/etc/sentinel.confæŸ¥çœ‹é›†ç¾¤çŠ¶æ€ èŠ‚ç‚¹2 redis-cli -h 192.168.10.113 -p 6379 info Replication # Replication role:master connected_slaves:2 slave0:ip=192.168.10.110,port=6379,state=online,offset=242697,lag=0 slave1:ip=192.168.10.114,port=6379,state=online,offset=242550,lag=1 master_failover_state:no-failover master_replid:d19f968c80d72a23ca373943dc166942a125758a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:242697 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:61752 repl_backlog_histlen:180946 èŠ‚ç‚¹3 redis-cli -h 192.168.10.114 -p 6379 info Replication # Replication role:slave master_host:192.168.10.113 master_port:6379 master_link_status:up master_last_io_seconds_ago:0 master_sync_in_progress:0 slave_repl_offset:251426 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:d19f968c80d72a23ca373943dc166942a125758a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:251426 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:174421 repl_backlog_histlen:77006 èŠ‚ç‚¹1 redis-cli -h 192.168.10.110 -p 6379 info Replication # Replication role:slave master_host:192.168.10.113 master_port:6379 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_repl_offset:254674 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:d19f968c80d72a23ca373943dc166942a125758a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:254674 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:62216 repl_backlog_histlen:192459æ•…éšœåˆ‡æ¢æ•ˆæœ redis-cli -h 192.168.10.110 -p 6379 info Replication # Replication role:master connected_slaves:2 #slave èŠ‚ç‚¹ slave0:ip=192.168.10.113,port=6379,state=online,offset=361163,lag=1 slave1:ip=192.168.10.114,port=6379,state=online,offset=361163,lag=1 master_failover_state:no-failover master_replid:c4b564add75141ccb26517b40194e48cc99e92e3 master_replid2:1f7ace","date":"2020-08-07","objectID":"/posts/redis/redis-7/:0:2","tags":["Redis"],"title":"Redis Sentinelï¼ˆå“¨å…µï¼‰ ï¼ˆä¸ƒï¼‰","uri":"/posts/redis/redis-7/"},{"categories":["æ•°æ®åº“"],"content":"Redis ä¸»ä»åŒæ­¥ redis ä½œä¸ºä¸€ä¸ªåˆ†å¸ƒå¼çš„æ•°æ®ç¼“å­˜å¹³å°ï¼Œæˆ‘ä»¬å¯ä»¥å€ŸåŠ©äºredisçš„å¤šå®ä¾‹æœºåˆ¶ï¼Œè®©å¤šä¸ªå®ä¾‹é—´çš„æ•°æ®ï¼Œ è¾¾æˆä¸€ä¸ªåŒæ­¥çš„æ•ˆæœï¼Œè¿™æ ·å³ä½¿æŸä¸ªå®ä¾‹å‡ºç°å¼‚å¸¸ï¼Œä¹Ÿä¸å½±å“æ•°æ®æ•´ä½“çš„ä½¿ç”¨ã€‚ ","date":"2020-08-06","objectID":"/posts/redis/redis-6/:0:0","tags":["Redis"],"title":"Redis ä¸»ä»åŒæ­¥ ï¼ˆå…­ï¼‰","uri":"/posts/redis/redis-6/"},{"categories":["æ•°æ®åº“"],"content":"åŸºç¡€çŸ¥è¯† å¤åˆ¶ç‰¹æ€§ redis å¦‚æœæƒ³è¦å®ç°ä¸»ä»å¤åˆ¶çš„æ•ˆæœï¼Œæˆ‘ä»¬éœ€è¦ä¸ºå®ƒåˆ’åˆ† ä¸»è§’è‰²å’Œä»è§’è‰²ï¼Œå®ç°æ•°æ® ç”±ä¸»å‘ä»çš„å•å‘ä¼ é€’ã€‚ å¯¹äº ä»redisï¼Œä¸€æ—¦å‘ç° ä¸»redis æ›´æ¢äº†ï¼Œé‚£ä¹ˆå°†æœ¬åœ°æ•°æ®æ¸…ç©ºï¼Œä»æ–°ä¸»ä¸ŠåŒæ­¥æ•°æ®ã€‚ å¦‚æœ ä»redis ä»…ä»…æ˜¯æ–­å¼€äº† ä¸»redisï¼Œé‚£ä¹ˆä¸ä¼šåˆ é™¤å·²ç»åŒæ­¥è¿‡çš„æ•°æ®ã€‚ å®è·µè¦ç‚¹ æŠŠå¤šä¸ªä¸»æœºèŠ‚ç‚¹ï¼Œå…³è”åœ¨ä¸€èµ·è®©è¿™äº›ä¸»æœºèŠ‚ç‚¹å½“ä¸­æœ‰ä¸€ä¸ªä¸»è§’è‰²ï¼Œä¸“é—¨è´Ÿè½½æ•°æ®çš„å†™ã€åˆ é™¤ã€æ›´æ–° å‰©ä¸‹çš„ä¸¤ä¸ªä»èŠ‚ç‚¹åªç”¨äºè¯»æ•°æ®ã€‚å› ä¸ºåœ¨å¤§éƒ¨åˆ†åœºæ™¯ä¸‹éƒ½æ˜¯è¯»å¤šå†™å°‘ã€‚ æ‰€ä»¥é€šè¿‡ä»èŠ‚ç‚¹åšåˆ°å¤§èŒƒå›´çš„è¯»æ“ä½œï¼Œè¿è¡Œä¸‰å°redis é€šè¿‡ä¸€æ¡å‘½ä»¤æŠŠä»åº“æŒ‚åˆ°ä¸»åº“ä¸Šã€‚ è°æ˜¯æˆ‘çš„è€å¤§ï¼Ÿ 1 ä¸»è§’è‰²redis å¿…é¡»å¼€å¯æŒä¹…åŒ–åŠŸèƒ½\r2 ä»è§’è‰²redis æŒ‡å®šè°æ˜¯ä¸»ï¼Œä»¥åŠè‡ªå·±ä½œä¸ºä»çš„å”¯ä¸€æ ‡è¯†ã€‚\rredis4.0ä¹‹å‰ç”¨ slaveof\rredis4.0ä¹‹åç”¨ replicaof\ræˆ‘æ˜¯è°çš„å‰¯æœ¬ è°æ˜¯æˆ‘çš„è€å¤§\rrelicaof \u003cmasterip\u003e \u003cmsterport\u003e ","date":"2020-08-06","objectID":"/posts/redis/redis-6/:0:1","tags":["Redis"],"title":"Redis ä¸»ä»åŒæ­¥ ï¼ˆå…­ï¼‰","uri":"/posts/redis/redis-6/"},{"categories":["æ•°æ®åº“"],"content":"å®è·µæ“ä½œ å¤åˆ¶å‘½ä»¤æ–¹å¼åŒæ­¥ 127.0.0.1:6379\u003e help SLAVEOF\rSLAVEOF host port\rsummary: Make the server a replica of another instance, or promote it as\rmaster. Deprecated starting with Redis 5. Use REPLICAOF instead.\rsince: 1.0.0\rgroup: server\r127.0.0.1:6379\u003e help REPLICAOF\rREPLICAOF host port\rsummary: Make the server a replica of another instance, or promote it as\rmaster.\rsince: 5.0.0\rgroup: server\ræ³¨æ„ï¼š\rå…³é—­å¤åˆ¶å…³ç³»å¯ä»¥é€šè¿‡ replicaof no one å‘½ä»¤é»˜è®¤æƒ…å†µä¸‹ï¼Œä»»ä½•ä¸€ä¸ªrediså®ä¾‹å¯åŠ¨æ—¶å€™ï¼Œä¼šè‡ªåŠ¨å°†è‡ªå·±ä½œä¸ºä¸»è§’è‰²è€Œå­˜åœ¨ 127.0.0.1:6379\u003e info Replication # Replication role:master connected_slaves:0åŒæ­¥å®è·µ #å¼€å¯ä¸€ä¸ªrediså®ä¾‹\rredis-server /data/server/redis/etc/redis.conf --port 6666 --daemonize yes\r#è¿æ¥æ–°å®ä¾‹æŸ¥çœ‹æ•ˆæœ\r# redis-cli -h 127.0.0.1 -p 6666\r\u003e info replication\r# Replication\rrole:master\rconnected_slaves:0\r...\r#æ–°å®ä¾‹åŒæ­¥ä¸»è§’è‰²\r# è®¾ç½®ä¸»è§’è‰²\r127.0.0.1:6666\u003e REPLICAOF 127.0.0.1 6379\rOK\r# æŸ¥çœ‹çŠ¶æ€\r127.0.0.1:6666\u003e info replication\r# Replication\rrole:slave\rmaster_host:127.0.0.1\rmaster_port:6379\rmaster_link_status:up\rmaster_last_io_seconds_ago:3\rmaster_sync_in_progress:0\rslave_repl_offset:0\rslave_priority:100\r...\r# æŸ¥çœ‹åŒæ­¥æ•ˆæœ\r127.0.0.1:6666\u003e KEYS *\r1) \"a1\"\r2) \"a3\"\r3) \"a2\"\rç»“æœæ˜¾ç¤ºï¼š\ræ•°æ®åŒæ­¥æˆåŠŸæ•ˆæœéªŒè¯ ä»è§’è‰²åªèƒ½æŸ¥çœ‹æ•°æ®ï¼Œä¸èƒ½ä¿®æ”¹æ•°æ® 127.0.0.1:6666\u003e FLUSHALL (error) READONLY You can't write against a read only replica. # ä¸»è§’è‰²åˆ é™¤æ•°æ® 127.0.0.1:6379\u003e keys * 1) \"a2\" 2) \"a1\" 3) \"a3\" 127.0.0.1:6379\u003e DEL a1 (integer) 1 # ä»è§’è‰²æŸ¥çœ‹æ•ˆæœ 127.0.0.1:6666\u003e keys * 1) \"a3\" 2) \"a2\" ç»“æœæ˜¾ç¤ºï¼š è‡ªåŠ¨åŒæ­¥æˆåŠŸã€‚ #åŒæ­¥çŠ¶æ€æŸ¥çœ‹ # åŒæ­¥åä¸»è§’è‰²æŸ¥çœ‹æ•ˆæœ 127.0.0.1:6379\u003e info Replication # Replication role:master connected_slaves:1 slave0:ip=127.0.0.1,port=6666,state=online,offset=1038,lag=0 master_failover_state:no-failover master_replid:571bcaecc7eeb590326fc5a9262df569f3623b36 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1038 # åŒæ­¥çš„åç§»é‡ second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1038 # åŒæ­¥åä»è§’è‰²æŸ¥çœ‹æ•ˆæœ 127.0.0.1:6666\u003e info replication # Replication role:slave master_host:127.0.0.1 master_port:6379 master_link_status:up master_last_io_seconds_ago:10 master_sync_in_progress:0 slave_repl_offset:1038 # åŒæ­¥çš„åç§»é‡ slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:571bcaecc7eeb590326fc5a9262df569f3623b36 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1038 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1038 é…ç½®æ–‡ä»¶æ–¹å¼ä¸»ä»åŒæ­¥ ç®€ä»‹ å¯¹äºä¸»ä»åŒæ­¥æ¥è¯´ï¼Œ ä¸»è§’è‰²ä¸ç”¨åšä»»ä½•é…ç½® - å¼€æ”¾è‡ªå·±çš„æ€€æŠ±å³å¯ ä»è§’è‰²éœ€è¦åšä¸¤ä¸ªæ–¹é¢çš„é…ç½® 1 bind å¼€æ”¾æœ¬æœºçš„ip 2 replicaof æŒ‡å®šä¸»è§’è‰² ä¿®æ”¹redis.conf æ–‡ä»¶ä¸­ relicaof \u003cmasterip\u003e \u003cmsterport\u003e relicaof ä¸» IP ç«¯å£ å®è·µ ä¸»è§’è‰² æ•°æ®çš„å¢åˆ æ”¹æŸ¥ ä»è§’è‰² ä»ä¸»è§’è‰²ä¸»æœºé‡Œè·å–æ•°æ® æ•°æ®çš„æŸ¥çœ‹ ç‰¹ç‚¹ï¼š å¦‚æœä»è§’è‰²ä¸»æœºæ•…éšœï¼Œé‚£ä¹ˆä¸»è§’è‰²ä¸»æœºä¸­çš„ä»ä¸»æœºçŠ¶æ€ä¼šè‡ªåŠ¨æ¶ˆé™¤ å¦‚æœä¸»è§’è‰²ä¸»æœºæ•…éšœï¼Œé‚£ä¹ˆæ•´ä¸ªé›†ç¾¤å°±å´©æºƒäº†(ç›¸å¯¹äºæ•°æ®æ›´æ”¹æ¥è¯´)","date":"2020-08-06","objectID":"/posts/redis/redis-6/:0:2","tags":["Redis"],"title":"Redis ä¸»ä»åŒæ­¥ ï¼ˆå…­ï¼‰","uri":"/posts/redis/redis-6/"},{"categories":["æ•°æ®åº“"],"content":"Redis æŒä¹…å¤åˆ¶ Redisè™½ç„¶æ˜¯ä¸€ä¸ªå†…å­˜çº§åˆ«çš„ç¼“å­˜ç¨‹åºï¼Œä½†æ˜¯å…¶å¯ä»¥å°†å†…å­˜çš„æ•°æ®æŒ‰ç…§ä¸€å®šçš„ç­–ç•¥ä¿å­˜åˆ°ç¡¬ç›˜ä¸Šï¼Œä»è€Œå®ç°æ•°æ®æŒä¹…ä¿å­˜çš„ç›®çš„ã€‚ ç›®å‰ï¼Œredisæ”¯æŒä¸¤ç§ä¸åŒæ–¹å¼çš„æ•°æ®æŒä¹…åŒ–ä¿å­˜æœºåˆ¶ï¼š RDB åŸºäºæ—¶é—´ï¼Œç”ŸæˆæŸä¸ªæ—¶é—´ç‚¹çš„å¿«ç…§æ–‡ä»¶ï¼Œé»˜è®¤åªä¿ç•™æœ€è¿‘çš„ä¸€æ¬¡å¿«ç…§ã€‚ æ¢å¤é€Ÿåº¦éå¸¸å¿«ï¼Œä½†æ˜¯å¯èƒ½ä¸¢å¤±ä¹‹å‰çš„å¿«ç…§æ•°æ®ï¼Œéå®æ—¶åŒæ­¥ã€‚ AOF AppendOnlyFile(æ—¥å¿—è¿½åŠ æ¨¡å¼),åŸºäºRedisåè®®æ ¼å¼ä¿å­˜ä¿¡æ¯åˆ°æŒ‡å®šæ—¥å¿—æ–‡ä»¶çš„æœ«å°¾ åŸºäºå†™æ—¶å¤åˆ¶çš„æœºåˆ¶ï¼Œæ¯éš”xç§’å°†æ–°æ‰§è¡Œçš„å‘½ä»¤åŒæ­¥åˆ°å¯¹åº”çš„æ–‡ä»¶ä¸­ é»˜è®¤æ˜¯ç¦ç”¨çš„ï¼Œéœ€è¦å¼€å¯æ•°æ®ä¿å­˜å…¨ï¼Œæ—¶é—´è¿‡é•¿å¯¼è‡´æ–‡ä»¶è¿‡å¤§ï¼Œæ¢å¤æ—¶å€™é€Ÿåº¦æ¯”RDBæ…¢ã€‚ æ•°æ®ä¿å­˜æ—¶æœ‰ä¸¤ä¸ªå‘½ä»¤ï¼Œ å®è·µæ•ˆæœï¼Œå…ˆæ‰§è¡Œä¸€ä¸ªbgsaveæŠŠåŒæ­¥è¿‡åçš„æ–‡ä»¶æ‹·è´åˆ°ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶é‡Œé¢ï¼Œç„¶åå†å½“å‰ç¯å¢ƒä¸‹åšä¸€äº›æ“ä½œï¼ŒæŠŠredis å…³é—­ï¼Œç„¶åæŠŠä¹‹å‰ä¿å­˜çš„æ–‡ä»¶æ‹·è´åˆ°redis æ•°æ®ç›®å½•ï¼Œredisåœ¨å¯åŠ¨çš„æ—¶å€™ä¼šè¯»å–dbæ–‡ä»¶ï¼Œç”±äºè¿™ä¸ªæ–‡ä»¶æ˜¯æ‹·è´å›æ¥çš„æ‰€ä»¥è¿˜åŸçš„æ•°æ®åº”è¯¥æ˜¯æ²¡æœ‰æ‰§è¡Œæ“ä½œä¹‹å‰çš„æ•°æ®ã€‚ ","date":"2020-08-05","objectID":"/posts/redis/redis-5/:0:0","tags":["Redis"],"title":"Redis æŒä¹…å¤åˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/redis/redis-5/"},{"categories":["æ•°æ®åº“"],"content":"RDBåŸç† Redisä»masterä¸»è¿›ç¨‹ä¸­åˆ›å»ºä¸€ä¸ªå­è¿›ç¨‹ï¼ŒåŸºäºå†™æ—¶å¤åˆ¶æœºåˆ¶ï¼Œå­è¿›ç¨‹å°†å†…å­˜çš„æ•°æ®ä¿å­˜åˆ°.rdbæ–‡ä»¶ä¸­ï¼Œæ•°æ®ä¿å­˜å®Œæ¯•åï¼Œå†å°†ä¸Šæ¬¡ä¿å­˜çš„rdbæ–‡ä»¶è¦†ç›–æ›¿æ¢æ‰ï¼Œæœ€åå…³é—­å­è¿›ç¨‹ã€‚ Redisæä¾›äº†æ‰‹å·¥çš„æœºåˆ¶ï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œå‘½ä»¤å®ç°æ–‡ä»¶çš„ä¿å­˜ ","date":"2020-08-05","objectID":"/posts/redis/redis-5/:0:1","tags":["Redis"],"title":"Redis æŒä¹…å¤åˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/redis/redis-5/"},{"categories":["æ•°æ®åº“"],"content":"AOF åŸç† AOF ä»¥åè®®æ–‡æœ¬çš„æ–¹å¼ï¼Œå°†æ‰€æœ‰å¯¹æ•°æ®åº“è¿›è¡Œè¿‡å†™å…¥çš„å‘½ä»¤ï¼ˆåŠå…¶å‚æ•°ï¼‰è®°å½•åˆ° AOF æ–‡ä»¶ï¼Œä»¥æ­¤è¾¾åˆ°è®°å½•æ•°æ®åº“çŠ¶æ€çš„ç›®çš„ã€‚ rdb ä¼˜åŠ¿ï¼š - åŸºäºæ•°æ®çš„å¿«ç…§æ¥è¿›è¡Œå­˜å‚¨ - æ•°æ®å®Œæ•´ - ç­–ç•¥éå¸¸çµæ´» åŠ£åŠ¿ï¼š - æ•°æ®é‡å¤§çš„æ—¶å€™ï¼Œå¿«ç…§æ–‡ä»¶ä¹Ÿå¤§ - bgsaveçš„æ—¶å€™ï¼Œä¼šä»¥è¦†ç›–çš„æ–¹å¼åŒæ­¥æ•°æ®ï¼Œæœ‰å¯èƒ½å¯¼è‡´éƒ¨åˆ†æ•°æ®ä¸¢å¤± å¯¹äºæ­¤æˆ‘ä»¬å¯ä»¥å€ŸåŠ©äº å®šæ—¶å¤‡ä»½çš„æ–¹å¼å°†æ•°æ®é¢å¤–ä¿å­˜ aof ä¼˜åŠ¿ï¼š - åŸºäºæ“ä½œå‘½ä»¤çš„æ–¹å¼è¿›è¡Œæ•°æ®çš„å­˜å‚¨ - å®¹é‡éå¸¸å° åŠ£åŠ¿ï¼š - å¯¹äºåŸºç¡€çš„æ•°æ®æœ‰ä¸€å®šçš„ä¾èµ– ä½¿ç”¨åœºæ™¯ï¼š rdb åšåŸºç¡€æ•°æ®çš„å¤‡ä»½ aof åšå®æ—¶æ•°æ®çš„å¤‡ä»½","date":"2020-08-05","objectID":"/posts/redis/redis-5/:0:2","tags":["Redis"],"title":"Redis æŒä¹…å¤åˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/redis/redis-5/"},{"categories":["æ•°æ®åº“"],"content":"ç®€å•å®è·µ RDB å®è·µ RDBé…ç½®è§£æ è‡ªåŠ¨ä¿å­˜æœºåˆ¶ root@python-auto:~# grep -Env '#|^$' /etc/redis/redis.conf ... save '' å…³é—­è¯¥åŠŸèƒ½ 381:save 3600 1 # 3600ç§’å†…æäº¤ä¸€æ¬¡æ•°æ® 382:save 300 100 383:save 60 10000 398:stop-writes-on-bgsave-error yes 404:rdbcompression yes 413:rdbchecksum yes 431:dbfilename dump.rdb #ä¿å­˜æ–‡ä»¶å 444:rdb-del-sync-files no 454:dir /var/lib/redis #ä¿å­˜è·¯å¾„ RDBæŒä¹…åŒ–å‘½ä»¤ # æ•°æ®åŒæ­¥æ“ä½œï¼Œæ‰§è¡Œæ—¶å€™ï¼Œä¼šå¯¼è‡´å…¶ä»–å‘½ä»¤æ— æ³•æ‰§è¡Œ 127.0.0.1:6379\u003e help SAVE SAVE - summary: Synchronously save the dataset to disk since: 1.0.0 group: server # å¼‚æ­¥æ–¹å¼åå°æ‰§è¡Œæ•°æ®çš„åŒæ­¥ï¼Œä¸å½±å“å…¶ä»–å‘½ä»¤çš„æ‰§è¡Œ 127.0.0.1:6379\u003e help BGSAVE BGSAVE [SCHEDULE] summary: Asynchronously save the dataset to disk since: 1.0.0 group: serverç®€å•æµ‹è¯• # æ‰§è¡Œå¤‡ä»½å‰æŸ¥çœ‹æ•ˆæœ root@python-auto:~# ll -h /var/lib/redis/*.rdb -rw-rw---- 1 redis redis 268 7æœˆ 28 18:31 /var/lib/redis/dump.rdb # æ‰§è¡Œå¤‡ä»½ 127.0.0.1:6379\u003e bgsave Background saving started # æ‰§è¡Œå¤‡ä»½åæŸ¥çœ‹æ•ˆæœ root@python-auto:~# ll -h /var/lib/redis/*.rdb -rw-rw---- 1 redis redis 268 7æœˆ 29 09:38 /var/lib/redis/dump.rdb # å¤‡ä»½æ–‡ä»¶ root@python-auto:/var/lib/redis# cp dump.rdb /tmp # åœ¨åšä¸€äº›æ“ä½œ 127.0.0.1:6379\u003e set xxx xxx ... # å…³é—­redis systemctl stop redis æŸ¥çœ‹æ•ˆæœ root@python-auto:~# ll -h /var/lib/redis/*.rdb -rw-rw---- 1 redis redis 488 7æœˆ 29 09:41 /var/lib/redis/dump.rdb è¿˜åŸé…ç½®æ–‡ä»¶ cp /tmp/dump.rdb ./ å¯åŠ¨redis systemctl start redis æŸ¥çœ‹æ•ˆæœ 127.0.0.1:6379\u003e keys *AOFå®è·µ é…ç½®è§£æ root@python-auto:~# grep -Env '#|^$' /etc/redis/redis.conf ... 1252:appendonly no 1256:appendfilename \"appendonly.aof\" 1282:appendfsync everysec 1304:no-appendfsync-on-rewrite no 1323:auto-aof-rewrite-percentage 100 1324:auto-aof-rewrite-min-size 64mb 1348:aof-load-truncated yes 1359:aof-use-rdb-preamble yes ... AOFæŒä¹…åŒ–å‘½ä»¤ # æ•°æ®åŒæ­¥æ“ä½œï¼Œæ‰§è¡Œæ—¶å€™ï¼Œä¼šå¯¼è‡´å…¶ä»–å‘½ä»¤æ— æ³•æ‰§è¡Œ 127.0.0.1:6379\u003e help BGREWRITEAOF BGREWRITEAOF - summary: Asynchronously rewrite the append-only file since: 1.0.0 group: server ç®€å•æµ‹è¯• # æ£€æŸ¥ç°çŠ¶ 127.0.0.1:6379\u003e CONFIG GET appendonly 1) \"appendonly\" 2) \"no\" root@python-auto:~# ll -h /var/lib/redis/*.rdb -rw-rw---- 1 redis redis 92 7æœˆ 29 10:06 /var/lib/redis/dump.rdb # ä¿®æ”¹æŒä¹…åŒ–æ¨¡å¼ 127.0.0.1:6379\u003e CONFIG SET appendonly yes OK # ç¡®è®¤æ•ˆæœ root@python-auto:~# ll -h /var/lib/redis/ æ€»ç”¨é‡ 16K -rw-rw---- 1 redis redis 92 7æœˆ 29 10:09 appendonly.aof -rw-rw---- 1 redis redis 92 7æœˆ 29 10:06 dump.rdb # å¼€å§‹å¤‡ä»½ 127.0.0.1:6379\u003e MSET a1 v1 a2 v2 a3 v3 OK 127.0.0.1:6379\u003e BGREWRITEAOF Background append only file rewriting started # æ£€æŸ¥æ•ˆæœ root@python-auto:~# ll -h /var/lib/redis/*.aof -rw-rw---- 1 redis redis 118 7æœˆ 29 10:11 /var/lib/redis/appendonly.aof","date":"2020-08-05","objectID":"/posts/redis/redis-5/:1:0","tags":["Redis"],"title":"Redis æŒä¹…å¤åˆ¶ ï¼ˆäº”ï¼‰","uri":"/posts/redis/redis-5/"},{"categories":["æ•°æ®åº“"],"content":"åº”ç”¨Redis python-Web Sessionå®è·µ æˆ‘ä»¬åœ¨åé¢æ˜¯å‡†å¤‡åœ¨python webé¡¹ç›®ä¸­åº”ç”¨redisï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åœ¨pythonè™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…redisçš„æ¨¡å—æ’ä»¶ï¼Œç„¶åæ‰å¯ä»¥æ­£å¸¸çš„åº”ç”¨ã€‚redis-pyæä¾›ä¸¤ä¸ªç±»Rediså’ŒStrictRedisç”¨äºå®ç°Redisçš„å‘½ä»¤ï¼ŒStrictRedisç”¨äºå®ç°å¤§éƒ¨åˆ†å®˜æ–¹çš„å‘½ä»¤ï¼Œå¹¶ä½¿ç”¨å®˜æ–¹çš„è¯­æ³•å’Œå‘½ä»¤ï¼ŒRedisæ˜¯StrictRedisçš„å­ç±»ï¼Œç”¨äºå‘åå…¼å®¹æ—§ç‰ˆæœ¬çš„redis-pyã€‚ ","date":"2020-08-04","objectID":"/posts/redis/redis-4/:0:0","tags":["Redis"],"title":"Redis å…±äº«Sessionå®è·µ ï¼ˆå››ï¼‰","uri":"/posts/redis/redis-4/"},{"categories":["æ•°æ®åº“"],"content":"ç¯å¢ƒå‡†å¤‡ éœ€è¦åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œä¸ºä»€ä¹ˆè¦ç”¨è™šæ‹Ÿç¯å¢ƒå‘¢ï¼Ÿ é»˜è®¤æƒ…å†µä¸‹åœ¨å½“å‰æ“ä½œç³»ç»Ÿä¸‹é‡Œé¢ï¼Œå®‰è£…ä¸€ä¸ªç‰ˆæœ¬ä¸º3.7çš„Python å†å®‰è£…ä¸€ä¸ªç‰ˆæœ¬ä¸º3.9çš„Python é‚£ä¹ˆå°±ä¼šæŠŠä¹‹å‰çš„ç‰ˆæœ¬è¦†ç›–æ‰ï¼Œé‚£ä¹ˆå¦‚æœå†å½“å‰ä¸»æœºä¸­æœ‰å¤šä¸ªé¡¹ç›®æ—¶ï¼Œæ¯ä¸ªåº”ç”¨éƒ½æœ‰ä¸åŒçš„åŠŸèƒ½ï¼Œä¸€ä¸ªæœ‰é—ç•™ä»£ç ä¾èµ–äº2.7ç‰ˆæœ¬ï¼Œä¸€ä¸ªä¾èµ–äº3.5ç‰ˆæœ¬ï¼Œæ–°çš„é¡¹ç›®è¦æ±‚3.9ç‰ˆæœ¬ï¼Œé‚£ä¹ˆç°åœ¨å¦‚æœæƒ³è¦åœ¨ä¸€ä¸ªä¸»æœºæŠŠä¸‰ä¸ªappå…¨éƒ¨è¿è¡Œèµ·æ¥è¯¥æ€ä¹ˆåŠï¼Ÿ é‚£ä¹ˆå°±éœ€è¦Pythonè™šæ‹Ÿç¯å¢ƒåŸºäºç›®å½•æ–¹å¼å®ç°å¤šä¸ªpythonç‰ˆæœ¬å…±å­˜ã€‚ è½¯ä»¶å®‰è£… apt install virtualenv apt install virtualenvwrapper\rå®šåˆ¶bashçº§åˆ«çš„ç¯å¢ƒå˜é‡\rcd vim .bashrc export WORKON_HOME=$HOME/.virtualenvs\rsource /usr/share/virtualenvwrapper/virtualenvwrapper.shè™šæ‹Ÿç¯å¢ƒå‘½ä»¤ workon åˆ‡æ¢åˆ°æŒ‡å®šçš„è™šæ‹Ÿç¯å¢ƒ deactivate é€€å‡ºè™šæ‹Ÿç¯å¢ƒ mkvirtualenv æŒ‡å®špythonç‰ˆæœ¬åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ rmvirtualenv åˆ é™¤æŒ‡å®šçš„pythonç‰ˆæœ¬åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ mkvirtualenv -p /usr/bin/python2.7 python_v2.7 åœ¨æŒ‡å®šç›®å½•ä¸‹åˆ›å»ºå¯¹åº”ç‰ˆæœ¬çš„python site-packages mkvirtualenv -p /usr/bin/python3.8 python_v3.8 mkvirtualenv -p /usr/bin/python3.9 python_v3.9 ","date":"2020-08-04","objectID":"/posts/redis/redis-4/:0:1","tags":["Redis"],"title":"Redis å…±äº«Sessionå®è·µ ï¼ˆå››ï¼‰","uri":"/posts/redis/redis-4/"},{"categories":["æ•°æ®åº“"],"content":"æ¨¡å—å®‰è£… pip install redispy\r#pythonå·¥å…·é›†\rpip install ipython\r#æŸ¥çœ‹å®‰è£…çš„package\rpip list WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('\u003curllib3.connection.VerifiedHTTPSConnection object at 0x7fe6924bdcd0\u003e: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/redispy/å‡ºç°ä»¥ä¸Šå‘Šè­¦ï¼Œæ›´æ¢pipæºä¸ºå›½å†…æº é˜¿é‡Œäº‘ http://mirrors.aliyun.com/pypi/simple/ ä¸­å›½ç§‘æŠ€å¤§å­¦ https://pypi.mirrors.ustc.edu.cn/simple/ è±†ç“£(douban) http://pypi.douban.com/simple/ æ¸…åå¤§å­¦ https://pypi.tuna.tsinghua.edu.cn/simple/ ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦ http://pypi.mirrors.ustc.edu.cn/simple/ ä¸´æ—¶ä½¿ç”¨ï¼š å¯ä»¥åœ¨ä½¿ç”¨pipçš„æ—¶å€™åœ¨åé¢åŠ ä¸Š-iå‚æ•°ï¼ŒæŒ‡å®špipæº pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple #æ³¨ï¼špip/pip.confâ€ E212: Cannot open file for writing é—®é¢˜æ˜¯è¦å…ˆåˆ›å»º ~/.pip æ–‡ä»¶å¤¹ã€‚ æ°¸ä¹…ä¿®æ”¹ï¼š linux: ä¿®æ”¹ ~/.pip/pip.conf (æ²¡æœ‰å°±åˆ›å»ºä¸€ä¸ª)ï¼Œ å†…å®¹å¦‚ä¸‹ï¼š #å¢åŠ é…ç½®æ–‡ä»¶ mkdir ~/.pip vim .pip/pip.conf [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple #pipç‰ˆæœ¬æŸ¥è¯¢ pip --version pip 20.0.2 from /root/.virtualenvs/python_v3.8/lib/python3.8/site-packages/pip (python 3.8) windows: #ç›´æ¥åœ¨userç›®å½•ä¸­åˆ›å»ºä¸€ä¸ªpipç›®å½•ï¼Œå¦‚ï¼šC:\\Users\\xx\\pipï¼Œåœ¨pip ç›®å½•ä¸‹æ–°å»ºæ–‡ä»¶pip.iniï¼Œ #æˆ–è€…æŒ‰ç…§ç½‘å‹çš„å»ºè®®ï¼šwin+R æ‰“å¼€ç”¨æˆ·ç›®å½•%HOMEPATH%ï¼Œåœ¨æ­¤ç›®å½•ä¸‹åˆ›å»º pip æ–‡ä»¶å¤¹ï¼Œåœ¨ pip ç›®å½•ä¸‹åˆ›å»º pip.ini æ–‡ä»¶, å†…å®¹å¦‚ä¸‹ [global] timeout = 6000 index-url = https://pypi.tuna.tsinghua.edu.cn/simple trusted-host = pypi.tuna.tsinghua.edu.c ç®€å•æ“ä½œ - ä»¥Stringä¸ºä¾‹ # å¯¼å…¥æ¨¡å—\rimport redis\r# æ–¹æ³•1\rr = redis.Redis(host='127.0.0.1', port=6379, db=2)\r# æ–¹æ³•2\rr = redis.StrictRedis(host='127.0.0.1', port=6379, db=2)\rredis-pyä½¿ç”¨connection poolæ¥ç®¡ç†å¯¹ä¸€ä¸ªredis serverçš„æ‰€æœ‰è¿æ¥ï¼Œé¿å…æ¯æ¬¡å»ºç«‹ã€é‡Šæ”¾è¿æ¥çš„å¼€\ré”€ã€‚é»˜è®¤ï¼Œæ¯ä¸ªRediså®ä¾‹éƒ½ä¼šç»´æŠ¤ä¸€ä¸ªè‡ªå·±çš„è¿æ¥æ± ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ç›´æ¥å»ºç«‹ä¸€ä¸ªè¿æ¥æ± ï¼Œç„¶åä½œä¸ºå‚\ræ•°Redisï¼Œè¿™æ ·å°±å¯ä»¥å®ç°å¤šä¸ªRediså®ä¾‹å…±äº«ä¸€ä¸ªè¿æ¥æ± \r# æ–¹æ³•3\rpool = redis.ConnectionPool(host='127.0.0.1', port=6379)\rr = redis.Redis(connection_pool=pool) # å¯¼å…¥æ¨¡å— import redis # åˆ›å»ºå¯¹è±¡ redis_obj = redis.Redis(host='127.0.0.1',port=6379,db=3) #è°ƒç”¨è®¾ç½®keyå€¼ redis_obj.set('key','value') #è·å–keyå€¼ redis_obj.get('key') #å•å€¼å®è·µ r.set('key', 'value', ex=5) æˆ– r.setex(\"key1\", 5, \"value1\") r.get('key') # å¤šå€¼å®è·µ r.mset(k1=\"v1\", k2=\"v2\") r.mset({'k3':\"v3\", 'k4':\"v4\"}) r.mget('k1', 'k2') r.mget(['k3', 'k4']) # è‡ªå¢è‡ªå‡ r.set('num',4) r.get('num') r.incr('num') r.incr('num', 6) r.incrby('num',6) r.decr('num') r.decr('num',3) æ³¨æ„ï¼šæ²¡æœ‰decrby # åˆ é™¤æ“ä½œ r.delete('num') # åˆ¤æ–­å­˜åœ¨ r.exists('num') # æ¨¡ç³ŠåŒ¹é… r.keys() r.keys('k*') r.keys('*2') # æŸ¥è¯¢æ•°æ®é‡ r.dbsize()","date":"2020-08-04","objectID":"/posts/redis/redis-4/:0:2","tags":["Redis"],"title":"Redis å…±äº«Sessionå®è·µ ï¼ˆå››ï¼‰","uri":"/posts/redis/redis-4/"},{"categories":["æ•°æ®åº“"],"content":"ç®€å•å®è·µ å¯¹äºå„ç§webæ¡†æ¶æ¥è¯´ï¼Œåªè¦æ¶‰åŠåˆ°redisï¼ŒåŸºæœ¬ä¸Šéƒ½æä¾›äº†ç›¸å…³çš„ å±æ€§é…ç½®ï¼Œæˆ‘ä»¬è¿™é‡Œä»¥ç®€å•çš„ Flask webæ¡†æ¶ä¸ºä¾‹ã€‚ å®‰è£…æ¨¡å— pip install Flask pip install flask-session æµ‹è¯•è¿è¡Œæ¡†æ¶ (python_v3.8) root@elkserver:~# vim python_flask.py #å¯¼å…¥æ¨¡å— from flask import Flask # åˆ›å»ºåº”ç”¨å¯¹è±¡ app = Flask(__name__) # å®šåˆ¶è·¯ç”±ç­–ç•¥ @app.route('/') def index(): return \"hello-flask app web\" # å¯åŠ¨åº”ç”¨ if __name__ == '__main__': app.run(host='192.168.10.110') (python_v3.8) root@elkserver:~# python python_flask.py * Serving Flask app 'python_flask' (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://192.168.10.110:5000/ (Press CTRL+C to quitFlask session å®˜æ–¹æ–‡æ¡£ï¼šhttps://flask-session.readthedocs.io/en/latest/ sessionå¸¸ç”¨çš„æ–¹æ³•å¦‚ä¸‹ getï¼šç”¨æ¥ä»sessionä¸­è·å–æŒ‡å®šå€¼ã€‚\rpopï¼šä»sessionä¸­åˆ é™¤ä¸€ä¸ªå€¼ã€‚\rkeysï¼šä»sessionä¸­è·å–æ‰€æœ‰çš„é”®ã€‚\ritemsï¼šä»sessionä¸­è·å–æ‰€æœ‰çš„å€¼ã€‚\rclearï¼šæ¸…é™¤å½“å‰è¿™ä¸ªç”¨æˆ·çš„sessionæ•°æ®ã€‚\rflushï¼šåˆ é™¤sessionå¹¶ä¸”åˆ é™¤åœ¨æµè§ˆå™¨ä¸­å­˜å‚¨çš„session_idï¼Œä¸€èˆ¬åœ¨æ³¨é”€çš„æ—¶å€™ç”¨å¾—æ¯”è¾ƒå¤šã€‚\rset_expiry(value)ï¼šè®¾ç½®è¿‡æœŸæ—¶é—´ã€‚ä»£ç å®ç° #å¯¼å…¥æ¨¡å— from flask import Flask, session from flask_session import Session import redis # åˆ›å»ºåº”ç”¨å¯¹è±¡ app = Flask(__name__) app.debug = True app.secret_key = 'x123asdaczxdasd' app.config['SESSION_TYPE'] = 'redis' app.config['SESSION_PERMANENT'] = True app.config['SESSION_USE_SIGNER'] = False app.config['SESSION_KEY_PREFIX'] = 'session:' app.config['SESSION_REDIS'] = redis.Redis(host='127.0.0.1', port='6379', db=4) Session(app) # å®šåˆ¶è·¯ç”±ç­–ç•¥ @app.route('/') def index(): return \"hello-flask app web\" @app.route('/set') def set_key(): session['user_name'] = \"zhangsan\" return 'ok' @app.route('/get') def get_key(): return session.get('user_name',\"æ²¡æœ‰è®¾ç½®username key\") @app.route('/pop') def pop_key(): session.pop('user_name') return session.get('user_name','pop key') @app.route('/clean') def clean_key(): session.clear() return session.get('user_name', 'clear key') # å¯åŠ¨åº”ç”¨ if __name__ == '__main__': app.run(host='192.168.10.110')å¯åŠ¨flask python flask_redis.py * Serving Flask app \"flask_redis\" (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: on * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit) * Restarting with stat * Debugger is active! * Debugger PIN: 170-146-674 ...æµè§ˆå™¨åˆ·æ–° http://0.0.0.0:5000/index ï¼ŒæŸ¥çœ‹æ•ˆæœ http://192.168.10.110:5000/set http://192.168.10.110:5000/get 127.0.0.1:6379\u003e select 4 OK 127.0.0.1:6379[4]\u003e KEYS * 1) \"session:8b6dd8af-fca8-4874-b92e-9ef13936287e\" 127.0.0.1:6379[4]\u003e get \"session:8b6dd8af-fca8-4874-b92e-9ef13936287e\" \"\\x80\\x04\\x95*\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\n_permanent\\x94\\x88\\x8c\\tuser_name\\x94\\x8c\\bzhangsan\\x94u.\" http://192.168.10.110:5000/pop get \"session:8b6dd8af-fca8-4874-b92e-9ef13936287e\" \"\\x80\\x04\\x95\\x12\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x94\\x8c\\n_permanent\\x94\\x88s.\" http://192.168.10.110:5000/clean 127.0.0.1:6379[4]\u003e KEYS * (empty array)","date":"2020-08-04","objectID":"/posts/redis/redis-4/:1:0","tags":["Redis"],"title":"Redis å…±äº«Sessionå®è·µ ï¼ˆå››ï¼‰","uri":"/posts/redis/redis-4/"},{"categories":["æ•°æ®åº“"],"content":"Redis åŸºç¡€çŸ¥è¯† Redis æ˜¯ Remote Dictionary Server(è¿œç¨‹æ•°æ®æœåŠ¡)çš„ç¼©å†™ï¼Œç”±æ„å¤§åˆ©äºº antirez(Salvatore Sanfilippo) å¼€å‘çš„ä¸€æ¬¾ å†…å­˜é«˜é€Ÿç¼“å­˜æ•°æ®åº“ï¼Œè¯¥è½¯ä»¶ä½¿ç”¨ C è¯­è¨€ç¼–å†™,å®ƒçš„æ•°æ®æ¨¡å‹ä¸º key-valueã€‚ å®˜æ–¹ä»‹ç»ï¼š Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache, and message broker. Redis provides data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, geospatial indexes, and streams. Redis has built-in replication, Lua scripting, LRU eviction, transactions, and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster. Redisæ˜¯ä¸€ä¸ªå¼€æºï¼ˆBSDè®¸å¯ï¼‰çš„å†…å­˜æ•°æ®ç»“æ„å­˜å‚¨ï¼Œè¢«ç”¨ä½œæ•°æ®åº“ã€ç¼“å­˜å’Œæ¶ˆæ¯ä»£ç†ã€‚Redisæä¾›çš„æ•°æ®ç»“æ„åŒ…æ‹¬ï¼šå­—ç¬¦ä¸²ã€å“ˆå¸Œå€¼ã€åˆ—è¡¨ã€é›†åˆã€å¸¦èŒƒå›´æŸ¥è¯¢çš„æ’åºé›†åˆã€ä½å›¾ã€è¶…æ—¥å¿—ã€åœ°ç†ç©ºé—´ç´¢å¼•å’Œæµã€‚Redisæœ‰å†…ç½®çš„å¤åˆ¶ã€Luaè„šæœ¬ã€LRUé©±é€ã€äº‹åŠ¡å’Œä¸åŒçº§åˆ«çš„ç£ç›˜æŒä¹…æ€§ï¼Œå¹¶é€šè¿‡Redis Sentinelå’ŒRedis Clusterçš„è‡ªåŠ¨åˆ†åŒºæä¾›é«˜å¯ç”¨æ€§ã€‚ å…³é”®ç‚¹ï¼š å¼€æºã€åŸºäºå†…å­˜çš„æ•°æ®ç»“æ„å­˜å‚¨ã€å¯ä»¥ä½œä¸ºæ•°æ®åº“ã€ç¼“å­˜ã€æ¶ˆæ¯ä»£ç† æä¾›äº† ä¹ç§+ çš„æ•°æ®ç»“æ„ã€‚ æ”¯æŒå„ç§åŠŸèƒ½ - å¤åˆ¶ã€å†…éƒ¨æ£€æµ‹ã€äº‹åŠ¡æ“ä½œã€æ•°æ®æŒä¹…åŒ–ã€é«˜å¯ç”¨åŠŸèƒ½(é«˜å¯ç”¨ã€é«˜æ‰©å±•) è¶‹åŠ¿ï¼š èµ„æ–™æ¥æºï¼šhttps://db-engines.com/en/ranking/key-value+store/all ","date":"2020-08-03","objectID":"/posts/redis/redis-3/:0:0","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"åº”ç”¨åœºæ™¯ æˆ‘ä»¬ç›´æ¥ä»å‡ ç§æ•°æ®æœ¬èº«çš„åº”ç”¨ç‰¹æ€§æ¥æè¿°ä¸€ä¸‹è¯¥è½¯ä»¶çš„åº”ç”¨åœºæ™¯ï¼š Sort Set (æœ‰åºé›†åˆ) æœ‰åºé›†åˆåœ¨æ™®é€šé›†åˆçš„åŸºç¡€ä¸Šåšäº†åˆ†æ•°æ¯”è¾ƒçš„ç‰¹æ€§ï¼Œæ‰€ä»¥ä¸»è¦ç”¨æ¥åšä¸€äº›åˆ†ç±»æ’åºç­‰åŠŸèƒ½ æ¯”å¦‚ï¼šæ’è¡Œæ¦œåº”ç”¨ï¼Œå– top n æ“ä½œ List (åˆ—è¡¨) åˆ—è¡¨æœ¬èº«å…·æœ‰æ’åºã€åˆ‡ç‰‡ç­‰ç‰¹æ€§ï¼Œå› ä¸ºredisçš„åŸºäºå†…å­˜çš„åˆ†å¸ƒå¼ç‰¹æ€§ï¼Œå®ƒä¸»è¦æ¥åšä¸€äº›æ•°æ®ç­›é€‰ã€æ’åºç­‰åŠŸèƒ½ æ¯”å¦‚ï¼šè·å¾—æœ€æ–° N ä¸ªæ•°æ® æˆ– æŸä¸ªåˆ†ç±»çš„æœ€æ–°æ•°æ®ç­‰ String (å­—ç¬¦ä¸²) å­—ç¬¦ä¸²çš„å…¶å®å°±æ˜¯æ•°æ®çš„ä¸´æ—¶å­˜å‚¨ï¼Œå€ŸåŠ©äºredisçš„å†…å­˜ç‰¹æ€§ï¼Œä¸»è¦åšä¸€äº›å…±äº«ä¹‹ç±»çš„åŠŸèƒ½ã€‚ æ¯”å¦‚ï¼šè®¡æ•°å™¨åº”ç”¨ã€ä¼šè¯å…±äº«ã€è´­ç‰©è½¦çŠ¶æ€æ•°æ®ç­‰ Set (é›†åˆ) é›†åˆä¸»è¦æ˜¯æ•°æ®çš„ç»Ÿè®¡ï¼Œç”±äºæ•°æ®æœ¬èº«å…·æœ‰æƒé‡çš„ç‰¹æ€§ï¼Œæ‰€ä»¥åˆ¤æ–­æ•°æ®æ˜¯å¦å­˜åœ¨çš„ç‰¹æ€§è¦æ¯”listå¥½å¾ˆå¤šã€‚ æ¯”å¦‚ï¼šè·å¾—å…±åŒæ•°æ®ã€å®‰å…¨é˜²å¾¡çš„ipåˆ¤æ–­ã€ç¤¾äº¤å¥½å‹ç­‰ ä»¥æ•°æ®å­˜å‚¨æœ¬èº«çš„è§’åº¦æ¥è¯´åœºæ™¯\ræœ‰åºé›†åˆ - å„ç§æ’è¡Œã€topn\rlist - æ•°æ®çš„æ’å¸ƒï¼Œé¡ºåº\rsorté›†åˆ - èŒƒå›´æ•°æ®åˆ—è¡¨\rstring - æ•°æ®çš„å­˜å‚¨\rhashå­—å…¸ - æ•°æ®åˆ†ç±»(å­åˆ†ç±»)åªè¦ä½ æœ‰ä¸°å¯Œçš„æƒ³è±¡åŠ›ï¼Œredisä½ æƒ³ç€ä¹ˆç”¨å°±æ€ä¹ˆç”¨ã€‚ ","date":"2020-08-03","objectID":"/posts/redis/redis-3/:1:0","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"Redis éƒ¨ç½² Redis çš„å®‰è£…æœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ä¸ªæ˜¯å¤šä¸»æœºç¯å¢ƒä¸‹ä½¿ç”¨ã€ä¸€ä¸ªæ˜¯å•å°ä¸»æœºéƒ¨ç½²æ–¹ä¾¿å®éªŒæµ‹è¯•ã€‚ é€šè¿‡è½¯ä»¶æºå®‰è£… # å®‰è£…æºä»“åº“ add-apt-repository ppa:redislabs/redis apt-get update # æŸ¥çœ‹è½¯ä»¶ç‰ˆæœ¬ apt info redis apt info redis-server # å®‰è£…è½¯ä»¶ apt install redis æ³¨æ„ï¼šä¼šè‡ªåŠ¨å®‰è£… redis-serverã€redis-tools ä¾èµ–è½¯ä»¶ # æœåŠ¡ç®¡ç† systemctl stop redisredis-server systemctl disable redis-server systemctl start redis-server # é»˜è®¤å¯åŠ¨çš„ç«¯å£å·6379 # è¿›å…¥redisæ•°æ®åº“ redis-cli # æŸ¥çœ‹ä¿¡æ¯ infoæ‰‹å·¥å®‰è£…æ–¹å¼ # ä¸‹è½½è½¯ä»¶ mkdir /data/softs \u0026\u0026 cd /data/softs wget https://download.redis.io/releases/redis-6.2.5.tar.gz # è§£å‹æ–‡ä»¶ tar xf redis-6.2.5.tar.gz cd redis-6.2.5/ # ç¡®è®¤å®‰è£…æ•ˆæœ grep 'make PREF' -B 2 README.md % make install # æŒ‡å®šå®‰è£…è·¯å¾„ You can use `make PREFIX=/some/other/directory install` if you wish to use a # ç¼–è¯‘å®‰è£… make PREFIX=/data/server/redis install # æ­¤å‘½ä»¤å·²ç»å°†makeç¼–è¯‘å®‰è£…çš„æ­¥éª¤æ•´åˆåœ¨ä¸€èµ· # æŸ¥çœ‹æ•ˆæœ # tree /data/server/redis/ /data/server/redis/ â””â”€â”€ bin â”œâ”€â”€ redis-benchmark â”œâ”€â”€ redis-check-aof -\u003e redis-server â”œâ”€â”€ redis-check-rdb -\u003e redis-server â”œâ”€â”€ redis-cli â”œâ”€â”€ redis-sentinel -\u003e redis-server â””â”€â”€ redis-server 1 directory, 6 files # é…ç½®ç¯å¢ƒå˜é‡ echo 'PATH=/data/server/redis/bin:$PATH' \u003e /etc/profile.d/redis.sh source /etc/profile.d/redis.sh # åˆ›å»ºåŸºæœ¬ç›®å½• mkdir /data/server/redis/{etc,log,data,run} -p # å› ä¸ºredis service é‡Œé¢æŒ‡å®šè¿™å‡ ä¸ªè·¯å¾„å› æ­¤è¦åˆ›å»ºå‡ºæ¥ç”¨äºæœåŠ¡å­˜æ”¾æ•°æ® cp redis.conf /data/server/redis/etc/å¯åŠ¨å‘½ä»¤ å‰å°æ–¹å¼å¯åŠ¨ redis redis-server /data/server/redis/etc/redis.conf æ£€æŸ¥æ•ˆæœ redisåœ¨å¯ä»¥åŸºäºåŒä¸€ä¸ªé…ç½®æ–‡ä»¶å¯åŠ¨å¤šä¸ªç¨‹åº # å¯åŠ¨å¤šä¸ªå®ä¾‹ redis-server /data/server/redis/etc/redis.conf --port 6666 redis-server /data/server/redis/etc/redis.conf --port 7777 redis-server /data/server/redis/etc/redis.conf --port 8888 redis-server /data/server/redis/etc/redis.conf --port 9999 # æŸ¥çœ‹æ•ˆæœ netstat -tnulp | grep redis åå°æ–¹å¼å¯åŠ¨ # å®šåˆ¶redisé…ç½®æ–‡ä»¶ root@python-auto:~# vim /data/server/redis/etc/redis.conf # daemonize no å°†redisçš„å¯åŠ¨è®¾å®šä¸ºåå°å¯åŠ¨ daemonize yes bind 10.0.0.12 127.0.0.1 #å¢åŠ æœ¬åœ°IPåœ°å€ # å¯åŠ¨redisæœåŠ¡ /data/server/redis/bin/redis-server /data/server/redis/etc/redis.conf # æŸ¥çœ‹æ•ˆæœ netstat -tnulp | grep redis # å…³é—­æœåŠ¡ redis-cli shutdown #æ³¨æ„æ­¤å‘½ä»¤æ˜¯å°†æœ¬æœºä¸­çš„æ‰€æœ‰å®ä¾‹è¿›ç¨‹å…¨éƒ¨å…³é—­ redis-cli -h 127.0.0.1 -p 6666 #è®¿é—®è¿›ç¨‹ kill -9 $(lsof -Pti :6379) #å¯åŠ¨å¤šå®ä¾‹ redis-server /data/server/redis/etc/redis.conf --port 6380 redis-server /data/server/redis/etc/redis.conf --port 6381 redis-server /data/server/redis/etc/redis.conf --port 6382 redis-server /data/server/redis/etc/redis.conf --port 6383 #ä¼ªé›†ç¾¤æ•ˆæœ","date":"2020-08-03","objectID":"/posts/redis/redis-3/:2:0","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"ç®€å•å®è·µ ","date":"2020-08-03","objectID":"/posts/redis/redis-3/:3:0","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"æŸ¥çœ‹é…ç½® root@python-auto:/etc/redis# grep -Env '#|^$' redis.conf 75:bind 127.0.0.1 -::1 ç»‘å®šåœ°å€ 94:protected-mode yes 98:port 6379 æš´éœ²ç«¯å£ 107:tcp-backlog 511 è¿æ¥é˜Ÿåˆ— 119:timeout 0 136:tcp-keepalive 300 257:daemonize yes åå°å¯åŠ¨ 275:supervised auto 289:pidfile /run/redis/redis-server.pid 297:loglevel notice 302:logfile /var/log/redis/redis-server.log 327:databases 16 é»˜è®¤16ä¸ªæ•°æ®åº“ 336:always-show-logo no 341:set-proc-title yes 358:proc-title-template \"{title} {listen-addr} {server-mode}\" 398:stop-writes-on-bgsave-error yes 404:rdbcompression yes 413:rdbchecksum yes 431:dbfilename dump.rdb æ•°æ®æ–‡ä»¶åç§° 444:rdb-del-sync-files no 454:dir /var/lib/redis æ•°æ®æ–‡ä»¶æ‰€åœ¨ç›®å½• ... ","date":"2020-08-03","objectID":"/posts/redis/redis-3/:3:1","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"å¸¸ç”¨æ“ä½œå‘½ä»¤ # è¿æ¥æ•°æ®åº“ root@python-auto:/etc/redis# redis-cli ç²¾ç®€è¿æ¥æ ¼å¼ 127.0.0.1:6379\u003e root@python-auto:/etc/redis# redis-cli -h localhost -p 6379 æ ‡å‡†è¿æ¥æ ¼å¼ localhost:6379\u003e root@python-auto:~# redis-cli --raw ä¸­æ–‡è¿æ¥æ ¼å¼ 127.0.0.1:6379\u003e # æµ‹è¯•æ•ˆæœ 127.0.0.1:6379\u003e ping PONG # é€€å‡ºæ•ˆæœ 127.0.0.1:6379[5]\u003e quitæŸ¥çœ‹å¸®åŠ©ä¿¡æ¯ï¼š â€‹ 127.0.0.1:6379\u003e help redis-cli 6.2.5 To get help about Redis commands type: \"help @\u003cgroup\u003e\" to get a list of commands in \u003cgroup\u003e \"help \u003ccommand\u003e\" for help on \u003ccommand\u003e \"help \u003ctab\u003e\" to get a list of possible help topics \"quit\" to exit To set redis-cli preferences: \":set hints\" enable online hints \":set nohints\" disable online hints Set your preferences in ~/.redisclirc æ³¨æ„ï¼š å†å²æ“ä½œå‘½ä»¤åœ¨ ~/.rediscli_history æ–‡ä»¶ä¸­å‘½ä»¤ç»„è§£æ rediså°†å¤§é‡çš„å‘½ä»¤è¿›è¡Œäº†ç®€å•çš„åˆ†ç»„æ“ä½œï¼Œå¯¹äº6.2.5æ¥è¯´ï¼Œä»–æœ‰ 15ä¸ªå‘½ä»¤ç»„ @generic é€šç”¨çš„å‘½ä»¤ç»„ @string å­—ç¬¦ç›¸å…³å‘½ä»¤ç»„ @list åˆ—è¡¨ç›¸å…³å‘½ä»¤ç»„ @set é›†åˆç›¸å…³å‘½ä»¤ç»„ @sorted_set æœ‰åºé›†åˆç›¸å…³å‘½ä»¤ç»„ @hash hashç›¸å…³å‘½ä»¤ç»„ @pubsub å‘å¸ƒè®¢é˜…ç›¸å…³å‘½ä»¤ç»„ @transactions äº‹åŠ¡ç›¸å…³å‘½ä»¤ç»„ @connection è¿æ¥ç›¸å…³å‘½ä»¤ç»„ @server æœåŠ¡ç›¸å…³å‘½ä»¤ç»„ @scripting è„šæœ¬ç›¸å…³å‘½ä»¤ç»„ @hyperloglog è¶…çº§æ—¥å¿—ç›¸å…³å‘½ä»¤ç»„ @cluster é›†ç¾¤ç›¸å…³å‘½ä»¤ç»„ @geo åŸºå› ç±»æ•°æ®ç›¸å…³å‘½ä»¤ç»„ @stream æµæ•°æ®ç›¸å…³å‘½ä»¤ç»„ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” #æŸ¥çœ‹å‘½ä»¤ç»„ 127.0.0.1:6379\u003e help @generic #æŸ¥çœ‹ç»„ä¸­å•ç‹¬å‘½ä»¤å¸®åŠ© 127.0.0.1:6379\u003e help ECHO ECHO message summary: Echo the given string since: 1.0.0 group: connectionç®€å•å®è·µ # é€‰æ‹©æ•°æ®åº“ 127.0.0.1:6379\u003e select 5 OK 127.0.0.1:6379[5]\u003e # æŸ¥çœ‹æ‰€æœ‰å±æ€§ä¿¡æ¯ 127.0.0.1:6379[5]\u003e info ... # æŸ¥çœ‹éƒ¨åˆ†å±æ€§ä¿¡æ¯ 127.0.0.1:6379[5]\u003e info cpu # CPU used_cpu_sys:1.222606 used_cpu_user:0.905046 used_cpu_sys_children:0.000000 used_cpu_user_children:0.000000 used_cpu_sys_main_thread:1.221889 used_cpu_user_main_thread:0.904515 # è·å–é…ç½®å±æ€§ 127.0.0.1:6379[5]\u003e CONFIG GET bind 1) \"bind\" 2) \"127.0.0.1 -::1\"Key ç›¸å…³å‘½ä»¤ # è·å–æ‰€æœ‰çš„keyä¿¡æ¯ 127.0.0.1:6379\u003e help KEYS KEYS pattern summary: Find all keys matching the given pattern since: 1.0.0 group: generic # åˆ¤æ–­ä¸€ä¸ªkeyæ˜¯å¦å­˜åœ¨ 127.0.0.1:6379\u003e help EXISTS EXISTS key [key ...] summary: Determine if a key exists since: 1.0.0 group: generic # è®¾ç½®ä¸€ä¸ªkey 127.0.0.1:6379\u003e help set SET key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT millisecondstimestamp| KEEPTTL] [NX|XX] [GET] summary: Set the string value of a key since: 1.0.0 group: string # è·å–ä¸€ä¸ªkey 127.0.0.1:6379\u003e help get GET key summary: Get the value of a key since: 1.0.0 group: string # åˆ é™¤ä¸€ä¸ªkey 127.0.0.1:6379\u003e help DEL DEL key [key ...] summary: Delete a key since: 1.0.0 group: generic # æŸ¥çœ‹keyçš„ç±»å‹ 127.0.0.1:6379\u003e help TYPE TYPE key summary: Determine the type stored at key since: 1.0.0 group: generic # è®¾ç½®ä¸€ä¸ªæœ‰è¿‡æœŸæœŸé™çš„key 127.0.0.1:6379\u003e help EXPIRE EXPIRE key seconds summary: Set a key's time to live in seconds since: 1.0.0 group: generic # æŸ¥çœ‹ä¸€ä¸ªkeyçš„æœ‰æ•ˆæ—¶é—´ 127.0.0.1:6379\u003e help TTL TTL key summary: Get the time to live for a key since: 1.0.0 group: generic # åˆ é™¤å½“å‰åº“çš„æ‰€æœ‰key 127.0.0.1:6379\u003e help FLUSHDB FLUSHDB [ASYNC|SYNC] summary: Remove all keys from the current database since: 1.0.0 group: server # åˆ é™¤å½“å‰æ•°æ®åº“æ‰€æœ‰çš„æ•°æ® 127.0.0.1:6379\u003e help FLUSHALL FLUSHALL [ASYNC|SYNC] summary: Remove all keys from all databases since: 1.0.0 group: server","date":"2020-08-03","objectID":"/posts/redis/redis-3/:3:2","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"String stringç±»å‹æ˜¯å®æˆ˜ä¸­åº”ç”¨æœ€å¤šçš„æ•°æ®ç±»å‹ï¼Œå¯ä»¥ç”¨äºå„ç§å…¶ä»–ç±»å‹æ•°æ®çš„å€¼çš„å­˜å‚¨ï¼Œéå¸¸æ–¹ä¾¿ ç‰¹ç‚¹ï¼š å…¶ä»–æ•°æ®ç±»å‹çš„æ•°æ®è¡¨ç°æ ·å¼ ç®€å•çš„æ•°æ®å­˜å‚¨ ç¤ºä¾‹ï¼š cookieã€sessionã€æ ¡éªŒç ç­‰ ç®€å•å®è·µ è®¾å®škey è®¾å®šä¸€ä¸ªæ™®é€šçš„key set key value è®¾å®šä¸€ä¸ªæœ‰è¿‡æœŸæ—¶é—´çš„key setex key seconds value åŒæ—¶è®¾å®šå¤šä¸ªå€¼ mset key1 value1 key2 value2 ... è·å–key è·å–ä¸€ä¸ªkey get key è·å–å¤šä¸ªkey mget key1 key2 ... åˆ é™¤key åˆ é™¤ä¸€ä¸ªkey del key1 åˆ é™¤å¤šä¸ªkey del key1 key2 ... ","date":"2020-08-03","objectID":"/posts/redis/redis-3/:3:3","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"List list æ˜¯ä¸€ä¸ªstringç±»å‹çš„ åˆ—è¡¨ï¼Œredisçš„æ¯ä¸ªlistéƒ½å¯ä»¥å­˜å‚¨ 2^32 -1 ä¸ªå…ƒç´ ï¼Œåˆ—è¡¨çš„å…ƒç´ æ–¹ä¾¿æ’ åºã€è·å–ã€ç»Ÿè®¡ç­‰ç›¸å…³æ“ä½œã€‚ å„ç§å„æ ·çš„åˆ—è¡¨åœºæ™¯éƒ½å¯ä»¥ è®¾å®škey å·¦ä¾§æ·»åŠ æ•°æ® lpush key value1 value2 å³ä¾§æ·»åŠ æ•°æ® rpush key value1 value2 æ’å…¥æŒ‡å®šå…ƒç´  linsert key before|after ç°æœ‰å…ƒç´  æ–°å…ƒç´  è·å–key è·å–åˆ—è¡¨æ•°æ® lrange key start stop æ³¨æ„ï¼šstart æ˜¯ä» 0å¼€å§‹ã€stopå¦‚æœä¸º -1çš„è¯ï¼Œä»£è¡¨æœ€åä¸€ä¸ªã€‚ è·å–keyæŒ‡å®šä½ç½®çš„å€¼ LINDEX key index è·å–keyåˆ—è¡¨çš„å€¼çš„æ•°é‡ LLEN key æ ¹æ®keyè·å–åœ¨å½“å‰åˆ—è¡¨çš„ä½ç½® LPOS key åˆ é™¤key ä»keyä¸­åˆ é™¤æŒ‡å®šçš„value lrem key count value æ³¨æ„ï¼š count \u003e 0: ä»å¤´å¾€å°¾ç§»é™¤æŒ‡å®šæ•°é‡ä¸ª value count \u003c 0: ä»å°¾å¾€å¤´ç§»é™¤æŒ‡å®šæ•°é‡ä¸ª value count = 0: ç§»é™¤æ‰€æœ‰çš„ value ä»keyçš„å·¦ä¾§åˆ é™¤æŒ‡å®šä¸ªæ•°çš„ value LPOP key [count] ä»keyçš„å³ä¾§åˆ é™¤æŒ‡å®šä¸ªæ•°çš„ value RPOP key [count] ä¿ç•™èŒƒå›´æ•°æ®ï¼ŒèŒƒå›´ä¹‹å¤–çš„éƒ½åˆ é™¤ LTRIM key èµ·å§‹ç´¢å¼• ç»“æŸç´¢å¼• å®è·µï¼š lpush mylist e b e b e b åœ¨å·¦ä¾§æ’å…¥ ebebebe lrang mylist 0 -1 æ˜¾ç¤º lrem mylist 3 e ä»å·¦ä¾§å¼€å§‹åˆ é™¤3ä¸ªe lrem mylist 3 b ä»å·¦ä¾§å¼€å§‹åˆ é™¤3ä¸ªb lrem mylist -1 3 ä»å°¾éƒ¨å³ä¾§åˆ é™¤1ä¸ª3 lrem mylist 0 a =0åˆ é™¤æ‰€æœ‰çš„a ltrim mylist 2 3 åªä¿ç•™2åˆ°3 å…¶ä»–çš„éƒ½åˆ é™¤","date":"2020-08-03","objectID":"/posts/redis/redis-3/:3:4","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"set set æ˜¯ä¸€ä¸ªstringç±»å‹çš„ é›†åˆï¼Œredisçš„æ¯ä¸ªlistéƒ½å¯ä»¥å­˜å‚¨ 2^32 -1 ä¸ªå…ƒç´ ï¼Œé›†åˆå…ƒç´ æ— åºä¸”ä¸é‡ å¤ï¼Œå¯ä»¥è¿›è¡Œå„ç§æ’åºç»Ÿè®¡åœºæ™¯ã€‚ åœºæ™¯ï¼š å†…å®¹ä¸é‡å¤çš„ä»»ä½•åœºæ™¯éƒ½å¯ä»¥ æ— åºé›†åˆ è®¾å®škey æ·»åŠ æ•°æ® SADD key member [member ...] æ³¨æ„ï¼š å› ä¸ºæ˜¯æ— åºçš„ï¼Œæ‰€ä»¥æŸ¥çœ‹çš„æ—¶å€™ï¼Œæ²¡æœ‰é¡ºåº å¦‚æœkeyä¸­å·²ç»å­˜åœ¨ memberï¼Œé‚£ä¹ˆä¸ä¼šé‡å¤å¢åŠ  åˆå¹¶å¤šä¸ªkey SUNION key [key ...] å°†å¤šä¸ªkeyçš„å†…å®¹åˆå¹¶åœ¨ä¸€èµ·ï¼Œç›¸åŒçš„memberåªä¼šå­˜åœ¨ä¸€ä¸ª è·å–key è·å–setæ•°æ® SMEMBERS key è·å–setä¸­çš„memberä¸ªæ•° SCARD key è·å–å¤šä¸ªkeyç›¸åŒçš„å†…å®¹ -- å–äº¤é›† SINTER key [key ...] è·å–å¤šä¸ªkeyä¸ç›¸åŒçš„å†…å®¹ -- å–å·®é›† SDIFF key [key ...]åˆ é™¤key ä»keyä¸­åˆ é™¤æŒ‡å®šçš„member\rSREM key member [member ...]\rä»keyçš„éšæœºåˆ é™¤æŒ‡å®šä¸ªæ•°çš„ member\rSPOP key [count] ","date":"2020-08-03","objectID":"/posts/redis/redis-3/:3:5","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"Sort set set æ˜¯ä¸€ä¸ªstringç±»å‹çš„ é›†åˆï¼Œredisçš„æ¯ä¸ªlistéƒ½å¯ä»¥å­˜å‚¨ 2^32 -1 ä¸ªå…ƒç´ ï¼Œé›†åˆå…ƒç´ æ— åºä¸”ä¸é‡ å¤ï¼Œå¯ä»¥è¿›è¡Œå„ç§æ’åºç»Ÿè®¡åœºæ™¯ã€‚ æœ‰åºé›†åˆ sortset åœºæ™¯ï¼š æ’è¡Œæ¦œã€topN è®¾å®škey æ·»åŠ æ•°æ®\rZADD key score member [score member ...]\ræ³¨æ„ï¼š\rå› ä¸ºæ¯ä¸ªmemberæœ‰scoreï¼Œæ‰€ä»¥æŸ¥çœ‹çš„æ—¶å€™ï¼Œæœ‰ä¼šæŒ‰ç…§scoreçš„å€¼è¿›è¡Œæ’åº\rå¦‚æœkeyä¸­å·²ç»å­˜åœ¨ memberï¼Œé‚£ä¹ˆä¸ä¼šé‡å¤å¢åŠ  è·å–key è·å–æœ‰åºé›†åˆæ•°æ®\rZRANGE key min max [REV]\ræ³¨æ„ï¼š\rmin æ˜¯ä» 0å¼€å§‹ã€maxå¦‚æœä¸º -1çš„è¯ï¼Œä»£è¡¨æœ€åä¸€ä¸ªã€‚\rrev ä»£è¡¨ååº\rè·å–æœ‰åºé›†åˆä¸­çš„æŒ‡å®šåˆ†æ•°èŒƒå›´çš„å…ƒç´ \rZRANGEBYSCORE key min max\rè·å–æœ‰åºé›†åˆå…ƒç´ çš„æƒé‡\rZSCORE key member\rè·å–æœ‰åºé›†åˆå…ƒç´ ä¸ªæ•°\rZCARD key åˆ é™¤key ä»keyä¸­åˆ é™¤æŒ‡å®šçš„member\rZREM key member [member ...]\rä»keyçš„éšæœºåˆ é™¤æŒ‡å®šä¸ªæ•°çš„ member\rZREMRANGEBYSCORE key min maxsortset å®è·µ\ræ·»åŠ æ•°æ®\rzadd mysortset 89 zhangsan 67 lisi 76 wangwu 91 madong 100 chunpeng\ræ­£åºæŸ¥çœ‹\rzrange mysortset 0 -1\rå€’åºæŸ¥çœ‹\rzrange mysortset 0 -1 rev\ræŸ¥çœ‹æœ‰åºé›†åˆkeyä¸ªæ•°\rzcard mysortset æŸ¥çœ‹66-89å¯¹åº”èŒƒå›´çš„äºº\rzrangebyscore mysortset 66 89\råˆ é™¤æŒ‡å®š zhangsan lisi\rzrem mysortset lishi zhangsan\råˆ é™¤æŒ‡å®šåˆ†æ•°èŒƒå›´çš„keyï¼Œåˆ é™¤60åˆ†ä»¥ä¸Šçš„äºº\rzremrangebyscore mysortset 60 100 ","date":"2020-08-03","objectID":"/posts/redis/redis-3/:3:6","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"Hash hash æ˜¯ä¸€ä¸ªstringç±»å‹çš„ å­—æ®µå’Œå€¼ çš„å…³è”è¡¨ï¼Œredisçš„æ¯ä¸ªhashéƒ½å¯ä»¥å­˜å‚¨ 2^32 -1 ä¸ªé”®å€¼å¯¹ï¼Œé å¸¸é€‚åˆäºå­˜å‚¨å¯¹è±¡åœºæ™¯ã€‚ ä½¿ç”¨åœºæ™¯ï¼š\ræŸä¸ªå¯¹è±¡çš„ç‰¹å®šå±æ€§ï¼š\rperson: {\rusername: zhangsan,\rpassword: 123456,\raddress: beijign,\rxxx: xxx\r} è®¾å®š key æ·»åŠ æ•°æ®\rHSET key field value [field value ...]\ræ³¨æ„ï¼šåœ¨å®è·µçš„æ—¶å€™ã€hset ä¹Ÿå¯ä»¥å®ç°æ·»åŠ å¤šä¸ªæ•°æ®å¯¹çš„æ•ˆæœ\ræ·»åŠ å¤šä¸ªæ•°æ®\rHMSET key field value [field value ...] è·å– key è·å–æ‰€æœ‰å±æ€§\rHKEYS key\rè·å–å¤šä¸ªå±æ€§çš„å€¼\rHMGET key field [field ...] åˆ é™¤ key ä»keyä¸­åˆ é™¤æŒ‡å®šçš„value\rHDEL key field [field ...]\rç›´æ¥åˆ é™¤keyæ‰€æœ‰çš„å†…å®¹\rdel key å®è·µï¼š\rå¢åŠ æ•°æ®\rhset person username zhangsan age 36 weight 140 height 1789 wife hanmeimei\ræŸ¥çœ‹é›†åˆ\rHKEYS person\rHMGET person username age wife\ræ™’é€‰åˆ é™¤å­—æ®µ\rhdel person wife","date":"2020-08-03","objectID":"/posts/redis/redis-3/:3:7","tags":["Redis"],"title":"Redis ç¯å¢ƒéƒ¨ç½² ï¼ˆä¸‰ï¼‰","uri":"/posts/redis/redis-3/"},{"categories":["æ•°æ®åº“"],"content":"NoSQL åŸºç¡€çŸ¥è¯† ä¸€ç±»æ–°å‡ºç°çš„æ•°æ®åº“(not only sql) ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:0:0","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"ç‰¹ç‚¹ æ³›æŒ‡éå…³ç³»å‹çš„æ•°æ®åº“ ä¸æ”¯æŒSQLè¯­æ³• å­˜å‚¨ç»“æ„è·Ÿä¼ ç»Ÿå…³ç³»å‹æ•°æ®åº“ä¸­çš„é‚£ç§å…³ç³»è¡¨å®Œå…¨ä¸åŒï¼Œnosqlä¸­å­˜å‚¨çš„æ•°æ®éƒ½æ˜¯KVå½¢å¼ NoSQLçš„ä¸–ç•Œä¸­æ²¡æœ‰ä¸€ç§é€šç”¨çš„è¯­è¨€ï¼Œæ¯ç§nosqlæ•°æ®åº“éƒ½æœ‰è‡ªå·±çš„apiå’Œè¯­æ³•ï¼Œä»¥åŠæ“…é•¿çš„ä¸šåŠ¡åœºæ™¯ ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:1:0","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"ç›¸å…³è½¯ä»¶ Redis ç®€ä»‹ï¼šå¼€æºçš„å†…å­˜ç»“æ„æ•°æ®åº“ å®˜ç½‘ï¼šhttps://redis.io/ æœ€æ–°ç‰ˆæœ¬ï¼š6.2.5 Mongodb ç®€ä»‹ï¼šåˆ†å¸ƒå¼æ–‡æ¡£å­˜å‚¨æ•°æ®åº“ï¼Œæ—¨åœ¨ä¸ºWEBåº”ç”¨æä¾›å¯æ‰©å±•çš„é«˜æ€§èƒ½æ•°æ®å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚ å®˜ç½‘ï¼šhttps://www.mongodb.com/ æœ€æ–°ç‰ˆæœ¬ï¼š4.4 CouchDB ç®€ä»‹ï¼šå¼€æºçš„é¢å‘æ–‡æ¡£çš„æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼Œå¯ä»¥é€šè¿‡ RESTful API æ–¹å¼è®¿é—®ã€‚ å®˜ç½‘ï¼šhttps://couchdb.apache.org/ ç‰ˆæœ¬ï¼š3.1.1 ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:2:0","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"NoSQL VS SQL ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:3:0","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"æ¦‚å¿µ SQL (Structured Query Language) å…³ç³»å‹æ•°æ®åº“ã€‚ ä¸»è¦ä»£è¡¨ï¼šSQL Serverï¼ŒOracleï¼ŒMySQL(å¼€æº)ï¼ŒPostgreSQL(å¼€æº)ã€‚ NoSQLï¼ˆNot Only SQLï¼‰æ³›æŒ‡éå…³ç³»å‹æ•°æ®åº“ã€‚ ä¸»è¦ä»£è¡¨ï¼šMongoDBï¼ŒRedisï¼ŒCouchDBã€‚ ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:3:1","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"å­˜å‚¨æ–¹å¼ SQLæ•°æ®å­˜åœ¨ç‰¹å®šç»“æ„çš„è¡¨ä¸­ï¼Œé€šå¸¸ä»¥æ•°æ®åº“è¡¨å½¢å¼å­˜å‚¨æ•°æ®ã€‚ NoSQLå­˜å‚¨æ–¹å¼æ¯”è¾ƒçµæ´»ï¼Œwebåœºæ™¯ä¸­ï¼Œé€šå¸¸ä»¥jsonæ ·å¼æ¥è¿›è¡Œæ•°æ®çš„æ‰¿è½½ã€‚ â€‹ æ•°æ®çš„å­˜å‚¨æ ·å¼ï¼š â€‹ SQL - äºŒç»´è¡¨æ ·å¼ â€‹ Nosql â€‹ æœ¬è´¨ä¸Šéƒ½æ˜¯ä»¥ k/v æ ·å¼æ¥å­˜å‚¨ï¼Œä½†æ˜¯åœ¨åº”ç”¨çš„æ—¶å€™ï¼Œå„æœ‰ç‰¹ç‚¹ â€‹ webå¼€å‘åœºæ™¯ä»¥jsonä¸ºä¸» â€‹ è‡ªåŠ¨åŒ–æµ‹è¯•åœºæ™¯ï¼Œä»¥ xml ä¸ºä¸»(æˆ‘è¯´çš„) ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:3:2","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"å­˜å‚¨ç†è®º åœ¨å®é™…æƒ…å†µä¸‹ï¼Œç½‘ç«™çš„æ•°æ®å­˜å‚¨ä¸å¯èƒ½åœ¨ä¸€å°ä¸»æœºä¸Šå®ç°äº¿ä¸‡çº§ç”¨æˆ·çš„è®¿é—®ã€‚åœ¨å¤§æ•°æ®é‡åœºæ™¯ä¸­æˆ‘ä»¬çš„æ•°æ®éƒ½æ˜¯ä»¥é›†ç¾¤çš„æ–¹å¼è¿›è¡Œå­˜å‚¨ã€‚æ­¤æ—¶é¢ä¸´ä¸€ä¸ªé—®é¢˜å°±æ˜¯é›†ç¾¤ä¸­çš„ä¸»æœºä¹‹é—´æ•°æ®å­˜å‚¨å¦‚ä½•è¾¾åˆ°ä¸€ä¸ªå¯å’Œè°ç¨³å®šè¿è¡ŒçŠ¶æ€ã€‚å› æ­¤æ¼”å˜å‡ºçš„å„ç§å„æ ·çš„ç†è®ºä¸‹é¢ä¸»è¦ä»¥ACIDã€BASEã€CAPæ–¹é¢ä»‹ç»ã€‚ ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:4:0","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"ACID å¯¹äºä¸€ä¸ªå…³ç³»å‹æ•°æ®åº“æ¥è¯´ï¼Œæœ‰ä¸€ä¸ªéå¸¸é‡è¦çš„åŸºæœ¬å±æ€§ï¼šACID ACIDï¼Œæ˜¯æŒ‡æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼ˆDBMSï¼‰åœ¨å†™å…¥æˆ–æ›´æ–°èµ„æ–™çš„è¿‡ç¨‹ä¸­ï¼Œä¸ºä¿è¯äº‹åŠ¡ï¼ˆtransactionï¼‰æ˜¯æ­£ç¡®å¯é çš„ï¼Œæ‰€å¿…é¡»å…·å¤‡çš„å››ä¸ªç‰¹æ€§. æ³¨æ„ï¼š äº‹åŠ¡æ˜¯ç”±ä¸€äº›åˆ—å¯¹ç³»ç»Ÿæ•°æ®è¿›è¡Œè®¿é—®æˆ–è€…æ›´æ–°æ“ä½œç»„æˆçš„ä¸€ä¸ªç¨‹åºæ‰§è¡Œå•å…ƒï¼Œç‹­ä¹‰çš„äº‹åŠ¡æŒ‡çš„æ˜¯æ•°æ®åº“äº‹åŠ¡ï¼Œè¿™é‡Œä¸»è¦æ¥è¯´åˆ†å¸ƒå¼åœºæ™¯çš„äº‹åŠ¡ ç‰¹æ€§ è§£é‡Š å¤‡æ³¨ åŸå­æ€§ (atomicity) ä¸€ä¸ªäº‹åŠ¡ï¼ˆtransactionï¼‰ä¸­çš„æ‰€æœ‰æ“ä½œï¼Œè¦ä¹ˆå…¨éƒ¨å®Œæˆï¼Œè¦ä¹ˆå…¨éƒ¨ä¸å®Œæˆï¼Œä¸ä¼šç»“æŸåœ¨ä¸­é—´æŸä¸ªç¯èŠ‚ã€‚ ä¸€è‡´æ€§ (consistency) åœ¨äº‹åŠ¡å¼€å§‹ä¹‹å‰å’Œäº‹åŠ¡ç»“æŸä»¥åï¼Œæ•°æ®åº“çš„å®Œæ•´æ€§æ²¡æœ‰è¢«ç ´åï¼Œä¾§é‡äºæ•´ä½“ã€‚ éš”ç¦»æ€§ (isolation) æ•°æ®åº“å…è®¸å¤šä¸ªå¹¶å‘äº‹åŠ¡åŒæ—¶å¯¹å…¶æ•°æ®è¿›è¡Œè¯»å†™å’Œä¿®æ”¹çš„èƒ½åŠ›ï¼Œéš”ç¦»æ€§å¯ä»¥é˜²æ­¢å¤šä¸ªäº‹åŠ¡å¹¶å‘æ‰§è¡Œæ—¶ç”±äºäº¤å‰æ‰§è¡Œè€Œå¯¼è‡´æ•°æ®çš„ä¸ä¸€è‡´ã€‚ æŒä¹…æ€§ (durability) äº‹åŠ¡å¤„ç†ç»“æŸåï¼Œå¯¹æ•°æ®çš„ä¿®æ”¹å°±æ˜¯æ°¸ä¹…çš„ï¼Œå³ä¾¿ç³»ç»Ÿæ•…éšœä¹Ÿä¸ä¼šä¸¢å¤±ã€‚ ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:4:1","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"CAP å¯¹äºæ•°æ®åº“æ¥è¯´ï¼Œå› ä¸ºå—åˆ°ä¸»æœºèµ„æºã€å®¹é‡é…ç½®ç­‰é™åˆ¶ï¼Œå¯¼è‡´æˆ‘ä»¬æ— æ³•ç”¨ä¸€ä¸ªæ•°æ®åº“ã€ä¸€å°ä¸»æœºæ¥å­˜å‚¨æ‰€æœ‰çš„æ•°æ®ï¼Œæ‰€ä»¥åœ¨å®é™…çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬çš„æ‰€æœ‰ä¿¡æ¯éƒ½æ˜¯åˆ†æ•£çš„å­˜å‚¨åœ¨ä¸åŒçš„ä¸»æœºä¸Šï¼Œè¿™å°±æ˜¯ â€“ åˆ†å¸ƒå¼æ•°æ®å­˜å‚¨ã€‚ å¯¹äºåˆ†å¸ƒå¼æ•°æ®å­˜å‚¨æ¥è¯´ï¼Œä¼ ç»Ÿçš„ACIDå°±ä¸å¤ªé€‚åˆäº†ï¼Œæ‰€ä»¥é’ˆå¯¹å½“å‰ç¯å¢ƒçš„ç‰¹æ€§å°±æ¢³ç†å‡ºæ¥ä¸€ç§ä¸ºäº‹åŠ¡æœåŠ¡çš„ç†è®º CAP â€“ å®ƒæ˜¯æŒ‡åœ¨ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä¸€è‡´æ€§ã€å¯ç”¨æ€§ã€å®¹é”™æ€§ä¸‰è€…ä¸å¯å…¼å¾—ã€‚ ç‰¹æ€§ è§£é‡Š ä¸€è‡´æ€§ (Consistency) æ›´æ–°æ“ä½œæˆåŠŸåï¼Œæ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€æ—¶é—´çš„æ•°æ®å®Œå…¨ä¸€è‡´ã€‚ å¯ç”¨æ€§ (Availability) ç”¨æˆ·è®¿é—®æ•°æ®æ—¶ï¼Œç³»ç»Ÿæ˜¯å¦èƒ½åœ¨æ­£å¸¸å“åº”æ—¶é—´è¿”å›ç»“æœã€‚ å®¹é”™æ€§(Partition Tolerance) åˆ†å¸ƒå¼ç³»ç»Ÿåœ¨é‡åˆ°æŸèŠ‚ç‚¹æˆ–ç½‘ç»œåˆ†åŒºæ•…éšœçš„æ—¶å€™ï¼Œä»ç„¶èƒ½å¤Ÿå¯¹å¤–æä¾›æ»¡è¶³ä¸€è‡´æ€§å’Œå¯ç”¨æ€§çš„æœåŠ¡ã€‚ åŸºäºCAPä¸‰ç§ç‰¹æ€§çš„ä¸¤ä¸¤ç»„åˆï¼Œå¯ä»¥å°†æˆ‘ä»¬ä¹‹å‰æ‰€è¯´çš„å„ç§æ•°æ®åº“æ¥è¿›è¡Œç®€å•çš„åˆ’åˆ†å½’ç±» CAPç†è®ºå‘Šè¯‰æˆ‘ä»¬ ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿä¸å¯èƒ½åŒæ—¶æ»¡è¶³ä¸€è‡´æ€§å¯ç”¨æ€§å’Œåˆ†åŒºå®¹é”™æ€§è¿™ä¸‰ä¸ªåŸºæœ¬éœ€æ±‚ï¼Œæœ€å¤šåŒæ—¶æ»¡è¶³. è¿™ä¸‰ä¸ªå½“ä¸­çš„ä¸¤é¡¹ ä¸€èˆ¬æ¥è¯´ï¼šæˆ‘ä»¬éƒ½æ˜¯åœ¨ä¸€è‡´æ€§å’Œåˆ†åŒºå®¹é”™æ€§ä¹‹é—´å¯»æ‰¾æ‰€è°“çš„å¹³è¡¡ ","date":"2020-08-02","objectID":"/posts/redis/redis-2/:4:2","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"BASE BASE ç†è®ºæ˜¯é’ˆå¯¹ NoSQL æ•°æ®åº“è€Œè¨€çš„ï¼Œå®ƒæ˜¯å¯¹ CAP ç†è®ºä¸­ä¸€è‡´æ€§ï¼ˆCï¼‰å’Œå¯ç”¨æ€§ï¼ˆAï¼‰è¿›è¡Œæƒè¡¡çš„ç»“æœï¼Œæºäºæå‡ºè€…è‡ªå·±åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿä¸Šå®è·µçš„æ€»ç»“ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯æ— æ³•åšåˆ°å¼ºä¸€è‡´æ€§ï¼Œä½†æ¯ä¸ªåº”ç”¨éƒ½å¯ä»¥æ ¹æ® è‡ªèº«çš„ç‰¹ç‚¹ï¼Œé‡‡ç”¨é€‚å½“æ–¹å¼è¾¾åˆ°æœ€ç»ˆä¸€è‡´æ€§ã€‚ BASEç†è®ºæ˜¯ç”±eBayçš„æ¶æ„å¸ˆæå‡ºã€‚ ç‰¹æ€§ è§£é‡Š åŸºæœ¬å¯ç”¨ (BasicallyAvailable) åˆ†å¸ƒå¼ç³»ç»Ÿåœ¨å‡ºç°ä¸å¯é¢„çŸ¥æ•…éšœæ—¶ï¼Œç³»ç»Ÿå…è®¸æŸå¤±éƒ¨åˆ†å¯ç”¨æ€§ï¼Œå³ä¿è¯æ ¸å¿ƒåŠŸèƒ½æˆ–è€…å½“å‰æœ€é‡è¦åŠŸèƒ½å¯ç”¨ã€‚æ¯”å¦‚è¯´ï¼šè®¿é—®çš„ç½‘é¡µé€Ÿåº¦ç¨å¾®é™ä½ä¸€äº›ï¼Œç”¨æˆ·é‡å¤§çš„æ—¶å€™ï¼Œå®æ—¶é™æµç­‰ è½¯çŠ¶æ€ (Softstate) å…è®¸ç³»ç»Ÿæ•°æ®å­˜åœ¨ä¸­é—´çŠ¶æ€ï¼Œä½†ä¸ä¼šå½±å“ç³»ç»Ÿçš„æ•´ä½“å¯ç”¨æ€§ï¼Œå³å…è®¸ä¸åŒèŠ‚ç‚¹çš„å‰¯æœ¬ä¹‹é—´å­˜åœ¨æš‚æ—¶çš„ä¸ä¸€è‡´æƒ…å†µã€‚æ¯”å¦‚ï¼šé›†ç¾¤ç³»ç»Ÿçš„å¤šä¸ªèŠ‚ç‚¹ä¹‹é—´è¿è¡Œxxç§’æ˜¯æ•°æ®åŒæ­¥å»¶è¿Ÿã€‚ æœ€ç»ˆä¸€è‡´ (EventuallyConsistent) è¿™æ˜¯ä¸‰ä¸ªç‰¹ç‚¹ä¸­æœ€é‡è¦çš„ï¼Œå®ƒå¼ºè°ƒçš„æ˜¯ç³»ç»Ÿä¸­æ‰€æœ‰ä¸»æœºçš„æ•°æ®å‰¯æœ¬ï¼Œåœ¨ä¸€æ®µæ—¶é—´åŒæ­¥åï¼Œæœ€ç»ˆèƒ½å¤Ÿè¾¾åˆ°ä¸€è‡´çŠ¶æ€ï¼Œè€Œä¸éœ€è¦å®æ—¶ä¿è¯æ•°æ®å‰¯æœ¬ä¸€è‡´ æœ€ç»ˆä¸€è‡´æ€§æ˜¯ BASE åŸç†çš„æ ¸å¿ƒï¼Œä¹Ÿæ˜¯ NoSQL æ•°æ®åº“çš„ä¸»è¦ç‰¹ç‚¹ï¼Œé€šè¿‡å¼±åŒ–ä¸€è‡´æ€§ï¼Œæé«˜ç³»ç»Ÿçš„å¯ä¼¸ç¼©æ€§ã€å¯é æ€§å’Œå¯ç”¨æ€§ã€‚è€Œä¸”å¯¹äºå¤§å¤šæ•° Web åº”ç”¨ï¼Œå…¶å®å¹¶ä¸éœ€è¦å¼ºä¸€è‡´æ€§ï¼Œå› æ­¤ç‰ºç‰²ä¸€è‡´æ€§è€Œæ¢å–é«˜å¯ç”¨æ€§ï¼Œæ˜¯å¤šæ•°åˆ†å¸ƒå¼æ•°æ®åº“äº§å“çš„æ–¹å‘ã€‚ å°ç»“ å‰æï¼š ä¸€å°ä¸»æœºçš„èµ„æºï¼Œæ— æ³•æŠ—ä½å¤§é‡ç”¨æˆ·æ•°æ®çš„æ“ä½œï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä»¥é›†ç¾¤çš„æ–¹å¼ï¼Œæ¥å¯¹æ•°æ®è¿›è¡Œç®¡ç† é—®é¢˜ï¼š å¦‚æœä¿è¯ é›†ç¾¤ä¸»æœº æ•°æ®æ˜¯ä¸€è‡´çš„ï¼Œå¯¹ç”¨æˆ·æ¥è¯´æ— æ‰€è°“ è¯é¢˜ï¼š äº‹åŠ¡ åœ¨ä¸€äº›ä¸šåŠ¡åœºæ™¯ä¸­ï¼Œä¸€ä¸ªæ“ä½œéœ€è¦å¤šä¸ªsqlæ‰èƒ½å¤Ÿå®ŒæˆæŒ‡å®šçš„åŠŸèƒ½ â€“ è¿™ä¸ªæ•´ä½“æ“ä½œå°±æ˜¯ä¸€ä¸ªäº‹åŠ¡ ACID A åŸå­æ€§ -- å¯¹äºäº‹åŠ¡æ“ä½œæ¥è¯´(å¤šæ¡å‘½ä»¤)ï¼Œè¦ä¹ˆæˆåŠŸï¼Œè¦ä¹ˆä¸€èµ·å¤±è´¥è¿˜åŸ\rB ä¸€è‡´æ€§ -- äº‹åŠ¡æ“ä½œå‰ å’Œå ï¼Œå¯¹äºæ•°æ®åº“æœ¬èº«çš„æ•°æ®è®¿é—®åŠŸèƒ½æ²¡æœ‰å½±å“\rC éš”ç¦»æ€§ -- åŒä¸€ä¸ªæ•°æ®é›†ç¾¤å†…éƒ¨çš„å¤šä¸ªäº‹åŠ¡æ“ä½œï¼Œå½¼æ­¤é—´æ— äº¤å‰å½±å“\rD æŒä¹…æ€§ -- æ•°æ®çš„è½åœ° CAP å‰æï¼š åœ¨åˆ†å¸ƒå¼é›†ç¾¤åœºæ™¯ä¸­ï¼Œæ— æ³•åšåˆ°å•å°ä¸»æœºèƒ½å¤Ÿå®ç°çš„ ACIDï¼Œé‚£ä¹ˆå°±åšä¸€ä¸ªç¼“å†² C -- é›†ç¾¤é—´æ‰€æœ‰ä¸»æœºæ•°æ®æ˜¯ä¸€è‡´çš„\r-- æ•°æ®åº“é›†ç¾¤çš„åŒæ­¥\rA -- é›†ç¾¤æ•´ä½“æä¾›çš„æœåŠ¡å¯¹ç”¨æˆ·æ¥è¯´ï¼Œå¯ç”¨\r-- P -- é›†ç¾¤æä¾›æœåŠ¡çš„è¿‡ç¨‹ä¸­ï¼Œå…è®¸å‡ºç°ä¸€äº›é”™è¯¯æ•°æ®ï¼Œæˆ–è€…è¿‡æœŸæ•°æ®ï¼Œ\r-- è®¿é—®è¯¾ç¨‹æ•°æ®çš„æ—¶å€™ï¼Œè¿è¡Œæ˜¯ä¸€ä¸ªæœˆå‰çš„è¿‡æœŸæ•°æ®\rBASE å‰æï¼š æˆ‘å·²ç»ç¡®å®šäº†ï¼Œé›†ç¾¤ç¯å¢ƒä¸­ï¼Œä¸å¯èƒ½ä¸å­˜å¼‚å¸¸æ•…éšœï¼Œæ¥ä¸‹æ¥åªèƒ½ä»CAP é‡Œé¢çš„ Cä¸€è‡´æ€§ å’Œ Aå¯ç”¨æ€§ ä¹‹é—´æ¥æ‰¾å¹³è¡¡ BA åŸºæœ¬å¯ç”¨\r-- æ— è®ºä»»ä½•æ—¶å€™ï¼Œæˆ‘ä»¬çš„ç½‘ç«™æœåŠ¡æ˜¯æ­£å¸¸ï¼Œè™½ç„¶æ•ˆæœæ²¡æœ‰é¢„æœŸçš„é‚£ä¹ˆå¥½\rS è½¯çŠ¶æ€\r-- é’ˆå¯¹çš„æ˜¯ é›†ç¾¤å†…éƒ¨çš„ä¸»æœº çŠ¶æ€è½¬æ¢çš„æ—¶å€™ -- ä¸€ä¸ªä¸­é—´è¿‡æ¸¡\rE æœ€ç»ˆä¸€è‡´æ€§\r-- å³ä½¿é›†ç¾¤å†…éƒ¨å‡ºç°æ•…éšœäº†ï¼Œä½†æ˜¯æœ€ç»ˆæ•…éšœæ¢å¤åï¼Œè¦ä¸å…¶ä»–ä¸»æœºæ•°æ®è¿›è¡ŒåŒæ­¥\r","date":"2020-08-02","objectID":"/posts/redis/redis-2/:4:3","tags":["Redis"],"title":"Redis åŸºç¡€-NoSQL ï¼ˆäºŒï¼‰","uri":"/posts/redis/redis-2/"},{"categories":["æ•°æ®åº“"],"content":"ç”¨æˆ·è®¿é—®çš„è¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿå„ç§å„æ ·çš„æ•°æ®ï¼Œä¸ºäº†è®©ç½‘ç«™èƒ½å¤Ÿæ­£å¸¸çš„è¿è¡Œï¼Œå¹¶ä¸”é«˜æ•ˆçš„è®©ç”¨æˆ·ç²¾å‡†çš„çœ‹åˆ°ç›¸åº”çš„æ•°æ®ï¼Œæˆ‘ä»¬å°±ä¼šåœ¨ä¸åŒä¸šåŠ¡åŠŸèƒ½åœºæ™¯ä¸­é‡‡ç”¨å„ç§å„æ ·çš„æ•°æ®ç±»å‹æ¥è¿›è¡Œæ‰¿è½½ã€‚ æ•°æ®åˆ†ç±» ç”¨æˆ·è®¿é—®çš„è¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿå„ç§å„æ ·çš„æ•°æ®ï¼Œä¸ºäº†è®©ç½‘ç«™èƒ½å¤Ÿæ­£å¸¸çš„è¿è¡Œï¼Œå¹¶ä¸”é«˜æ•ˆçš„è®©ç”¨æˆ·ç²¾å‡†çš„çœ‹åˆ°ç›¸åº”çš„æ•°æ®ï¼Œæˆ‘ä»¬å°±ä¼šåœ¨ä¸åŒä¸šåŠ¡åŠŸèƒ½åœºæ™¯ä¸­é‡‡ç”¨å„ç§å„æ ·çš„æ•°æ®ç±»å‹æ¥è¿›è¡Œæ‰¿è½½ã€‚ æŒ‰ç…§æˆ‘ä»¬çš„é¡¹ç›®åœºæ™¯è½åœ°çš„å®ç°æ–¹å¼åˆ†ä¸ºä¸‰ç§ç±»å‹ï¼š ç»“æ„åŒ–æ•°æ® åŠç»“æ„åŒ–æ•°æ® éç»“æ„åŒ–æ•°æ® ","date":"2020-08-01","objectID":"/posts/redis/redis-1/:0:0","tags":["Redis"],"title":"Redis åŸºç¡€-æ•°æ®åˆ†ç±» ï¼ˆä¸€ï¼‰","uri":"/posts/redis/redis-1/"},{"categories":["æ•°æ®åº“"],"content":"ç»“æ„åŒ–æ•°æ® æ‰€è°“çš„ç»“æ„åŒ–æ•°æ®ï¼ŒæŒ‡çš„æ˜¯æ•°æ®çš„è¡¨ç°æ ·å¼æœ‰ä¸€å®šçš„(æ¨ªç«–)ç»“æ„,ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œè¿™ç§æ•°æ®æ˜¯ä»¥äºŒç»´è¡¨çš„æ–¹å¼æ¥å®ç°æ•°æ®çš„å­˜å‚¨å’Œé€»è¾‘å…³ç³»çš„è¡¨è¾¾ã€‚ â€“ æ•°æ®ä»¥è¡Œä¸ºå•ä½ï¼Œä¸€è¡Œæ•°æ®è¡¨ç¤ºä¸€ä¸ªå®ä½“çš„ä¿¡æ¯ï¼Œæ¯ä¸€è¡Œæ•°æ®çš„å±æ€§æ˜¯ç›¸åŒçš„ã€‚ è¿™äº›æ•°æ®åœ¨å­˜å‚¨çš„æ—¶å€™ï¼Œä¸ºäº†å®ç°æ•°æ®çš„ç»Ÿä¸€å­˜å‚¨ï¼Œå¾€å¾€å¯¹æ•°æ®å­˜å‚¨çš„æ ¼å¼å’Œé•¿åº¦è§„èŒƒéƒ½è¿›è¡Œäº†ä¸€å®šç¨‹åº¦çš„é™åˆ¶ï¼Œè¿™äº›æ•°æ®çš„å…·ä½“å­˜å‚¨ä¸»è¦æ˜¯ä»¥å…³ç³»å‹æ•°æ®åº“è½¯ä»¶æ¥å®ç°ã€‚ ç»“æ„åŒ–æ•°æ®ï¼Œæ˜¯æŒ‡ç”±äºŒç»´è¡¨ç»“æ„æ¥é€»è¾‘è¡¨è¾¾å’Œå®ç°çš„æ•°æ®ï¼Œä¸¥æ ¼åœ°éµå¾ªæ•°æ®æ ¼å¼ä¸é•¿åº¦è§„èŒƒï¼Œä¸»è¦é€šè¿‡å…³ç³»å‹æ•°æ®åº“è¿›è¡Œå­˜å‚¨å’Œç®¡ç†ã€‚ ç»“æ„åŒ–æ•°æ®çš„å­˜å‚¨å’Œæ’åˆ—æ˜¯å¾ˆæœ‰è§„å¾‹çš„ï¼Œæ‰€ä»¥è¿™äº›æ•°æ®åœ¨æŸ¥è¯¢æˆ–ä¿®æ”¹ç­‰æ“ä½œçš„æ—¶å€™éå¸¸æ–¹ä¾¿ï¼Œä½†æ˜¯ç”±äºæ•°æ®åœ¨å­˜å‚¨çš„æ—¶å€™ï¼Œæœ‰ä¸€å®šçš„å…³è”å…³ç³»ï¼Œæ‰€ä»¥åœ¨æ•°æ®æ‰©å……å±æ€§æˆ–è€…æ”¶ç¼©å±æ€§çš„æ—¶å€™ä¸å¤ªæ–¹ä¾¿ â€“ æ‰©å±•æ€§ä¸å¥½ã€‚ æ•°æ®åœ¨å­˜å‚¨çš„è¿‡ç¨‹ä¸­æœ¬èº«æ˜¯æœ‰å¼ºå…³è”çš„ï¼Œåœ¨å‚¨å­˜æ•°æ®æœ¬èº«æœ‰ç›¸åº”çš„æ•°æ®ç»“æ„æ¥è¿›è¡Œé™åˆ¶ï¼Œä¸¤ä¸ªä¸åŒä¸šåŠ¡åœºæ™¯ä¹‹ä¸­çš„æ•°æ®ï¼Œä¸€æ—¦ä»–ä»¬ä¹‹é—´æœ‰ç›¸åº”å…³è”çš„è¯ï¼Œæˆ‘ä»¬ä¼šåŸºäºæ•°æ®å­˜å‚¨è½¯ä»¶æœ¬èº«çš„ç‰¹æ€§å°†è¿™äº›æ•°æ®å…³è”åœ¨ä¸€èµ·ã€‚å¯¹äºæ•°æ®å®Œæ•´çš„æ•´ä½“æ¥è¯´ä»–ä»¬ä¹‹é—´æ˜¯å¼ºå…³è”çš„æœ‰ç›¸åº”çš„ç»“æ„ã€‚ ç»“æ„åŒ–æ•°æ®è¡¨ç°æ ·å¼å¦‚ä¸‹ï¼š ID å§“å æ€§åˆ« ç”µè¯ ç±è´¯ 1 å¼ ä¸‰ ç”· 13382261344 å±±è¥¿ 2 æå›› å¥³ 18612388412 å±±ä¸œ å¯¹äºæŸä¸€æ¡æ•°æ®æ¥è¯´ï¼Œå®ƒçš„å†…éƒ¨æœ‰ç›¸åº”æ•°æ®å­˜å‚¨æ ¼å¼ï¼Œå¯¹äºæ•°æ®æ•´ä½“æ¥è¯´ç”±å¤§é‡æ•°æ®æ•´åˆä¸€èµ·ã€‚ å¯¹äºè¡Œæ¥è¯´æ˜¯ç”±å¤šä¸ªå…·ä½“çš„æ•°æ®ç»„åˆåœ¨ä¸€èµ·çš„å…·æœ‰ç‰¹æ®Šçš„å«ä¹‰ï¼Œå¯¹äºæ¯ä¸€åˆ—æ¥è¯´å¯¹æ•°æ®çš„å±æ€§ã€é•¿åº¦ æ˜¯å¦å¯ä»¥ä¸ºç©ºç­‰ç­‰éƒ½æœ‰ç›¸åº”çš„é™åˆ¶ã€‚å¯ä»¥é€šè¿‡æŸ¥çœ‹è¡¨ç»“æ„æŸ¥çœ‹ç›¸åº”çš„å±æ€§ã€‚å¦‚ mysql ä¸­ desc user; ","date":"2020-08-01","objectID":"/posts/redis/redis-1/:1:0","tags":["Redis"],"title":"Redis åŸºç¡€-æ•°æ®åˆ†ç±» ï¼ˆä¸€ï¼‰","uri":"/posts/redis/redis-1/"},{"categories":["æ•°æ®åº“"],"content":"åŠç»“æ„åŒ–æ•°æ® æ‰€è°“çš„åŠç»“æ„åŒ–æ•°æ®ï¼Œåº”ç”¨æ•°æ®ä½¿ç”¨çš„æ—¶å€™æœ‰ä¸€å®šçš„å…³è”ã€å±‚æ¬¡ï¼Œ ä½†æ˜¯è¿™äº›æ•°æ®åœ¨å­˜å‚¨çš„æ—¶å€™æ²¡æœ‰åƒå…³ç³»å‹æ•°æ®æœ‰æ•°æ®å±æ€§ã€é•¿åº¦ã€æ˜¯å¦ä¸ºç©ºã€æ•°æ®å”¯ä¸€æ€§çš„é™åˆ¶ã€‚ä½†åœ¨å­˜å‚¨çš„æ—¶å€™æœ‰ä¸€å®šä¸šåŠ¡å…³è”ã€‚ åŠç»“æ„åŒ–æ•°æ®çš„å­˜å‚¨ä¸€èˆ¬æ˜¯ä»¥æ–‡ä»¶çš„æ–¹å¼æ¥å®ç°çš„ï¼Œæ¯”è¾ƒå¸¸è§çš„æ–‡ä»¶æ ·å¼æœ‰ï¼šjsonã€XMLç­‰ã€‚ åœ¨jsonå­˜å‚¨è¿‡ç¨‹ä¸­ï¼Œä¼šæ„é€ å­—å…¸ç„¶åæŒ‰ç…§å›ºå®šæ ¼å¼è¿›è¡Œå­˜å‚¨é‡Œé¢çš„æ•°æ®è‡ªç”±è·å–ã€‚ Jsonæ•°æ® { \"status\": 200, \"message\": { \"person\": [ { \"id\": 1, \"name\": \"å¼ ä¸‰\", \"gender\": \"ç”·\", \"address\": { \"Country\": \"ä¸­å›½\", \"Province\": \"åŒ—äº¬å¸‚\", \"city\": \"åŒ—äº¬å¸‚\", \"district\": \"ä¸°å°åŒº\", \"town\": \"äº”é‡Œåº—\" }, }, ], } } æ•°æ®å…³ç³» []ä¸­æ‹¬å·ä»£è¡¨çš„æ˜¯ä¸€ä¸ªæ•°ç»„æˆ–åˆ—è¡¨ {}å¤§æ‹¬å·ä»£è¡¨çš„æ˜¯ä¸€ä¸ªæ•°æ®å¯¹è±¡ åŒå¼•å·â€œâ€è¡¨ç¤ºçš„æ˜¯å±æ€§å€¼ å†’å·ï¼šä»£è¡¨çš„æ˜¯å‰åä¹‹é—´çš„å…³ç³»ï¼Œå†’å·å‰é¢æ˜¯å±æ€§çš„åç§°ï¼Œåé¢æ˜¯å±æ€§çš„å€¼XML æ•°æ® \u003c?xml version=\"1.0\" encoding=\"gb2312\"?\u003e \u003cnamelist\u003e \u003cname1\u003e \u003cID\u003e01\u003c/ID\u003e \u003cname\u003eå¼ ä¸‰\u003c/name\u003e \u003csex\u003eç”·\u003c/sex\u003e \u003caddress\u003eåŒ—äº¬å¸‚å¸‚ä¸°å°åŒºäº”é‡Œåº—\u003c/address\u003e \u003c/name1\u003e \u003cnamelist\u003e æ•°æ®å…³ç³» å­˜å‚¨æ ¼å¼æ˜¯ä»¥èŠ‚ç‚¹ä¸ºä¸»,ä¸€ä¸ªèŠ‚ç‚¹è¡ç”Ÿå‡ºå¦å¤–çš„å­èŠ‚ç‚¹ æ¯ä¸ªèŠ‚ç‚¹éµå¾ªhtmlçš„é£æ ¼ï¼Œä½†æ˜¯é‡Œé¢çš„æ ‡ç­¾å±æ€§æ˜¯æˆ‘ä»¬è‡ªå®šä¹‰çš„ã€‚XML ä¸»è¦ç”¨äºæµ‹è¯•ï¼Œå¦‚æµ‹è¯•ç½‘é¡µåŠŸèƒ½ å°†æˆåŠŸçš„æ•°æ®å’Œä¸æˆåŠŸçš„æ•°æ®å…¨éƒ¨ç½—åˆ—å‡ºæ¥ï¼Œä»¥XMLçš„æ ·å¼å•ç‹¬å®ç°ï¼Œåœ¨æµ‹è¯•çš„æ—¶å€™åŸºäºå¯¹åº”çš„æµ‹è¯•è½¯ä»¶æ¡†æ¶åŠ è½½å®šåˆ¶å¥½çš„æµ‹è¯•æ•°æ®ä»¥è‡ªåŠ¨åŒ–çš„æ–¹å¼ï¼ŒæŠŠæ‰€æœ‰çš„åŠŸèƒ½å…¨éƒ¨æµ‹è¯•å‡ºæ¥ã€‚ æµ‹è¯•çš„æ•°æ®ä»…ä»…æ˜¯ä¸ºäº†åŠŸèƒ½æµ‹è¯•æ—¶ä½¿ç”¨çš„ï¼Œæ²¡æœ‰å¿…è¦å­˜å‚¨ä¸‹æ¥ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±ç”¨ç®€å•çš„Htmlåœºæ™¯å½“ä¸­çš„æ•°æ®å•ç‹¬å­˜å‚¨xmlæ ¼å¼æ¥è¿›è¡Œå­˜å‚¨ã€‚ æ•°æ®æœ¬èº«å­˜å‚¨æ²¡æœ‰å¼ºå…³è”ï¼Œä½†æ˜¯åº”ç”¨çš„æ—¶å€™æœ‰ä¸€å®šçš„å…³è”ç»“æ„ã€‚è¿™ç§æ•°æ®è¢«ç§°ä¹‹ä¸ºåŠç»“æ„åŒ–æ•°æ®ã€‚ ","date":"2020-08-01","objectID":"/posts/redis/redis-1/:2:0","tags":["Redis"],"title":"Redis åŸºç¡€-æ•°æ®åˆ†ç±» ï¼ˆä¸€ï¼‰","uri":"/posts/redis/redis-1/"},{"categories":["æ•°æ®åº“"],"content":"éç»“æ„åŒ–æ•°æ® æ‰€è°“éç»“æ„åŒ–æ•°æ®ï¼Œåœ¨å­˜å‚¨çš„æ—¶å€™æ•°æ®å’Œæ•°æ®ä¹‹é—´æ²¡æœ‰æ‰€è°“çš„å¼ºå…³è”ï¼Œåº”ç”¨åœºæ™¯ä¹Ÿæ²¡æœ‰æ‰€è°“çš„æ•´ä½“ä¸€èµ·ä½¿ç”¨ã€‚ ç”¨çš„æ—¶å€™ç›´æ¥è°ƒç”¨å°±å¯ä»¥äº†ã€‚ éç»“æ„åŒ–æ•°æ®ï¼Œå…¶å®å°±æ˜¯æ²¡æœ‰å›ºå®šç»“æ„çš„æ•°æ® â€“ å³ç»“æ„åŒ–æ•°æ®ä¹‹å¤–çš„ä¸€åˆ‡æ•°æ®ã€‚å®ƒä»¬å¸¸ä»¥ å›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ç­‰ æ ·å¼å­˜åœ¨ã€‚å¯¹äºè¿™ç±»æ•°æ®ï¼Œæˆ‘ä»¬ä¸€èˆ¬ç›´æ¥æ•´ä½“è¿›è¡Œå­˜å‚¨ï¼Œè€Œä¸”ä¸€èˆ¬å­˜å‚¨ä¸ºäºŒè¿›åˆ¶çš„æ•°æ®æ ¼å¼ã€‚ éç»“æ„åŒ–æ•°æ®ä¸€èˆ¬æœ‰ä¸¤ç§ç”Ÿæˆæ–¹å¼ï¼š äººä¸ºæ‰‹å·¥ç”Ÿæˆ - æ–‡æœ¬æ–‡ä»¶ã€å›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ã€ä¸šåŠ¡åº”ç”¨ç¨‹åºç­‰ã€‚ æœºå™¨è‡ªåŠ¨ç”Ÿæˆ - å«æ˜Ÿå›¾å½¢ã€ç§‘å­¦æ•°æ®ã€æ•°æ®ç›‘æ§ã€ä¼ æ„Ÿæ•°æ®ç­‰ ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œéç»“æ„åŒ–æ•°æ®å­˜å‚¨åœ¨éå…³ç³»æ•°æ®åº“ä¸­ï¼Œå¹¶ä½¿ç”¨NoSQLè¿›è¡ŒæŸ¥è¯¢ã€‚å·¥ä½œç”Ÿæ´»ï¼Œéç»“æ„åŒ–æ•°æ®æ˜¯è¶Šæ¥è¶Šå¤šï¼Œå æ¯”è¿œè¿œçš„è¶…å‡ºç»“æ„åŒ–æ•°æ®ã€‚ èµ„æ–™æ¥æºï¼šhttps://db-engines.com/en/ranking æ•°æ®è½¯ä»¶çš„åº”ç”¨ ç›®å‰ ç»“æ„åŒ–è½¯ä»¶è¿˜æ˜¯å æ®ç»å¯¹çš„ä½ç½® éç»“æ„åŒ–æ•°æ®è½¯ä»¶ï¼Œåœ¨ç‰¹å®šåœºæ™¯ä¸­ï¼Œå æ®ä¸€å¸­åœ°ä½ ç›®å‰æ‰€æœ‰çš„è½¯ä»¶ï¼Œéƒ½æœ‰ä¸€ä¸ªè¶‹åŒçš„å‘å±• â€œæˆ‘æ˜¯ç»“æ„åŒ–æ•°æ®è½¯ä»¶ï¼Œä½†æ˜¯èƒ½åšå¯¹æ–¹çš„äº‹æƒ…â€œ å°ç»“ ç»“æ„åŒ–æ•°æ® 1 æ•°æ®å­˜å‚¨æœ¬èº«æ˜¯æœ‰æ„ä¹‰çš„ â€“ å¼ºå…³è”å’Œå­˜å‚¨çº¦æŸ 2 æ•°æ®å­˜å‚¨çš„æ•´ä½“ï¼Œåœ¨ä¸šåŠ¡åœºæ™¯ä¸­ä¹Ÿæœ‰å…³è” â€“ ä¸€å¯¹å¤šã€å¤šå¯¹ä¸€ã€ä¸€å¯¹ä¸€ç­‰ åŠç»“æ„åŒ–æ•°æ® 1 å¼€å‘åœºæ™¯ï¼š é¡µé¢çš„å±•ç¤º å’Œ å±•ç¤ºçš„æ•°æ® åˆ†å¼€ æ•°æ®æœ¬èº«æ²¡æœ‰æ„ä¹‰ï¼Œä½†æ˜¯ç»„åˆåœ¨ä¸€èµ·èƒ½å¤Ÿä½¿ç”¨ - json 2 æµ‹è¯•åœºæ™¯ï¼› è‡ªåŠ¨åŒ–æµ‹è¯• â€“ æ„é€ å¤§é‡çš„æµ‹è¯•æ•°æ®å•ç‹¬ä¿å­˜ - xml éç»“æ„åŒ–æ•°æ® æ•°æ®æœ¬èº«å­˜å‚¨å’Œä¸šåŠ¡åœºæ™¯å­˜å‚¨æ²¡æœ‰æ‰€è°“çš„å…³è” â€“ ä½†æ˜¯æˆ‘è¦çš„æ—¶å€™ï¼Œå¿…é¡»ç»™æˆ‘ kv æ³¨æ„ï¼š è¿™é‡Œçš„ç»“æ„ ä¸æ˜¯ æ•°æ®ç»“æ„ä¸ç®—æ³•é‡Œé¢ æ•°æ®å­˜å‚¨åº”ç”¨åˆ°çš„ç»“æ„ æŒ‡çš„æ˜¯ ä¸šåŠ¡åœºæ™¯ä¸­çš„æ•°æ®å…³è”å­˜å‚¨ ","date":"2020-08-01","objectID":"/posts/redis/redis-1/:3:0","tags":["Redis"],"title":"Redis åŸºç¡€-æ•°æ®åˆ†ç±» ï¼ˆä¸€ï¼‰","uri":"/posts/redis/redis-1/"},{"categories":null,"content":"å…³äºæˆ‘ ğŸ‘¨ğŸ»â€ğŸ’» ä¸€åäº‘åŸç”Ÿå·¥ç¨‹å¸ˆ ğŸŸçˆ±åƒå¥½åƒçš„é¥­,ç©å¥½ç©çš„æ¸¸æˆï¼Œçœ‹å¥½çœ‹çš„å‰§ ğŸ›¸ AIä¾èµ–æ‚£è€… @Ryan's Recent activity\rhttps://github.com/ryanxin7\r2020 å¹´æ¯•ä¸šåä¸ºäº†â€œæ··å£é¥­åƒâ€ä¾¿å¼€å¯äº†è¿ç»´å¼€å‘çš„å‡çº§ä¹‹è·¯ï¼Œåœ¨å‡çº§çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘å‘ç°æˆ‘å¾ˆå–œæ¬¢â€œæŠ˜è…¾â€ğŸ¤”ã€‚ å‘ç°äº†è‡ªå·±å¯¹æŠ€æœ¯çš„å…´è¶£å’Œçƒ­çˆ±ï¼Œä¹Ÿå–œæ¬¢ä¸æ–­åœ°å°è¯•æ–°çš„ä¸œè¥¿å’Œæ¢ç´¢æœªçŸ¥çš„é¢†åŸŸã€‚ æˆ‘å¸Œæœ›èƒ½å¤Ÿä¸ä»–äººäº¤æµå’Œåˆ†äº«è‡ªå·±çš„ç»éªŒå’Œå¿ƒå¾—ğŸ™ˆã€‚ åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ç›¸ä¿¡è‡ªå·±å¯ä»¥ä¸æ–­åœ°æˆé•¿å’Œè¿›æ­¥ï¼Œå®ç°è‡ªå·±çš„æ¢¦æƒ³å’Œç›®æ ‡ã€‚ ä¸ºæ‹æ¸…è„‘è¢‹ä¸­æ— åºçš„ç‰‡æ®µï¼Œäºæ˜¯æˆ‘å¼€å§‹åœ¨æ­¤è¿›è¡Œè®°å½•ğŸ“ã€‚\r","date":"2020-07-28","objectID":"/about/:1:0","tags":null,"title":"å…³äº","uri":"/about/"},{"categories":["Linux"],"content":"LNMPç½‘ç«™æ¶æ„å®æˆ˜ [[toc]] ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:0:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"1. å®æ–½æ­¥éª¤è¯´æ˜ :::tip æœåŠ¡å®æ–½æ­¥éª¤ äº†è§£LNMPæ¶æ„çš„ç»„æˆä½œç”¨ æ¶æ„çš„éƒ¨ç½² æ¶æ„é€šè®¯åŸç† LNMPæœåŠ¡ä¹‹é—´å¦‚ä½•å»ºç«‹ç®¡ç† è¿ç»´äººå‘˜ä»£ç ä¸Šçº¿ NFSæœåŠ¡å™¨å’ŒWebæœåŠ¡å™¨å»ºç«‹è”ç³» æ•°æ®åº“ã€å­˜å‚¨è¿œç«¯è¿ç§» ::: ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:1:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"1.1 Nginx æ¨¡å—å›é¡¾ Nginx æœåŠ¡çš„ä¼ä¸šåº”ç”¨ (nginxæ¨¡å—) å®ç°ç½‘ç«™é¡µé¢ç›®å½•ç´¢å¼•åŠŸèƒ½ (yumä»“åº“æ­å»º) å®ç°ç½‘ç«™è®¿é—®åˆ«ååŠŸèƒ½ server_name å®ç°ç½‘ç«™é¡µé¢ç”¨æˆ·è®¿é—®ç›‘æ§ keepalived_timeout 65s HTTPè¯·æ±‚æŠ¥æ–‡: è¯·æ±‚å¤´â€”connection: keepalivedâ€¦/closed çŸ­è¿æ¥ HTTPå“åº”æŠ¥æ–‡: å“åº”å¤´â€”connection: closed çŸ­è¿æ¥ VPNâ€”æ— æ³•è®¿é—®å¤–ç½‘/xshellæ— æ³•è¿œç¨‹è¿æ¥ å®ç°ç½‘ç«™æœåŠ¡æ—¥å¿—åŠŸèƒ½é…ç½® é”™è¯¯æ—¥å¿—: é”™è¯¯æ—¥å¿—çº§åˆ« è®¿é—®æ—¥å¿—: æ—¥å¿—çš„æ ¼å¼ä¿¡æ¯ è‡ªåŠ¨åŒ–åˆ†ææ—¥å¿—(ELK ä¸‰ä¸ªè½¯ä»¶) æ ¹æ®ç”¨æˆ·è®¿é—®uriè¿›è¡ŒåŒ¹é…å¤„ç† location = xxx ç²¾ç¡®åŒ¹é… ä¼˜å…ˆçº§01 location ^~ xxx ä¼˜å…ˆåŒ¹é… ä¼˜å…ˆçº§02 location ~ åŒºåˆ†å¤§å°å†™åŒ¹é… ä¼˜å…ˆçº§03 â€‹ location ~* ä¸åŒºåˆ†å¤§å°å†™ ä¼˜å…ˆçº§03 â€‹ location uri æ ¹æ®uriè¿›è¡ŒåŒ¹é… ä¼˜å…ˆçº§03 â€‹ location / é»˜è®¤åŒ¹é… ä¼˜å…ˆçº§æœ€ä½ â€‹ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:1:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"1.2 ä¼ä¸šåº”ç”¨: ç½‘ç«™ locationåº”ç”¨æ¡ˆä¾‹ ä¾‹å¦‚åœ¨æ´»åŠ¨æ—¶æœŸæ‰“æŠ˜ä¿ƒé”€ï¼Œç½‘ç«™çš„é¡µé¢ä¿¡æ¯å’Œå¹³å¸¸ä¸ä¸€æ ·ã€‚æˆ‘ä»¬ä¸å¯èƒ½æŠŠå¹³å¸¸çš„é¡µé¢ä¸ºæ´»åŠ¨ç›´æ¥è¿›è¡Œä¿®æ”¹ï¼Œè¿™æ—¶æˆ‘ä»¬å°±éœ€è¦è°ƒç”¨ä¸€ä¸ªä¸“é—¨åœ¨æ´»åŠ¨æ—¶ä¸Šçº¿çš„é¡µé¢ä½œä¸ºä¸»ç«™å¹¿å‘Šã€‚ æœ‰ä¸¤ä¸ªç«™ç‚¹ç›®å½•: å¹³å¸¸ç½‘ç«™çš„ç«™ç‚¹ç›®å½• /html/jd-normal èŠ‚æ—¥ç½‘ç«™çš„ç«™ç‚¹ç›®å½• /html/jd-teshu â€‹ location / { root /html/jd-normal } location / ç‰¹æ®Š { root /html/jd-teshu } ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:1:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"1.3 ç½‘ç«™é¡µé¢è·³è½¬åŠŸèƒ½ â€‹ ç¬¬ä¸€ç§æ–¹æ³•ï¼š server { location / { rewrite ^/(.*)$ https://www.ryanxin.com/$1 permanent; } } ç¬¬äºŒç§æ–¹æ³•ï¼š server { location / { return 301 https://www.ryanxin.com; } } ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:1:3","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"2. LNMP æ¶æ„ä»‹ç» L ä»£è¡¨ Linuxç³»ç»Ÿ æ³¨æ„: selinuxå¿…é¡»å…³é—­ é˜²ç«å¢™å…³é—­ /tmp 1777 mysql æœåŠ¡æ— æ³•å¯åŠ¨ N ä»£è¡¨ NginxæœåŠ¡ ä½œç”¨: å¤„ç†ç”¨æˆ·çš„é™æ€è¯·æ±‚ html jpg txt mp4/avi P ä»£è¡¨ php æœåŠ¡ ä½œç”¨: å¤„ç†åŠ¨æ€çš„é¡µé¢è¯·æ±‚ è´Ÿè´£å’Œæ•°æ®åº“å»ºç«‹å…³ç³» M ä»£è¡¨ mysqlæœåŠ¡éƒ¨ç½² ä½œç”¨: å­˜å‚¨ç”¨æˆ·çš„å­—ç¬¦ä¸²æ•°æ®ä¿¡æ¯ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:2:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"3. ç½‘ç«™çš„ LNMP æ¶æ„éƒ¨ç½² ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:3:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"3.1åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å’Œæ ¹ç›®å½• åˆ›å»ºç”¨æˆ· useradd -M -s /sbin/nologin www -u 1002 id www systemctl restart nginx åˆ›å»ºæˆ˜ç‚¹æ ¹ç›®å½• mkdir -p /html/bbs/ chown -R www.www /html/bbs/ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:3:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"3.2 ç¼–å†™ Nginx é…ç½®æ–‡ä»¶ vim /etc/nginx/nginx.conf server { server_name ryanxin.com; rewrite ^/(.*) http://www.ryanxin.com/$1 permanent; } server { listen 80; server_name www.ryanxin.com; error_page 500 502 503 504 /50x.html; location / { root /html/bbs; index index.html; } } ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:3:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"3.3 å®‰è£…æ•°æ®åº“è½¯ä»¶ yum install mariadb-server mariadb -y #è¡¥å……: æ•°æ®åº“åˆå§‹åŒ–è¿‡ç¨‹ mysql_install_db --basedir=path The path to the MariaDB installation directory. #æŒ‡å®šmysqlç¨‹åºç›®å½• --datadir=path The path to the MariaDB data directory. #æŒ‡å®šæ•°æ®ä¿¡æ¯ä¿å­˜çš„ç›®å½• --user=mysql #è®©mysqlç®¡ç†æ•°æ®ç›®å½• 700 åˆ›å»ºæ•°æ®åº“çš„å¯†ç ä¿¡æ¯: /application/mysql/bin/mysqladmin -u root password 'new-password' # ç»™æœ¬åœ°æ•°æ®åº“è®¾ç½®å¯†ç  /application/mysql/bin/mysqladmin -u root -h web01 password 'new-password' # ç»™è¿œç¨‹æ•°æ®åº“è®¾ç½®å¯†ç  mysqladmin -u root password 'xin123' --- è®¾ç½®å¯†ç  mysql -u root -pxin123 å¯åŠ¨æ•°æ®åº“æœåŠ¡ systemctl start mariadb.service systemctl enable mariadb.service ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:3:3","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"4. PHPæœåŠ¡éƒ¨ç½²æµç¨‹ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:4:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"4.1 æ›´æ–° æºå¸è½½ç³»ç»Ÿè‡ªå¸¦çš„PHPè½¯ä»¶ â€‹ yum remove php-mysql php php-fpm php-common rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:4:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"4.2 å®‰è£… PHP yum install -y php71w php71w-cli php71w-common php71w-devel php71w-embedded php71w-gd php71w-mcrypt php71w-mbstring php71w-pdo php71w-xml php71w-fpm php71w-mysqlnd php71w-opcache php71w-pecl-memcached php71w-pecl-redis php71w-pecl-mongodb ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:4:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"4.3 ç¼–å†™é…ç½®æ–‡ä»¶ vim /etc/php-fpm.d/www.conf user = www group = www #ä¿è¯nginxè¿›ç¨‹çš„ç®¡ç†ç”¨æˆ·å’ŒphpæœåŠ¡è¿›ç¨‹çš„ç®¡ç†ç”¨æˆ·ä¿æŒä¸€è‡´ systemctl start php-fpm LNMP æœåŠ¡é—´è°ƒç”¨å›¾ Nginx é€šè¿‡locationåŒ¹é…ä»¥PHPç»“å°¾çš„æ–‡ä»¶ï¼Œè°ƒç”¨Fastcgiæ¥å£æ‰§è¡Œfastcgi_pass å‘½ä»¤å‘é€ç»™PHPçš„php-famè¿›ç¨‹æ¥æ”¶ï¼Œwrapperè¿›ç¨‹è¿›è¡Œå¤„ç†ï¼Œå¤„ç†ååœ¨åŸè·¯è¿”å›ç»™nginxæœ€åå®¢æˆ·ç«¯å¯ä»¥çœ‹åˆ°åŠ¨æ€é¡µé¢ï¼Œå¦‚æœéœ€è¦è°ƒç”¨æ•°æ®åº“åœ¨é€šè¿‡phpè§£æå™¨è§£ææˆsqlè¯­å¥ä¸æ•°æ®åº“è¿›è¡Œè°ƒç”¨æ•°æ®æ“ä½œã€‚æœ€åç”ŸæˆåŠ¨æ€é¡µé¢è¿”å›ç»™nginxå®¢æˆ·ç«¯å¯ä»¥çœ‹åˆ°é¡µé¢ã€‚ è°ƒç”¨æµç¨‹ ç”¨æˆ·è®¿é—®ç½‘ç«™ â€” \u003e nginx(fastcgi_pass) â€“ FastCGIâ€“\u003e (php-fpm â€“ wrapper) php (phpè§£æå™¨) â€”\u003e mysql(è¯»å–æˆ–å†™å…¥) ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:4:3","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"5. å®ç° LNMP æ¶æ„æœåŠ¡ä¹‹é—´å»ºç«‹å…³ç³» Nginxæ— æ³•ç›´æ¥ å’Œ æ•°æ®åº“å»ºç«‹è”ç³»ï¼Œå› æ­¤è¦å…ˆå’ŒPHP å»ºç«‹å…³ç³»ã€‚ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:5:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"5.1 å®ç° Nginxä¸ PHP å»ºç«‹å…³ç³» ç¼–å†™ nginx é…ç½®æ–‡ä»¶ location ~ \\.php$ { root /www; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; include fastcgi_params; #å˜é‡é…ç½®æ–‡ä»¶ } systemctl nginx restart #é‡å¯æœåŠ¡ server { server_name ryanxin.com rewrite ^/(.*) http://www.ryanxin.com/$1 permanent; } server { listen 80; server_name www.ryanxin.com; error_page 500 502 503 504 /50x.html; location /{ root /html/bbs; index index.html; } location ~ \\.php$ { root /bbs; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; include fastcgi_params; } } ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:5:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"5.2 ç¼–å†™åŠ¨æ€èµ„æºæ–‡ä»¶æµ‹è¯•é¡µé¢ vim /html/blog/test_php.php \u003c?php phpinfo(); ?\u003e æµè§ˆå™¨è¾“å…¥åœ°å€è¿›è¡Œè®¿é—®æµ‹è¯• http://www.ryanxin.com/index.php æ³¨æ„ ï¼š è¦åœ¨æœ¬åœ°Hostæ–‡ä»¶æ‰‹åŠ¨æ·»åŠ åŸŸååœ°å€ï¼Œæ‰èƒ½å®ç°æœ¬åœ°åŸŸåè§£æè®¿é—®ã€‚ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:5:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"6. å®ç° PHP ä¸æ•°æ®åº“å»ºç«‹å…³ç³» ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:6:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"6.1 ç¼–å†™ PHP è¿æ¥æ•°æ®åº“æµ‹è¯•æ–‡ä»¶ # vim test_mysql.php \u003c?php $servername = \"localhost\"; $username = \"root\"; $password = \"oldboy123\"; //$link_id=mysql_connect('ä¸»æœºå','ç”¨æˆ·','å¯†ç '); //mysql -uç”¨æˆ· -på¯†ç  -h ä¸»æœº $conn = mysqli_connect($servername, $username, $password); if($conn) { echo \"mysql successful by root !\\n\"; }else{ die(\"Connection failed: \" . mysqli_connect_error()); } ?\u003e ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:6:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"6.2 è®¿é—®æµ‹è¯• http://www.ryanxin.com/test_mysql.php å¦‚æœè¿æ¥æˆåŠŸ ï¼šæç¤º Mysql successful by rootï¼ å¤±è´¥åˆ™æç¤ºæŠ¥é”™ä¿¡æ¯ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:6:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"7. éƒ¨ç½²æ­å»ºç½‘ç«™é¡µé¢ ä»£ç ä¸Šçº¿ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:7:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"7.1 å¸¸ç”¨çš„å¼€æºæºç ç½‘ç«™ â€‹ ä¸»ç«™ç½‘ç«™é¡µé¢: http://www.dedecms.com/ â€‹ è®ºå›ç½‘ç«™é¡µé¢: http://www.discuz.net/forum.php â€‹ åšå®¢ç½‘ç«™é¡µé¢: https://cn.wordpress.org/ â€‹ çŸ¥ä¹ç±»å‹ç½‘ç«™é¡µé¢: http://www.wecenter.com/?copyright ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:7:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"7.3 å°†æºç è§£å‹åæ”¾å…¥åˆ°ç«™ç‚¹ç›®å½•ä¸­ è¿™é‡Œæ¼”ç¤ºçš„æ˜¯ Wordpress åšå®¢ç³»ç»Ÿ tar xf wordpress-5.2.1.tar.gz mv ./* /html/bbs ä¿®æ”¹ç«™ç‚¹ç›®å½•æƒé™ chown -R www.www blog ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:7:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"7.4 è¿›è¡Œç½‘ç«™é¡µé¢åˆå§‹åŒ–æ“ä½œ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:7:3","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"7.5 å¯¹æ•°æ®åº“æœåŠ¡è¿›è¡Œé…ç½® --åˆ›å»ºæ•°æ®åº“ create databases wordpress; --æ£€æŸ¥ show databases; --åˆ›å»ºæ•°æ®åº“ç®¡ç†ç”¨æˆ·: grant all on wordpress.* to 'wordpress'@'localhost' identified by 'xin123'; --æ£€æŸ¥ select user,host from mysql.user --ä¼˜åŒ–: åˆ é™¤æ— ç”¨çš„ç”¨æˆ·ä¿¡æ¯ delete from mysql.user where user=\"\" and host=\"localhost\"; delete from mysql.user where user=\"\" and host=\"web01\"; flush privileges; --åˆ·æ–° åˆ©ç”¨blogç½‘ç«™å‘å¸ƒåšæ–‡ ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:7:4","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":"8. å¸¸è§é—®é¢˜è§£å†³ ä¸Šä¼ wordpressä¸»é¢˜,æŠ¥413é”™è¯¯,å¦‚ä½•è§£å†³? 1.ä¿®æ”¹nginxé…ç½®æ–‡ä»¶ vim blog.conf server { client_max_body_size 50m; #æŒ‡å®šç”¨æˆ·ä¸Šä¼ æ•°æ®çš„å¤§å°é™åˆ¶(é»˜è®¤1M) } ä¿®æ”¹php.inié…ç½®æ–‡ä»¶ upload_max_filesize = 50M #ä½¿PHPæ¥æ”¶ç”¨æˆ·ä¸Šä¼ çš„æ›´å¤§çš„æ•°æ®(é»˜è®¤2M) ","date":"2019-11-28","objectID":"/posts/linux-basic/lnmp/:8:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","LNMP"],"title":"å®æˆ˜æ¡ˆä¾‹-LNMPç½‘ç«™æ¶æ„","uri":"/posts/linux-basic/lnmp/"},{"categories":["Linux"],"content":" Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½² â€‹ Keepalived è½¯ä»¶æœ€æ—©æ˜¯é…åˆ LVS è´Ÿè½½å‡è¡¡è½¯ä»¶è€Œè®¾è®¡çš„ï¼Œç”¨æ¥ç®¡ç†å¹¶ç›‘æ§LVSé›†ç¾¤ç³»ç»Ÿä¸­å„ä¸ªæœåŠ¡èŠ‚ç‚¹çš„çŠ¶æ€ï¼Œåæ¥åˆåŠ å…¥äº†VRRP åè®®å¯ä»¥å®ç°é«˜å¯ç”¨çš„åŠŸèƒ½ã€‚ è½¯ä»¶ä¸»è¦æ˜¯é€šè¿‡ VRRP åè®®å®ç°é«˜å¯ç”¨åŠŸèƒ½çš„,VRRP æ˜¯Virtual Router Redundancy Protocolï¼ˆè™šæ‹Ÿè·¯ç”±å™¨å†—ä½™åè®®ï¼‰çš„ç¼©å†™ï¼ŒVRRPå‡ºç°çš„ç›®çš„å°±æ˜¯ä¸ºäº†è§£å†³é™æ€è·¯ç”±å•ç‚¹æ•…éšœé—®é¢˜çš„ï¼Œå®ƒèƒ½å¤Ÿä¿è¯å½“ä¸ªåˆ«èŠ‚ç‚¹å®•æœºæ—¶ï¼Œæ•´ä¸ªç½‘ç»œå¯ä»¥ä¸é—´æ–­åœ°è¿è¡Œ ","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:0:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"ä¸€ã€Keepalived è½¯ä»¶å·¥ä½œåŸç† â€‹ å¯åˆ VRRP çš„å‡ºç°æ˜¯ä¸ºäº†è§£å†³é™æ€è·¯ç”±çš„å•ç‚¹æ•…éšœã€‚VRRP æ˜¯ç”¨è¿‡IPå¤šæ’­çš„æ–¹å¼å®ç°é«˜å¯ç”¨å¯¹ä¹‹é—´é€šä¿¡çš„ã€‚å·¥ä½œæ—¶ä¸»æœåŠ¡å™¨èŠ‚ç‚¹å‘åŒ…ï¼Œå¤‡æœåŠ¡å™¨èŠ‚ç‚¹æ¥åŒ…ï¼Œå½“å¤‡æœåŠ¡å™¨èŠ‚ç‚¹æ¥æ”¶ä¸åˆ°ä¸»æœåŠ¡å™¨èŠ‚ç‚¹å‘çš„æ•°æ®åŒ…çš„æ—¶å€™ï¼Œå°±å¯åŠ¨æ¥ç®¡ç¨‹åºæ¥ç®¡ä¸»æœåŠ¡å™¨èŠ‚ç‚¹çš„èµ„æºã€‚å¤‡æœåŠ¡å™¨èŠ‚ç‚¹å¯ä»¥æœ‰å¤šä¸ªï¼Œé€šè¿‡ä¼˜å…ˆçº§ç«é€‰ã€‚ä¼˜å…ˆçº§æ•°å€¼è¶Šå¤§ä¼˜å…ˆçº§è¶Šå¤§ã€‚ ","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:1:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"äºŒã€Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½² ","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:2:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"1.ç¡®è®¤åå‘ä»£ç†æœåŠ¡æ˜¯å¦å·¥ä½œæ­£å¸¸ åœ¨kl1å’Œkl02æœåŠ¡å™¨ä¸Šæµ‹è¯•webæœåŠ¡å™¨æ˜¯å¦å¯ä»¥æ­£å¸¸ï¼ˆæœ€å¥½æœ‰3å°åå‘ä»£ç†åŠŸèƒ½çš„WebæœåŠ¡å™¨ï¼‰ curl -H host:www.rxinxin.org 192.168.10.10/webserver.html curl -H host:www.rxinxin.org 192.168.10.11/webserver.html curl -H host:www.rxinxin.org 192.168.10.11/webserver.html systemctl enable mariadb","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:2:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"2.åœ¨æµè§ˆå™¨ä¸Šæµ‹è¯•è®¿é—®kl1å’Œkl2 åŸŸå è§£æhostsæ–‡ä»¶ï¼Œå°†åŸŸåè§£æä¸º192.168.10.20ï¼Œè¿›è¡Œæµ‹è¯•è®¿é—® è§£æhostsæ–‡ä»¶ï¼Œå°†åŸŸåè§£æä¸º192.168.10.30ï¼Œè¿›è¡Œæµ‹è¯•è®¿é—® æµ‹è¯•å‰åŒæ­¥kl1å’Œkl2çš„ Nginx é…ç½®æ–‡ä»¶ scp -rp /app/nginx/conf/nginx.conf 192.168.10.30:/app/nginx/conf/ ","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:2:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"ä¸‰ã€å®‰è£… Keepalived æœåŠ¡è½¯ä»¶ ç¬¬ä¸€æ­¥ï¼šå®‰è£…è½¯ä»¶ yum install -y keepalivedç¬¬äºŒæ­¥ï¼šç¼–å†™keepalivedé…ç½®æ–‡ä»¶ vim /etc/keepalived/keepalived.conf\rman keepalived.conf //æŸ¥çœ‹æ–‡ä»¶è¯´æ˜ä¿¡æ¯é…ç½®æ–‡ä»¶ç»“æ„ï¼š GLOBAL CONFIGURATION --- å…¨å±€é…ç½®\rVRRPD CONFIGURATION --- vrrpé…ç½®\rLVS CONFIGURATION --- LVSæœåŠ¡ç›¸å…³é…ç½® ï¼ˆå¯ä»¥åˆ æ‰ä¸ç”¨ï¼‰ kl1ä¸» è´Ÿè½½å‡è¡¡å™¨é…ç½® global_defs { //å…¨å±€é…ç½® router_id kl1 //å®šä¹‰è·¯ç”±æ ‡è¯†ä¿¡æ¯ï¼Œç›¸åŒå±€åŸŸç½‘å”¯ä¸€ } vrrp_instance klg1 { //Vrrp é…ç½® state MASTER //å®šä¹‰å®ä¾‹ä¸­ä¸»å¤‡çŠ¶æ€çš„è§’è‰²ï¼ˆMASTER/BACKUPï¼‰ interface eth0 //è®¾ç½®ä¸»å¤‡æœåŠ¡å™¨è™šæ‹ŸIPåœ°å€æ”¾ç½®ç½‘å¡ä½ç½® virtual_router_id 31 //è™šæ‹Ÿè·¯ç”±IDæ ‡è¯†ï¼Œä¸åŒå®ä¾‹ä¸åŒï¼Œä¸»å¤‡ç›¸åŒ priority 150 //è®¾ç½®æŠ¢å ä¼˜å…ˆçº§ï¼Œæ•°å€¼è¶Šå¤§è¶Šä¼˜å…ˆ advert_int 1 //ä¸»å¤‡é—´é€šè®¯æ—¶é—´é—´éš” authentication { //ä¸»å¤‡é—´é€šè¿‡è®¤è¯å»ºç«‹è¿æ¥ auth_type PASS auth_pass 1111 } virtual_ipaddress { å®šä¹‰ä¸»å¤‡æœåŠ¡å™¨ä¹‹é—´ä½¿ç”¨çš„è™šæ‹ŸIPåœ°å€ä¿¡æ¯ 192.168.10.60/24 dev eth0 label eth0:1 } } /etc/init.d/keepalived reload //å¹³æ»‘é‡å¯ Keeplived kl2å¤‡ è´Ÿè½½å‡è¡¡å™¨é…ç½® global_defs { router_id kl2 } vrrp_instance klg1 { state BACKUP interface eth0 virtual_router_id 31 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.10.60/24 dev eth0 label eth0:1 } } /etc/init.d/keepalived reload","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:3:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"å››ã€éƒ¨ç½²é«˜å¯ç”¨æœåŠ¡æ—¶é‡åˆ°çš„é—®é¢˜ åŒæ—¶åœ¨keepalivedé«˜å¯ç”¨é›†ç¾¤ä¸­ï¼Œå‡ºç°äº†ä¸¤ä¸ªè™šæ‹ŸIPåœ°å€ä¿¡æ¯ï¼Œè¿™ç§æƒ…å†µå°±ç§°ä¸ºè„‘è£‚ è„‘è£‚æƒ…å†µå‡ºç°åŸå› ï¼š 1. å¿ƒè·³çº¿å‡ºç°é—®é¢˜\rç½‘å¡é…ç½®æœ‰é—®é¢˜\räº¤æ¢è®¾å¤‡æœ‰é—®é¢˜\rçº¿ç¼†è¿æ¥æœ‰é—®é¢˜\r2. æœ‰é˜²ç«å¢™è½¯ä»¶é˜»æ­¢é—®é¢˜\r3. virtual_router_id\ré…ç½®æ•°å€¼ä¸æ­£ç¡® æ€»ä¹‹ï¼šåªè¦å¤‡æœåŠ¡å™¨æ”¶ä¸åˆ°ä¸»æœåŠ¡å™¨å‘å‡ºçš„ç»„æ’­åŒ…ï¼Œå°±ä¼šæˆä¸ºä¸»æœåŠ¡å™¨ï¼Œè€Œä¸»æœåŠ¡å™¨èµ„æºæ²¡æœ‰é‡Šæ”¾ï¼Œå¤‡æœåŠ¡å™¨è¦ç¯¡ä½å°±ä¼šå‡ºç°è„‘è£‚ã€‚ ","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:4:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"äº”ã€åˆ©ç”¨shellè„šæœ¬å®ç°ç›‘æ§ç®¡ç† å¤‡è®¾å¤‡æœ‰ VIP å°±æ˜¯è¡¨ç¤ºä¸æ­£å¸¸\rçœŸæ­£å®ç°ä¸»å¤‡åˆ‡æ¢ 2. å‡ºç°è„‘è£‚æƒ…å†µäº† #!/bin/bash\rcheck_info=$(ip a|grep -c 192.168.10.60) //å®šä¹‰ä¸€ä¸ªå‚æ•°ä¸ºVIPåœ°å€ .60\rif [ $check_info -ne 0 ] //å¦‚æœç­‰äº 0 then\recho \"keepalived server error!!!\" //æ‰“å°å‘Šè­¦æç¤º keepalived æœåŠ¡å‡ºç°é”™è¯¯\rfi","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:5:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"å…­ã€Nginxåå‘ä»£ç†ç›‘å¬è™šæ‹ŸIPåœ°å€ ç¼–å†™nginxåå‘ä»£ç†é…ç½® server {\rlisten 192.168.10.60:80;\rserver_name www.rxinxin.org;\rroot html;\rindex index.html index.htm;\rlocation / {\rproxy_pass http://xinxin;\rproxy_set_header host $host;\rproxy_set_header X-Forwarded-For $remote_addr;\r}\r}\rserver {\rlisten 192.168.10.60:80;\rserver_name bbs.rxinxin.org;\rroot html;\rindex index.html index.htm;\rlocation / {\rproxy_pass http://xinxin;\rproxy_set_header host $host;\rproxy_set_header X-Forwarded-For $remote_addr;\r}\r}\r/application/nginx/sbin/nginx -s stop //Nginx æ›´æ”¹ip ä¸€å®šè¦é‡å¯\r/application/nginx/sbin/nginx\rnetstat -lntup|grep nginx //æŸ¥çœ‹ç«¯å£\rtcp 0 0 192.168.10.60:80 0.0.0.0:* LISTEN 53334/nginx è™šæ‹ŸIPåœ°å€ å®ç°ç›‘å¬æœ¬åœ°ç½‘å¡ä¸Šæ²¡æœ‰çš„IPåœ°å€ echo 'net.ipv4.ip_nonlocal_bind = 1' \u003e\u003e/etc/sysctl.conf æ›´æ”¹å†…æ ¸ sysctl -p ","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:6:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"ä¸ƒã€å°†é«˜å¯ç”¨å’Œåå‘ä»£ç†æœåŠ¡å»ºç«‹è”ç³» å› ä¸ºNginx åå‘ä»£ç†æœåŠ¡å¤„äºå¼‚å¸¸çŠ¶æ€ä¸‹ï¼ŒkeepalivedæœåŠ¡å¹¶æ²¡æœ‰ä»ä¸»æœåŠ¡å™¨åˆ‡æ¢åˆ°å¤‡æœåŠ¡å™¨ï¼Œæ‰€ä»¥å®¢æˆ·è®¿é—®ç½‘ç«™æ—¶åå‘ä»£ç†æœåŠ¡ä¸€ç›´å¤„äºæŒ‚äº†çš„å¼‚å¸¸çŠ¶æ€å¯¼è‡´ç½‘ç«™æ— æ³•æ­£å¸¸è®¿é—®ã€‚ å®ç°çš„ç›®çš„ï¼šNginxåå‘ä»£ç†æœåŠ¡åœæ­¢ï¼ŒKeepalivedæœåŠ¡ä¹Ÿåœæ­¢ ç¼–å†™è„šæœ¬ #!/bin/bash\rweb_info=$(ps -ef|grep [n]ginx|wc -l) //å½“Nginxè¿›ç¨‹å°äº2æ—¶\rif [ $web_info -lt 2 ]\rthen\r/etc/init.d/keepalived stop //å…³é—­keepalived æœåŠ¡\rfi2.è¿è¡Œè„šæœ¬ï¼Œå®ç°ç›‘æ§nginxæœåŠ¡ ç¼–è¾‘keepalivedæœåŠ¡é…ç½®æ–‡ä»¶ #å®šä¹‰ä¸€ä¸ªç›‘æ§è„šæœ¬ï¼Œè„šæœ¬å¿…é¡»æœ‰æ‰§è¡Œæƒé™\rscript \"/server/scripts/check_web.sh\" #æŒ‡å®šè„šæœ¬é—´éš”æ—¶é—´\rinterval 2 #è„šæœ¬æ‰§è¡Œå®Œæˆï¼Œè®©ä¼˜å…ˆçº§å€¼å’Œæƒé‡å€¼è¿›è¡Œè¿ç®—ï¼Œä»è€Œå®ç°ä¸»å¤‡åˆ‡æ¢ weight 2 }\rtrack_script {\rcheck_web\r} chmod +x check_kls.sh ç»™äºˆè„šæœ¬å¯æ‰§è¡Œæƒé™ ","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:7:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"å…«ã€å®ç°é«˜å¯ç”¨é›†ç¾¤æ¶æ„ä¸­åŒä¸»é…ç½® äº’ä¸ºä¸»å¤‡é…ç½®é…ç½® ç”±äºä¼ä¸šå®é™…ç¯å¢ƒï¼Œå¾ˆå°‘ç­‰ä¸»æœåŠ¡å™¨æŒ‚æ‰æ‰è°ƒç”¨å¤‡æœåŠ¡å™¨ï¼Œæ‰€ä»¥ä¼šå°†WebæœåŠ¡åˆ†é…ç»™ä¸¤èŠ‚ç‚¹æˆ–å¤šä¸ªé›†ç¾¤å¹¶è¡Œä½¿ç”¨èŠ‚çº¦æˆæœ¬ã€‚ kl1\rvrrp_instance klg1 {\rstate MASTER\rinterface eth0\rvirtual_router_id 31\rpriority 150\radvert_int 1\rauthentication {\rauth_type PASS\rauth_pass 1111\r}\rvirtual_ipaddress {\r192.168.10.60/24 dev eth0 label eth0:1\r}\r}\rvrrp_instance klg2 {\rstate BACKUP\rinterface eth0\rvirtual_router_id 32\rpriority 100\radvert_int 1\rauthentication {\rauth_type PASS\rauth_pass 1111\r}\rvirtual_ipaddress {\r192.168.10.80/24 dev eth0 label eth0:1\r}\r} kl2 vrrp_instance klg1 { state BACKUP interface eth0 virtual_router_id 31 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.10.60/24 dev eth0 label eth0:1 } } vrrp_instance klg2 { state MASTER interface eth0 virtual_router_id 32 priority 150 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.10.80/24 dev eth0 label eth0:1 } } æœ€åä¿®æ”¹ Nginx åå‘ä»£ç†æœåŠ¡é…ç½®æ–‡ä»¶çš„ç›‘å¬IPåœ°å€ä¿¡æ¯ å®Œæˆå¯¹ Keepalived äº’ä¸ºä¸»å¤‡èŠ‚ç‚¹çš„é…ç½®éƒ¨ç½²ã€‚ ","date":"2019-11-25","objectID":"/posts/linux-basic/linux3/:8:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","Keepalived"],"title":"Keepalived é«˜å¯ç”¨æœåŠ¡éƒ¨ç½²","uri":"/posts/linux-basic/linux3/"},{"categories":["Linux"],"content":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç» ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:0:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"ä¸€ã€SSHè¿œç¨‹ç™»å½•æœåŠ¡ä»‹ç»è¯´æ˜ SSHæ˜¯Secure Shell Protocolçš„ç®€å†™ï¼Œç”± IETF ç½‘ç»œå·¥ä½œå°ç»„ï¼ˆNetwork Working Groupï¼‰åˆ¶å®šï¼›åœ¨è¿›è¡Œæ•°æ®ä¼ è¾“ä¹‹å‰ï¼ŒSSHå…ˆå¯¹è”æœºæ•°æ®åŒ…é€šè¿‡åŠ å¯†æŠ€æœ¯è¿›è¡ŒåŠ å¯†å¤„ç†ï¼ŒåŠ å¯†ååœ¨è¿›è¡Œæ•°æ®ä¼ è¾“ã€‚ç¡®ä¿äº†ä¼ é€’çš„æ•°æ®å®‰å…¨ã€‚ â€‹ SSHæ˜¯ä¸“ä¸ºè¿œç¨‹ç™»å½•ä¼šè¯å’Œå…¶ä»–ç½‘ç»œæœåŠ¡æä¾›çš„å®‰å…¨æ€§åè®®ã€‚ åˆ©ç”¨SSHåè®®å¯ä»¥æœ‰æ•ˆçš„é˜²æ­¢è¿œç¨‹ç®¡ç†è¿‡ç¨‹ä¸­çš„ä¿¡æ¯æ³„éœ²é—®é¢˜ï¼Œåœ¨å½“å‰çš„ç”Ÿäº§ç¯å¢ƒè¿ç»´å·¥ä½œä¸­ï¼Œç»å¤§å¤šæ•°ä¼ä¸šæ™®éé‡‡ç”¨SSHåè®®æœåŠ¡æ¥ä»£æ›¿ä¼ ç»Ÿçš„ä¸å®‰å…¨çš„è¿œç¨‹è”æœºæœåŠ¡è½¯ä»¶ï¼Œå¦‚telnet(23ç«¯å£ï¼ŒéåŠ å¯†çš„)ç­‰ã€‚ åœ¨é»˜è®¤çŠ¶æ€ä¸‹ï¼ŒSSHæœåŠ¡ä¸»è¦æä¾›ä¸¤ä¸ªæœåŠ¡åŠŸèƒ½ï¼š ä¸€æ˜¯æä¾›ç±»ä¼¼telnetè¿œç¨‹è”æœºæœåŠ¡å™¨çš„æœåŠ¡ï¼Œå³ä¸Šé¢æåˆ°çš„SSHæœåŠ¡ï¼› å¦ä¸€ä¸ªæ˜¯ç±»ä¼¼FTPæœåŠ¡çš„sftp-serverï¼Œå€ŸåŠ©SSHåè®®æ¥ä¼ è¾“æ•°æ®çš„ï¼Œæä¾›æ›´å®‰å…¨çš„SFTPæœåŠ¡(vsftp,proftp)ã€‚ SSHè¿œç¨‹ç™»å½•æœåŠ¡æ’é”™æ€è·¯ æ£€æŸ¥é“¾è·¯æ˜¯å¦é€šç•…â€”ping(icmp)/tracert/traceroute æ£€æŸ¥é“¾è·¯æ˜¯å¦é˜»æ–­â€”å°†é˜²ç«å¢™åŠŸèƒ½å…³é—­ æ£€æŸ¥æœåŠ¡æ˜¯å¦å¼€å¯â€”ss/netstat -lntupï¼ˆæœåŠ¡ç«¯æ£€æŸ¥ï¼‰ /telnet/nmap/ncï¼ˆå®¢æˆ·ç«¯æ£€æŸ¥ï¼‰ [D:\\~]$ telnet 10.0.0.41 22 Connecting to 10.0.0.41:22 ... Connection established. To escape to local shell, press 'Ctrl+Alt+]'. SSH-2.0-OpenSSH_5.3 ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:1:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"äºŒã€SSHè¿œç¨‹ç™»å½•æœåŠ¡ç‰¹ç‚¹è¯´æ˜ SSHæœåŠ¡ç«¯å£å·ä¸º22 SSHæœåŠ¡é‡‡ç”¨å¯†æ–‡æ–¹å¼ä¼ è¾“æ•°æ® SSHæœåŠ¡é»˜è®¤æ”¯æŒrootç”¨æˆ·è¿›è¡Œè¿œç¨‹ç™»å½• [root@backup ~]# netstat -lntp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1227/sshd ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:2:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"ä¸‰ã€Telnetè¿œç¨‹ç™»å½•æœåŠ¡åŠŸèƒ½ä½œç”¨ SSHæœåŠ¡ç«¯å£å·ä¸º23 SSHæœåŠ¡é‡‡ç”¨æ˜æ–‡æ–¹å¼ä¼ è¾“æ•°æ® SSHæœåŠ¡é»˜è®¤ä¸æ”¯æŒrootç”¨æˆ·è¿›è¡Œè¿œç¨‹ç™»å½• Telnetéœ€è¦å•ç‹¬å®‰è£… yum install -y telnet-server telnet # xinetdç›¸å½“äºä¸€ä¸ªè¶…çº§å®ˆæŠ¤è¿›ç¨‹æœåŠ¡ï¼Œç”¨xinetdæœåŠ¡ä¸ºé‚£äº›å°è¿›ç¨‹ï¼Œå°æœåŠ¡æä¾›ç®¡ç† # é¦–å…ˆå°è¿›ç¨‹telnetè¦å…è®¸è¢«ç®¡ç†ï¼Œå³disable=no,é»˜è®¤æ˜¯yes [root@backup ~]# vim /etc/xinetd.d/telnet # default: on # description: The telnet server serves telnet sessions; it uses \\ # unencrypted username/password pairs for authentication. service telnet { flags = REUSE socket_type = stream wait = no user = root server = /usr/sbin/**in**.telnetd log_on_failure += USERID disable = no } # é‡å¯ä¸€ä¸‹ï¼Œxinetdï¼ˆå› ä¸ºä¹‹å‰æ²¡æœ‰å¯åŠ¨è¿‡ï¼Œæ‰€ä»¥ç”¨çš„startï¼‰ [root@backup ~]# netstat -lntup|grep 23 tcp 0 0 :::23 :::* LISTEN 1340/xinetd # å·²ç»æœ‰äº† #ç°åœ¨å¯ä»¥æµ‹è¯•äº†ï¼Œä½¿ç”¨telnetè¿æ¥æœåŠ¡å™¨ï¼ˆåˆšæ‰æ˜¯åœ¨backupä¸»æœºä¸Šå®‰è£…çš„ï¼‰ [D:\\~]$ telnet 10.0.0.41 connecting to 10.0.0.41:23... Connection established. To escape to local shell, press 'Ctrl+Alt+]'. CentOS release 6.9 (Final) Kernel 2.6.32-696.el6.x86_64 on an x86_64 backup login: root Password: Login incorrect backup login: # å› ä¸ºtelneté»˜è®¤ä¸æ”¯æŒroot backup login: xinxin Password: [xinxin**@backup** ~]$ # è¿ä¸Šäº† # å¯¹äºæ²¡æœ‰å®‰è£… telnetçš„ä¸»æœºï¼Œå°±è¿ä¸ä¸Šäº† [D:\\~]$ telnet 10.0.0.31 Connecting to 10.0.0.31:23... Could not connect to '10.0.0.31' (port 23): Connection failed. # ä½¿ç”¨sshè¿æ¥ [D:\\~]$ ssh 10.0.0.41 Connecting to 10.0.0.41:22... Connection established. To escape to local shell, press 'Ctrl+Alt+]'. WARNING! The remote SSH server rejected X11 forwarding request. [root@backup ~]# ç”¨wireshark æŠ“åŒ…æŸ¥çœ‹å‘ç° ä¸€ä¸ªæ˜¯æ˜æ–‡ï¼Œä¸€ä¸ªæ˜¯å¯†æ–‡ ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:3:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"å››ã€è¿œç¨‹ç®¡ç†æœåŠ¡æ¦‚å¿µè¯¦è§£ SSHè¿œç¨‹ç®¡ç†æœåŠ¡åŠ å¯†æŠ€æœ¯ é‡‡ç”¨å…¬é’¥å’Œç§é’¥è¿›è¡Œç®—æ³•åŠ å¯†ï¼Œå£ä»¤ç™»å½• sshè¿æ¥ç™»å½•è¿‡ç¨‹ sshå®¢æˆ·ç«¯å‘å‡ºè¿æ¥è¯·æ±‚ \\\u003e/root/.ssh/known_hosts æ¸…ç©ºæ–‡ä»¶ sshæœåŠ¡ç«¯ä¼šå‘å‡ºç¡®è®¤ä¿¡æ¯ï¼Œè¯¢é—®å®¢æˆ·ç«¯ä½ æ˜¯å¦çœŸçš„è¦è¿æ¥æˆ‘ ssh 10.0.0.41 sshå®¢æˆ·ç«¯è¾“å…¥å®Œæˆyesï¼Œä¼šç­‰åˆ°ä¸€ä¸ªå…¬é’¥ä¿¡æ¯ cat /root/.ssh/known_hosts sshæœåŠ¡ç«¯å°†å…¬é’¥ä¿¡æ¯å‘é€ç»™sshå®¢æˆ·ç«¯ sshå®¢æˆ·ç«¯åˆ©ç”¨å¯†ç è¿›è¡Œç™»å½• [root@web01 ~]# cat .ssh/known_hosts 10.0.0.41 ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA47PsJW7rLbHv7mREm2 juOVznW7dJamrWQSSHyprcvfQvMQjg6f7P9XLEfLfqx67kQvpUdZ65S52DMp cDlEmiiX8hseiM/8zIMBw3XH/F3BHPxlP54067QaRFRFPsZ4nFH4LCF 6u4uST1YBJfIvyKKpQb6s+ZplDIMwfZxeWTK9QSREKijQzf7CvLN+Ekt 9rYWqKFHrhv/Ae5Lxro0jKasgF3tIsvnq75cqYN57or+mZux5v jnrs/PkRsLLNnAkIJfDMbUoG3WfAjJD18UPL3glmyzuMNfj5YHT4Vj QKC9Eq+WmOsDKl/Q501xpCDXx/dunCXDy+MRXgs/hpRtInjw== # ä¸Šé¢æ—¶å®¢æˆ·ç«¯ç§é’¥ [root@web01 ~]# cd /etc/ssh/ [root@web01 ssh]# ll\\ [root@web01 ssh]# ll total 160 -rw-------. 1 root root 125811 Mar 22 2017 moduli -rw-r--r--. 1 root root 2047 Mar 22 2017 ssh_config -rw------ 1 root root 3876 Feb 22 19:36 sshd_config -rw------ 1 root root 3876 Feb 22 17:22 sshd_config.bak -rw-------. 1 root root 672 Jan 10 14:54 ssh_host_dsa_key -rw-r--r--. 1 root root 590 Jan 10 14:54 ssh_host_dsa_key.pub -rw-------. 1 root root 963 Jan 10 14:54 ssh_host_key -rw-r--r--. 1 root root 627 Jan 10 14:54 ssh_host_key.pub -rw-------. 1 root root 1675 Jan 10 14:54 ssh_host_rsa_key -rw-r--r--. 1 root root 382 Jan 10 14:54 ssh_host_rsa_key.pub # ssh [root@backup ssh]# cat ssh_host_rsa_key.pub ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA47PsJW7rLbHv7mREm2juOVznW7dJamr WQSSHyprcvfQvMQjg6f7P9XLEfLfqx67kQvpUdZ65S52DMpcDlEmiiX8hseiM/8zIMB w3XH/F3BHPxlP54067QaRFRFPsZ4nFH4LCF6u4uST1YBJfIvyKKpQb6s+ZplDIMwfZx eWTK9QSREKijQzf7CvLN+Ekt9rYWqKFHrhv/Ae5Lxro0jKasgF3tIsvnq75cqYN57o r+mZux5vjnrs/PkRsLLNnAkIJfDMbUoG3WfAjJD18UPL3glmyzuMNfj5YHT4VjQKC9E q+WmOsDKl/Q501xpCDXx/dunCXDy+MRXgs/hpRtInjw== # ä¸Šé¢æ˜¯æœåŠ¡ç«¯ç§é’¥ # åŠ å¯†ä¹Ÿæ˜¯åˆ©ç”¨ç§˜é’¥ # å®¢æˆ·ç«¯æœ‰é”å¤´ï¼ŒæœåŠ¡ç«¯æœ‰é’¥åŒ™å’Œé”å¤´ï¼Œæ¯æ¬¡å®¢æˆ·ç«¯è¦è¿æ¥çš„æ—¶å€™å°±å¸¦ç€é”å¤´ï¼Œ # å¦‚æœåœ¨æœåŠ¡ç«¯èƒ½ç”¨é’¥åŒ™æ‰“å¼€è¿™ä¸ªé”ï¼Œå°±è¿æ¥æˆåŠŸ SSHè¿œç¨‹ç®¡ç†æœåŠ¡è®¤è¯ç±»å‹ åŠ å¯†æŠ€æœ¯åˆ†ä¸ºv1å’Œv2ä¸¤ä¸ªç‰ˆæœ¬ sshv1ç‰ˆæœ¬ä¸ä¼šç»å¸¸æ›´æ¢é”å¤´å’Œé’¥åŒ™ï¼Œå› æ­¤ä¼šæœ‰å®‰å…¨éšæ‚£ sshv2ç‰ˆæœ¬ä¼šç»å¸¸æ›´æ¢é”å¤´å’Œé’¥åŒ™ï¼Œå› æ­¤æé«˜äº†è¿œç¨‹è¿æ¥å®‰å…¨æ€§ åŸºäºå¯†é’¥æ–¹å¼å®ç°è¿œç¨‹ç™»å½• sshç®¡ç†æœåŠ¡å™¨ä¸Šåˆ›å»ºå¯†é’¥å¯¹ä¿¡æ¯ï¼ˆå…¬é’¥ ç§é’¥ï¼‰ sshç®¡ç†æœåŠ¡å™¨ä¸Šå°†å…¬é’¥å‘é€ç»™è¢«ç®¡ç†æœåŠ¡å™¨ sshç®¡ç†æœåŠ¡å™¨å‘è¢«ç®¡ç†æœåŠ¡å™¨å‘é€è¿æ¥è¯·æ±‚ sshè¢«ç®¡ç†æœåŠ¡å™¨å‘ç®¡ç†æœåŠ¡å™¨å‘é€å…¬é’¥è´¨è¯¢ sshç®¡ç†æœåŠ¡å™¨å¤„ç†å…¬é’¥è´¨è¯¢è¯·æ±‚ï¼Œå°†å…¬é’¥è´¨è¯¢ç»“æœå‘é€ç»™è¢«ç®¡ç†ä¸»æœº sshè¢«ç®¡ç†æœåŠ¡å™¨æ¥æ”¶å…¬é’¥è´¨è¯¢å“åº”ä¿¡æ¯ï¼Œä»è€Œç¡®è®¤è®¤è¯æˆåŠŸ sshç®¡ç†æœåŠ¡ç«¯å¯ä»¥å’Œè¢«ç®¡ç†æœåŠ¡ç«¯å»ºç«‹åŸºäºå¯†é’¥è¿æ¥ç™»å½• ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:4:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"äº”ã€åŸºäºå¯†é’¥ç™»å½•æ–¹å¼éƒ¨ç½²æµç¨‹ ï¼ˆ1ï¼‰åœ¨ç®¡ç†ä¸»æœºä¸Šåˆ›å»ºå¯†é’¥å¯¹ä¿¡æ¯ - ssh-keygen -t dsa #\u003c- åˆ›å»ºå¯†é’¥å¯¹å‘½ä»¤ -t dsaè¡¨ç¤ºæŒ‡å®šå¯†é’¥å¯¹åŠ å¯†ç±»å‹ - Generating public/private dsa key pair. - Enter file in which to save the key (/root/.ssh/id_dsa): #\u003c- ç¡®è®¤ç§é’¥æ–‡ä»¶æ‰€ä¿å­˜çš„è·¯å¾„ - Created directory '/root/.ssh'. - Enter passphrase (empty for no passphrase): #\u003c- ç¡®è®¤æ˜¯å¦ç»™ç§é’¥è®¾ç½®å¯†ç ä¿¡æ¯ï¼ˆä¸€èˆ¬ä¸ºç©ºï¼‰ - Enter same passphrase again: - Your identification has been saved in /root/.ssh/id_dsa. - Your public key has been saved in /root/.ssh/id_dsa.pub. - The key fingerprint is: 95:12:71:f9:ea:34:18:e8:a4:fa:0b:0b:f5:92:5c:1b root@m01 - The key's randomart image is: +--[ DSA 1024]----+ | o... | | o.. | | .. o. | | o .o . | | . E+ So . | | o +.o. . + | |. =.o o . | | ..+ . | | ..o. | +-----------------+ [root@m01 ~]# ll /root/.ssh/ - total 8 -rw------ 1 root root 668 Sep 21 17:23 id_dsa -rw-r--r- 1 root root 598 Sep 21 17:23 id_dsa.pub ï¼ˆ2ï¼‰å°†ç®¡ç†ä¸»æœºä¸Šå…¬é’¥ä¿¡æ¯å‘é€ç»™è¢«ç®¡ç†ä¸»æœº - ssh-copy-id -i /root/.ssh/id_dsa.pub 172.16.1.31 - root@172.16.1.31's password: - Now try logging into the machine, with \"ssh '172.16.1.31'\", **and** check **in**: .ssh/authorized_keys - to make sure we haven't added extra keys that you weren't expecting. ç®¡ç†æœåŠ¡å™¨ç«¯ è¢«ç®¡ç†æœåŠ¡å™¨ç«¯ # ä¿å­˜åœ¨äº†è¿œç¨‹ä¸»æœºä¸­ç”¨æˆ·çš„å®¶ç›®å½•ä¸‹çš„.sshç›®å½•ä¸‹ [root**@nfs01** ~]# cd /root/.ssh/ [root**@nfs01** .ssh]# ll - total 4 -rw------ 1 root root 598 Feb 25 11:09 authorized_keys ssh-keygen -R 172.16.152.209 æ¸…ç©ºå…¬é’¥è®°å½•ï¼ˆ3ï¼‰è¿›è¡Œè¿œç¨‹ç®¡ç†æµ‹è¯•ï¼ˆåŸºäºå¯†é’¥çš„æ–¹å¼è¿›è¡Œè¿œç¨‹ç®¡ç†ï¼‰ ssh 172.16.1.31 \u003c- å¯ä»¥ä¸ç”¨è¾“å…¥å¯†ç ä¿¡æ¯ï¼Œå°±èƒ½ç™»é™†æˆåŠŸ ssh 172.16.1.31 uptime \u003c- å¯ä»¥ä¸ç”¨ç™»é™†åˆ°è¿œç¨‹ä¸»æœºï¼Œå°±å¯ä»¥ç›´æ¥æŸ¥çœ‹è¿œç¨‹ä¸»æœºä¿¡æ¯ ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:5:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"å…­ã€SSHæœåŠ¡ç«¯é…ç½®æ–‡ä»¶ä¿¡æ¯è¯´æ˜ é…ç½®æ–‡ä»¶è·¯å¾„ï¼š /etc/ssh/sshd_config ä¿®æ”¹SSHæœåŠ¡ç«¯ç«¯å£å· ä¸º52113 é…ç½®ç›‘å¬åœ°å€ å®¢æˆ·ç«¯æµ‹è¯•ï¼š ç›‘å¬åœ°å€è¯´æ˜å›¾ï¼š SSHæœåŠ¡ç«¯é…ç½®æ–‡ä»¶ä¿¡æ¯è¯´æ˜ /etc/ssh/sshd_config Port 52113 \u003c- ä¿®æ”¹sshæœåŠ¡ç«¯å£å·ä¿¡æ¯ ListenAddress 0.0.0.0 \u003c- ä¸»è¦ä½œç”¨æå‡ç½‘ç»œè¿æ¥å®‰å…¨æ€§ PSï¼šç›‘å¬åœ°å€åªèƒ½é…ç½®ä¸ºæœåŠ¡å™¨ç½‘å¡ä¸Šæ‹¥æœ‰çš„åœ°å€ PermitRootLogin no \u003c- æ˜¯å¦å…è®¸rootç”¨æˆ·è¿œç¨‹ç™»å½• PermitEmptyPasswords no \u003c- æ˜¯å¦å…è®¸ç©ºå¯†ç  UseDNS no \u003c- æ˜¯å¦è¿›è¡ŒDNSåå‘è§£æï¼ˆæå‡sshè¿œç¨‹è¿æ¥æ•ˆç‡ï¼‰ GSSAPIAuthentication no \u003c- æ˜¯å¦è¿›è¡Œè¿œç¨‹GSSAPIè®¤è¯ï¼ˆæå‡sshè¿œç¨‹è¿æ¥æ•ˆç‡ï¼‰ ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:6:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"ä¸ƒã€SSHè¿œç¨‹ç®¡ç†æœåŠ¡å…¥ä¾µé˜²èŒƒ åˆ©ç”¨å¯†é’¥ç™»å½•æé«˜å®‰å…¨æ€§ å®‰å…¨è®¾å¤‡ç­–ç•¥é˜»æ­¢è®¿é—®ï¼Œåªæ”¾å¼€å°‘é‡æœåŠ¡ç«¯å£ å¼€å¯SSHç›‘å¬åœ°å€åŠŸèƒ½ï¼Œåªç›‘å¬å†…ç½‘ç½‘å¡åœ°å€ åˆ©ç”¨æœåŠ¡å™¨ä¸é…ç½®å¤–ç½‘IPæé«˜å®‰å…¨æ€§ åˆ©ç”¨æˆæƒä¸ç³»ç»Ÿå®‰è£…æœ€å°åŒ–æé«˜å®‰å…¨æ€§ åˆ©ç”¨æŒ‡çº¹ä¿¡æ¯å¯¹ç³»ç»Ÿé‡è¦æ–‡ä»¶è¿›è¡ŒåŠ å¯†å¤„ç† åˆ©ç”¨ç³»ç»Ÿé‡è¦æ–‡ä»¶åŠ é”åŠŸèƒ½æé«˜å®‰å…¨æ€§ ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:7:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"å…«ã€SFTP å¸¸ç”¨æ“ä½œå‘½ä»¤æ€»ç»“ å‘½ä»¤ å¸®åŠ©ä¿¡æ¯ æ“ä½œè¯´æ˜ bye Quit sftp è¡¨ç¤ºé€€å‡º sftp ä¼ è¾“æ¨¡å¼ cd path Change remote directory to path æ”¹å˜è¿œç¨‹ç›®å½•ä¿¡æ¯ pwd Display remote working directory æ˜¾ç¤ºè¿œç¨‹ä¸»æœºå½“å‰ç›®å½•ä¿¡æ¯ lcd path Change local directory to â€˜pathâ€™ æ”¹å˜æœ¬åœ°ç›®å½•è·¯å¾„ä¿¡æ¯ lpwd Print local working directory è¾“å‡ºæœ¬åœ°ç›®å½•è·¯å¾„ä¿¡æ¯ get [-P] remote-path [local-path] Download file ä¸‹è½½æ–‡ä»¶å‘½ä»¤ put [-P] local-path [remote-path] Upload file ä¸Šä¼ æ–‡ä»¶å‘½ä»¤ ","date":"2019-11-22","objectID":"/posts/linux-basic/linux2/:8:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","SSH"],"title":"è¿œç¨‹ç®¡ç†æœåŠ¡çŸ¥è¯†ä»‹ç»","uri":"/posts/linux-basic/linux2/"},{"categories":["Linux"],"content":"Linuxçš„ç›®å½•ç»“æ„ç‰¹ç‚¹ ","date":"2019-11-21","objectID":"/posts/linux-basic/linux-basics/:0:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linuxçš„ç›®å½•ç»“æ„ç‰¹ç‚¹","uri":"/posts/linux-basic/linux-basics/"},{"categories":["Linux"],"content":"ç›®å½•ç»“æ„ç‰¹ç‚¹ ä¸€åˆ‡ä»æ ¹root å¼€å§‹ Linuxä¸­æ¯ä¸ªè®¾å¤‡å¯ä»¥æŒ‚åœ¨ä»»ä½•ç›®å½•ä¸Šé¢ Linuxä¸‹é¢è®¾å¤‡æ²¡æœ‰æŒ‚è½½æ— æ³•ä½¿ç”¨ linuxä¸­ä¸€åˆ‡çš†æ–‡ä»¶ ","date":"2019-11-21","objectID":"/posts/linux-basic/linux-basics/:1:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linuxçš„ç›®å½•ç»“æ„ç‰¹ç‚¹","uri":"/posts/linux-basic/linux-basics/"},{"categories":["Linux"],"content":"ä»€ä¹ˆæ˜¯æŒ‚è½½ï¼Ÿ ä¸¾ä¾‹ï¼šåœ¨ linux ç³»ç»Ÿä¸‹é¢ä½¿ç”¨å…‰ç›˜ æŠŠå…‰ç›˜æ”¾å…¥å…‰é©±ä¸­ æŸ¥çœ‹å…‰ç›˜ ll /dev/cdrom ä½¿ç”¨å…‰ç›˜ cat ä¹±ç  æŠŠå…‰ç›˜æŒ‚è½½ mount /dev/cdrom /mnt/ read-only åªè¯» df-h æŸ¥çœ‹ç³»ç»Ÿç©ºé—´è°æŒ‚è½½è·¯å¾„ è¿›å…¥ç›®å½•ä½¿ç”¨ cd /mnt å®é™…ä¸Šè¿›å…¥äº†å…‰ç›˜ å¯ä»¥çœ‹åˆ°å…‰ç›˜å†…å®¹ å¦‚æœç¡¬ç›˜è®¾å¤‡ä¸æŒ‚è½½æ˜¯æ²¡æœ‰è®¿é—®å…¥å£çš„,å°±åƒæˆ¿å­æ²¡æœ‰å¤§é—¨ï¼ŒæŒ‚è½½å°±åƒç»™è®¾å¤‡æ‰¾äº†ä¸€ä¸ªå…¥å£ã€‚ mount /dev/cdrom /mnt è®¾å¤‡ æŒ‚è½½ç‚¹(mount point) ","date":"2019-11-21","objectID":"/posts/linux-basic/linux-basics/:2:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linuxçš„ç›®å½•ç»“æ„ç‰¹ç‚¹","uri":"/posts/linux-basic/linux-basics/"},{"categories":["Linux"],"content":"Linux ç›®å½•ç»“æ„è¯¦è§£ ç›®å½•åç§° ç›®å½•ä»‹ç» /etc é…ç½®æ–‡ä»¶ /home ç”¨æˆ·çš„å®¶ç›®å½•ï¼Œæ¯ä¸€ä¸ªç”¨æˆ·çš„å®¶ç›®å½•é€šå¸¸é»˜è®¤ä¸º/home/USERNAME /root ç®¡ç†å‘˜çš„å®¶ç›®å½• /lib åº“æ–‡ä»¶ é™æ€åº“ï¼šå•åœ¨ç¨‹åºä¸­çš„åº“ï¼Œå…¶ä»–ç¨‹åºä¸èƒ½ä½¿ç”¨è¯¥åº“æ–‡ä»¶åŠ¨æ€åº“ï¼šåœ¨å†…å­˜ä¸­ï¼Œä»»ä½•ç”¨åˆ°è¯¥åº“çš„ç¨‹åºéƒ½å¯ä»¥ä½¿ç”¨ /lib/modules å†…æ ¸æ¨¡å—æ–‡ä»¶ /media æŒ‚è½½ç‚¹ç›®å½•ï¼Œç§»åŠ¨è®¾å¤‡ã€‚åœ¨windowsä¸­ï¼Œæ’å…¥ä¸€å¼ å…‰ç›˜ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯»å–å…‰ç›˜ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥æ‰§è¡Œï¼Œä½†åœ¨linuxä¸­ï¼Œæ’å…¥å…‰ç›˜åéœ€è¦åœ¨æŒ‚è½½ç‚¹æŒ‚è½½è¿™ä¸ªè®¾å¤‡ä¹‹åæ‰å¯ä»¥ä½¿ç”¨è¿™ä¸ªè®¾å¤‡ /mnt æŒ‚è½½ç‚¹ç›®å½•ï¼Œé¢å¤–çš„ä¸´æ—¶æ–‡ä»¶ç³»ç»Ÿ /opt å¯é€‰ç›®å½•ï¼Œç¬¬ä¸‰æ–¹ç¨‹åºçš„å®‰è£…ç›®å½• /proc ä¼ªæ–‡ä»¶ç³»ç»Ÿï¼Œå†…æ ¸æ˜ å°„æ–‡ä»¶ /sys ä¼ªæ–‡ä»¶ç³»ç»Ÿï¼Œè·Ÿç¡¬ä»¶è®¾å¤‡ç›¸å…³çš„å±æ€§æ˜ å°„æ–‡ä»¶ /tmp ä¸´æ—¶æ–‡ä»¶ /var å¯å˜åŒ–çš„æ–‡ä»¶ï¼Œç»å¸¸å‘ç”Ÿå˜åŒ–çš„æ–‡ä»¶ /bin å¯æ‰§è¡Œæ–‡ä»¶ï¼Œç”¨æˆ·å‘½ä»¤ï¼›å…¶ä¸­ç”¨åˆ°çš„åº“æ–‡ä»¶å¯èƒ½åœ¨/libï¼Œé…ç½®æ–‡ä»¶å¯èƒ½åœ¨/etc /sbin å¯æ‰§è¡Œæ–‡ä»¶ï¼Œç®¡ç†å‘½ä»¤ï¼›å…¶ä¸­ç”¨åˆ°çš„åº“æ–‡ä»¶å¯èƒ½åœ¨/libï¼Œé…ç½®æ–‡ä»¶å¯èƒ½åœ¨/etc /usr åªè¯»æ–‡ä»¶ï¼Œshared read-only /usr/local ç¬¬ä¸‰æ–¹è½¯ä»¶ /boot ç³»ç»Ÿå¯åŠ¨ç›¸å…³çš„æ–‡ä»¶ï¼Œå¦‚å†…æ ¸ã€initrdï¼Œä»¥åŠgrubï¼ˆBootLoaderï¼‰ â€‹ è¯¦ç»†åŸæ–‡ ","date":"2019-11-21","objectID":"/posts/linux-basic/linux-basics/:3:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linuxçš„ç›®å½•ç»“æ„ç‰¹ç‚¹","uri":"/posts/linux-basic/linux-basics/"},{"categories":["Linux"],"content":"Linux åŸºç¡€ Linuxï¼Œå…¨ç§°GNU/Linuxï¼Œæ˜¯ä¸€å¥—å…è´¹ä½¿ç”¨å’Œè‡ªç”±ä¼ æ’­çš„ç±»UNIXæ“ä½œç³»ç»Ÿï¼Œå…¶å†…æ ¸ç”±æ—çº³æ–¯Â·æœ¬çº³ç¬¬å…‹ç‰¹Â·æ‰˜ç“¦å…¹äº1991å¹´ç¬¬ä¸€æ¬¡é‡Šå‡ºï¼Œå®ƒä¸»è¦å—åˆ°Minixå’ŒUnixæ€æƒ³çš„å¯å‘ï¼Œæ˜¯ä¸€ä¸ªåŸºäºPOSIXå’ŒUnixçš„å¤šç”¨æˆ·ã€å¤šä»»åŠ¡ã€æ”¯æŒå¤šçº¿ç¨‹å’Œå¤šCPUçš„æ“ä½œç³»ç»Ÿã€‚å®ƒèƒ½è¿è¡Œä¸»è¦çš„Unixå·¥å…·è½¯ä»¶ã€åº”ç”¨ç¨‹åºå’Œç½‘ç»œåè®®ã€‚å®ƒæ”¯æŒ32ä½å’Œ64ä½ç¡¬ä»¶ã€‚Linuxç»§æ‰¿äº†Unixä»¥ç½‘ç»œä¸ºæ ¸å¿ƒçš„è®¾è®¡æ€æƒ³ï¼Œæ˜¯ä¸€ä¸ªæ€§èƒ½ç¨³å®šçš„å¤šç”¨æˆ·ç½‘ç»œæ“ä½œç³»ç»Ÿã€‚Linuxæœ‰ä¸Šç™¾ç§ä¸åŒçš„å‘è¡Œç‰ˆï¼Œå¦‚åŸºäºç¤¾åŒºå¼€å‘çš„debianã€archlinuxï¼Œå’ŒåŸºäºå•†ä¸šå¼€å‘çš„[Red Hat Enterprise Linux](https://baike.baidu.com/item/Red Hat Enterprise Linux/10770503)ã€SUSEã€[oracle linux](https://baike.baidu.com/item/oracle linux/6876458)ç­‰ã€‚ ","date":"2019-11-20","objectID":"/posts/linux-basic/linux1/:0:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linux åŸºç¡€çŸ¥è¯†","uri":"/posts/linux-basic/linux1/"},{"categories":["Linux"],"content":"ä¸€ã€æ“ä½œç³»ç»Ÿçš„åŸºæœ¬çŸ¥è¯† ä¸€èˆ¬è€Œè¨€ï¼Œç°ä»£è®¡ç®—æœºè®¡ç®—æœºç³»ç»Ÿæ˜¯ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿï¼Œæ•…è‹¥ç¨‹åºå‘˜éœ€è¦æŒæ¡è¯¥ç³»ç»Ÿçš„æ¯ä¸€ä¸ªç»†èŠ‚ä¾‹å¦‚å¦‚ä½•é€šè¿‡ä»£ç å»è°ƒç”¨éŸ³å“ç­‰è¿™äº›äº‹æƒ…ï¼Œé‚£å¯èƒ½ä¸å†ç¼–å†™ä»£ç äº†ï¼Œè¿™ç§æƒ…å†µä¼šä¸¥é‡å½±å“ç¨‹åºå‘˜çš„å¼€å‘æ•ˆç‡ã€‚ å¹¶ä¸”ç®¡ç†è¿™äº›éƒ¨ä»¶å¹¶åŠ ä»¥ä¼˜åŒ–ä½¿ç”¨ï¼Œæ˜¯ä¸€ä»¶æå¯ŒæŒ‘æˆ˜æ€§çš„å·¥ä½œï¼Œäºæ˜¯ï¼Œè®¡ç®—å®‰è£…äº†ä¸€å±‚è½¯ä»¶ï¼ˆç³»ç»Ÿè½¯ä»¶ï¼‰ï¼Œç§°ä¸ºæ“ä½œç³»ç»Ÿã€‚å®ƒçš„ä»»åŠ¡å°±æ˜¯ä¸ºç”¨æˆ·ç¨‹åºæä¾›ä¸€ä¸ªæ›´å¥½ã€æ›´ç®€å•ã€æ›´æ¸…æ™°çš„è®¡ç®—æœºæ¨¡å‹ï¼Œå¹¶ç®¡ç†åˆšæ‰æåˆ°çš„æ‰€æœ‰è®¾å¤‡ã€‚ ","date":"2019-11-20","objectID":"/posts/linux-basic/linux1/:1:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linux åŸºç¡€çŸ¥è¯†","uri":"/posts/linux-basic/linux1/"},{"categories":["Linux"],"content":"1. linux ä»‹ç» Linux æ˜¯ä¸€ä¸ªå¤šç”¨æˆ·å¤šä»»åŠ¡çš„æ“ä½œç³»ç»Ÿï¼Œä¹Ÿæ˜¯ä¸€æ¬¾è‡ªç”±è½¯ä»¶ï¼Œæ‹¥æœ‰è‰¯å¥½çš„ç”¨æˆ·ç•Œé¢ï¼Œæ”¯æŒå¤šç§å¤„ç†å™¨æ¶æ„ï¼Œç§»æ¤æ–¹ä¾¿ã€‚ä¸¥æ ¼çš„æ¥è®²ï¼ŒLinux å¹¶ä¸ç®—æ˜¯ä¸€ä¸ªæ“ä½œç³»ç»Ÿï¼Œåªæ˜¯ä¸€ä¸ª Linux ç³»ç»Ÿä¸­çš„å†…æ ¸ï¼Œå³è®¡ç®—æœºè½¯ä»¶ä¸ç¡¬ä»¶é€šè®¯ä¹‹é—´çš„å¹³å°ã€‚ 1.1 GUNåè®® Linuxçš„å…¨ç§°æ˜¯GNU/Linuxï¼Œè¿™æ‰ç®—æ˜¯ä¸€ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„Linuxç³»ç»Ÿã€‚ è®¾è®¡åŸåˆ™ï¼š 1ï¼‰æ‰€æœ‰çš„ä¸œè¥¿éƒ½æ˜¯æ–‡ä»¶ï¼Œæ‰€ä»¥ç®¡ç†ç®€å•\r2ï¼‰æ‰€æœ‰æ“ä½œç³»ç»Ÿé…ç½®æ•°æ®éƒ½å­˜å‚¨åœ¨æ­£æ–‡æ–‡ä»¶ä¸­\r3ï¼‰æ¯ä¸ªæ“ä½œç³»ç»Ÿå‘½ä»¤æˆ–åº”ç”¨ç¨‹åºå¾ˆå°ï¼Œåªå®Œæˆå•ä¸€åŠŸèƒ½\r4ï¼‰é¿å…ä½¿ç”¨ä¿˜è·ç”¨æˆ·çš„æ¥å£ï¼Œå¾ˆå°‘äº¤äº’å‘½ä»¤ï¼Œåº”ç”¨ç¨‹åºç”±viç¼–è¾‘å™¨ç­‰å®Œæˆäº¤äº’\r5ï¼‰å¤šä¸ªç¨‹åºä¸²æ¥åœ¨ä¸€èµ·å®Œæˆå¤æ‚ä»»åŠ¡\räºŒã€Linux å¸¸ç”¨å‘½ä»¤ 1ã€pwd è¿”å›å½“å‰å·¥ä½œç›®å½•ï¼Œç›´æ¥è¾“å…¥ pwd å³å¯ï¼Œåé¢ä¸å¸¦å‚æ•°ã€‚ 2ã€ls å³è‹±æ–‡å•è¯listçš„ç¼©å†™ï¼Œåˆ—å‡ºæŒ‡å®šç›®å½•çš„æ‰€æœ‰æ–‡ä»¶åæˆ–è€…æ–‡ä»¶å¤¹åï¼ˆé»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•ä¸‹ï¼‰ï¼Œ å…¶é€‰é¡¹å¦‚ä¸‹ï¼š å‚æ•° å«ä¹‰ -a æ˜¾ç¤ºæŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰å­ç›®å½•ä¸æ–‡ä»¶ï¼ŒåŒ…æ‹¬éšè—æ–‡ä»¶ -i ä»¥åˆ—è¡¨æ–¹å¼æ˜¾ç¤ºæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯ -h é…åˆ -i ä»¥äººæ€§åŒ–æ–¹å¼æ˜¾ç¤ºæ–‡ä»¶å¤§å° 3ã€cd åˆ‡æ¢å·¥ä½œç›®å½•ï¼› åœ¨ä½¿ç”¨Unix/Linuxçš„æ—¶å€™ï¼Œç»å¸¸éœ€è¦æ›´æ¢å·¥ä½œç›®å½•ã€‚cdå‘½ä»¤å¯ä»¥å¸®åŠ©ç”¨æˆ·åˆ‡æ¢å·¥ä½œç›®å½•ã€‚Linuxæ‰€æœ‰çš„ç›®å½•å’Œæ–‡ä»¶åå¤§å°å†™æ•æ„Ÿcdåé¢å¯è·Ÿç»å¯¹è·¯å¾„ï¼Œä¹Ÿå¯ä»¥è·Ÿç›¸å¯¹è·¯å¾„ã€‚å¦‚æœçœç•¥ç›®å½•ï¼Œåˆ™é»˜è®¤åˆ‡æ¢åˆ°å½“å‰ç”¨æˆ·çš„ä¸»ç›®å½•ã€‚ å‘½ä»¤ å«ä¹‰ cd åˆ‡æ¢åˆ°å½“å‰ç”¨æˆ·çš„ä¸»ç›®å½•ï¼Œç”¨æˆ·ç™»å½•çš„ä½¿ç”¨ï¼Œé»˜è®¤çš„ç›®å½•å°±æ˜¯ç”¨æˆ·çš„ä¸»ç›®å½•ã€‚ cd ~ åˆ‡æ¢åˆ°å½“å‰ç”¨æˆ·çš„ä¸»ç›®å½• cd . åˆ‡æ¢åˆ°å½“å‰ç›®å½• ![](C:\\Users\\xinxi\\Desktop\\æœŸæœ«è€ƒè¯• 2020æ˜¥\\1328034-20180704191623328-304845393.png) ","date":"2019-11-20","objectID":"/posts/linux-basic/linux1/:1:1","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linux åŸºç¡€çŸ¥è¯†","uri":"/posts/linux-basic/linux1/"},{"categories":["Linux"],"content":"ä¸‰ã€æ–‡ä»¶æƒé™ åœ¨Linuxæ“ä½œç³»ç»Ÿä¸Šï¼Œæœ‰äº›æ–‡ä»¶å¾ˆé‡è¦ï¼Œè¿™äº›æ–‡ä»¶åªæœ‰ç³»ç»Ÿæˆ–ç»è¿‡æˆæƒçš„ç”¨æˆ·æ‰èƒ½ä½¿ç”¨ï¼Œè¿™æ ·æ‰èƒ½ä¿æŠ¤ç³»ç»Ÿçš„å®‰å…¨ã€‚å› ä¸ºæœ‰ä¸€äº›æ–‡ä»¶æ˜¯åªæœ‰éƒ¨åˆ†æŒ‡å®šçš„äººæ‰èƒ½å­˜å–ï¼Œä»¥å…ä¸å°å¿ƒè¢«ä»–äººåˆ é™¤æˆ–ä¿®æ”¹ï¼Œå› æ­¤æ–‡ä»¶çš„å®‰å…¨ç®¡ç†æ˜¯éå¸¸é‡è¦çš„ã€‚ä¸ºäº†é˜²æ­¢æœªæˆæƒç”¨æˆ·è®¿é—®ä½ çš„ æ–‡ä»¶ï¼Œå¯ä»¥åœ¨æ–‡ä»¶å’Œç›®å½•ä¸Šè®¾ç½®æƒé™ä½ã€‚è¿˜å¯ä»¥è®¾å®šæ–‡ä»¶åœ¨åˆ›å»ºæ—¶æ‰€å…·æœ‰çš„ç¼ºçœæƒé™ã€‚ ","date":"2019-11-20","objectID":"/posts/linux-basic/linux1/:2:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linux åŸºç¡€çŸ¥è¯†","uri":"/posts/linux-basic/linux1/"},{"categories":["Linux"],"content":"ç½‘å¡æ–‡ä»¶é…ç½®æ–‡ä»¶è¯¦è§£ æ–‡ä»¶è·¯å¾„ï¼š //etc/sysconfig/network-scripts/ifcfg-eth0 ä¸ºç½‘å¡æ–‡ä»¶è·¯å¾„ é…ç½®å‚æ•° å‚æ•°è¯¦è§£ DEVICE=eth0 ç½‘å¡åå­— HWADDR=00:0c:29:bc:1f:24 Hardware address ç¡¬ä»¶åœ°å€ TYPE=Ethernet ç½‘ç»œç±»å‹ å› ç‰¹ç½‘ UUID=1c340c4c-e0ec-4672-81e7-a5f4110dd1f9 UUIDç³»ç»Ÿä¸­å”¯ä¸€çš„æ ‡è¯† ONBOOT=yes boot on åœ¨é‡å¯æ—¶å€™æ˜¯å¦å¼€å¯ç½‘å¡ è‡ªåŠ¨è¿è¡Œ NM_CONTROLLED=yes æ˜¯å¦é€šè¿‡networkè½¯ä»¶è¿›è¡Œç®¡ç† BOOTPROTO=none ç½‘å¡è·å–IPåœ°å€çš„æ–¹å¼ static ipåœ°å€å›º dhcp è‡ªåŠ¨è·å– IPADDR=10.0.0.200 IPåœ°å€ NETMASK=255.255.255.0 å­ç½‘æ©ç  GATEWAY=10.0.0.2 ç½‘å…³ é»˜è®¤çš„å‡ºå£ USERCTL=no æ˜¯å¦å…è®¸æ™®é€šç”¨æˆ·ç®¡ç†ç½‘å¡ å¼€ å…³ é‡å¯ PEERDNS=yes DNS ä¼˜å…ˆæ€§ IPV6INIT=no IPv6 DNS1=223.5.5.5 DNSåœ°å€ DNS2=223.6.6.6 DNSåœ°å€ ","date":"2019-11-20","objectID":"/posts/linux-basic/linux-network/:0:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"ç¶²å¡æ–‡ä»¶é…ç½®æ–‡ä»¶è©³è§£","uri":"/posts/linux-basic/linux-network/"},{"categories":["Linux"],"content":"åŸºäº Linux ç³»ç»Ÿçš„æœåŠ¡è¯¾ç¨‹ç¬”è®° â€‹ äº’è”ç½‘è¿ç»´æ˜¯ä¸€ä¸ªèåˆå¤šå­¦ç§‘ï¼ˆç½‘ç»œã€ç³»ç»Ÿã€å¼€å‘ã€å®‰å…¨ã€åº”ç”¨æ¶æ„ã€å­˜å‚¨ç­‰ï¼‰çš„ç»¼åˆæ€§æŠ€æœ¯å²—ä½ï¼Œç»™è¿ç»´å·¥ç¨‹å¸ˆæä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„ä¸ªäººèƒ½åŠ›ä¸æŠ€æœ¯çš„å‘å±•ç©ºé—´ã€‚è¿ç»´å·¥ä½œçš„ç›¸å…³ç»éªŒå°†ä¼šå˜å¾—éå¸¸é‡è¦ï¼Œè€Œä¸”ä¹Ÿå°†æˆä¸ºä¸ªäººçš„æ ¸å¿ƒç«äº‰åŠ›ï¼Œä¼˜ç§€çš„è¿ç»´å·¥ç¨‹å¸ˆå…·å¤‡å¾ˆå¥½çš„å„å±‚é¢é—®é¢˜çš„è§£å†³èƒ½åŠ›åŠæ–¹æ¡ˆæä¾›ã€å…¨å±€æ€è€ƒçš„èƒ½åŠ›ç­‰ã€‚ç”±äºè¿ç»´å²—ä½æ‰€æ¥è§¦çš„çŸ¥è¯†é¢éå¸¸å¹¿é˜”ï¼Œæ›´å®¹æ˜“åŸ¹å…»æˆ–å‘æŒ¥å‡ºä¸ªäººæŸäº›æ–¹é¢çš„ç‰¹é•¿æˆ–çˆ±å¥½ï¼Œå¦‚å†…æ ¸ã€ç½‘ç»œã€å¼€å‘ã€æ•°æ®åº“ç­‰æ–¹é¢ï¼Œå¯ä»¥åšå¾—éå¸¸æ·±å…¥ç²¾é€šã€æˆä¸ºè¿™æ–¹é¢çš„ä¸“å®¶ã€‚ ","date":"2019-11-11","objectID":"/posts/linux-basic/linux-technology-stack/:0:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linux ç³»ç»Ÿçš„æœåŠ¡è¯¾ç¨‹ç¬”è®°","uri":"/posts/linux-basic/linux-technology-stack/"},{"categories":["Linux"],"content":"Linux è¿ç»´å·¥ç¨‹å¸ˆæŠ€æœ¯å›¾è°± è¿ç»´æ¶æ„æŠ€æœ¯ç±»å‹ ä¸»è¦æŠ€æœ¯å…³é”®è¯ è„šæœ¬ç¼–ç¨‹ AWKã€Sedã€Grepã€Shellã€Python WebæœåŠ¡ Apacheã€Nginxã€Tomcatã€JBossã€Resin æ•°æ®ä¼ è¾“ Rsyncã€Scpã€Inodify/Sersync æ€§èƒ½åˆ†æ topã€freeã€dfã€iftopã€iostatã€vmstatã€dstatã€sarã€sysdig è¿›ç¨‹ç®¡ç† Supervisor ç½‘ç»œæœåŠ¡ vsftpã€nfsã€sambaã€bindã€dhcpã€postfifix æ•°æ®åº“ MySQLã€MariaDBã€PostgreSQLï¼ŒOracle NoSQL Redisã€MongoDB æ¶ˆæ¯ä¸­é—´ä»¶ RabbitMQã€ActiveMQ ç‰ˆæœ¬ç®¡ç† SVNã€Git é™æ€ç¼“å­˜ Squidã€Varnishã€Nginx è´Ÿè½½å‡è¡¡ LVSã€HAProxyã€Nginx é«˜å¯ç”¨è½¯ä»¶ Keepalivedã€Heartbeatã€DRBDã€corosync+pacemaker é›†ä¸­ç®¡ç†å·¥å…· Ansibleã€Saltstackã€Chefã€Puppet è™šæ‹ŸåŒ– KVMã€Xenã€Openstackã€Cloudstack å®¹å™¨åŒ– Dockerã€Kubernetesã€Rancherã€Openshift è‡ªåŠ¨è£…æœº Kickstartã€Cobbler æŠ“åŒ…åˆ†æ Tcpdumpã€Wireshark æŒç»­é›†æˆ Jenkinsã€Gitlab MySQLä»£ç† Altasã€Cobarã€Mycat å‹åŠ›æµ‹è¯• abã€fifioã€sysbenchã€mysqlslapã€Jemter æ—¥å¿—æ”¶é›† ELK Stackã€Graylog ç›‘æ§ç³»ç»Ÿ Zabbixã€Prometheusã€Open-falcon åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ Cephã€GlusterFSã€FastDFS :::tip è¯¾ç¨‹çŸ¥è¯†æŒ‡å— Linux åˆå§‹åŸºç¡€é˜¶æ®µéœ€è¦ç†Ÿæ‚‰ Linux æ“ä½œç³»ç»Ÿå®‰è£…ï¼Œç›®å½•ç»“æ„ã€æ–‡ä»¶æƒé™ã€ç½‘å¡æ–‡ä»¶ç­‰é…ç½®ã€ç³»ç»Ÿå¯åŠ¨æµç¨‹ç­‰ã€‚ ç³»ç»Ÿç®¡ç† ä¸»è¦å­¦ä¹ Linuxç³»ç»Ÿï¼ŒæŒæ¡å¸¸ç”¨çš„å‡ åä¸ªåŸºæœ¬ç®¡ç†å‘½ä»¤ï¼ŒåŒ…æ‹¬ç”¨æˆ·ç®¡ç†ã€ç£ç›˜åˆ†åŒºã€è½¯ä»¶åŒ…ç®¡ç†ã€æ–‡ä»¶æƒé™ã€æ–‡æœ¬å¤„ç†ã€è¿›ç¨‹ç®¡ç†ã€æ€§èƒ½åˆ†æå·¥å…·ç­‰ã€‚ ç½‘ç»œåŸºç¡€ OSIå’ŒTCP/IPæ¨¡å‹ä¸€å®šè¦ç†Ÿæ‚‰ã€‚åŸºæœ¬çš„äº¤æ¢æœºã€è·¯ç”±å™¨æ¦‚å¿µåŠå®ç°åŸç†è¦çŸ¥é“ã€‚ Shellè„šæœ¬ç¼–ç¨‹åŸºç¡€ æŒæ¡ShellåŸºæœ¬è¯­æ³•ç»“æ„ï¼Œèƒ½ç¼–å†™ç®€å•çš„è„šæœ¬å³å¯ã€‚ ç½‘ç»œæœåŠ¡ å¸¸è§çš„ç½‘ç»œæœåŠ¡è¦ä¼šéƒ¨ç½²ï¼Œæ¯”å¦‚vsftpã€nfsã€sambaã€bindã€dhcpç­‰ã€‚ ä»£ç ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿå°‘ä¸äº†ï¼Œå¯ä»¥å­¦ä¹ ä¸‹ä¸»æµçš„GITï¼Œèƒ½éƒ¨ç½²å’Œç®€å•ä½¿ç”¨å°±å¯ä»¥äº†ã€‚ ç»å¸¸åœ¨æœåŠ¡å™¨ä¹‹é—´ä¼ è¾“æ•°æ®ï¼Œæ‰€ä»¥è¦ä¼šä½¿ç”¨ï¼šrsyncå’Œscpã€‚ æ•°æ®åŒæ­¥ï¼šinotify/sersyncã€‚ é‡å¤æ€§å®Œæˆä¸€äº›å·¥ä½œï¼Œå¯å†™æˆè„šæœ¬å®šæ—¶å»è¿è¡Œï¼Œæ‰€ä»¥å¾—ä¼šé…ç½®Linuxä¸‹çš„å®šæ—¶ä»»åŠ¡æœåŠ¡crondã€‚ WebæœåŠ¡ æ¯ä¸ªå…¬å¸åŸºæœ¬éƒ½ä¼šæœ‰ç½‘ç«™ï¼Œèƒ½è®©ç½‘ç«™è·‘èµ·æ¥ï¼Œå°±éœ€è¦æ­å»ºWebæœåŠ¡å¹³å°äº†ã€‚ å¦‚æœæ˜¯ç”¨PHPè¯­è¨€å¼€å‘çš„ï¼Œé€šå¸¸æ­å»ºLNMPç½‘ç«™å¹³å°ï¼Œè¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯åè¯ç»„åˆçš„æ‹¼å†™ï¼Œåˆ†å¼€è®²å°±æ˜¯å¾—ä¼šéƒ¨ç½²Nginxã€MySQLå’ŒPHPã€‚ å¦‚æœæ˜¯JAVAè¯­è¨€å¼€å‘çš„ï¼Œé€šå¸¸ä½¿ç”¨Tomcatè¿è¡Œé¡¹ç›®ï¼Œä¸ºäº†æé«˜è®¿é—®é€Ÿåº¦ï¼Œå¯ä»¥ä½¿ç”¨Nginxåå‘ä»£ç†Tomcatï¼ŒNginxå¤„ç†é™æ€é¡µé¢ï¼ŒTomcatå¤„ç†åŠ¨æ€é¡µé¢ï¼Œå®ç°åŠ¨é™åˆ†ç¦»ã€‚ ä¸æ˜¯ä¼šéƒ¨ç½²è¿™ä¹ˆç®€å•ï¼Œè¿˜è¦çŸ¥é“HTTPåè®®å·¥ä½œåŸç†ã€ç®€å•çš„æ€§èƒ½è°ƒä¼˜ã€‚ è´Ÿè½½å‡è¡¡å™¨ å•å°æœåŠ¡å™¨ç»ˆç©¶èµ„æºæœ‰é™ï¼ŒæŠµæŠ—é«˜è®¿é—®é‡è‚¯å®šæ˜¯æ— æ³•æ”¯æ’‘çš„ï¼Œè§£å†³æ­¤é—®é¢˜æœ€å…³é”®çš„æŠ€æœ¯å°±æ˜¯é‡‡ç”¨è´Ÿè½½å‡è¡¡å™¨ï¼Œæ°´å¹³æ‰©å±•å¤šå°WebæœåŠ¡å™¨ï¼ŒåŒæ—¶å¯¹å¤–æä¾›æœåŠ¡ï¼Œè¿™æ ·å°±æˆå€æ‰©å±•æ€§èƒ½äº†ã€‚è´Ÿè½½å‡è¡¡å™¨ä¸»æµå¼€æºæŠ€æœ¯æœ‰LVSã€HAProxyå’ŒNginxã€‚ä¸€å®šè¦ç†Ÿæ‚‰ä¸€ä¸¤ä¸ªï¼ æ•°æ®åº“ æ•°æ®åº“é€‰æ‹©MySQLï¼Œå®ƒæ˜¯ä¸–ç•Œä¸Šä½¿ç”¨æœ€ä¸ºå¹¿æ³›çš„å¼€æºæ•°æ®åº“ã€‚å­¦å®ƒå‡†æ²¡é”™ï¼ ä¹Ÿè¦ä¼šä¸€äº›ç®€å•çš„SQLè¯­å¥ã€ç”¨æˆ·ç®¡ç†ã€å¸¸ç”¨å­˜å‚¨å¼•æ“ã€æ•°æ®åº“å¤‡ä»½ä¸æ¢å¤ã€‚ æƒ³è¦æ·±å…¥ç‚¹ï¼Œå¿…é¡»ä¼šä¸»ä»å¤åˆ¶ã€æ€§èƒ½ä¼˜åŒ–ã€ä¸»æµé›†ç¾¤æ–¹æ¡ˆï¼šMHAã€MGRç­‰ã€‚ NoSQLè¿™ä¹ˆæµè¡Œå½“ç„¶ä¹Ÿå°‘ä¸äº†ï¼Œå­¦ä¸‹Redisã€MongoDBè¿™ä¸¤ä¸ªå°±å¥½äº†ã€‚ ç›‘æ§ç³»ç»Ÿ ç›‘æ§å¿…ä¸å¯å°‘ï¼Œæ˜¯åŠæ—¶å‘ç°é—®é¢˜å’Œè¿½æº¯é—®é¢˜çš„æ•‘å‘½ç¨»è‰ã€‚å¯ä»¥é€‰æ‹©å­¦ä¹ ä¸»æµçš„Zabbixã€Prometheuså¼€æºç›‘æ§ç³»ç»Ÿï¼ŒåŠŸèƒ½ä¸°å¯Œï¼Œèƒ½æ»¡è¶³ä¼ä¸šçº§ç›‘æ§éœ€æ±‚ã€‚ç›‘æ§ç‚¹åŒ…æ‹¬æœåŠ¡å™¨ç¡¬ä»¶ã€æœåŠ¡å™¨æ€§èƒ½ã€APIã€ä¸šåŠ¡ã€PV/UVã€æ—¥å¿—ç­‰æ–¹é¢ã€‚ ä¹Ÿå¯ä»¥å¼„ä¸ªä»ªè¡¨ç›˜å±•ç¤ºå‡ ä¸ªå®æ—¶å…³é”®çš„æ•°æ®ï¼Œæ¯”å¦‚Grafanaï¼Œä¼šéå¸¸ç‚«é…·ã€‚ æ—¥å¿—åˆ†æç³»ç»Ÿ æ—¥å¿—ä¹Ÿå¾ˆé‡è¦ï¼Œå®šæœŸçš„åˆ†æï¼Œå¯å‘ç°æ½œåœ¨éšæ‚£ï¼Œæç‚¼å‡ºæœ‰ä»·å€¼çš„ä¸œè¥¿ã€‚ ä¸»æµæ—¥å¿—ç³»ç»Ÿï¼šELK Stack å­¦ä¼šéƒ¨ç½²ä½¿ç”¨ï¼Œèƒ½åˆ†ææ—¥å¿—å¹¶å¯è§†åŒ–ï¼Œæ–¹ä¾¿æ•…éšœæ’æŸ¥ã€‚ å®‰å…¨é˜²èŒƒ å®‰å…¨å¾ˆé‡è¦ï¼Œä¸è¦ç­‰åˆ°ç³»ç»Ÿè¢«æ”»å‡»äº†ï¼Œå†åšå®‰å…¨ç­–ç•¥ï¼Œæ­¤æ—¶å·²æ™šï¼æ‰€ä»¥ï¼Œå½“ä¸€å°æœåŠ¡å™¨ä¸Šçº¿ååº”é©¬ä¸Šåšå®‰å…¨è®¿é—®æ§åˆ¶ç­–ç•¥ï¼Œæ¯”å¦‚ä½¿ç”¨iptablesé™åˆ¶åªå…è®¸ä¿¡ä»»æºIPè®¿é—®ï¼Œå…³é—­ä¸€äº›æ— ç”¨çš„æœåŠ¡å’Œç«¯å£ç­‰ã€‚ ä¸€äº›å¸¸è§çš„æ”»å‡»ç±»å‹ä¸€å®šå¾—çŸ¥é“å•Šï¼Œå¦åˆ™æ€ä¹ˆå¯¹ç—‡ä¸‹è¯å‘¢ï¼æ¯”å¦‚CCã€DDOSã€ARPç­‰ã€‚ Shellè„šæœ¬ç¼–ç¨‹è¿›é˜¶ Shellè„šæœ¬æ˜¯Linuxè‡ªåŠ¨å®Œæˆå·¥ä½œçš„åˆ©å™¨ï¼Œå¿…é¡»å¾—ç†Ÿç»ƒç¼–å†™ï¼Œæ‰€ä»¥å¾—è¿›ä¸€æ­¥å­¦ä¹ å‡½æ•°ã€æ•°ç»„ã€ä¿¡å·ã€å‘é‚®ä»¶ç­‰ã€‚ æ–‡æœ¬å¤„ç†ä¸‰å‰‘å®¢ï¼ˆgrepã€sedã€awkï¼‰å¾—ç©6å•Šï¼ŒLinuxä¸‹æ–‡æœ¬å¤„ç†å°±æŒ‡æœ›å®ƒä»¬äº†ã€‚ Python/Go å¼€å‘åŸºç¡€ Shellè„šæœ¬åªèƒ½å®Œæˆä¸€äº›åŸºæœ¬çš„ä»»åŠ¡ï¼Œæƒ³è¦å®Œæˆæ›´å¤æ‚äº›çš„ä»»åŠ¡ï¼Œæ¯”å¦‚è°ƒç”¨APIã€å¤šè¿›ç¨‹ç­‰ã€‚å°±éœ€è¦å­¦é«˜çº§è¯­è¨€äº†ã€‚Pythonæ˜¯è¿ç»´é¢†åŸŸä½¿ç”¨æœ€å¤šçš„è¯­è¨€ï¼Œç®€å•æ˜“ç”¨ï¼Œå­¦å®ƒå‡†æ²¡é”™ï¼æ­¤é˜¶æ®µæŒæ¡åŸºç¡€å°±å¯ä»¥äº†ï¼Œä¾‹å¦‚åŸºæœ¬è¯­æ³•ç»“æ„ã€æ–‡ä»¶å¯¹è±¡æ“ä½œã€å‡½æ•°ã€è¿­ä»£å¯¹è±¡ã€å¼‚å¸¸å¤„ç†ã€å‘é‚®ä»¶ã€æ•°æ®åº“ç¼–ç¨‹ç­‰ã€‚ ::: ::: warning ç‰ˆæƒå£°æ˜ æœ¬ç«™æ–‡ç« æ¥æºäºäº’è”ç½‘ä¸ä¸ªäººå­¦ä¹ ç¬”è®°æ€»ç»“ï¼Œä»…ç”¨äºæŠ€æœ¯åˆ†äº«äº¤æµä½¿ç”¨ã€‚æœªç»å…è®¸ä¸å¾—è½¬è½½ï¼ ::: ","date":"2019-11-11","objectID":"/posts/linux-basic/linux-technology-stack/:1:0","tags":["Linux å­¦ä¹ ä¹‹æ—…"],"title":"Linux ç³»ç»Ÿçš„æœåŠ¡è¯¾ç¨‹ç¬”è®°","uri":"/posts/linux-basic/linux-technology-stack/"},{"categories":["Linux"],"content":"nfså…±äº«å­˜å‚¨ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:0:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"1.NFSåŸºæœ¬æ¦‚è¿° ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:1:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"1.1 ä»€ä¹ˆæ˜¯NFS? NFSæ˜¯Network File Systemçš„ç¼©å†™åŠç½‘ç»œæ–‡ä»¶ç³»ç»Ÿã€‚[ é€šå¸¸æˆ‘ä»¬ç§°NFSä¸ºå…±äº«å­˜å‚¨] ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:1:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"1.2 NFSèƒ½å¹²ä»€ä¹ˆ? NFSçš„ä¸»è¦åŠŸèƒ½æ˜¯é€šè¿‡å±€åŸŸç½‘ç»œè®©ä¸åŒä¸»æœºç³»ç»Ÿä¹‹é—´å¯ä»¥å…±äº«ç›®å½•ã€‚ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:1:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"1.3 ä¸ºä»€ä¹ˆè¦ä½¿ç”¨NFS? åœ¨ç½‘ç«™é›†ç¾¤æ¶æ„ä¸­å¦‚æœæ²¡æœ‰å…±äº«å­˜å‚¨çš„æƒ…å†µå¦‚ä¸‹: Aç”¨æˆ·ä¸Šä¼ å›¾ç‰‡ç»è¿‡è´Ÿè½½å‡è¡¡ï¼Œè´Ÿè½½å‡è¡¡å°†ä¸Šä¼ è¯·æ±‚è°ƒåº¦è‡³WEB1æœåŠ¡å™¨ä¸Šã€‚ Bç”¨æˆ·è®¿é—®Aç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ï¼Œæ­¤æ—¶Bç”¨æˆ·è¢«è´Ÿè½½å‡è¡¡è°ƒåº¦è‡³WEB2_ä¸Šï¼Œå› ä¸ºWEB2_ ä¸Šæ²¡æœ‰è¿™å¼ å›¾ç‰‡ï¼Œæ‰€ä»¥Bç”¨æˆ·æ— æ³•çœ‹åˆ°Aç”¨æˆ·ä¼ çš„å›¾ç‰‡ã€‚ åœ¨ç½‘ç«™é›†ç¾¤æ¶æ„ä¸­å¦‚æœæœ‰å…±äº«å­˜å‚¨çš„æƒ…å†µå¦‚ä¸‹: Aç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ— è®ºè¢«è´Ÿè½½å‡è¡¡è°ƒåº¦è‡³WEB1è¿˜æ˜¯WEB2,æœ€ç»ˆæ•°æ®éƒ½è¢«å†™å…¥è‡³å…±äº«å­˜å‚¨ Bç”¨æˆ·è®¿é—®Aç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ—¶ï¼Œæ— è®ºè°ƒåº¦è‡³WEB1è¿˜æ˜¯WEB2ï¼Œæœ€ç»ˆéƒ½ä¼šä¸Šå…±äº«å­˜å‚¨è®¿é—®å¯¹åº”çš„æ–‡ä»¶ï¼Œè¿™æ ·å°±å¯ä»¥è®¿é—®åˆ°èµ„æºäº† ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:1:3","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"1.4 ä½¿ç”¨NFSå…±äº«å­˜å‚¨èƒ½è§£å†³é›†ç¾¤æ¶æ„çš„ä»€ä¹ˆé—®é¢˜? è§£å†³å¤šå°webé™æ€èµ„æºçš„å…±äº«(æ‰€æœ‰å®¢æˆ·ç«¯éƒ½æŒ‚è½½æœåŠ¡ç«¯ï¼Œçœ‹åˆ°çš„æ•°æ®éƒ½- -æ ·) è§£å†³å¤šå°webé™æ€èµ„æº-è‡´æ€§(å¦‚æœå®¢æˆ·ç«¯Aåˆ é™¤NFSæœåŠ¡ä¸Šçš„testæ–‡ä»¶ï¼Œå®¢æˆ·ç«¯B. ä¸Šä¹Ÿä¼šçœ‹ä¸è§testæ–‡ä»¶) è§£å†³å¤šå°webç£ç›˜ç©ºé—´çš„æµªè´¹ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:1:4","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"1.5 ä¼ä¸šä½¿ç”¨NFSæ³¨æ„äº‹é¡¹ ç”±äºç”¨æˆ·è¯·æ±‚é™æ€èµ„æºæ¯æ¬¡éƒ½éœ€è¦webè¿æ¥NFSæœåŠ¡è·å–ï¼Œé‚£ä¹ˆåŠ¿å¿…ä¼šå¸¦æ¥-å®šçš„ç½‘ç»œå¼€é”€ã€ä»¥åŠç½‘ç»œå»¶æ—¶ã€æ‰€ä»¥å¢åŠ NFSæœåŠ¡å¹¶ä¸èƒ½ç»™ç½‘ç«™å¸¦æ¥è®¿é—®é€Ÿåº¦çš„æå‡ã€‚ å¦‚æœå¸Œæœ›å¯¹ä¸Šä¼ çš„å›¾ç‰‡ã€é™„ä»¶ç­‰é™èµ„æºè¿›è¡ŒåŠ é€Ÿï¼Œå»ºè®®å°†é™æ€èµ„æºç»Ÿ-å­˜æ”¾è‡³NFSæœåŠ¡ç«¯ã€‚è¿™æ ·ä¾¿äºåæœŸç»Ÿä¸€æ¨é€è‡³CDN, ä»¥æ­¤æ¥å®ç°èµ„æºçš„åŠ é€Ÿã€‚ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:1:5","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"2.NFSåŸç† ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:2:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"2.1 æœ¬åœ°æ–‡ä»¶æ“ä½œæ–¹å¼ å½“ç”¨æˆ·æ‰§è¡Œmkdirå‘½ä»¤, BashShellæ— æ³•å®Œæˆè¯¥å‘½ä»¤æ“ä½œï¼Œä¼šå°†å…¶ç¿»è¯‘ç»™å†…æ ¸ã€‚ Kernelå†…æ ¸è§£æå®Œæˆåä¼šé©±åŠ¨å¯¹åº”çš„ç£ç›˜è®¾å¤‡ï¼Œå®Œæˆåˆ›å»ºç›®å½•çš„æ“ä½œã€‚ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:2:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"NFSå®ç°åŸç† éœ€è¦å…ˆäº†è§£ ç¨‹åº|è¿›ç¨‹|çº¿ç¨‹ NFSå®¢æˆ·ç«¯æ‰§è¡Œå¢ã€åˆ ç­‰æ“ä½œï¼Œå®¢æˆ·ç«¯ä¼šä½¿ç”¨ä¸åŒçš„å‡½æ•°å¯¹è¯¥æ“ä½œè¿›è¡Œå°è£…ã€‚ NFSå®¢æˆ·ç«¯ä¼šé€šè¿‡TCP/IPçš„æ–¹å¼ä¼ é€’ç»™NFSæœåŠ¡ç«¯ã€‚ NFSæœåŠ¡ç«¯æ¥æ”¶åˆ°è¯·æ±‚åï¼Œä¼šå…ˆ è°ƒç”¨portmapè¿›ç¨‹è¿›è¡Œç«¯Cæ˜ å°„ã€‚ nfsdè¿›ç¨‹ç”¨äºåˆ¤æ–­NFSå®¢æˆ·ç«¯æ˜¯å¦æ‹¥æœ‰æƒé™è¿æ¥NFSæœåŠ¡ç«¯ã€‚ Rpc.mountè¿›ç¨‹åˆ¤æ–­å®¢æˆ·ç«¯æ˜¯å¦æœ‰å¯¹åº”çš„æƒé™è¿›è¡ŒéªŒè¯ã€‚ idmapè¿›ç¨‹å®ç°ç”¨æˆ·æ˜ å°„å’Œå‹ç¼©ã€‚ æœ€åNFSæœåŠ¡ç«¯ä¼šå°†å®¢æˆ·ç«¯çš„å‡½æ•°è½¬æ¢ä¸ºæœ¬åœ°èƒ½æ‰§è¡Œçš„å‘½ä»¤ï¼Œç„¶åå°†å‘½ä»¤ä¼ é€’è‡³å†…æ ¸ï¼Œç”±å†…æ ¸ é©±åŠ¨ç¡¬ä»¶ æ³¨æ„:rpcæ˜¯ ä¸€ä¸ªè¿œç¨‹è¿‡ç¨‹è°ƒç”¨ï¼Œé‚£ä¹ˆä½¿ç”¨nfså¿…é¡»æœ‰rpcæœåŠ¡ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:2:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"3.NFSæœåŠ¡å®‰è£… æœåŠ¡å™¨ç³»ç»Ÿ è§’è‰² å¤–ç½‘IP å†…ç½‘IP CentOS 7.6 NFSæœåŠ¡ç«¯ eth0:10.0.0.31 eth1:172.16.1.31 CentOS 7.6 NFSå®¢æˆ·ç«¯ eth0:10.0.0.41 eth1:172.16.1.41 ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:3:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"3.1 ç¯å¢ƒé…ç½® #å…³é—­Firewalldé˜²ç«å¢™ [root@nfs ~]# systemctL disable firewalld [root@nfs ~]# systemctl stop firewalld #å…³é—­selinux [root@nfs ~]# sed -ri ' #^SEL INUX=#cSEL INUX=Disabled' /etc/selinux/config [root@nfs ~]# setenforce 0 #å®‰è£…nfs-serveræœåŠ¡ yum -y install nfs-utils ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:3:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"3.2é…ç½®nfsæœåŠ¡ nfsæœåŠ¡ç¨‹åºçš„é…ç½®æ–‡ä»¶ä¸º/etc/exportsï¼Œéœ€è¦ä¸¥æ ¼æŒ‰ç…§å…±äº«ç›®å½•çš„è·¯å¾„å…è®¸è®¿é—®çš„NFSå®¢æˆ·ç«¯(å…±äº«æƒé™å‚æ•°)æ ¼å¼ä¹¦å†™ï¼Œ å®šä¹‰è¦å…±äº«çš„ç›®å½•ä¸ç›¸åº”çš„æƒé™ï¼Œå…·ä½“ä¹¦å†™æ–¹å¼å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:3:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"3.3.ä½¿ç”¨åœºæ™¯ å°†nfsæœåŠ¡ç«¯çš„ /data ç›®å½•å…±äº«ç»™ 172.16.1.0/24 ç½‘æ®µå†…çš„æ‰€æœ‰ä¸»æœº æ‰€æœ‰å®¢æˆ·ç«¯ä¸»æœºéƒ½æ‹¥æœ‰è¯»å†™æƒé™ åœ¨å°†æ•°æ®å†™å…¥åˆ°NFSæœåŠ¡å™¨çš„ç¡¬ç›˜ä¸­åæ‰ä¼šç»“æŸæ“ä½œï¼Œæœ€å¤§é™åº¦ä¿è¯æ•°æ®ä¸ä¸¢å¤± å°†æ‰€æœ‰ç”¨æˆ·æ˜ å°„ä¸ºæœ¬åœ°çš„åŒ¿åç”¨æˆ·(nfsnobody) #NFSå®¢æˆ·ç«¯åœ°å€ä¸æƒé™ä¹‹é—´æ²¡æœ‰ç©ºæ ¼ [root@nfs ~]# vim /etc/exports /data 172.16.1.0/24(rw, sync , all_ squash) #åœ¨NFSæœåŠ¡å™¨ä¸Šå»ºç«‹ç”¨äºNFSæ–‡ä»¶å…±äº«çš„ç›®å½•ï¼Œå¹¶è®¾ç½®å¯¹åº”æƒé™ [root@nfs ~]# mkdir /data [root@nfs ~]# chown -R nfsnobody. nfsnobody /data #NFSå…±äº«ç›®å½•ä¼šè®°å½•è‡³/var/lib/nfs/etab,å¦‚æœè¯¥ç›®å½•ä¸å­˜åœ¨å…±äº«ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥/etc/exportsæ˜¯å¦é…ç½®é”™è¯¯ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:3:3","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"3.4 å®‰è£…RPC åœ¨ä½¿ç”¨NFSæœåŠ¡è¿›è¡Œæ–‡ä»¶å…±äº«ä¹‹å‰ï¼Œéœ€è¦ä½¿ç”¨RPC (Remote Procedure Call è¿œç¨‹è¿‡ç¨‹è°ƒç”¨æœåŠ¡ å°†NFSæœåŠ¡å™¨çš„IPåœ°å€å’Œç«¯å£å·ä¿¡æ¯å‘é€ç»™å®¢æˆ·ç«¯ã€‚å› æ­¤ï¼Œåœ¨å¯åŠ¨NFSæœåŠ¡ä¹‹å‰ï¼Œéœ€è¦å…ˆé‡å¯å¹¶. å¯ç”¨rpcbindæœåŠ¡ç¨‹åº,åŒæ—¶éƒ½åŠ å…¥å¼€æœºè‡ªå¯åŠ¨ #åŠ å…¥å¼€æœºè‡ªå¯ [root@nfs ~]# systemctL enable rpcbind nfs -server #å¯åŠ¨æœåŠ¡ [root@nfs ~]# systemctl restart rpcbind nfs-server ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:3:4","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"4.NFSå®¢æˆ·ç«¯æŒ‚è½½å¸è½½ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:4:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"4.1 æŸ¥çœ‹è¿œç¨‹å…±äº«ç›®å½• NFSå®¢æˆ·ç«¯çš„é…ç½®æ­¥éª¤ä¹Ÿ+åˆ†ç®€å•ã€‚å…ˆä½¿ç”¨showmountå‘½ä»¤ï¼ŒæŸ¥è¯¢NFSæœåŠ¡å™¨çš„è¿œç¨‹å…±äº«ä¿¡æ¯ï¼Œå…¶è¾“å‡ºæ ¼å¼ä¸ºâ€œå…±äº«çš„ç›®å½•åç§°å…è®¸ä½¿ç”¨å®¢æˆ·ç«¯åœ°å€â€ã€‚ #å®‰è£…å®¢æˆ·ç«¯å·¥å…·ï¼Œå®‰è£…nfs-utilså³å¯ï¼Œ ä¼šè‡ªåŠ¨å¯åŠ¨rpcbindæœåŠ¡ã€‚ [root@nfs-client ~]# yum -y install nfs-utils #å®¢æˆ·ç«¯ä½¿ç”¨showmount -eæŸ¥çœ‹è¿œç¨‹æœåŠ¡å™¨rpcæä¾›çš„å¯æŒ‚è½½nfsä¿¡æ¯. [root@nfs-client ~]# showmount -e 172.16.1.31 Export list for 172.16.1.31: /data 172.16.1.0/24 ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:4:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"4.2 æŒ‚è½½è¿œç¨‹å…±äº«ç›®å½• åœ¨NFSå®¢æˆ·ç«¯åˆ›å»ºä¸€ä¸ªæŒ‚è½½ç›®å½•,ä½¿ç”¨mountå‘½ä»¤å¹¶ç»“åˆ-tå‚æ•°,æŒ‡å®šè¦æŒ‚è½½çš„æ–‡ä»¶ç³»ç»Ÿçš„ç±»å‹,å¹¶åœ¨å‘½ä»¤åé¢å†™ä¸ŠæœåŠ¡å™¨çš„IPåœ°å€,ä»¥åŠæœåŠ¡å™¨ä¸Šçš„å…±äº«ç›®å½•,æœ€åéœ€è¦å†™ä¸Šè¦æŒ‚è½½åˆ°æœ¬åœ°ç³»ç»Ÿ(å®¢æˆ·ç«¯)çš„ç›®å½•ã€‚ [root@nfs-client ~]# mkdir /nfsdir [root@nfs-client ~]# mount -t nfs 172. 16.1.31:/data /nfsdir #æŸ¥çœ‹æŒ‚è½½ä¿¡æ¯(mountä¹Ÿå¯ä»¥æŸ¥çœ‹) [root@nfs-client ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/sda3 62G 845M 58G 2% /tmpfs 244M 0 244M 0% /dev/shm /dev/sda1 190M 26M 155M 14% /boot 172. 16.1.31:/data 62G 880M 58G 2% /nfsdir ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:4:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"4.3 å®¢æˆ·ç«¯è¿œç¨‹å…±äº«ç›®å½•æ“ä½œ æŒ‚è½½æˆåŠŸåå¯ä»¥è¿›è¡Œå¢åˆ æ”¹æ“ä½œ #ä½¿ç”¨å®¢æˆ·ç«¯å¾€nfså­˜å‚¨å†™å…¥ [root@nfs-client ~]# echo \"nfs-client\" \u003e\u003e /mnt/test. txt #æ£€æŸ¥nfsæœåŠ¡ç«¯æ˜¯å¦å­˜åœ¨å®¢æˆ·ç«¯åˆ›å»ºçš„æ–°æ–‡ä»¶ [root@nfs-client ~]# cat /data/test. txt nfs-client #å¦‚æœå¸Œæœ›NFSæ–‡ä»¶å…±äº«æœåŠ¡èƒ½ä¸€ç›´æœ‰æ•ˆï¼Œåˆ™éœ€è¦å°†å…¶å†™å…¥åˆ°fstabæ–‡ä»¶ä¸­ [root@nfs-client ~]# vim /etc/fstab 172.16.1.31: /data /nfsdir nfs defaults 0 0 ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:4:3","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"4.4 å®¢æˆ·ç«¯å¸è½½ å¦‚æœä¸å¸Œæœ›ä½¿ç”¨NFSå…±äº«,å¯è¿›è¡Œå¸è½½ umount /nfsdir #æ³¨æ„:å¸è½½çš„æ—¶å€™å¦‚æœæç¤ºâ€umount. nfs: /nfsdir: device is busyâ€ #åˆ‡æ¢è‡³å…¶ä»–ç›®å½•ï¼Œç„¶ååœ¨è¿›è¡Œå¸è½½ã€‚ #NFS Serverå®•æœºï¼Œå¼ºåˆ¶å¸è½½ umount -lf /nfsdir ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:4:4","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"4.5 å®¢æˆ·ç«¯å®‰å…¨å‚æ•° åœ¨ä¼ä¸šå·¥ä½œåœºæ™¯ï¼Œé€šå¸¸æƒ…å†µNFSæœåŠ¡å™¨å…±äº«çš„åªæ˜¯æ™®é€šé™æ€æ•°æ®(å›¾ç‰‡ã€é™„ä»¶ã€è§†é¢‘)ï¼Œä¸éœ€ è¦æ‰§è¡Œsuidã€exec ç­‰æƒé™ï¼ŒæŒ‚è½½çš„è¿™ä¸ªæ–‡ä»¶ç³»ç»Ÿåªèƒ½ä½œä¸ºæ•°æ®å­˜å–ä¹‹ç”¨ï¼Œæ— æ³•æ‰§è¡Œç¨‹åºï¼Œå¯¹äº å®¢æˆ·ç«¯æ¥è®²å¢åŠ äº†å®‰å…¨æ€§ã€‚ ä¾‹å¦‚:å¾ˆå¤šæœ¨é©¬ç¯¡æ”¹ç«™ç‚¹æ–‡ä»¶éƒ½æ˜¯ç”±ä¸Šä¼ å…¥å£ä¸Šä¼ çš„ç¨‹åºåˆ°å­˜å‚¨ç›®å½•ã€‚ç„¶åæ‰§è¡Œçš„ã€‚ #é€šè¿‡mount -oæŒ‡å®šæŒ‚è½½å‚æ•°ï¼Œç¦æ­¢ä½¿ç”¨suid, exec, å¢åŠ å®‰å…¨æ€§èƒ½ [root@nfs-client ~]# mount -t nfs -ã€‚ nosuid, noexec, nodev 172. 16. 1.31:/data /mntæœ‰æ—¶ä¹Ÿéœ€è¦è€ƒè™‘æ€§èƒ½ç›¸å…³å‚æ•°[å¯é€‰] #é€šè¿‡mount -oæŒ‡å®šæŒ‚è½½å‚æ•°ï¼Œç¦æ­¢æ›´æ–°ç›®å½•åŠæ–‡ä»¶æ—¶é—´æˆ³æŒ‚è½½ [root@nfs-client ~]# mount -t nfs -0 noatime, nodiratime 172. 16.1.31:/data /mnt ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:4:5","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"5.NFSé…ç½®è¯¦è§£ nfså…±äº«å‚æ•° å‚æ•°ä½œç”¨ rw* è¯»å†™æƒé™ ro åªè¯»æƒé™ root_ squash å½“NFSå®¢æˆ·ç«¯ä»¥rootç®¡ç†å‘˜è®¿é—®æ—¶ï¼Œæ˜ å°„ä¸ºNFSæœåŠ¡å™¨çš„åŒ¿åç”¨æˆ·(ä¸å¸¸ç”¨) no_ root_ squash å½“NFSå®¢æˆ·ç«¯ä»¥rootç®¡ç†å‘˜è®¿é—®æ—¶ï¼Œæ˜ å°„ä¸ºNFSæœåŠ¡å™¨çš„rootç®¡ç†å‘˜(ä¸å¸¸ç”¨) all squash æ— è®ºNFSå®¢æˆ·ç«¯ä½¿ç”¨ä»€ä¹ˆè´¦æˆ·è®¿é—®ï¼Œå‡æ˜ å°„ä¸ºNFSæœåŠ¡å™¨çš„åŒ¿åç”¨æˆ·(å¸¸ç”¨) no_ all squash æ— è®ºNFSå®¢æˆ·ç«¯ä½¿ç”¨ä»€ä¹ˆè´¦æˆ·è®¿é—®ï¼Œéƒ½ä¸è¿›è¡Œå‹ç¼© sync* åŒæ—¶å°†æ•°æ®å†™å…¥åˆ°å†…å­˜ä¸ç¡¬ç›˜ä¸­ï¼Œä¿è¯ä¸ä¸¢å¤±æ•°æ® async ä¼˜å…ˆå°†æ•°æ®ä¿å­˜åˆ°å†…å­˜ï¼Œç„¶åå†å†™å…¥ç¡¬ç›˜; è¿™æ ·æ•ˆç‡æ›´é«˜ï¼Œä½†å¯èƒ½ä¼šä¸¢å¤±æ•°æ® anonuid* é…ç½®all_ squashä½¿ç”¨,æŒ‡å®šNFSçš„ç”¨æˆ·UID,å¿…é¡»å­˜åœ¨ç³»ç»Ÿ anongid* é…ç½®all_ squashä½¿ç”¨ï¼ŒæŒ‡å®šNFSçš„ç”¨æˆ·UID,å¿…é¡»å­˜åœ¨ç³»ç»Ÿ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:5:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"6.NFSæƒé™å®è·µ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:6:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"6.1 éªŒè¯roæƒé™å®è·µ #æœåŠ¡ç«¯ä¿®æ”¹rwä¸ºroå‚æ•° [root@nfs ~]# cat /etc/exports /data 172.16.1. 0/24(ro, sync ,all_ squash) [root@nfs ~]# systemctl restart nfs -server #å®¢æˆ·ç«¯éªŒè¯ [root@nfs-client ~]# mount -t nfs 172. 16.1.31:/data /mnt [root@nfs-client ~]# df -h Filesystem Size Used Avail Use% Mounted on 172.16.1.31: /data 98G 1.7G 97G 2% /mnt #å‘ç°æ— æ³•æ­£å¸¸å†™å…¥æ–‡ä»¶ [root@backup mnt]# touch file touch: cannot touch 'file' : Read-only file system","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:6:1","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"6.2 éªŒè¯all squashã€anonuidã€ anongidæƒé™ #NFSæœåŠ¡ç«¯é…ç½® [root@nfs ~]# cat /etc/exports /data 172.16.1.0/24(rw,sync,all_squash,anonuid=666,anongid=666) #æœåŠ¡ç«¯éœ€è¦åˆ›å»ºå¯¹åº”çš„ç”¨æˆ· [root@nfs ~]# groupadd -g 666 ww [root@nfs ~]# useradd -u 666 -g 666 www [root@nfs ~]# id www uid=666(www) gid=666(www) groups=666(www) #é‡è½½nfs-server [root@nfs ~]# systemctl restart nfs -server [root@nfs ~]# cat /var/lib/nfs/etab /data 172.16.1.0/ 24(rw, sync,wdelay,hide,nocrossmnt,secure,root_squash,all_squash, no_subtree_check,secure_locks,acl,no_ pnfs,anonuid=666,anongid=666,sec=sys,secure,ro ot_squash,all_squash) #æˆæƒå…±äº«ç›®å½•ä¸ºwww [root@nfs ~]# chown -R www. www /data/ [root@nfs ~]# ll -d /data/ drwxr-xr-x 3 wwW WWW 53 Sep 3 02:08 /data/ #å®¢æˆ·ç«¯éªŒè¯ [root@backup ~]# umount /mnt/ [root@backup ~]# mount -t nfs 172. 16.1.31:/data /mnt #å®¢æˆ·ç«¯æŸ¥çœ‹åˆ°çš„æ–‡ä»¶ï¼Œèº«ä»½æ˜¯666 [root@backup ~]# Ll /mnt/ drwxr-xr-x 2 666 666 6 Sep3 02:08 rsync_ dir-rw-r--r-- 1 666 666 0 Sep 3 02:08 rsync_ file #å®¢æˆ·ç«¯ä¾æ—§èƒ½å¾€/mntç›®å½•ä¸‹å†™æ–‡ä»¶ [root@backup mnt]# touch fff [root@backup mnt]# mkdir 111 [root@backup mnt]# ll drwxr-xr-x 2 666 666 6 Sep3 03:05 111 -rw-r--r-- 1 666 666 0 Sep3 03:05 fff #å»ºè®®:å°†å®¢æˆ·ç«¯ä¹Ÿåˆ›å»ºä¸€ä¸ªuidä¸º666, gidä¸º666ï¼Œ ç»Ÿä¸€èº«ä»½,é¿å…åç»­å‡ºç°æƒé™ä¸è¶³çš„æƒ…å†µ [root@backup mnt]# groupadd -g 666 Www [root@backup mnt]# useradd -g 666 -u 666 Www [root@backup mnt]# id www uid=666(www) gid=666(www) groups=666( www) #æœ€åæ£€æŸ¥æ–‡ä»¶çš„èº«ä»½ [root@backup mnt]# ll /mnt/ total 4 drwxr-xr-x 2 wwW WWW 6 Sep 3 03:05 111 -rw-r--r-- 1 WwW wwW 0 Sep 3 03:05 fff ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:6:2","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"},{"categories":["Linux"],"content":"7.NFSå­˜å‚¨æ€»ç»“ NFSå­˜å‚¨ä¼˜ç‚¹ NFSç®€å•æ˜“ç”¨ã€æ–¹ä¾¿éƒ¨ç½²æ•°æ®å¯é ã€æœåŠ¡ç¨³å®šã€æ»¡è¶³ä¸­å°ä¼ä¸šéœ€æ±‚ã€‚ NFSçš„æ•°æ®éƒ½åœ¨æ–‡ä»¶ç³»ç»Ÿä¹‹ä¸Šï¼Œæ‰€æœ‰æ•°æ®éƒ½æ˜¯èƒ½çœ‹å¾—è§ã€‚ NFSå­˜å‚¨å±€é™ å­˜åœ¨å•ç‚¹æ•…éšœ,å¦‚æœæ„å»ºé«˜å¯ç”¨ç»´æŠ¤éº»çƒ¦web- \u003enfs( )- \u003ebackup NFSæ•°æ®éƒ½æ˜¯æ˜æ–‡ï¼Œå¹¶ä¸å¯¹æ•°æ® åšä»»ä½•æ ¡éªŒï¼Œä¹Ÿæ²¡æœ‰å¯†ç éªŒè¯(å¼ºçƒˆå»ºè®®å†…ç½‘ä½¿ç”¨)ã€‚ NFSåº”ç”¨å»ºè®® ç”Ÿäº§åœºæ™¯åº”å°†é™æ€æ•°æ®(ipg\\png\\mp4\\av\\cssjs)å°½å¯èƒ½æ”¾ç½®CDNåœºæ™¯è¿›è¡Œç¯å¢ƒä»¥æ­¤æ¥å‡å°‘åç«¯å­˜å‚¨å‹åŠ› å¦‚æœæ²¡æœ‰ç¼“å­˜æˆ–æ¶æ„ã€ä»£ç ç­‰,æœ¬èº«å†å²é—ç•™é—®é¢˜å¤ªå¤§ï¼Œåœ¨å¤šå­˜å‚¨ä¹Ÿæ²¡æ„ä¹‰ ","date":"2019-09-13","objectID":"/posts/linux-basic/nfs/:7:0","tags":["Linux å­¦ä¹ ä¹‹æ—…","NFS"],"title":"NFS-ç½‘ç»œå…±äº«å­˜å‚¨æœåŠ¡","uri":"/posts/linux-basic/nfs/"}]